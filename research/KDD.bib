@inproceedings{10.1145/3580305.3599281,
author = {Ji, Shuo and Lu, Xiaodong and Liu, Mingzhe and Sun, Leilei and Liu, Chuanren and Du, Bowen and Xiong, Hui},
title = {Community-based Dynamic Graph Learning for Popularity Prediction},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599281},
doi = {10.1145/3580305.3599281},
abstract = {Popularity prediction, which aims to forecast how many users would like to interact with a target item or online content in the future, can help online shopping or social media platforms to identify popular items or digital contents. Many efforts have been made to study how the multi-faceted factors, such as item features, user preferences, and social influence, affect user-item interactions, but little work has focused on the evolutionary dynamics of these factors for individuals or groups. In that light, this paper develops a community-based dynamic graph learning method for popularity prediction. First, a dynamic graph learning framework is proposed to maintain a dynamic representation for each item or user entity and update the representations according to the newly observed user-item interactions. Second, a community detection module is designed to capture the evolving community structures and identify the most influential nodes. More importantly, our framework leverages a community-level message passing during the learning process to balance local and global information propagation. Finally, we predict the popularity of the target item or online content based on the learned representations. Our experimental results based on three real-world datasets demonstrate that the proposed method achieves better performance than the baselines. Our method could not only model the changes in a user's preferences, but also capture how the communities evolve over time.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {930–940},
numpages = {11},
keywords = {community detection, dynamic graph learning, popularity prediction},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3637528.3672041,
author = {Cheng, Zhangtao and Zhang, Jienan and Xu, Xovee and Trajcevski, Goce and Zhong, Ting and Zhou, Fan},
title = {Retrieval-Augmented Hypergraph for Multimodal Social Media Popularity Prediction},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672041},
doi = {10.1145/3637528.3672041},
abstract = {Accurately predicting the popularity of multimodal user-generated content (UGC) is fundamental for many real-world applications such as online advertising and recommendation. Existing approaches generally focus on limited contextual information within individual UGCs, yet overlook the potential benefit of exploiting meaningful knowledge in relevant UGCs. In this work, we propose RAGTrans, an aspect-aware retrieval-augmented multi-modal hypergraph transformer that retrieves pertinent knowledge from a multi-modal memory bank and enhances UGC representations via neighborhood knowledge aggregation on multi-model hypergraphs. In particular, we initially retrieve relevant multimedia instances from a large corpus of UGCs via the aspect information and construct a knowledge-enhanced hypergraph based on retrieved relevant instances. This allows capturing meaningful contextual information across the data. We then design a novel bootstrapping hypergraph transformer on multimodal hypergraphs to strengthen UGC representations across modalities via customizing a propagation algorithm to effectively diffuse information across nodes and edges. Additionally, we propose a user-aware attention-based fusion module to comprise the enriched UGC representations for popularity prediction. Extensive experiments on real-world social media datasets demonstrate that RAGTrans outperforms state-of-the-art popularity prediction models across settings.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {445–455},
numpages = {11},
keywords = {hypergraph, multimedia popularity, retrieval augmentation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3690624.3709308,
author = {Cheng, Zhangtao and Lang, Jian and Zhong, Ting and Zhou, Fan},
title = {Seeing the Unseen in Micro-Video Popularity Prediction: Self-Correlation Retrieval for Missing Modality Generation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709308},
doi = {10.1145/3690624.3709308},
abstract = {Micro-video popularity prediction (MVPP) plays a crucial role in numerous real-world applications, including product marketing and recommendation systems. While existing methodologies predominantly assume complete modalities during multimodal learning, this assumption often fails to hold in practical scenarios due to various constraints, such as privacy concerns or data integrity issues. To address this limitation, we propose SCRAG, a novel Self-Correlation Retrieval-Augmented Generative framework designed to enhance missing-modality robustness in MVPP. SCRAG operates in a retrieval-guided generation manner that explores relevant knowledge to enhance the reconstruction of missing content, which consists of two primary components: (1) a self-correlation retriever and (2) a multimodal mixture-of-experts generator. It first acquires instances pertinent to the missing content through multimodal prompt alignment. Subsequently, the generator extracts contextual modal information from the retrieved context-rich instances. By learning the joint distribution of modalities, SCRAG effectively recovers missing content and addresses the modal heterogeneity challenge inherent in cross-modal generation approaches. Extensive experiments conducted on three real-world datasets demonstrate that SCRAG consistently outperforms state-of-the-art baselines, underscoring its effectiveness in handling incomplete modalities and improving the accuracy of micro-video popularity prediction.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {142–152},
numpages = {11},
keywords = {incomplete multimodal learning, multimedia popularity, multimodal generation, retrieval augmentation},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3625007.3627517,
author = {Steuber, Florian and Schneider, Sinclair and Schneider, Jo\~{a}o A. G. and Rodosek, Gabi Dreo},
title = {Real-Time Anomaly Detection and Popularity Prediction for Emerging Events on Twitter},
year = {2024},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625007.3627517},
doi = {10.1145/3625007.3627517},
abstract = {Due to their high volume and data recency, communications from social media platforms have become an excellent source for monitoring information diffusion. The insights leveraged are invaluable for social media analysts in the areas of event analysis and emergency management. Existing work ranges from the initial detection of incidents over information enrichment to determining an incident's relevance and life span. Until now, individual parts of this process have been considered separately, but never in combination.In this work, we address this crucial need and present an approach for detecting the onset and context of emerging events and predicting their popularity two weeks after emergence on Twitter in real time. Our contribution is threefold. We first present an online learning anomaly detection method refined with temporal clustering to identify abnormal conversational volumes of keywords. Second, we reconstruct potentially underlying events causing the anomaly through the enrichment of contextual and temporal information. Third, we assess an event's relevance and life span by predicting the resonance corresponding tweets receive shortly after their publication.},
booktitle = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {300–304},
numpages = {5},
keywords = {anomaly detection, event reconstruction, cascade prediction, social media},
location = {Kusadasi, Turkiye},
series = {ASONAM '23}
}

@inproceedings{10.1145/3447548.3467212,
author = {Snow, Oliver and Sharifi-Noghabi, Hossein and Lu, Jialin and Zolotareva, Olga and Lee, Mark and Ester, Martin},
title = {Interpretable Drug Response Prediction using a Knowledge-based Neural Network},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467212},
doi = {10.1145/3447548.3467212},
abstract = {Predicting drug response based on the genomic profile of a cancer patient is one of the hallmarks of precision oncology. Despite current methods for drug response prediction becoming more accurate, there is still a need to switch from 'black box' predictions to methods that offer high accuracy as well as interpretable predictions. This is of particular importance in real-world applications such as drug response prediction in cancer patients. In this paper, we propose BDKANN, a novel knowledge-based method that employs the hierarchical information on how proteins form complexes and act together in pathways to form the architecture of a deep neural network. We employ BDKANN to predict cancer drug response from cell line gene expression data and our experimental results demonstrate that not only does BDKANN have a low prediction error compared to baseline models but it also allows meaningful interpretation of the network. These interpretations can both explain predictions made and discover novel connections in the biological knowledge that may lead to new hypotheses about mechanisms of drug action.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3558–3568},
numpages = {11},
keywords = {biological networks, drug response prediction, interpretability, neural networks},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3447548.3467111,
author = {Huang, Zai and Tao, Mingyuan and Zhang, Bufeng},
title = {Deep Inclusion Relation-aware Network for User Response Prediction at Fliggy},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467111},
doi = {10.1145/3447548.3467111},
abstract = {User response prediction plays a crucial role in many applications (e.g. search ranking and personalized recommendation) at online travel platforms. Although existing methods have made a great success by focusing on feature interaction or user behaviors, they cannot synthetically exploit item inclusion relations describing relationships of an item including or being included by another one, which are important components among travel items. To this end, in this paper, we propose a novel Deep Inclusion Relation-aware Network (DIRN) for user response prediction by synthetically exploiting inclusion relations among travel items. Specifically, on the item graph constructed with inclusion relations, we first leverage a node embedding approach to learn the item graph-based embedding. Then, we design Representation-based Interest Layer and Relation Path Interest Layer to extract user latent interest with user behaviors in two ways. Representation-based Interest Layer models the item-to-item similarity based on item representations containing the graph-based embedding with an attention mechanism and obtains user temporal interest by summing up representations of interacted items with similarities. Relation Path Interest Layer measures item-to-item realistic associations to extract user interest with inclusion relation paths. Offline experiments on a real-world data from Fliggy clearly validate the effectiveness of DIRN. Furthermore, DIRN has been successfully deployed online in search ranking at Fliggy and achieves significant improvement.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3059–3067},
numpages = {9},
keywords = {click-through rate prediction, inclusion relation, online travel platform, user response prediction},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.5555/3382225.3382409,
author = {Reiffers-Masson, Alexandre and Hayel, Yezekael and Altman, Eitan and Marrel, Guillaume},
title = {A generalized fractional program for maximizing content popularity in online social networks},
year = {2020},
isbn = {9781538660515},
publisher = {IEEE Press},
abstract = {In this paper, we consider a "generalized" fractional program in order to solve a popularity optimization problem in which a source of contents controls the topics of her contents and the rate with which posts are sent to a time line. The objective of the source is to maximize its overall popularity in an Online Social Network (OSN). We propose an efficient algorithm that converges to the optimal solution of the Popularity maximization problem.},
booktitle = {Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {869–872},
numpages = {4},
location = {Barcelona, Spain},
series = {ASONAM '18}
}

@inproceedings{10.1145/3394486.3403276,
author = {Tang, Xianfeng and Liu, Yozen and Shah, Neil and Shi, Xiaolin and Mitra, Prasenjit and Wang, Suhang},
title = {Knowing your FATE: Friendship, Action and Temporal Explanations for User Engagement Prediction on Social Apps},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403276},
doi = {10.1145/3394486.3403276},
abstract = {With the rapid growth and prevalence of social network applications (Apps) in recent years, understanding user engagement has become increasingly important, to provide useful insights for future App design and development. While several promising neural modeling approaches were recently pioneered for accurate user engagement prediction, their black-box designs are unfortunately limited in model explainability. In this paper, we study a novel problem of explainable user engagement prediction for social network Apps. First, we propose a flexible definition of user engagement for various business scenarios, based on future metric expectations. Next, we design an end-to-end neural framework, FATE, which incorporates three key factors that we identify to influence user engagement, namely friendships, user actions, and temporal dynamics to achieve explainable engagement predictions. FATE is based on a tensor-based graph neural network (GNN), LSTM and a mixture attention mechanism, which allows for (a) predictive explanations based on learned weights across different feature categories, (b) reduced network complexity, and (c) improved performance in both prediction accuracy and training/inference time. We conduct extensive experiments on two large-scale datasets from Snapchat, where FATE outperforms state-of-the-art approaches by 10% error and 20% runtime reduction. We also evaluate explanations from FATE, showing strong quantitative and qualitative performance.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2269–2279},
numpages = {11},
keywords = {explainable neural networks, social sciences, user modeling},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/2351333.2351337,
author = {Dong, Zhenhua and Zhao, Qian},
title = {Experimental analysis on cross domain preferences association and rating prediction},
year = {2012},
isbn = {9781450315555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351333.2351337},
doi = {10.1145/2351333.2351337},
abstract = {Cross domain recommendation and preferences association are emerging research topics. In this paper, we will study the two topics through experimental analysis methods: firstly, we use folksonamy to analyze the preferences association among different domains; secondly, we analyze the feasibility of cross domain rating prediction based on KNN model. The experimental results report the associative tag pairs of users' preferences on items across domains. In addition, we report the cross domain prediction results here.},
booktitle = {Proceedings of the 1st International Workshop on Cross Domain Knowledge Discovery in Web and Social Network Mining},
pages = {26–31},
numpages = {6},
keywords = {KNN, collaborative filtering, cross domain preferences association, cross domain recommendation, tag},
location = {Beijing, China},
series = {CDKD '12}
}

@inproceedings{10.1145/2020408.2020436,
author = {Menon, Aditya Krishna and Chitrapura, Krishna-Prasad and Garg, Sachin and Agarwal, Deepak and Kota, Nagaraj},
title = {Response prediction using collaborative filtering with hierarchies and side-information},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020408.2020436},
doi = {10.1145/2020408.2020436},
abstract = {In online advertising, response prediction is the problem of estimating the probability that an advertisement is clicked when displayed on a content publisher's webpage. In this paper, we show how response prediction can be viewed as a problem of matrix completion, and propose to solve it using matrix factorization techniques from collaborative filtering (CF). We point out the two crucial differences between standard CF problems and response prediction, namely the requirement of predicting probabilities rather than scores, and the issue of confidence in matrix entries. We address these issues using a matrix factorization analogue of logistic regression, and by applying a principled confidence-weighting scheme to its objective. We show how this factorization can be seamlessly combined with explicit features or side-information for pages and ads, which let us combine the benefits of both approaches. Finally, we combat the extreme sparsity of response prediction data by incorporating hierarchical information about the pages and ads into our factorization model. Experiments on three very large real-world datasets show that our model outperforms current state-of-the-art methods for response prediction.},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {141–149},
numpages = {9},
keywords = {collaborative filtering, hierarchies, response prediction},
location = {San Diego, California, USA},
series = {KDD '11}
}

@inproceedings{10.1145/3637528.3671966,
author = {Wu, Zhen and Zhou, Jingya and Zhang, Jinghui and Liu, Ling and Huang, Chizhou},
title = {A Deep Prediction Framework for Multi-Source Information via Heterogeneous GNN},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671966},
doi = {10.1145/3637528.3671966},
abstract = {Predicting information diffusion is a fundamental task in online social networks (OSNs). Recent studies mainly focus on the popularity prediction of specific content but ignore the correlation between multiple pieces of information. The topic is often used to correlate such information and can correspond to multi-source information. The popularity of a topic relies not only on information diffusion time but also on users' followership. Current solutions concentrate on hard time partition, lacking versatility. Meanwhile, the hop-based sampling adopted in state-of-the-art (SOTA) methods encounters redundant user followership. Moreover, many SOTA methods are not designed with good modularity and lack evaluation for each functional module and enlightening discussion. This paper presents a novel extensible framework, coined as HIF, for effective popularity prediction in OSNs with four original contributions. First, HIF adopts a soft partition of users and time intervals to better learn users' behavioral preferences over time. Second, HIF utilizes weighted sampling to optimize the construction of heterogeneous graphs and reduce redundancy. Furthermore, HIF supports multi-task collaborative optimization to improve its learning capability. Finally, as an extensible framework, HIF provides generic module slots to combine different submodules (e.g., RNNs, Transformer encoders). Experiments show that HIF significantly improves performance and interpretability compared to SOTAs.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3460–3471},
numpages = {12},
keywords = {deep learning, heterogeneous graph, multi-source information, popularity prediction, social networks},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/2939672.2939684,
author = {Zhang, XianXing and Zhou, Yitong and Ma, Yiming and Chen, Bee-Chung and Zhang, Liang and Agarwal, Deepak},
title = {GLMix: Generalized Linear Mixed Models For Large-Scale Response Prediction},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939684},
doi = {10.1145/2939672.2939684},
abstract = {Generalized linear model (GLM) is a widely used class of models for statistical inference and response prediction problems. For instance, in order to recommend relevant content to a user or optimize for revenue, many web companies use logistic regression models to predict the probability of the user's clicking on an item (e.g., ad, news article, job). In scenarios where the data is abundant, having a more fine-grained model at the user or item level would potentially lead to more accurate prediction, as the user's personal preferences on items and the item's specific attraction for users can be better captured. One common approach is to introduce ID-level regression coefficients in addition to the global regression coefficients in a GLM setting, and such models are called generalized linear mixed models (GLMix) in the statistical literature. However, for big data sets with a large number of ID-level coefficients, fitting a GLMix model can be computationally challenging. In this paper, we report how we successfully overcame the scalability bottleneck by applying parallelized block coordinate descent under the Bulk Synchronous Parallel (BSP) paradigm. We deployed the model in the LinkedIn job recommender system, and generated 20% to 40% more job applications for job seekers on LinkedIn.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {363–372},
numpages = {10},
keywords = {big data, spark, statistical model},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/3292500.3330906,
author = {Liu, Donghua and Li, Jing and Du, Bo and Chang, Jun and Gao, Rong},
title = {DAML: Dual Attention Mutual Learning between Ratings and Reviews for Item Recommendation},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330906},
doi = {10.1145/3292500.3330906},
abstract = {Despite the great success of many matrix factorization based collaborative filtering approaches, there is still much space for improvement in recommender system field. One main obstacle is the cold-start and data sparseness problem, requiring better solutions. Recent studies have attempted to integrate review information into rating prediction. However, there are two main problems: (1) most of existing works utilize a static and independent method to extract the latent feature representation of user and item reviews ignoring the correlation between the latent features, which may fail to capture the preference of users comprehensively. (2) there is no effective framework that unifies ratings and reviews. Therefore, we propose a novel d ual a ttention m utual l earning between ratings and reviews for item recommendation, named DAML. Specifically, we utilize local and mutual attention of the convolutional neural network to jointly learn the features of reviews to enhance the interpretability of the proposed DAML model. Then the rating features and review features are integrated into a unified neural network model, and the higher-order nonlinear interaction of features are realized by the neural factorization machines to complete the final rating prediction. Experiments on the five real-world datasets show that DAML achieves significantly better rating prediction accuracy compared to the state-of-the-art methods. Furthermore, the attention mechanism can highlight the relevant information in reviews to increase the interpretability of rating prediction.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {344–352},
numpages = {9},
keywords = {attention mechanism, neural factorization machines, neural network, rating prediction, recommender systems},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/3637528.3671652,
author = {Jayagopal, Aishwarya and Xue, Hansheng and He, Ziyang and Walsh, Robert J. and Hariprasannan, Krishna Kumar and Tan, David Shao Peng and Tan, Tuan Zea and Pitt, Jason J. and Jeyasekharan, Anand D. and Rajan, Vaibhav},
title = {Personalised Drug Identifier for Cancer Treatment with Transformers using Auxiliary Information},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671652},
doi = {10.1145/3637528.3671652},
abstract = {Cancer remains a global challenge due to its growing clinical and economic burden. Its uniquely personal manifestation, which makes treatment difficult, has fuelled the quest for personalized treatment strategies. Thus, genomic profiling is increasingly becoming part of clinical diagnostic panels. Effective use of such panels requires accurate drug response prediction (DRP) models, which are challenging to build due to limited labelled patient data. Previous methods to address this problem have used various forms of transfer learning. However, they do not explicitly model the variable length sequential structure of the list of mutations in such diagnostic panels. Further, they do not utilize auxiliary information (like patient survival) for model training. We address these limitations through a novel transformer-based method, which surpasses the performance of state-of-the-art DRP models on benchmark data. Code for our method is available at https://github.com/CDAL-SOC/PREDICT-AI.We also present the design of a treatment recommendation system (TRS), which is currently deployed at the National University Hospital, Singapore and is being evaluated in a clinical trial. We discuss why the recommended drugs and their predicted scores alone, obtained from DRP models, are insufficient for treatment planning. Treatment planning for complex cancer cases, in the face of limited clinical validation, requires assessment of many other factors, including several indirect sources of evidence on drug efficacy. We discuss key lessons learnt on model validation and use of indirect supporting evidence to build clinicians' trust and aid their decision making.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5138–5149},
numpages = {12},
keywords = {auxiliary information, cancer drug response prediction, clinical deployment, personalized treatment recommendation, survival prediction, transformers},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3711896.3737398,
author = {Mungari, Simone and Coppolillo, Erica and Ritacco, Ettore and Manco, Giuseppe},
title = {Flexible Generation of Preference Data for Recommendation Analysis},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737398},
doi = {10.1145/3711896.3737398},
abstract = {Simulating a recommendation system in a controlled environment, to identify specific behaviors and user preferences, requires highly flexible synthetic data generation models capable of mimicking the patterns and trends of real datasets. In this context, we propose HYDRA, a novel preferences data generation model driven by three main factors: user-item interaction level, item popularity, and user engagement level. The key innovations of the proposed process include the ability to generate user communities characterized by similar item adoptions, reflecting real-world social influences and trends. Additionally, HYDRA considers item popularity and user engagement as mixtures of different probability distributions, allowing for a more realistic simulation of diverse scenarios. This approach enhances the model's capacity to simulate a wide range of real-world cases, capturing the complexity and variability found in actual user behavior. We demonstrate the effectiveness of HYDRA through extensive experiments on well-known benchmark datasets. The results highlight its capability to replicate real-world data patterns, offering valuable insights for developing and testing recommendation systems in a controlled and realistic manner. The code used to perform the experiments is publicly available: https://github.com/flexibledatageneration/HYDRA.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {5710–5721},
numpages = {12},
keywords = {benchmarking, data generation, probabilistic modeling, recommendation},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3637528.3671698,
author = {Wang, Chen and Fan, Ziwei and Yang, Liangwei and Yang, Mingdai and Liu, Xiaolong and Liu, Zhiwei and Yu, Philip},
title = {Pre-Training with Transferable Attention for Addressing Market Shifts in Cross-Market Sequential Recommendation},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671698},
doi = {10.1145/3637528.3671698},
abstract = {Cross-market recommendation (CMR) involves selling the same set of items across multiple nations or regions within a transfer learning framework. However, CMR's distinctive characteristics, including limited data sharing due to privacy policies, absence of user overlap, and a shared item set between markets present challenges for traditional recommendation methods. Moreover, CMR experiences market shifts, leading to differences in item popularity and user preferences among different markets. This study focuses on cross-market sequential recommendation (CMSR) and proposes the Cross-market Attention Transferring with Sequential Recommendation (CAT-SR) framework to address these challenges and market shifts. CAT-SR incorporates a pre-training strategy emphasizing item-item correlation, selective self-attention transferring for effective transfer learning, and query and key adapters for market-specific user preferences. Experimental results on real-world cross-market datasets demonstrate the superiority of CAT-SR, and ablation studies validate the benefits of its components across different geographical continents. CAT-SR offers a robust and adaptable solution for cross-market sequential recommendation. The code is available at https://github.com/ChenMetanoia/CATSR-KDD/.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2970–2979},
numpages = {10},
keywords = {cross-market recommendation, pre-training, self-attention, sequential recommendation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3690624.3709299,
author = {Yoo, Hyunsik and Qiu, Ruizhong and Xu, Charlie and Wang, Fei and Tong, Hanghang},
title = {Generalizable Recommender System During Temporal Popularity Distribution Shifts},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709299},
doi = {10.1145/3690624.3709299},
abstract = {Many modern recommender systems represent user and item attributes as embedding vectors, relying on them for accurate recommendations. However, entangled embeddings often capture not only intrinsic property factors (e.g., user interest in item property) but also popularity factors (e.g., user conformity to item popularity) indistinguishably. These embeddings, influenced by popularity distribution, may face challenges when the popularity distribution at test time differs from historical distribution. Existing remedies in the literature involve disentangled embedding learning, which aims to separately capture intrinsic and popularity factors, demonstrating plausible generalization during popularity distribution shifts. However, we highlight that these methods often overlook a crucial aspect of popularity shifts-their temporal nature-in both training and inference phases. To address this, we propose Temporal Popularity distribution shift generalizABle recommender system (TPAB), a novel disentanglement framework incorporating temporal popularity. TPAB introduce a new (1) temporal-aware embedding design for users and items. Within this design, (2) popularity coarsening and (3) popularity bootstrapping are proposed to enhance generalization further. We also provide theoretical analysis showing that the bootstrapping loss eliminates the effect of popularity on the learned model. During inference, we infer test-time popularity and corresponding embeddings, using them alongside property embeddings for prediction. Extensive experiments on real-world datasets validate TPAB, showcasing its outstanding generalization ability during temporal popularity distribution shifts.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {1833–1843},
numpages = {11},
keywords = {embedding disentanglement, recommender systems, temporal popularity distribution shifts},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3711896.3737146,
author = {Tan, Shiyin and Li, Dongyuan and Jiang, Renhe and Wang, Zhen and Yu, Xingtong and Okumura, Manabu},
title = {Taming Recommendation Bias with Causal Intervention on Evolving Personal Popularity},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737146},
doi = {10.1145/3711896.3737146},
abstract = {Popularity bias occurs when popular items are recommended far more frequently than they should be, negatively impacting both user experience and recommendation accuracy. Existing debiasing methods mitigate popularity bias often uniformly across all users and only partially consider the time evolution of users or items. However, users have different levels of preference for item popularity, and this preference is evolving over time. To address these issues, we propose a novel method called CausalEPP (Causal Intervention on Evolving Personal Popularity) for taming recommendation bias, which accounts for the evolving personal popularity of users. Specifically, we first introduce a metric called Evolving Personal Popularity to quantify each user's preference for popular items. Then, we design a causal graph that integrates evolving personal popularity into the conformity effect, and apply deconfounded training to mitigate the popularity bias of the causal graph. During inference, we consider the evolution consistency between users and items to achieve a better recommendation. Empirical studies demonstrate that CausalEPP outperforms baseline methods in reducing popularity bias while improving recommendation accuracy.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {2790–2800},
numpages = {11},
keywords = {causal inference, popularity bias, recommendation},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3690624.3709336,
author = {Luo, Yunze and Jiang, Yuezihan and Jiang, Yinjie and Chen, Gaode and Wang, Jingchi and Bian, Kaigui and Li, Peiyi and Zhang, Qi},
title = {Online Item Cold-Start Recommendation with Popularity-Aware Meta-Learning},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709336},
doi = {10.1145/3690624.3709336},
abstract = {With the rise of e-commerce and short videos, online recommender systems that can capture users' interests and update new items in real-time play an increasingly important role. In both online and offline recommendation systems, the cold-start problem caused by interaction sparsity has been impacting the effectiveness of recommendations for cold-start items. Many cold-start scheme based on fine-tuning or knowledge transferring shows excellent performance on offline recommendation. Yet, these schemes are infeasible for online recommendation on streaming data pipelines due to different training method, computational overhead and time constraints. Inspired by the above questions, we propose a model-agnostic recommendation algorithm called Popularity-Aware Meta-learning (PAM), to address the item cold-start problem under streaming data settings. PAM divides the incoming data into different meta-learning tasks by predefined item popularity thresholds. The model can distinguish and reweight behavior-related and content-related features in each task based on their different roles in different popularity levels, thus adapting to recommendations for cold-start samples. These task-fixing design significantly reduces additional computation and storage costs compared to offline methods. Furthermore, PAM also introduced data augmentation and an additional self-supervised loss specifically designed for low-popularity tasks, leveraging insights from high-popularity samples. This approach effectively mitigates the issue of inadequate supervision due to the scarcity of cold-start samples. Experimental results across multiple public datasets demonstrate the superiority of our approach over other baseline methods in addressing cold-start challenges in online streaming data scenarios.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {927–937},
numpages = {11},
keywords = {cold-start problem, meta-learning, online recommendation, recommender system},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3292500.3330750,
author = {Liu, Yozen and Shi, Xiaolin and Pierce, Lucas and Ren, Xiang},
title = {Characterizing and Forecasting User Engagement with In-App Action Graph: A Case Study of Snapchat},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330750},
doi = {10.1145/3292500.3330750},
abstract = {While mobile social apps have become increasingly important in people's daily life, we have limited understanding on what motivates users to engage with these apps. In this paper, we answer the question whether users' in-app activity patterns help inform their future app engagement (e.g., active days in a future time window)? Previous studies on predicting user app engagement mainly focus on various macroscopic features (e.g., time-series of activity frequency), while ignoring fine-grained inter-dependencies between different in-app actions at the microscopic level. Here we propose to formalize individual user's in-app action transition patterns as a temporally evolving action graph, and analyze its characteristics in terms of informing future user engagement. Our analysis suggested that action graphs are able to characterize user behavior patterns and inform future engagement. We derive a number of high-order graph features to capture in-app usage patterns and construct interpretable models for predicting trends of engagement changes and active rates. To further enhance predictive power, we design an end-to-end, multi-channel neural model to encode both temporal action graphs, activity sequences, and other macroscopic features. Experiments on predicting user engagement for 150k Snapchat new users over a 28-day period demonstrate the effectiveness of the proposed prediction models. The analysis and prediction framework is also deployed at Snapchat to deliver real world business insights. Our proposed framework is also general and can be applied to any online platform.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2023–2031},
numpages = {9},
keywords = {action graph, app usage pattern, graph neural network, time-series model, user engagement prediction},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/3534678.3539103,
author = {Shi, Jun and Jiang, Chengming and Gupta, Aman and Zhou, Mingzhou and Ouyang, Yunbo and Xiao, Qiang Charles and Song, Qingquan and Wu, Yi (Alice) and Wei, Haichao and Gao, Huiji},
title = {Generalized Deep Mixed Models},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539103},
doi = {10.1145/3534678.3539103},
abstract = {We introduce generalized deep mixed model (GDMix), a class of machine learning models for large-scale recommender systems that combines the power of deep neural networks and the efficiency of logistic regression. GDMix leverages state-of-the-art deep neural networks (DNNs) as the global models (fixed effects), and further improves the performance by adding entity-specific personalized models (random effects). For instance, the click response from a particular user m to a job posting j may consist of contributions from a DNN model common to all users and job postings, a model specific to the user m and a model specific to the job j. GDMix models not only possess powerful modeling capabilities but also enjoy high training efficiency especially for web-scale recommender systems. We demonstrate the capabilities by detailing their use in Feed and Ads recommendation at LinkedIn. The source code for the GDMix training framework is available at https://github.com/linkedin/gdmix https://github.com/linkedin/gdmix under the BSD-2-Clause License.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3869–3877},
numpages = {9},
keywords = {generalized deep mixed model, neural networks, recommender systems, response prediction},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3447548.3467289,
author = {Wei, Tianxin and Feng, Fuli and Chen, Jiawei and Wu, Ziwei and Yi, Jinfeng and He, Xiangnan},
title = {Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467289},
doi = {10.1145/3447548.3467289},
abstract = {The general aim of the recommender system is to provide personalized suggestions to users, which is opposed to suggesting popular items. However, the normal training paradigm, i.e., fitting a recommender model to recover the user behavior data with pointwise or pairwise loss, makes the model biased towards popular items. This results in the terrible Matthew effect, making popular items be more frequently recommended and become even more popular. Existing work addresses this issue with Inverse Propensity Weighting (IPW), which decreases the impact of popular items on the training and increases the impact of long-tail items. Although theoretically sound, IPW methods are highly sensitive to the weighting strategy, which is notoriously difficult to tune.In this work, we explore the popularity bias issue from a novel and fundamental perspective --- cause-effect. We identify that popularity bias lies in the direct effect from the item node to the ranking score, such that an item's intrinsic property is the cause of mistakenly assigning it a higher ranking score. To eliminate popularity bias, it is essential to answer the counterfactual question that what the ranking score would be if the model only uses item property. To this end, we formulate a causal graph to describe the important cause-effect relations in the recommendation process. During training, we perform multi-task learning to achieve the contribution of each cause; during testing, we perform counterfactual inference to remove the effect of item popularity. Remarkably, our solution amends the learning process of recommendation which is agnostic to a wide range of models --- it can be easily implemented in existing methods. We demonstrate it on Matrix Factorization (MF) and LightGCN [20], which are representative of the conventional and SOTA model for collaborative filtering. Experiments on five real-world datasets demonstrate the effectiveness of our method.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {1791–1800},
numpages = {10},
keywords = {causal reasoning, popularity bias, recommendation},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3625007.3627486,
author = {Pham, Dang and Le, Tuan},
title = {Utilizing Textual Reviews for Visualizing and Understanding User Preferences},
year = {2024},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625007.3627486},
doi = {10.1145/3625007.3627486},
abstract = {Latent factor models are widely used in recommender systems. In these models, users and items are represented as vectors in a joint latent factor space. The inner products of user vectors and item vectors are used to model the user-item interactions (e.g., ratings). A review is often posted by the user to explain the given rating. Therefore, reviews can be used to understand how users rate the items and to interpret the latent dimensions of user and item vectors. In this paper, we propose a probabilistic model that learns latent vectors of users and items in a two- or three-dimensional space for visualization. Our proposed model also extracts review topics and visualizes them in the same visualization space for interpreting the ratings. We model the user-item interactions by using the distances between users and items in the visualization space. Extensive experiments using several real-world datasets demonstrate the effectiveness of our proposed model in recommendation and visualization tasks.},
booktitle = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {335–339},
numpages = {5},
keywords = {latent factor models, visualization, topic models},
location = {Kusadasi, Turkiye},
series = {ASONAM '23}
}

@inproceedings{10.1145/3637528.3671824,
author = {Cai, Miaomiao and Chen, Lei and Wang, Yifan and Bai, Haoyue and Sun, Peijie and Wu, Le and Zhang, Min and Wang, Meng},
title = {Popularity-Aware Alignment and Contrast for Mitigating Popularity Bias},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671824},
doi = {10.1145/3637528.3671824},
abstract = {Collaborative Filtering~(CF) typically suffers from the significant challenge of popularity bias due to the uneven distribution of items in real-world datasets. This bias leads to a significant accuracy gap between popular and unpopular items. It not only hinders accurate user preference understanding but also exacerbates the Matthew effect in recommendation systems. To alleviate popularity bias, existing efforts focus on emphasizing unpopular items or separating the correlation between item representations and their popularity. Despite the effectiveness, existing works still face two persistent challenges: (1) how to extract common supervision signals from popular items to improve the unpopular item representations, and (2) how to alleviate the representation separation caused by popularity bias. In this work, we conduct an empirical analysis of popularity bias and propose &lt;u&gt;P&lt;/u&gt;opularity-&lt;u&gt;A&lt;/u&gt;ware &lt;u&gt;A&lt;/u&gt;lignment and &lt;u&gt;C&lt;/u&gt;ontrast (PAAC) to address two challenges. Specifically, we use the common supervisory signals modeled in popular item representations and propose a novel popularity-aware supervised alignment module to learn unpopular item representations. Additionally, we suggest re-weighting the contrastive learning loss to mitigate the representation separation from a popularity-centric perspective. Finally, we validate the effectiveness and rationale of PAAC in mitigating popularity bias through extensive experiments on three real-world datasets. Our code is available at https://github.com/miaomiao-cai2/KDD2024-PAAC.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {187–198},
numpages = {12},
keywords = {collaborative filtering, contrastive learning, popularity bias, re-weighting, supervised alignment},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3711896.3737156,
author = {Fu, Haoyan and Qin, Zhida and Yang, Shixiao and Zhang, Haoyao and Lu, Bin and Li, Shuang and Huang, Tianyu and Lui, John C.S.},
title = {Time Matters: Enhancing Sequential Recommendations with Time-Guided Graph Neural ODEs},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737156},
doi = {10.1145/3711896.3737156},
abstract = {Sequential recommendation (SR) is widely deployed in e-commerce platforms, streaming services, etc., revealing significant potential to enhance user experience. The core of SR lies in exploring the sequential relationships in historical user-item interactions. However, existing methods often overlook two critical factors: irregular user interests between interactions and highly uneven item distributions over time. The former factor implies that actual user preferences are not always continuous, and long-term historical interactions may not be relevant to current purchasing behavior. Therefore, relying only on these historical interactions for recommendations may result in a lack of user interest at the target time. The latter factor, characterized by peaks and valleys in interaction frequency, may result from seasonal trends, special events, or promotions. These externally driven distributions may not align with individual user interests, leading to inaccurate recommendations. To address these deficiencies, we propose TGODE to both enhance and capture the long-term historical interactions. Specifically, we first construct the user time graph and item evolution graph, which utilize user personalized preferences and global item distribution information, respectively. To tackle the temporal sparsity caused by irregular user interactions, we design a time-guided diffusion generator to automatically obtain an augmented time-aware user graph. Additionally, we devise a user interest truncation factor to efficiently identify sparse time intervals and achieve balanced preference inference. After that, the augmented user graph and item graph are fed into a generalized graph neural ordinary differential equation (ODE) to align with the evolution of user preferences and item distributions. This allows two patterns of information evolution to be matched over time. Experimental results demonstrate that TGODE outperforms baseline methods across five datasets, with improvements ranging from 10% to 46%. The code is available at https://github.com/Qin-lab-code/TGODE.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {637–648},
numpages = {12},
keywords = {diffusion model, graph neural networks, neural ordinary differential equation, sequential recommendation},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3394486.3403278,
author = {Ma, Yifei and Narayanaswamy, Balakrishnan (Murali) and Lin, Haibin and Ding, Hao},
title = {Temporal-Contextual Recommendation in Real-Time},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403278},
doi = {10.1145/3394486.3403278},
abstract = {Personalized real-time recommendation has had a profound impact on retail, media, entertainment and other industries. However, developing recommender systems for every use case is costly, time consuming and resource-intensive. To fill this gap, we present a black-box recommender system that can adapt to a diverse set of scenarios without the need for manual tuning. We build on techniques that go beyond simple matrix factorization to incorporate important new sources of information: the temporal order of events [Hidasi et al., 2015], contextual information to bootstrap cold-start users, metadata information about items [Rendle 2012] and the additional information surrounding each event. Additionally, we address two fundamental challenges when putting recommender systems in the real-world: how to efficiently train them with even millions of unique items and how to cope with changing item popularity trends [Wu et al., 2017]. We introduce a compact model, which we call hierarchical recurrent network with meta data (HRNN-meta) to address the real-time and diverse metadata needs; we further provide efficient training techniques via importance sampling that can scale to millions of items with little loss in performance. We report significant improvements on a wide range of real-world datasets and provide intuition into model capabilities with synthetic experiments. Parts of HRNN-meta have been deployed in production at scale for customers to use at Amazon Web Services and serves as the underlying recommender engine for thousands of websites.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2291–2299},
numpages = {9},
keywords = {collaborative filtering, content filtering, hybrid model, negative sampling, real-time, recommender systems, recurrent neural networks},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/2339530.2339717,
author = {Borghol, Youmna and Ardon, Sebastien and Carlsson, Niklas and Eager, Derek and Mahanti, Anirban},
title = {The untold story of the clones: content-agnostic factors that impact YouTube video popularity},
year = {2012},
isbn = {9781450314626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2339530.2339717},
doi = {10.1145/2339530.2339717},
abstract = {Video dissemination through sites such as YouTube can have widespread impacts on opinions, thoughts, and cultures. Not all videos will reach the same popularity and have the same impact. Popularity differences arise not only because of differences in video content, but also because of other "content-agnostic" factors. The latter factors are of considerable interest but it has been difficult to accurately study them. For example, videos uploaded by users with large social networks may tend to be more popular because they tend to have more interesting content, not because social network size has a substantial direct impact on popularity.In this paper, we develop and apply a methodology that is able to accurately assess, both qualitatively and quantitatively, the impacts of various content-agnostic factors on video popularity. When controlling for video content, we observe a strong linear "rich-get-richer" behavior, with the total number of previous views as the most important factor except for very young videos. The second most important factor is found to be video age. We analyze a number of phenomena that may contribute to rich-get-richer, including the first-mover advantage, and search bias towards popular videos. For young videos we find that factors other than the total number of previous views, such as uploader characteristics and number of keywords, become relatively more important. Our findings also confirm that inaccurate conclusions can be reached when not controlling for content.},
booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1186–1194},
numpages = {9},
keywords = {clones, content popularity, rich-get-richer, youtube},
location = {Beijing, China},
series = {KDD '12}
}

@inproceedings{10.1145/3534678.3539098,
author = {Yue, Han and Xia, Steve and Liu, Hongfu},
title = {Multi-task Envisioning Transformer-based Autoencoder for Corporate Credit Rating Migration Early Prediction},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539098},
doi = {10.1145/3534678.3539098},
abstract = {Corporate credit ratings issued by third-party rating agencies are quantified assessments of a company's creditworthiness. Credit Ratings highly correlate to the likelihood of a company defaulting on its debt obligations. These ratings play critical roles in investment decision-making as one of the key risk factors. They are also central to the regulatory framework such as BASEL II in calculating necessary capital for financial institutions. Being able to predict rating changes will greatly benefit both investors and regulators alike. In this paper, we consider the corporate credit rating migration early prediction problem, which predicts the credit rating of an issuer will be upgraded, unchanged, or downgraded after 12 months based on its latest financial reporting information at the time. We investigate the effectiveness of different standard machine learning algorithms and conclude these models deliver inferior performance. As part of our contribution, we propose a new Multi-task Envisioning Transformer-based Autoencoder (META) model to tackle this challenging problem. META consists of Positional Encoding, Transformer-based Autoencoder, and Multi-task Prediction to learn effective representations for both migration prediction and rating prediction. This enables META to better explore the historical data in the training stage for one-year later prediction. Experimental results show that META outperforms all baseline models.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4452–4460},
numpages = {9},
keywords = {fin-tech, machine learning, rating migration},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3447548.3467244,
author = {Zhong, Mingze and Xie, Hong and Zhu, Qingsheng},
title = {Quantifying Assimilate-Contrast Effects in Online Rating Systems: Modeling, Analysis and Application},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467244},
doi = {10.1145/3447548.3467244},
abstract = {Online rating system serves as an indispensable building block for many web applications such as Amazon, TripAdvior and Yelp. It enables production quality estimation via aggregate ratings (a.k.a. wisdom of the crowd) as well as product recommendation via inferring user preference from ratings, etc. Previous studies showed that due to assimilate-contrast effects, historical ratings can significantly distort user's ratings, leading to low accuracy of product quality estimation and recommendation. To understand assimilate-contrast effects, an "accurate'' model is still missing as previous models do not capture important factors like rating recency, selection bias, etc. Furthermore, an analytical framework to characterize product estimation accuracy under assimilate-contrast effects is also missing. This paper aims to fill in this gap. We propose a mathematical model to quantify the aforementioned important factors on assimilate-contrast effects. Our model attains a good balance between model complexity and model accuracy, such that it is neat enough for us to develop an analytical framework to study assimilate-contrast effects. Based on our model, we derive sufficient conditions, under which the product estimation and collective opinion converges to the "ground-truth''. These conditions reveal important insights on how the aforementioned factors influence the convergence and guide the online rating system operator to design appropriate rating aggregation rules and rating displaying strategies. To demonstrate the versatility of our model, we apply to rating prediction tasks and product recommendation tasks. Experiment results on four public datasets show that our model can improve the rating prediction and and recommendation accuracy over previous models significantly.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2369–2377},
numpages = {9},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3625007.3627724,
author = {Bartley, Nathan and Burghardt, Keith and Lerman, Kristina},
title = {Evaluating Content Exposure Bias in Social Networks},
year = {2024},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625007.3627724},
doi = {10.1145/3625007.3627724},
abstract = {Online social platforms employ personalized feed algorithms to gather and prioritize messages from accounts followed by users, which distorts content's perceived popularity prior to personalization. We call this "exposure bias," and our research focuses on quantifying it using diverse exposure bias metrics, and we evaluate recommendation algorithms through various content ranking heuristics. Similarly we simulate activity in a network to assess the influence of such ranking heuristics on exposure bias. Furthermore, we are working on agent-based model simulations to comprehend the impact of ranking schemes, with the ultimate goal of exploring intervention effects over time. Our empirical findings reveal that users exposed to popularity-based feeds experience significantly lower exposure bias compared to chronologically-ordered feeds.},
booktitle = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {379–383},
numpages = {5},
keywords = {auditing, exposure bias, recommendations},
location = {Kusadasi, Turkiye},
series = {ASONAM '23}
}

@inproceedings{10.5555/3191835.3191895,
author = {Richier, C\'{e}dric and Altman, Eitan and Elazouzi, Rachid and Jimenez, Tania and Linares, Georges and Portilla, Yonathan},
title = {Bio-inspired models for characterizing youtube viewcout},
year = {2014},
isbn = {9781479958764},
publisher = {IEEE Press},
abstract = {The goal of this paper is to study the behaviour of viewcount in YouTube. We first propose several bio-inspired models for the evolution of the viewcount of YouTube videos. We show, using a large set of empirical data, that the viewcount for 90% of videos in YouTube can indeed be associated to at least one of these models, with a Mean Error which does not exceed 5%. We derive automatic ways of classifying the viewcount curve into one of these models and of extracting the most suitable parameters of the model. We study empirically the impact of videos' popularity and category on the evolution of its viewcount. We finally use the above classification along with the automatic parameters extraction in order to predict the evolution of videos' viewcount.},
booktitle = {Proceedings of the 2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {297–305},
numpages = {9},
keywords = {bio-inspired models, online videos, popularity growth, popularity prediction, regression model, video popularity},
location = {Beijing, China},
series = {ASONAM '14}
}

@inproceedings{10.1145/3487351.3488357,
author = {Caetano, Josemar Alves and Almeida, Jussara and Gon\c{c}alves, Marcos and Meira, Wagner and Marques-Neto, Humberto T. and Almeida, Virg\'{\i}lio},
title = {Analyzing topic attention in online small groups},
year = {2022},
isbn = {9781450391283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487351.3488357},
doi = {10.1145/3487351.3488357},
abstract = {Attention is a scarce resource disputed by algorithms and people on the Internet. This competition for attention is part of online spaces especially online small groups where there is a limited number of individuals interacting with each other using text and media content that is not controlled by algorithms or human curators. In these groups, as certain participants and piece of content can catch the collective attention, a question that naturally arises is: how to analyze topic attention in online small groups? In this paper, we propose a methodology aimed at answering this question. Our proposal consists of sets of analyses over topical (obtained from topic analysis) transition graphs for characterizing attention allocation, permanence and shifting as well as participant role characterization during discussions in online small groups. We experimented with our methodology using WhatsApp groups as a case study. Among other results, we identified and characterized abrupt and smooth topic transitions as well as patterns of participant activity related to certain topics.},
booktitle = {Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {64–68},
numpages = {5},
keywords = {WhatsApp, attention, small groups, social computing, topic modeling},
location = {Virtual Event, Netherlands},
series = {ASONAM '21}
}

@inproceedings{10.1145/3690624.3709267,
author = {Liu, Gang and Yang, Fan and Jiao, Yang and Bagheri Garakani, Alireza and Tong, Tian and Gao, Yan and Jiang, Meng},
title = {Learning Attribute as Explicit Relation for Sequential Recommendation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709267},
doi = {10.1145/3690624.3709267},
abstract = {The data on user behaviors is sparse given the vast array of user-item combinations. Attributes related to users (e.g., age), items (e.g., brand), and behaviors (e.g., co-purchase) serve as crucial input sources for item-item transitions of user's behavior prediction. While recent Transformer-based sequential recommender systems learn the attention matrix for each attribute to update item representations, the attention of a specific attribute is optimized by gradients from all input sources, leading to potential information mixture. Besides, Transformers mainly focus on intra-sequence attention for item attributes, neglecting cross-sequence relations and user attributes. Addressing these challenges, we propose the Attribute Transformer (AttrFormer) to learn attributes as explicit relations. This model transforms each type of attribute into an explicit relation defined in the feature space, and it ensures no information mixing among different input sources. Explicit relations introduce cross-sequence and intra-sequence relations. AttrFormer has novel relation-augmented heads to handle them at both the item and behavioral levels, seamlessly integrating the augmented heads into the multi-head attention mechanism. Furthermore, we employ position-to-position aggregation to refine behavior representation for users with similar patterns at the sequence level. To capture the subjective nature of user preferences, AttrFormer is trained using posterior targets where upcoming user behaviors follow a multinomial distribution with a Dirichlet prior. Our evaluations on four popular datasets, including Amazon (Toys &amp; Games and Beauty) and MovieLens (1M and 25M versions), reveal that AttrFormer outperforms leading Transformer baselines, achieving around 20% improvement in NDCG@20 scores. Extensive ablation studies also demonstrate the efficiency of AttrFormer in managing long behavior sequences and inter-sequence relations.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {800–811},
numpages = {12},
keywords = {attributes, sequential recommendation, transformer, user modeling},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3447548.3467216,
author = {Qin, Jiarui and Zhang, Weinan and Su, Rong and Liu, Zhirong and Liu, Weiwen and Tang, Ruiming and He, Xiuqiang and Yu, Yong},
title = {Retrieval &amp; Interaction Machine for Tabular Data Prediction},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467216},
doi = {10.1145/3447548.3467216},
abstract = {Prediction over tabular data is an essential task in many data science applications such as recommender systems, online advertising, medical treatment, etc. Tabular data is structured into rows and columns, with each row as a data sample and each column as a feature attribute. Both the columns and rows of the tabular data carry useful patterns that could improve the model prediction performance. However, most existing models focus on the cross-column patterns yet overlook the cross-rowpatterns as they deal with single samples independently. In this work, we propose a general learning framework named Retrieval &amp; Interaction Machine (RIM) that fully exploits both cross-row and cross-column patterns among tabular data. Specifically, RIM first leverages search engine techniques to efficiently retrieve useful rows of the table to assist the label prediction of the target row, then uses feature interaction networks to capture the cross-column patterns among the target row and the retrieved rows so as to make the final label prediction. We conduct extensive experiments on 11 datasets of three important tasks, i.e., CTR prediction (classification), top-n recommendation (ranking) and rating prediction (regression). Experimental results show that RIM achieves significant improvements over the state-of-the-art and various baselines, demonstrating the superiority and efficacy of RIM.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {1379–1389},
numpages = {11},
keywords = {information retrieval, recommender systems, tabular data},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3341161.3345620,
author = {Margaris, Dionisis and Spiliotopoulos, Dimitris and Vassilakis, Costas},
title = {Social relations versus near neighbours: reliable recommenders in limited information social network collaborative filtering for online advertising},
year = {2020},
isbn = {9781450368681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341161.3345620},
doi = {10.1145/3341161.3345620},
abstract = {Online advertising benefits by recommender systems since the latter analyse reviews and rating of products, providing useful insight of the buyer perception of products and services. When traditional recommender system information is enriched with social network information, more successful recommendations are produced, since more users' aspects are taken into consideration. However, social network information may be unavailable since some users may not have social network accounts or may not consent to their use for recommendations, while rating data may be unavailable due to the cold start phenomenon. In this paper, we propose an algorithm that combines limited collaborative filtering information, comprised only of users' ratings on items, with limited social network information, comprised only of users' social relations, in order to improve (1) prediction accuracy and (2) prediction coverage in collaborative filtering recommender systems, at the same time. The proposed algorithm considerably improves rating prediction accuracy and coverage, while it can be easily integrated in recommender systems.},
booktitle = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {1160–1167},
numpages = {8},
keywords = {collaborative filtering, evaluation, limited information, near neighbours, online advertising, pearson correlation coefficient, social networks},
location = {Vancouver, British Columbia, Canada},
series = {ASONAM '19}
}

@inproceedings{10.1145/3219819.3220086,
author = {Tay, Yi and Luu, Anh Tuan and Hui, Siu Cheung},
title = {Multi-Pointer Co-Attention Networks for Recommendation},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220086},
doi = {10.1145/3219819.3220086},
abstract = {Many recent state-of-the-art recommender systems such as D-ATT, TransNet and DeepCoNN exploit reviews for representation learning. This paper proposes a new neural architecture for recommendation with reviews. Our model operates on a multi-hierarchical paradigm and is based on the intuition that not all reviews are created equal, i.e., only a selected few are important. The importance, however, should be dynamically inferred depending on the current target. To this end, we propose a review-by-review pointer-based learning scheme that extracts important reviews from user and item reviews and subsequently matches them in a word-by-word fashion. This enables not only the most informative reviews to be utilized for prediction but also a deeper word-level interaction. Our pointer-based method operates with a gumbel-softmax based pointer mechanism that enables the incorporation of discrete vectors within differentiable neural architectures. Our pointer mechanism is co-attentive in nature, learning pointers which are co-dependent on user-item relationships. Finally, we propose a multi-pointer learning scheme that learns to combine multiple views of user-item interactions. We demonstrate the effectiveness of our proposed model via extensive experiments on 24 benchmark datasets from Amazon and Yelp. Empirical results show that our approach significantly outperforms existing state-of-the-art models, with up to 19% and 71% relative improvement when compared to TransNet and DeepCoNN respectively. We study the behavior of our multi-pointer learning mechanism, shedding light on 'evidence aggregation' patterns in review-based recommender systems.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2309–2318},
numpages = {10},
keywords = {attention mechanism, collaborative filtering, deep learning, information retrieval, natural language processing, pointer networks, recommendation, review rating prediction, review-based recommender systems},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1109/ASONAM49781.2020.9381314,
author = {Margaris, Dionisis and Spiliotopoulos, Dimitris and Vassilakis, Costas},
title = {Neighbourhood aging factors for limited information social network collaborative filtering},
year = {2021},
isbn = {9781728110561},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASONAM49781.2020.9381314},
doi = {10.1109/ASONAM49781.2020.9381314},
abstract = {Businesses benefit by recommender systems since the latter analyse reviews and ratings of products and services, providing useful insight of the buyer perception of them. One of the most popular, successful and easy-to-build recommender system techniques is collaborative filtering. Recommender systems take into account social network information, to achieve more accurate predictions. Unfortunately, however, many applications do not have full access to such "rich" information, so they have to properly manage the limited information, which, in the worst case, is comprised of just the user relationships in the social network. A social network collaborative filtering system combines the two sources of information, in order to formulate rating predictions which will lead to recommendations. However, the vast majority of users change their tastes, as time goes by, a phenomenon termed as concept drift, and in order for a recommender system to be successful, it must effectively face this problem. In this paper, we present a social network collaborative filtering rating prediction algorithm that tunes the weight-importance of each source of information based on the age of the information. The proposed algorithm considerably improves rating prediction accuracy, while it can be easily integrated in social network collaborative filtering recommender systems.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {877–883},
numpages = {7},
keywords = {business, collaborative filtering, concept drift, personalization, prediction accuracy, recommender systems, social networks},
location = {Virtual Event, Netherlands},
series = {ASONAM '20}
}

@inproceedings{10.1145/3394486.3403373,
author = {Luo, Wenjuan and Zhang, Han and Yang, Xiaodi and Bo, Lin and Yang, Xiaoqing and Li, Zang and Qie, Xiaohu and Ye, Jieping},
title = {Dynamic Heterogeneous Graph Neural Network for Real-time Event Prediction},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403373},
doi = {10.1145/3394486.3403373},
abstract = {Customer response prediction is critical in many industrial applications such as online advertising and recommendations. In particular, the challenge is greater for ride-hailing platforms such as Uber and DiDi, because the response prediction models need to consider historical and real-time event information in the physical environment, such as surrounding traffic and supply and demand conditions. In this paper, we propose to use dynamically constructed heterogeneous graph for each ongoing event to encode the attributes of the event and its surroundings. In addition, we propose a multi-layer graph neural network model to learn the impact of historical actions and the surrounding environment on the current events, and generate an effective event representation to improve the accuracy of the response model. We investigate this framework to two practical applications on the DiDi platform. Offline and online experiments show that the framework can significantly improve prediction performance. The framework has been deployed in the online production environment and serves tens of millions of event prediction requests every day.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {3213–3223},
numpages = {11},
keywords = {dynamic graph embedding, heterogeneous graph neural networks, real-time event embedding},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.5555/3382225.3382369,
author = {C, Santosh K and De Sarkar, Sohan and Mukherjee, Arjun},
title = {Product popularity modeling via time series embedding},
year = {2020},
isbn = {9781538660515},
publisher = {IEEE Press},
abstract = {Electronic commerce has a dominant role in consumer economics. and popular garnering a lot of research attention. Understanding consumer market dynamics based on product popularity is crucial for business intelligence. This work explores the temporal dynamics in online marketing. We introduce a new popularity index based on Amazon: Product Popularity based on Sales Review Volume (PPSRV). We explore and evaluate sequential deep learning models to obtain time series embedding that can predict the product popularity. We further characterize popularity competition between similar products and extend our model of popularity prediction in a competitive environment. Experimental results on large-scale reviews demonstrate the effectiveness of our approach.},
booktitle = {Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {650–653},
numpages = {4},
location = {Barcelona, Spain},
series = {ASONAM '18}
}

@inproceedings{10.1145/3534678.3539439,
author = {Wang, Zimu and He, Yue and Liu, Jiashuo and Zou, Wenchao and Yu, Philip S. and Cui, Peng},
title = {Invariant Preference Learning for General Debiasing in Recommendation},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539439},
doi = {10.1145/3534678.3539439},
abstract = {Current recommender systems have achieved great successes in online services, such as E-commerce and social media. However, they still suffer from the performance degradation in real scenarios, because various biases always occur in the generation process of user behaviors. Despite the recent development of addressing some specific type of bias, a variety of data bias, some of which are even unknown, are often mixed up in real applications. Although the uniform (or unbiased) data may help for the purpose of general debiasing, such data can either be hardly available or induce high experimental cost. In this paper, we consider a more practical setting where we aim to conduct general debiasing with the biased observational data alone. We assume that the observational user behaviors are determined by invariant preference (i.e. a user's true preference) and the variant preference (affected by some unobserved confounders). We propose a novel recommendation framework called InvPref which iteratively decomposes the invariant preference and variant preference from biased observational user behaviors by estimating heterogeneous environments corresponding to different types of latent bias. Extensive experiments, including the settings of general debiasing and specific debiasing, verify the advantages of our method.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1969–1978},
numpages = {10},
keywords = {general debiasing, invariant preference, recommender system},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3580305.3599487,
author = {Xiao, Teng and Chen, Zhengyu and Wang, Suhang},
title = {Reconsidering Learning Objectives in Unbiased Recommendation: A Distribution Shift Perspective},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599487},
doi = {10.1145/3580305.3599487},
abstract = {This work studies the problem of learning unbiased algorithms from biased feedback for recommendation. We address this problem from a novel distribution shift perspective. Recent works in unbiased recommendation have advanced the state-of-the-art with various techniques such as re-weighting, multi-task learning, and meta-learning. Despite their empirical successes, most of them lack theoretical guarantees, forming non-negligible gaps between theories and recent algorithms. In this paper, we propose a theoretical understanding of why existing unbiased learning objectives work for unbiased recommendation. We establish a close connection between unbiased recommendation and distribution shift, which shows that existing unbiased learning objectives implicitly align biased training and unbiased test distributions. Built upon this connection, we develop two generalization bounds for existing unbiased learning methods and analyze their learning behavior. Besides, as a result of the distribution shift, we further propose a principled framework, Adversarial Self-Training (AST), for unbiased recommendation. Extensive experiments on real-world and semi-synthetic datasets demonstrate the effectiveness of AST.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2764–2775},
numpages = {12},
keywords = {causal inference, unbiased recommendation},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3637528.3671915,
author = {Li, Haoxuan and Zheng, Chunyuan and Wang, Wenjie and Wang, Hao and Feng, Fuli and Zhou, Xiao-Hua},
title = {Debiased Recommendation with Noisy Feedback},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671915},
doi = {10.1145/3637528.3671915},
abstract = {Ratings of a user to most items in recommender systems are usually missing not at random (MNAR), largely because users are free to choose which items to rate. To achieve unbiased learning of the prediction model under MNAR data, three typical solutions have been proposed, including error-imputation-based (EIB), inverse-propensity-scoring (IPS), and doubly robust (DR) methods. However, these methods ignore an alternative form of bias caused by the inconsistency between the observed ratings and the users' true preferences, also known as noisy feedback or outcome measurement errors (OME), e.g., due to public opinion or low-quality data collection process. In this work, we study intersectional threats to the unbiased learning of the prediction model from data MNAR and OME in the collected data. First, we design OME-EIB, OME-IPS, and OME-DR estimators, which largely extend the existing estimators to combat OME in real-world recommendation scenarios. Next, we theoretically prove the unbiasedness and generalization bound of the proposed estimators. We further propose an alternate denoising training approach to achieve unbiased learning of the prediction model under MNAR data with OME. Extensive experiments are conducted on three real-world datasets and one semi-synthetic dataset to show the effectiveness of our proposed approaches. The code is available at https://github.com/haoxuanli-pku/KDD24-OME-DR.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1576–1586},
numpages = {11},
keywords = {bias, debias, noisy feedback, recommender systems},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3447548.3467399,
author = {Gao, Chen and Yao, Quanming and Jin, Depeng and Li, Yong},
title = {Efficient Data-specific Model Search for Collaborative Filtering},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467399},
doi = {10.1145/3447548.3467399},
abstract = {Collaborative filtering (CF), as a fundamental approach for recommender systems, is usually built on the latent factor model with learnable parameters to predict users' preferences towards items. However, designing a proper CF model for a given data is not easy, since the properties of datasets are highly diverse. In this paper, motivated by the recent advances in automated machine learning (AutoML), we propose to design a data-specific CF model by AutoML techniques. The key here is a new framework that unifies state-of-the-art (SOTA) CF methods and splits them into disjoint stages of input encoding, embedding function, interaction function, and prediction function. We further develop an easy-to-use, robust, and efficient search strategy, which utilizes random search and a performance predictor for efficient searching within the above framework. In this way, we can combinatorially generalize data-specific CF models, which have not been visited in the literature, from SOTA ones. Extensive experiments on five real-world datasets demonstrate that our method can consistently outperform SOTA ones for various CF tasks. Further experiments verify the rationality of the proposed framework and the efficiency of the search strategy. The searched CF models can also provide insights for exploring more effective methods in the future.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {415–425},
numpages = {11},
keywords = {automated machine learning, collaborative filtering, recommender system},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.5555/3192424.3192573,
author = {Borondo, J. and Morales, A. J. and Losada, J. C. and Benito, R. M.},
title = {Analyzing the usage of social media during Spanish presidential electoral campaigns},
year = {2016},
isbn = {9781509028467},
publisher = {IEEE Press},
abstract = {The large amount of user generated data that Online Social Networks produce has remarkably drawn the attention for researchers on human behavior in the recent years. In this work, we use temporal series and complex network analysis to unveil the users' behavioral patterns during the Spanish presidential electoral campaigns in Twitter. We introduce a new measure to study political sentiment in Twitter, which we call the relative support. We have also characterized user behavior by analyzing the structural and dynamical patterns of the complex networks emergent from the mention and retweet networks. Our results suggest that the collective attention is driven by a very small fraction of users. Furthermore, we have analyzed the interactions taking place among politicians, observing a lack of debate. Moreover, we characterize the users and politicians' interactions and propose a model to simulate their behavior.},
booktitle = {Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {785–792},
numpages = {8},
keywords = {Twitter, communities, complex networks, online communication patterns, political conversations, political elections, relative support parameter, social network analysis},
location = {Davis, California},
series = {ASONAM '16}
}

@inproceedings{10.1145/3447548.3467067,
author = {Li, Siqing and Yao, Liuyi and Mu, Shanlei and Zhao, Wayne Xin and Li, Yaliang and Guo, Tonglei and Ding, Bolin and Wen, Ji-Rong},
title = {Debiasing Learning based Cross-domain Recommendation},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467067},
doi = {10.1145/3447548.3467067},
abstract = {As it becomes prevalent that user information exists in multiple platforms or services, cross-domain recommendation has been an important task in industry. Although it is well known that users tend to show different preferences in different domains, existing studies seldom model how domain biases affect user preferences. Focused on this issue, we develop a casual-based approach to mitigating the domain biases when transferring the user information cross domains. To be specific, this paper presents a novel debiasing learning based cross-domain recommendation framework with causal embedding. In this framework, we design a novel Inverse-Propensity-Score (IPS) estimator designed for cross-domain scenario, and further propose three kinds of restrictions for propensity score learning. Our framework can be generally applied to various recommendation algorithms for cross-domain recommendation. Extensive experiments on both public and industry datasets have demonstrated the effectiveness of the proposed framework.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3190–3199},
numpages = {10},
keywords = {causal embedding, cross-domain recommendation, debiasing learning},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3690624.3709293,
author = {Sun, Zexu and Han, Qiyu and Zhu, Minqin and Gong, Hao and Liu, Dugang and Ma, Chen},
title = {Robust Uplift Modeling with Large-Scale Contexts for Real-time Marketing},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709293},
doi = {10.1145/3690624.3709293},
abstract = {Improving user engagement and platform revenue is crucial for online marketing platforms. Uplift modeling is proposed to solve this problem, which applies different treatments (e.g., discounts, bonus) to satisfy corresponding users. Despite progress in this field, limitations persist. Firstly, most of them focus on scenarios where only user features exist. However, in real-world scenarios, there are rich contexts available in the online platform (e.g., short videos, news), and the uplift model needs to infer an incentive for each user on the specific item, which is called real-time marketing. Thus, only considering the user features will lead to biased prediction of the responses, which may cause the cumulative error for uplift prediction. Moreover, due to the large-scale contexts, directly concatenating the context features with the user features will cause a severe distribution shift in the treatment and control groups. Secondly, capturing the interaction relationship between the user features and context features can better predict the user response. To solve the above limitations, we propose a novel model-agnostic Robust Uplift Modeling with Large-Scale Contexts (UMLC) framework for Real-time Marketing. Our UMLC includes two customized modules. 1) A response-guided context grouping module for extracting context features information and condensing value space through clusters. 2) A feature interaction module for obtaining better uplift prediction. Specifically, this module contains two parts: a user-context interaction component for better modeling the response; a treatment-feature interaction component for discovering the treatment assignment sensitive feature of each instance to better predict the uplift. Moreover, we conduct extensive experiments on a synthetic dataset and a real-world product dataset to verify the effectiveness and compatibility of our UMLC.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {1325–1336},
numpages = {12},
keywords = {large-scale contexts, real-time marketing, uplift modeling},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/2487575.2487624,
author = {Iwata, Tomoharu and Shah, Amar and Ghahramani, Zoubin},
title = {Discovering latent influence in online social activities via shared cascade poisson processes},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487624},
doi = {10.1145/2487575.2487624},
abstract = {Many people share their activities with others through online communities. These shared activities have an impact on other users' activities. For example, users are likely to become interested in items that are adopted (e.g. liked, bought and shared) by their friends. In this paper, we propose a probabilistic model for discovering latent influence from sequences of item adoption events. An inhomogeneous Poisson process is used for modeling a sequence, in which adoption by a user triggers the subsequent adoption of the same item by other users. For modeling adoption of multiple items, we employ multiple inhomogeneous Poisson processes, which share parameters, such as influence for each user and relations between users. The proposed model can be used for finding influential users, discovering relations between users and predicting item popularity in the future. We present an efficient Bayesian inference procedure of the proposed model based on the stochastic EM algorithm. The effectiveness of the proposed model is demonstrated by using real data sets in a social bookmark sharing service.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {266–274},
numpages = {9},
keywords = {bayesian inference, latent variable models, poisson processes, social community},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@inproceedings{10.1145/3487351.3488340,
author = {Vassio, Luca and Garetto, Michele and Chiasserini, Carla and Leonardi, Emilio},
title = {Temporal dynamics of posts and user engagement of influencers on Facebook and Instagram},
year = {2022},
isbn = {9781450391283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487351.3488340},
doi = {10.1145/3487351.3488340},
abstract = {A relevant fraction of human interactions occurs on online social networks. Freshness of content seems to play an important role, with content popularity rapidly vanishing over time. In this paper, we investigate how influencers' generated content (i.e., posts) attracts interactions, measured by number of likes or reactions. We analyse the activity of Italian influencers and followers over more than 5 years, focusing on two popular social networks: Facebook and Instagram, including more than 13 billion interactions and about 4 million posts. We characterise the influencers' and followers' behaviour over time, show that influencers' posts are short-lived with an exponential temporal decay, and characterise the time evolution of the interactions from their initial peak till the end of a post lifetime. Finally, leveraging our findings, we discuss how they can be exploited to develop an analytical model of the interactions temporal dynamics.},
booktitle = {Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {129–133},
numpages = {5},
keywords = {Facebook, Instagram, online social networks, popularity evolution, temporal dynamics, user engagement},
location = {Virtual Event, Netherlands},
series = {ASONAM '21}
}

@inproceedings{10.1145/3580305.3599814,
author = {Zhang, Yin and Wang, Ruoxi and Cheng, Derek Zhiyuan and Yao, Tiansheng and Yi, Xinyang and Hong, Lichan and Caverlee, James and Chi, Ed H.},
title = {Empowering Long-tail Item Recommendation through Cross Decoupling Network (CDN)},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599814},
doi = {10.1145/3580305.3599814},
abstract = {Industry recommender systems usually suffer from highly-skewed long-tail item distributions where a small fraction of the items receives most of the user feedback. This skew hurts recommender quality especially for the item slices without much user feedback. While there have been many research advances made in academia, deploying these methods in production is very difficult and very few improvements have been made in industry. One challenge is that these methods often hurt overall performance; additionally, they could be complex and expensive to train and serve.In this work, we aim to improve tail item recommendations while maintaining the overall performance with less training and serving cost. We first find that the predictions of user preferences are biased under long-tail distributions. The bias comes from the differences between training and serving data in two perspectives: 1) the item distributions, and 2) user's preference given an item. Most existing methods mainly attempt to reduce the bias from the item distribution perspective, ignoring the discrepancy from user preference given an item. This leads to a severe forgetting issue and results in sub-optimal performance.To address the problem, we design a novel Cross Decoupling Network (CDN) to reduce the two differences. Specifically, CDN (i) decouples the learning process of memorization and generalization on the item side through a mixture-of-expert architecture; (ii) decouples the user samples from different distributions through a regularized bilateral branch network. Finally, a new adapter is introduced to aggregate the decoupled vectors, and softly shift the training attention to tail items. Extensive experimental results show that CDN significantly outperforms state-of-the-art approaches on popular benchmark datasets. We also demonstrate its effectiveness by a case study of CDN in a large-scale recommendation system at Google.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5608–5617},
numpages = {10},
keywords = {decoupling, memorization and generalization, recommendation},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3534678.3539194,
author = {Hu, Weihua and Bansal, Rajas and Cao, Kaidi and Rao, Nikhil and Subbian, Karthik and Leskovec, Jure},
title = {Learning Backward Compatible Embeddings},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539194},
doi = {10.1145/3534678.3539194},
abstract = {Embeddings, low-dimensional vector representation of objects, are fundamental in building modern machine learning systems. In industrial settings, there is usually an embedding team that trains an embedding model to solve intended tasks (e.g., product recommendation). The produced embeddings are then widely consumed by consumer teams to solve their unintended tasks (e.g., fraud detection). However, as the embedding model gets updated and retrained to improve performance on the intended task, the newly-generated embeddings are no longer compatible with the existing consumer models. This means that historical versions of the embeddings can never be retired or all consumer teams have to retrain their models to make them compatible with the latest version of the embeddings, both of which are extremely costly in practice.  Here we study the problem of embedding version updates and their backward compatibility. We formalize the problem where the goal is for the embedding team to keep updating the embedding version, while the consumer teams do not have to retrain their models. We develop a solution based on learning backward compatible embeddings, which allows the embedding model version to be updated frequently, while also allowing the latest version of the embedding to be quickly transformed into any backward compatible historical version of it, so that consumer teams do not have to retrain their models. Our key idea is that whenever a new embedding model is trained, we learn it together with a light-weight backward compatibility transformation that aligns the new embedding to the previous version of it. Our learned backward transformations can then be composed to produce any historical version of embedding. Under our framework, we explore six methods and systematically evaluate them on a real-world recommender system application. We show that the best method, which we call BC-Aligner, maintains backward compatibility with existing unintended tasks even after multiple model version updates. Simultaneously, BC-Aligner achieves the intended task performance similar to the embedding model that is solely optimized for the intended task. Code is publicly available at https://github.com/snap-stanford/bc-emb},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3018–3028},
numpages = {11},
keywords = {backward compatibility, embeddings, graph neural networks, recommender systems},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3534678.3539430,
author = {Damak, Khalil and Khenissi, Sami and Nasraoui, Olfa},
title = {Debiasing the Cloze Task in Sequential Recommendation with Bidirectional Transformers},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539430},
doi = {10.1145/3534678.3539430},
abstract = {Bidirectional Transformer architectures are state-of-the-art sequential recommendation models that use a bi-directional representation capacity based on the Cloze task, a.k.a. Masked Language Modeling. The latter aims to predict randomly masked items within the sequence. Because they assume that the true interacted item is the most relevant one, an exposure bias results, where non-interacted items with low exposure propensities are assumed to be irrelevant. The most common approach to mitigating exposure bias in recommendation has been Inverse Propensity Scoring (IPS), which consists of down-weighting the interacted predictions in the loss function in proportion to their propensities of exposure, yielding a theoretically unbiased learning. In this work, we argue and prove that IPS does not extend to sequential recommendation because it fails to account for the temporal nature of the problem. We then propose a novel propensity scoring mechanism, which can theoretically debias the Cloze task in sequential recommendation. Finally we empirically demonstrate the debiasing capabilities of our proposed approach and its robustness to the severity of exposure bias.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {273–282},
numpages = {10},
keywords = {cloze task, exposure bias, sequential recommender system, transformers},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3447548.3467233,
author = {Zhang, Hengtong and Tian, Changxin and Li, Yaliang and Su, Lu and Yang, Nan and Zhao, Wayne Xin and Gao, Jing},
title = {Data Poisoning Attack against Recommender System Using Incomplete and Perturbed Data},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467233},
doi = {10.1145/3447548.3467233},
abstract = {Recent studies reveal that recommender systems are vulnerable to data poisoning attack due to their openness nature. In data poisoning attack, the attacker typically recruits a group of controlled users to inject well-crafted user-item interaction data into the recommendation model's training set to modify the model parameters as desired. Thus, existing attack approaches usually require full access to the training data to infer items' characteristics and craft the fake interactions for controlled users. However, such attack approaches may not be feasible in practice due to the attacker's limited data collection capability and the restricted access to the training data, which sometimes are even perturbed by the privacy preserving mechanism of the service providers. Such design-reality gap may cause failure of attacks. In this paper, we fill the gap by proposing two novel adversarial attack approaches to handle the incompleteness and perturbations in user-item interaction data. First, we propose a bi-level optimization framework that incorporates a probabilistic generative model to find the users and items whose interaction data is sufficient and has not been significantly perturbed, and leverage these users and items' data to craft fake user-item interactions. Moreover, we reverse the learning process of recommendation models and develop a simple yet effective approach that can incorporate context-specific heuristic rules to handle data incompleteness and perturbations. Extensive experiments on two datasets against three representative recommendation models show that the proposed approaches can achieve better attack performance than existing approaches.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2154–2164},
numpages = {11},
keywords = {adversarial learning, data poisoning, recommender system},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3711896.3736903,
author = {Zhang, Sixiao and Long, Cheng and Yuan, Wei and Chen, Hongxu and Yin, Hongzhi},
title = {Data Watermarking for Sequential Recommender Systems},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3736903},
doi = {10.1145/3711896.3736903},
abstract = {In the era of large foundation models, data has become a crucial component in building high-performance AI systems. As the demand for high-quality and large-scale data continues to rise, data copyright protection is attracting increasing attention. In this work, we explore the problem of data watermarking for sequential recommender systems, where a watermark is embedded into the target dataset and can be detected in models trained on that dataset. We focus on two settings: dataset watermarking, which protects the ownership of the entire dataset, and user watermarking, which safeguards the data of individual users. We present a method named Dataset Watermarking for Recommender Systems (DWRS) to address them. We define the watermark as a sequence of consecutive items inserted into normal users' interaction sequences. We define a Receptive Field (RF) to guide the inserting process to facilitate the memorization of the watermark. Extensive experiments on five representative sequential recommendation models and three benchmark datasets demonstrate the effectiveness of DWRS in protecting data copyright while preserving model utility.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {3819–3830},
numpages = {12},
keywords = {data watermarking, recommender systems},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3219819.3219987,
author = {Zhang, Bang and Zhang, Lelin and Guo, Ting and Wang, Yang and Chen, Fang},
title = {Simultaneous Urban Region Function Discovery and Popularity Estimation via an Infinite Urbanization Process Model},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219987},
doi = {10.1145/3219819.3219987},
abstract = {Urbanization is a global trend that we have all witnessed in the past decades. It brings us both opportunities and challenges. On the one hand, urban system is one of the most sophisticated social-economic systems that is responsible for efficiently providing supplies meeting the demand of residents in various of domains, e.g., dwelling, education, entertainment, healthcare, etc. On the other hand, significant diversity and inequality exist in the development patterns of urban systems, which makes urban data analysis difficult. Different urban regions often exhibit diverse urbanization patterns and provide distinct urban functions, e.g., commercial and residential areas offer significantly different urban functions. It is desired to develop the data analytic capabilities for discovering the underlying cross-domain urbanization patterns, clustering urban regions based on their function similarity and predicting region popularity in specified domains. Previous studies in the urban data analysis area often just focus on individual domains and rarely consider cross-domain urban development patterns hidden in different urban regions. In this paper, we propose the infinite urbanization process (IUP) model for simultaneous urban region function discovery and region popularity prediction. The IUP model is a generative Bayesian nonparametric process that is capable of describing a potentially infinite number of urbanization patterns. It is developed within the supervised topic modelling framework and is supported by a novel hierarchical spatial distance dependent Bayesian nonparametric prior over the spatial region partition space. The empirical study conducted on the real-world datasets shows promising outcome compared with the state-of-the-art techniques.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2692–2700},
numpages = {9},
keywords = {bayesian nonparametric, topic modelling, urban computing, urban function discovery},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3097983.3098091,
author = {Huang, Qiming and Zhu, Michael},
title = {SPOT: Sparse Optimal Transformations for High Dimensional Variable Selection and Exploratory Regression Analysis},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098091},
doi = {10.1145/3097983.3098091},
abstract = {We develop a novel method called SParse Optimal Transformations (SPOT) to simultaneously select important variables and explore relationships between the response and predictor variables in high dimensional nonparametric regression analysis. Not only are the optimal transformations identified by SPOT interpretable, they can also be used for response prediction. We further show that SPOT achieves consistency in both variable selection and parameter estimation. Numerical experiments and real data applications demonstrate that SPOT outperforms other existing methods and can serve as an effective tool in practice.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {857–865},
numpages = {9},
keywords = {monotone transformation, optimal transformation, regression analysis, spline, variable selection},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3690624.3709250,
author = {Tang, Gu and Wang, Jinghe and Gan, Xiaoying and Lu, Bin and Zhao, Ze and Fu, Luoyi and Wang, Xinbing and Zhou, Chenghu},
title = {R2MR: Review and Rewrite Modality for Recommendation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709250},
doi = {10.1145/3690624.3709250},
abstract = {With the explosive growth of online multimodal content, multimodal recommender systems(MRSs) have brought significant benefits to multimedia platforms. As MRSs evolve, many studies incorporate advanced technologies like graph neural networks(GNNs) and self-supervised learning(SSL), achieving remarkable results. However, these efforts still suffer from the quality disparity problem. It refers to the mixture of high and low quality across items' multiple modalities, owing to disparities in construction costs or design levels. These low-quality modalities often lack crucial details or introduce noise to the depiction of item, leading to insufficient or polluted item representation. Therefore, we propose a novel framework R2MR: Review and Rewrite Modality for Recommendation to tackle this issue. Specifically, R2MR is composed of two key components: Modality Reviewer and Modality Rewriter. The Modality Reviewer introduces a Consensus Review Mechanism. It performs perspective decomposition based on user representations and learns the consensus quality scores for modalities from diverse perspectives of multiple users. The Modality Rewriter proposes a Latent Mapping Model, which improves the quality of inferior modalities by learning various mapping patterns from high-quality modalities. Comprehensive experiments across three benchmark datasets reveal that R2MR substantially outperforms state-of-the-art methods, achieving an average improvement of 9.20%. The implementations are available at https://github.com/gutang-97/R2MR.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {1337–1348},
numpages = {12},
keywords = {generative model, multimodal recommendation, quality disparity},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3711896.3737068,
author = {Loveland, Donald and Ju, Mingxuan and Zhao, Tong and Shah, Neil and Koutra, Danai},
title = {On the Role of Weight Decay in Collaborative Filtering: A Popularity Perspective},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737068},
doi = {10.1145/3711896.3737068},
abstract = {Collaborative filtering (CF) enables large-scale recommendation systems by encoding information from user-item interactions into dense ID-embedding tables. However, as embedding tables grow, closed-form solutions become impractical, necessitating the use of mini-batch gradient descent. Despite extensive work on loss function design, we argue that one core component of these pipelines is heavily overlooked: weight decay. Attaining high-performing models typically requires careful tuning of weight decay, regardless of loss, yet its necessity is not well understood. In this work, we question why weight decay is crucial in CF pipelines and how it impacts training. Through theoretical and empirical analysis, we uncover that weight decay's primary function is to encode popularity information into the magnitudes of the embedding vectors. Moreover, we find that tuning weight decay acts as a coarse, non-linear, knob to influence preference towards popular or unpopular items. Based on these findings, we propose PRISM (Popularity-awaRe Initialization Strategy for embedding Magnitudes), a straightforward yet effective solution to simplify the training of CF models. PRISM pre-encodes the popularity information typically learned through weight decay, eliminating its necessity. Our experiments show that PRISM improves performance by up to 4.77% and reduces training times by 38.48%, compared to state-of-the-art training strategies. Additionally, PRISM offers a cost-effective and meaningful strategy to mitigate popularity bias.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {1975–1986},
numpages = {12},
keywords = {magnitude, popularity, recommender systems, weight decay},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3447548.3467208,
author = {Zhao, Xiangyu and Liu, Haochen and Fan, Wenqi and Liu, Hui and Tang, Jiliang and Wang, Chong},
title = {AutoLoss: Automated Loss Function Search in Recommendations},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467208},
doi = {10.1145/3447548.3467208},
abstract = {Designing an effective loss function plays a crucial role in training deep recommender systems. Most existing works often leverage a predefined and fixed loss function that could lead to suboptimal recommendation quality and training efficiency. Some recent efforts rely on exhaustively or manually searched weights to fuse a group of candidate loss functions, which is exceptionally costly in computation and time. They also neglect the various convergence behaviors of different data examples. In this work, we propose an AutoLoss framework that can automatically and adaptively search for the appropriate loss function from a set of candidates. To be specific, we develop a novel controller network, which can dynamically adjust the loss probabilities in a differentiable manner. Unlike existing algorithms, the proposed controller can adaptively generate the loss probabilities for different data examples according to their varied convergence behaviors. Such design improves the model's generalizability and transferability between deep recommender systems and datasets. We evaluate the proposed framework on two benchmark datasets. The results show that AutoLoss outperforms representative baselines. Further experiments have been conducted to deepen our understandings of AutoLoss, including its transferability, components and training efficiency.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3959–3967},
numpages = {9},
keywords = {AutoML, loss functions, recommender systems},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/2808797.2808819,
author = {AlMansour, Amal Abdullah and Iliopoulos, Costas S.},
title = {Using Arabic Microblogs Features in Determining Credibility},
year = {2015},
isbn = {9781450338547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2808797.2808819},
doi = {10.1145/2808797.2808819},
abstract = {The increased usage of Twitter as a medium for reporting news and sharing information between people has caught the attention of researchers from different disciplines. One of the research directions is the analysis of online information from the perspective of its credibility. This paper aims to assess and analyze the credibility of tweets in Arabic language. In order to achieve the stated goal, first we employ the idea of crowdsourcing where users can explicitly express their opinions about credibility of a set of tweets. This information coupled with the data about tweets' features enable us to investigate which features may indicate the credibility level of a tweet, e.g. tweet with attached image and was authored by a person who posts a lot of tweets will be, with high probability, a credible tweet. We distinguish three main groups of features: authority and topical expertise (of the source), data quality (of the content), and popularity (of the content and the source). We argue that content data quality factor based on content linguistic features in addition to source authority is more important than content popularity in identifying credible messages. In addition to this, we identified three experts who also rated the credibility of tweets and based on that we investigate the level of agreement between experts and the crowd, and we identify which expert represents the crowd in the best way. This can allow us to select the most representative expert when it is needed. This study is a pilot of a large study that aims at predicting credibility of Arabic Twitter messages using machine learning approaches.},
booktitle = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015},
pages = {1212–1219},
numpages = {8},
keywords = {arabic, credibility, microblogs, social networks, trust, twitter},
location = {Paris, France},
series = {ASONAM '15}
}

@inproceedings{10.1145/3637528.3671781,
author = {Zhang, Jingsen and Tang, Jiakai and Chen, Xu and Yu, Wenhui and Hu, Lantao and Jiang, Peng and Li, Han},
title = {Natural Language Explainable Recommendation with Robustness Enhancement},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671781},
doi = {10.1145/3637528.3671781},
abstract = {Natural language explainable recommendation has become a promising direction to facilitate more efficient and informed user decisions. Previous models mostly focus on how to enhance the explanation accuracy. However, the robustness problem has been largely ignored, which requires the explanations generated for similar user-item pairs should not be too much different. Different from traditional classification problems, improving the robustness of natural languages has two unique characteristics: (1) Different token importances, that is, different tokens play various roles in representing the complete sentence, and the robustness requirements for predicting them should also be different. (2) Continuous token semantics, that is, the similarity of the output should be judged based on semantics, and the sequences without any token-level overlap may also be highly similar. Based on these characteristics, we formulate and solve a novel problem in the recommendation domain, that is, robust natural language explainable recommendation. To the best of our knowledge, it is the first time in this field. Specifically, we base our modeling on adversarial robust optimization and design four types of heuristic methods to modify the adversarial outputs with weighted token probabilities and synonym replacements. Furthermore, to consider the mutual influence between the above characteristics, we regard language generation as a decision-making problem and design a dual-policy reinforcement learning framework to improve the robustness of the generated languages. We conduct extensive experiments to demonstrate the effectiveness of our framework.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4203–4212},
numpages = {10},
keywords = {adversarial learning, explainable recommendation, natural language explanations},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/2939672.2945388,
author = {Zhu, Qiang and Guo, Songtao and Ogilvie, Paul and Liu, Yan},
title = {Business Applications of Predictive Modeling at Scale},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2945388},
doi = {10.1145/2939672.2945388},
abstract = {Predictive modeling is the art of building statistical models that forecast probabilities and trends of future events. It has broad applications in industry across different domains. Some popular examples include user intention predictions, lead scoring, churn analysis, etc. In this tutorial, we will focus on the best practice of predictive modeling in the big data era and its applications in industry, with motivating examples across a range of business tasks and relevance products. We will start with an overview of how predictive modeling helps power and drive various key business use cases. We will introduce the essential concepts and state of the art in building end-to-end predictive modeling solutions, and discuss the challenges, key technologies, and lessons learned from our practice, including case studies of LinkedIn feed relevance and a platform for email response prediction. Moreover, we will discuss some practical solutions of building predictive modeling platform to scale the modeling efforts for data scientists and analysts, along with an overview of popular tools and platforms used across the industry.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {2139–2140},
numpages = {2},
keywords = {business analytics, machine learning, machine learning platforms, predictive modeling},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/3534678.3539306,
author = {Kim, Jooyeon and Lamb, Angus and Woodhead, Simon and Peyton Jones, Simon and Zhang, Cheng and Allamanis, Miltiadis},
title = {CoRGi: Content-Rich Graph Neural Networks with Attention},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539306},
doi = {10.1145/3534678.3539306},
abstract = {Graph representations of a target domain often project it to a set of entities (nodes) and their relations (edges). However, such projections often miss important and rich information. For example, in graph representations used in missing value imputation, items --- represented as nodes --- may contain rich textual information. However, when processing graphs with graph neural networks (GNN), such information is either ignored or summarized into a single vector representation used to initialize the GNN. Towards addressing this, we present CoRGi, a GNN that considers the rich data within nodes in the context of their neighbors. This is achieved by endowing CoRGi's message passing with a personalized attention mechanism over the content of each node. This way, CoRGi assigns user-item-specific attention scores with respect to the words that appear in an item's content. We evaluate CoRGi on two edge-value prediction tasks and show that CoRGi is better at making edge-value predictions over existing methods, especially on sparse regions of the graph.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {773–783},
numpages = {11},
keywords = {graph neural networks, missing value imputation, neural networks, recommendation},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/1401890.1401969,
author = {Singh, Ajit P. and Gordon, Geoffrey J.},
title = {Relational learning via collective matrix factorization},
year = {2008},
isbn = {9781605581934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1401890.1401969},
doi = {10.1145/1401890.1401969},
abstract = {Relational learning is concerned with predicting unknown values of a relation, given a database of entities and observed relations among entities. An example of relational learning is movie rating prediction, where entities could include users, movies, genres, and actors. Relations encode users' ratings of movies, movies' genres, and actors' roles in movies. A common prediction technique given one pairwise relation, for example a #users x #movies ratings matrix, is low-rank matrix factorization. In domains with multiple relations, represented as multiple matrices, we may improve predictive accuracy by exploiting information from one relation while predicting another. To this end, we propose a collective matrix factorization model: we simultaneously factor several matrices, sharing parameters among factors when an entity participates in multiple relations. Each relation can have a different value type and error distribution; so, we allow nonlinear relationships between the parameters and outputs, using Bregman divergences to measure error. We extend standard alternating projection algorithms to our model, and derive an efficient Newton update for the projection. Furthermore, we propose stochastic optimization methods to deal with large, sparse matrices. Our model generalizes several existing matrix factorization methods, and therefore yields new large-scale optimization algorithms for these problems. Our model can handle any pairwise relational schema and a wide variety of error models. We demonstrate its efficiency, as well as the benefit of sharing parameters among relations.},
booktitle = {Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {650–658},
numpages = {9},
keywords = {matrix factorization, relational learning, stochastic approximation},
location = {Las Vegas, Nevada, USA},
series = {KDD '08}
}

@inproceedings{10.1145/3637528.3671474,
author = {Deldjoo, Yashar and He, Zhankui and McAuley, Julian and Korikov, Anton and Sanner, Scott and Ramisa, Arnau and Vidal, Ren\'{e} and Sathiamoorthy, Maheswaran and Kasirzadeh, Atoosa and Milano, Silvia},
title = {A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671474},
doi = {10.1145/3637528.3671474},
abstract = {Traditional recommender systems typically use user-item rating histories as their main data source. However, deep generative models now have the capability to model and sample from complex data distributions, including user-item interactions, text, images, and videos, enabling novel recommendation tasks. This comprehensive, multidisciplinary survey connects key advancements in RS using Generative Models (Gen-RecSys), covering: interaction-driven generative models; the use of large language models (LLM) and textual data for natural language recommendation; and the integration of multimodal models for generating and processing images/videos in RS. Our work highlights necessary paradigms for evaluating the impact and harm of Gen-RecSys and identifies open challenges. This survey accompanies a "tutorial" presented at ACM KDD'24, with supporting materials provided at: https://encr.pw/vDhLq.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6448–6458},
numpages = {11},
keywords = {ethical and societal considerations, gans, generative models, llms, multimodal, recommender systems, vaes, vllms},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3690624.3709220,
author = {Li, Xiaodong and Tang, Hengzhu and Sheng, Jiawei and Zhang, Xinghua and Gao, Li and Cheng, Suqi and Yin, Dawei and Liu, Tingwen},
title = {Exploring Preference-Guided Diffusion Model for Cross-Domain Recommendation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709220},
doi = {10.1145/3690624.3709220},
abstract = {Cross-domain recommendation (CDR) has been proven as a promising way to alleviate the cold-start issue, in which the most critical problem is how to draw an informative user representation in the target domain via the transfer of user preference existing in the source domain. Prior efforts mostly follow the embedding-and-mapping paradigm, which first integrate the preference into user representation in the source domain, and then perform a mapping function on this representation to the target domain. However, they focus on mapping features across domains, neglecting to explicitly model the preference integration process, which may lead to learning coarse user representation. Diffusion models (DMs), which contribute to more accurate user/item representations due to their explicit information injection capability, have achieved promising performance in recommendation systems. Nevertheless, these DMs-based methods cannot directly account for valuable user preference in other domains, leading to challenges in adapting to the transfer of preference for cold-start users. Consequently, the feasibility of DMs for CDR remains underexplored. To this end, we explore to utilize the explicit information injection capability of DMs for user preference integration and propose a Preference-Guided Diffusion Model for CDR to cold-start users, termed as DMCDR. Specifically, we leverage a preference encoder to establish the preference guidance signal with the user's interaction history in the source domain. Then, we explicitly inject the preference guidance signal into the user representation step by step to guide the reverse process, and ultimately generate the personalized user representation in the target domain, thus achieving the transfer of user preference across domains. Furthermore, we comprehensively explore the impact of six DMs-based variants on CDR. Extensive experiments on three real-world CDR scenarios demonstrate the superiority of our DMCDR over SOTA methods and six DMs-based variants.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {719–728},
numpages = {10},
keywords = {cold-start recommendation, cross-domain recommendation, diffusion models},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/2237827.2237831,
author = {Reed, Colorado and Elvers, Todd and Srinivasan, Padmini},
title = {What's trending? mining topical trends in UGC systems with YouTube as a case study},
year = {2011},
isbn = {9781450308410},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2237827.2237831},
doi = {10.1145/2237827.2237831},
abstract = {User-generated content (UGC) systems such as Twitter, Face-book, and YouTube are quickly becoming the dominant form of information exchange on the web: shifting informational power from media conglomerates to individual users. Understanding the popularity trends in UGC content has proven problematic as traditional content popularity techniques (e.g. those developed for television) are not suited for the disparate origins and ephemeral lifecycle of UGC. Content-based trend detection with UGC systems has been an intensely growing field of research in recent years, yet surprisingly, there is no single method or approach that can be used to track and compare trends in user posts across multiple UGC sources. Therefore, in this work, we develop a standard system for detecting emerging trends in user posts for UGC that contains some form of textual data. We demonstrate the use and implementation of this system through a case study with approximately 2 million YouTube video posts. Furthermore, to help facilitate future comparative studies in UGC trend analysis, we have made this system open-source and straightforward to integrate with various UGC systems (Twitter, Facebook, Flickr, Digg, Blogger, etc.).},
booktitle = {Proceedings of the Eleventh International Workshop on Multimedia Data Mining},
articleno = {4},
numpages = {9},
location = {San Diego, California},
series = {MDMKDD '11}
}

@inproceedings{10.1145/3580305.3599296,
author = {Zhang, Qing and Zhang, Xiaoying and Liu, Yang and Wang, Hongning and Gao, Min and Zhang, Jiheng and Guo, Ruocheng},
title = {Debiasing Recommendation by Learning Identifiable Latent Confounders},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599296},
doi = {10.1145/3580305.3599296},
abstract = {Recommendation systems aim to predict users' feedback on items not exposed to them yet. Confounding bias arises due to the presence of unmeasured variables (e.g., the socio-economic status of a user) that can affect both a user's exposure and feedback. Existing methods either (1) make untenable assumptions about these unmeasured variables or (2) directly infer latent confounders from users' exposure. However, they cannot guarantee the identification of counterfactual feedback, which can lead to biased predictions. In this work, we propose a novel method, i.e., identifiable deconfounder (iDCF), which leverages a set of proxy variables (e.g., observed user features) to resolve the aforementioned non-identification issue. The proposed iDCF is a general deconfounded recommendation framework that applies proximal causal inference to infer the unmeasured confounders and identify the counterfactual feedback with theoretical guarantees. Extensive experiments on various real-world and synthetic datasets verify the proposed method's effectiveness and robustness.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3353–3363},
numpages = {11},
keywords = {deconfounder, recommendation, unmeasured confounder},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/2492517.2492565,
author = {Ren, Yongli and Li, Gang and Zhang, Jun and Zhou, Wanlei},
title = {AdaM: adaptive-maximum imputation for neighborhood-based collaborative filtering},
year = {2013},
isbn = {9781450322409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2492517.2492565},
doi = {10.1145/2492517.2492565},
abstract = {In the context of collaborative filtering, the well-known data sparsity issue makes two like-minded users have little similarity, and consequently renders the k nearest neighbour rule inapplicable. In this paper, we address the data sparsity problem in the neighbourhood-based CF methods by proposing an Adaptive-Maximum imputation method (AdaM). The basic idea is to identify an imputation area that can maximize the imputation benefit for recommendation purposes, while minimizing the imputation error brought in. To achieve the maximum imputation benefit, the imputation area is determined from both the user and the item perspectives; to minimize the imputation error, there is at least one real rating preserved for each item in the identified imputation area. A theoretical analysis is provided to prove that the proposed imputation method outperforms the conventional neighbourhood-based CF methods through more accurate neighbour identification. Experiment results on benchmark datasets show that the proposed method significantly outperforms the other related state-of-the-art imputation-based methods in terms of accuracy.},
booktitle = {Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {628–635},
numpages = {8},
location = {Niagara, Ontario, Canada},
series = {ASONAM '13}
}

@inproceedings{10.1145/2501221.2501222,
author = {Amatriain, Xavier},
title = {Big &amp; personal: data and models behind netflix recommendations},
year = {2013},
isbn = {9781450323246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2501221.2501222},
doi = {10.1145/2501221.2501222},
abstract = {Since the Netflix $1 million Prize, announced in 2006, our company has been known to have personalization at the core of our product. Even at that point in time, the dataset that we released was considered "large", and we stirred innovation in the (Big) Data Mining research field. Our current product offering is now focused around instant video streaming, and our data is now many orders of magnitude larger. Not only do we have many more users in many more countries, but we also receive many more streams of data. Besides the ratings, we now also use information such as what our members play, browse, or search.In this paper, we will discuss the different approaches we follow to deal with these large streams of data in order to extract information for personalizing our service. We will describe some of the machine learning models used, as well as the architectures that allow us to combine complex offline batch processes with real-time data streams.},
booktitle = {Proceedings of the 2nd International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
pages = {1–6},
numpages = {6},
location = {Chicago, Illinois},
series = {BigMine '13}
}

@inproceedings{10.1145/3447548.3467188,
author = {Hashemi, Helia and Pappu, Aasish and Tian, Mi and Chandar, Praveen and Lalmas, Mounia and Carterette, Benjamin},
title = {Neural Instant Search for Music and Podcast},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467188},
doi = {10.1145/3447548.3467188},
abstract = {Over recent years, podcasts have emerged as a novel medium for sharing and broadcasting information over the Internet. Audio streaming platforms originally designed for music content, such as Amazon Music, Pandora, and Spotify, have reported a rapid growth, with millions of users consuming podcasts every day. With podcasts emerging as a new medium for consuming information, the need to develop information access systems that enable efficient and effective discovery from a heterogeneous collection of music and podcasts is more important than ever. However, information access in such domains still remains understudied. In this work, we conduct a large-scale log analysis to study and compare podcast and music search behavior on Spotify, a major audio streaming platform. Our findings suggest that there exist fundamental differences in user behavior while searching for podcasts compared to music. Specifically, we identify the need to improve podcast search performance. We propose a simple yet effective transformer-based neural instant search model that retrieves items from a heterogeneous collection of music and podcast content. Our model takes advantage of multi-task learning to optimize for a ranking objective in addition to a query intent type identification objective. Our experiments on large-scale search logs show that the proposed model significantly outperforms strong baselines for both podcast and music queries.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2984–2992},
numpages = {9},
keywords = {instant search, music search, neural information retrieval, podcast search},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3711896.3736985,
author = {Mei, Tiehua and Chen, Hengrui and Yu, Peng and Liang, Jiaqing and Yang, Deqing},
title = {GORACS: Group-level Optimal Transport-guided Coreset Selection for LLM-based Recommender Systems},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3736985},
doi = {10.1145/3711896.3736985},
abstract = {Although large language models (LLMs) have shown great potential in recommender systems, the prohibitive computational costs for fine-tuning LLMs on entire datasets hinder their successful deployment in real-world scenarios. To develop affordable and effective LLM-based recommender systems, we focus on the task of coreset selection which identifies a small subset of fine-tuning data to optimize the test loss, thereby facilitating efficient LLMs' fine-tuning. Although there exist some intuitive solutions of subset selection, including distribution-based and importance-based approaches, they often lead to suboptimal performance due to the misalignment with downstream fine-tuning objectives or weak generalization ability caused by individual-level sample selection. To overcome these challenges, we propose GORACS, which is a novel Group-level Optimal tRAnsport-guided Coreset Selection framework for LLM-based recommender systems. GORACS is designed based on two key principles for coreset selection: 1) selecting the subsets that minimize the test loss to align with fine-tuning objectives, and 2) enhancing model generalization through group-level data selection. Corresponding to these two principles, GORACS has two key components: 1) a Proxy Optimization Objective (POO) leveraging optimal transport and gradient information to bound the intractable test loss, thus reducing computational costs by avoiding repeated LLM retraining, and 2) a two-stage Initialization-Then-Refinement Algorithm (ITRA) for efficient group-level selection. Our extensive experiments across diverse recommendation datasets and tasks validate that GORACS significantly reduces fine-tuning costs of LLMs while achieving superior performance over the state-of-the-art baselines and full data training.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {2126–2137},
numpages = {12},
keywords = {coreset selection, llm-based recommendation, model training},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3534678.3539240,
author = {Ding, Sihao and Wu, Peng and Feng, Fuli and Wang, Yitong and He, Xiangnan and Liao, Yong and Zhang, Yongdong},
title = {Addressing Unmeasured Confounder for Recommendation with Sensitivity Analysis},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539240},
doi = {10.1145/3534678.3539240},
abstract = {Recommender systems should answer the intervention question "if recommending an item to a user, what would the feedback be", calling for estimating the causal effect of a recommendation on user feedback. Generally, this requires blocking the effect of confounders that simultaneously affect the recommendation and feedback. To mitigate the confounding bias, a strategy is incorporating propensity into model learning. However, existing methods forgo possible unmeasured confounders (e.g., user financial status), which can result in biased propensities and hurt recommendation performance. This work combats the risk of unmeasured confounders in recommender systems.  Towards this end, we propose Robust Deconfounder (RD) that accounts for the effect of unmeasured confounders on propensities, under the mild assumption that the effect is bounded. It estimates the bound with sensitivity analysis, learning a recommender model robust to unmeasured confounders within the bound by adversarial learning. However, pursuing robustness within a bound may restrict model accuracy. To avoid the trade-off between robustness and accuracy, we further propose Benchmarked RD (BRD) that incorporates a pre-trained model into the learning as the benchmark. Theoretical analyses prove the stronger robustness of our methods compared to existing propensity-based deconfounders, and also prove the no-harm property of BRD. Our methods are applicable to any propensity-based estimators, where we select three representative ones: IPS, Doubly Robust, and AutoDebias. We conduct experiments on three real-world datasets to demonstrate the effectiveness of our methods.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {305–315},
numpages = {11},
keywords = {deconfounder, recommendation, unmeasured confounder},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3637528.3671661,
author = {Tang, Jiakai and Dai, Sunhao and Sun, Zexu and Chen, Xu and Xu, Jun and Yu, Wenhui and Hu, Lantao and Jiang, Peng and Li, Han},
title = {Towards Robust Recommendation via Decision Boundary-aware Graph Contrastive Learning},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671661},
doi = {10.1145/3637528.3671661},
abstract = {In recent years, graph contrastive learning (GCL) has received increasing attention in recommender systems due to its effectiveness in reducing bias caused by data sparsity. However, most existing GCL models rely on heuristic approaches and usually assume entity independence when constructing contrastive views. We argue that these methods struggle to strike a balance between semantic invariance and view hardness across the dynamic training process, both of which are critical factors in graph contrastive learning.To address the above issues, we propose a novel GCL-based recommendation framework RGCL, which effectively maintains the semantic invariance of contrastive pairs and dynamically adapts as the model capability evolves through the training process. Specifically, RGCL first introduces decision boundary-aware adversarial perturbations to constrain the exploration space of contrastive augmented views, avoiding the decrease of task-specific information. Furthermore, to incorporate global user-user and item-item collaboration relationships for guiding on the generation of hard contrastive views, we propose an adversarial-contrastive learning objective to construct a relation-aware view-generator. Besides, considering that unsupervised GCL could potentially narrower margins between data points and the decision boundary, resulting in decreased model robustness, we introduce the adversarial examples based on maximum perturbations to achieve margin maximization. We also provide theoretical analyses on the effectiveness of our designs. Through extensive experiments on five public datasets, we demonstrate the superiority of RGCL compared against twelve baseline models.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2854–2865},
numpages = {12},
keywords = {adversarial learning, graph contrastive learning, recommender robustness},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671802,
author = {Lei, Yuxuan and Lian, Jianxun and Yao, Jing and Huang, Xu and Lian, Defu and Xie, Xing},
title = {RecExplainer: Aligning Large Language Models for Explaining Recommendation Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671802},
doi = {10.1145/3637528.3671802},
abstract = {Recommender systems are widely used in online services, with embedding-based models being particularly popular due to their expressiveness in representing complex signals. However, these models often function as a black box, making them less transparent and reliable for both users and developers. Recently, large language models (LLMs) have demonstrated remarkable intelligence in understanding, reasoning, and instruction following. This paper presents the initial exploration of using LLMs as surrogate models to explaining black-box recommender models. The primary concept involves training LLMs to comprehend and emulate the behavior of target recommender models. By leveraging LLMs' own extensive world knowledge and multi-step reasoning abilities, these aligned LLMs can serve as advanced surrogates, capable of reasoning about observations. Moreover, employing natural language as an interface allows for the creation of customizable explanations that can be adapted to individual user preferences. To facilitate an effective alignment, we introduce three methods: behavior alignment, intention alignment, and hybrid alignment. Behavior alignment operates in the language space, representing user preferences and item information as text to mimic the target model's behavior; intention alignment works in the latent space of the recommendation model, using user and item representations to understand the model's behavior; hybrid alignment combines both language and latent spaces. Comprehensive experiments conducted on three public datasets show that our approach yields promising results in understanding and mimicking target models, producing high-quality, high-fidelity, and distinct explanations. Our code is available at https://github.com/microsoft/RecAI.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1530–1541},
numpages = {12},
keywords = {large language models, model explainability, recommender systems},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3447548.3467220,
author = {Chen, Tong and Yin, Hongzhi and Zheng, Yujia and Huang, Zi and Wang, Yang and Wang, Meng},
title = {Learning Elastic Embeddings for Customizing On-Device Recommenders},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467220},
doi = {10.1145/3447548.3467220},
abstract = {In today's context, deploying data-driven services like recommendation on edge devices instead of cloud servers becomes increasingly attractive due to privacy and network latency concerns. A common practice in building compact on-device recommender systems is to compress their embeddings which are normally the cause of excessive parameterization. However, despite the vast variety of devices and their associated memory constraints, existing memory-efficient recommender systems are only specialized for a fixed memory budget in every design and training life cycle, where a new model has to be retrained to obtain the optimal performance while adapting to a smaller/larger memory budget. In this paper, we present a novel lightweight recommendation paradigm that allows a well-trained recommender to be customized for arbitrary device-specific memory constraints without retraining. The core idea is to compose elastic embeddings for each item, where an elastic embedding is the concatenation of a set of embedding blocks that are carefully chosen by an automated search function. Correspondingly, we propose an innovative approach, namely recommendation with universally learned elastic embeddings (RULE). To ensure the expressiveness of all candidate embedding blocks, RULE enforces a diversity-driven regularization when learning different embedding blocks. Then, a performance estimator-based evolutionary search function is designed, allowing for efficient specialization of elastic embeddings under any memory constraint for on-device recommendation. Extensive experiments on real-world datasets reveal the superior performance of RULE under tight memory budgets.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {138–147},
numpages = {10},
keywords = {elastic embeddings, lightweight recommendation},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3534678.3539269,
author = {Wei, Tianxin and He, Jingrui},
title = {Comprehensive Fair Meta-learned Recommender System},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539269},
doi = {10.1145/3534678.3539269},
abstract = {In recommender systems, one common challenge is the cold-start problem, where interactions are very limited for fresh users in the systems. To address this challenge, recently, many works introduce the meta-optimization idea into the recommendation scenarios, i.e. learning to learn the user preference by only a few past interaction items. The core idea is to learn global shared meta-initialization parameters for all users and rapidly adapt them into local parameters for each user respectively. They aim at deriving general knowledge across preference learning of various users, so as to rapidly adapt to the future new user with the learned prior and a small amount of training data. However, previous works have shown that recommender systems are generally vulnerable to bias and unfairness. Despite the success of meta-learning at improving the recommendation performance with cold-start, the fairness issues are largely overlooked.In this paper, we propose a comprehensive fair meta-learning framework, named CLOVER, for ensuring the fairness of meta-learned recommendation models. We systematically study three kinds of fairness - individual fairness, counterfactual fairness, and group fairness in the recommender systems, and propose to satisfy all three kinds via a multi-task adversarial learning scheme. Our framework offers a generic training paradigm that is applicable to different meta-learned recommender systems. We demonstrate the effectiveness of CLOVER on the representative meta-learned user preference estimator on three real-world data sets. Empirical results show that CLOVER achieves comprehensive fairness without deteriorating the overall cold-start recommendation performance.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1989–1999},
numpages = {11},
keywords = {fairness, meta-learning, recommender systems},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3447548.3467421,
author = {Zhang, Sixiao and Chen, Hongxu and Ming, Xiao and Cui, Lizhen and Yin, Hongzhi and Xu, Guandong},
title = {Where are we in embedding spaces?},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467421},
doi = {10.1145/3447548.3467421},
abstract = {Hyperbolic space and hyperbolic embeddings are becoming a popular research field for recommender systems. However, it is not clear under what circumstances the hyperbolic space should be considered. To fill this gap, This paper provides theoretical analysis and empirical results on when and where to use hyperbolic space and hyperbolic embeddings in recommender systems. Specifically, we answer the questions that which type of models and datasets are more suited for hyperbolic space, as well as which latent size to choose. We evaluate our answers by comparing the performance of Euclidean space and hyperbolic space on different latent space models in both general item recommendation domain and social recommendation domain, with 6 widely used datasets and different latent sizes. Additionally, we propose a new metric learning based recommendation method called SCML and its hyperbolic version HSCML. We evaluate our conclusions regarding hyperbolic space on SCML and show the state-of-the-art performance of hyperbolic space by comparing HSCML with other baseline methods.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2223–2231},
numpages = {9},
keywords = {hyperbolic space, node embeddings, recommender systems},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/2939672.2939780,
author = {Mukherjee, Subhabrata and G\"{u}nnemann, Stephan and Weikum, Gerhard},
title = {Continuous Experience-aware Language Model},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939780},
doi = {10.1145/2939672.2939780},
abstract = {Online review communities are dynamic as users join and leave, adopt new vocabulary, and adapt to evolving trends. Recent work has shown that recommender systems benefit from explicit consideration of user experience. However, prior work assumes a fixed number of discrete experience levels, whereas in reality users gain experience and mature continuously over time. This paper presents a new model that captures the continuous evolution of user experience, and the resulting language model in reviews and other posts. Our model is unsupervised and combines principles of Geometric Brownian Motion, Brownian Motion, and Latent Dirichlet Allocation to trace a smooth temporal progression of user experience and language model respectively. We develop practical algorithms for estimating the model parameters from data and for inference with our model (e.g., to recommend items). Extensive experiments with five real-world datasets show that our model not only fits data better than discrete-model baselines, but also outperforms state-of-the-art methods for predicting item ratings.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1075–1084},
numpages = {10},
keywords = {brownian motion, language evolution, recommendation, review community, topic modeling, user experience},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/3534678.3539452,
author = {Chen, Yankai and Guo, Huifeng and Zhang, Yingxue and Ma, Chen and Tang, Ruiming and Li, Jingjie and King, Irwin},
title = {Learning Binarized Graph Representations with Multi-faceted Quantization Reinforcement for Top-K Recommendation},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539452},
doi = {10.1145/3534678.3539452},
abstract = {Learning vectorized embeddings is at the core of various recommender systems for user-item matching. To perform efficient online inference, representation quantization, aiming to embed the latent features by a compact sequence of discrete numbers, recently shows the promising potentiality in optimizing both memory and computation overheads. However, existing work merely focuses on numerical quantization whilst ignoring the concomitant information loss issue, which, consequently, leads to conspicuous performance degradation. In this paper, we propose a novel quantization framework to learn Binarized Graph Representations for Top-K Recommendation (BiGeaR). We introduce multi-faceted quantization reinforcement at the pre-, mid-, and post-stage of binarized representation learning, which substantially retains the informativeness against embedding binarization. In addition to saving the memory footprint, it further develops solid online inference acceleration with bitwise operations, providing alternative flexibility for the realistic deployment. The empirical results over five large real-world benchmarks show that BiGeaR achieves about 22%~40% performance improvement over the state-of-the-art quantization-based recommender system, and recovers about 95%~102% of the performance capability of the best full-precision counterpart with over 8\texttimes{} time and space reduction.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {168–178},
numpages = {11},
keywords = {embedding binarization, graph convolutional network, graph representation, quantization-based, recommender system},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3711896.3737116,
author = {Zhang, Zhaoyang and Chen, Ziqi and Liu, Qiao and Xie, Jinhan and Zhu, Hongtu},
title = {Sampling-guided Heterogeneous Graph Neural Network with Temporal Smoothing for Scalable Longitudinal Data Imputation},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737116},
doi = {10.1145/3711896.3737116},
abstract = {In this paper, we propose a novel framework, the Sampling-guided Heterogeneous Graph Neural Network (HT-GNN), to effectively tackle the challenge of missing data imputation in longitudinal studies. Unlike traditional methods, which often require extensive preprocessing to handle irregular or inconsistent missing data, our approach accommodates arbitrary missing data patterns while maintaining computational efficiency. HT-GNN models both observations and covariates as distinct node types, connecting observation nodes at successive time points through subject-specific longitudinal subnetworks, while covariate-observation interactions are represented by attributed edges within bipartite graphs. By leveraging subject-wise mini-batch sampling and a multi-layer temporal smoothing mechanism, HT-GNN efficiently scales to large datasets, while effectively learning node representations and imputing missing data. Extensive experiments on both synthetic and real-world datasets, including the Alzheimer's Disease Neuroimaging Initiative (DNI) dataset, demonstrate that HT-GNN significantly outperforms existing imputation methods, even with high missing data rates (e.g., 80%). The empirical results highlight HT-GNN's robust imputation capabilities and superior performance, particularly in the context of complex, large-scale longitudinal data.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {3912–3920},
numpages = {9},
keywords = {graph neural network, longitudinal data, missing data},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3711896.3736967,
author = {Liu, Chengkai and Zhang, Yangtian and Wang, Jianling and Ying, Rex and Caverlee, James},
title = {Flow Matching for Collaborative Filtering},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3736967},
doi = {10.1145/3711896.3736967},
abstract = {Generative models have shown great promise in collaborative filtering by capturing the underlying distribution of user interests and preferences. However, existing approaches struggle with inaccurate posterior approximations and misalignment with the discrete nature of recommendation data, limiting their expressiveness and real-world performance. To address these limitations, we propose FlowCF, a novel flow-based recommendation system leveraging flow matching for collaborative filtering. We tailor flow matching to the unique challenges in recommendation through two key innovations: (1) a behavior-guided prior that aligns with user behavior patterns to handle the sparse and heterogeneous user-item interactions, and (2) a discrete flow framework to preserve the binary nature of implicit feedback while maintaining the benefits of flow matching, such as stable training and efficient inference. Extensive experiments demonstrate that FlowCF achieves state-of-the-art recommendation accuracy across various datasets with the fastest inference speed, making it a compelling approach for real-world recommender systems. The code is available at https://github.com/chengkai-liu/FlowCF.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {1765–1775},
numpages = {11},
keywords = {collaborative filtering, flow matching, generative models, recommender systems},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3292500.3330952,
author = {Warlop, Romain and Mary, J\'{e}r\'{e}mie and Gartrell, Mike},
title = {Tensorized Determinantal Point Processes for Recommendation},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330952},
doi = {10.1145/3292500.3330952},
abstract = {Interest in determinantal point processes (DPPs) is increasing in machine learning due to their ability to provide an elegant parametric model over combinatorial sets. In particular, the number of required parameters in a DPP grows only quadratically with the size of the ground set (e.g., item catalog), while the number of possible sets of items grows exponentially. Recent work has shown that DPPs can be effective models for product recommendation and basket completion tasks, since they are able to account for both the diversity and quality of items within a set. We present an enhanced DPP model that is specialized for the task of basket completion, the tensorized DPP. We leverage ideas from tensor factorization in order to customize the model for the next-item basket completion task, where the next item is captured in an extra dimension of the model. We evaluate our model on several real-world datasets, and find that the tensorized DPP provides significantly better predictive quality in several settings than a number of state-of-the art models.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1605–1615},
numpages = {11},
keywords = {basket completion, determinantal point process, tensor},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1109/ASONAM55673.2022.10068664,
author = {Alanezi, Khaled and Albadi, Nuha and Hammad, Omar and Kurdi, Maram and Mishra, Shivakant},
title = {Understanding the Impact of Culture in Assessing Helpfulness of Online Reviews},
year = {2023},
isbn = {9781665456616},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASONAM55673.2022.10068664},
doi = {10.1109/ASONAM55673.2022.10068664},
abstract = {Online reviews have become essential for users to make informed decisions in everyday tasks ranging from planning summer vacations to purchasing groceries and making financial investments. A key problem in using online reviews is the overabundance of online that overwhelms the users. As a result, recommendation systems for providing helpfulness of reviews are being developed. This paper argues that cultural background is an important feature that impacts the nature of a review written by the user, and must be considered as a feature in assessing the helpfulness of online reviews. The paper provides an in-depth study of differences in online reviews written by users from different cultural backgrounds and how incorporating culture as a feature can lead to better review helpfulness recommendations. In particular, we analyze online reviews originating from two distinct cultural spheres, namely Arabic and Western cultures, for two different products, hotels and books. Our analysis demonstrates that the nature of reviews written by users differs based on their cultural backgrounds and that this difference varies based on the specific product being reviewed. Finally, we have developed six different review helpfulness recommendation models that demonstrate that taking culture into account leads to better recommendations.},
booktitle = {Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {308–315},
numpages = {8},
keywords = {online review helpfulness, cultural background, review recommendations},
location = {Istanbul, Turkey},
series = {ASONAM '22}
}

@inproceedings{10.1145/3394486.3403175,
author = {Jeunen, Olivier and Rohde, David and Vasile, Flavian and Bompaire, Martin},
title = {Joint Policy-Value Learning for Recommendation},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403175},
doi = {10.1145/3394486.3403175},
abstract = {Conventional approaches to recommendation often do not explicitly take into account information on previously shown recommendations and their recorded responses. One reason is that, since we do not know the outcome of actions the system did not take, learning directly from such logs is not a straightforward task. Several methods for off-policy or counterfactual learning have been proposed in recent years, but their efficacy for the recommendation task remains understudied. Due to the limitations of offline datasets and the lack of access of most academic researchers to online experiments, this is a non-trivial task. Simulation environments can provide a reproducible solution to this problem.In this work, we conduct the first broad empirical study of counterfactual learning methods for recommendation, in a simulated environment. We consider various different policy-based methods that make use of the Inverse Propensity Score (IPS) to perform Counterfactual Risk Minimisation (CRM), as well as value-based methods based on Maximum Likelihood Estimation (MLE). We highlight how existing off-policy learning methods fail due to stochastic and sparse rewards, and show how a logarithmic variant of the traditional IPS estimator can solve these issues, whilst convexifying the objective and thus facilitating its optimisation. Additionally, under certain assumptions the value- and policy-based methods have an identical parameterisation, allowing us to propose a new model that combines both the MLE and CRM objectives. Extensive experiments show that this "Dual Bandit" approach achieves state-of-the-art performance in a wide range of scenarios, for varying logging policies, action spaces and training sample sizes.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1223–1233},
numpages = {11},
keywords = {bandit feedback, counterfactual learning, policy learning},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3534678.3539092,
author = {Zhan, Ruohan and Pei, Changhua and Su, Qiang and Wen, Jianfeng and Wang, Xueliang and Mu, Guanyu and Zheng, Dong and Jiang, Peng and Gai, Kun},
title = {Deconfounding Duration Bias in Watch-time Prediction for Video Recommendation},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539092},
doi = {10.1145/3534678.3539092},
abstract = {Watch-time prediction remains to be a key factor in reinforcing user engagement via video recommendations. It has become increasingly important given the ever-growing popularity of online videos. However, prediction of watch time not only depends on the match between the user and the video but is often mislead by the duration of the video itself. With the goal of improving watch time, recommendation is always biased towards videos with long duration. Models trained on this imbalanced data face the risk of bias amplification, which misguides platforms to over-recommend videos with long duration but overlook the underlying user interests. This paper presents the first work to study duration bias in watch-time prediction for video recommendation. We employ a causal graph illuminating that duration is a confounding factor that concurrently affects video exposure and watch-time prediction---the first effect on video causes the bias issue and should be eliminated, while the second effect on watch time originates from video intrinsic characteristics and should be preserved. To remove the undesired bias but leverage the natural effect, we propose a Duration-Deconfounded Quantile-based (D2Q) watch-time prediction framework, which allows for scalability to perform on industry production systems. Through extensive offline evaluation and live experiments, we showcase the effectiveness of this duration-deconfounding framework by significantly outperforming the state-of-the-art baselines. We have fully launched our approach on Kuaishou App, which has substantially improved real-time video consumption due to more accurate watch-time predictions.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4472–4481},
numpages = {10},
keywords = {causal intervention, duration bias, video recommendation, watch-time prediction},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3711896.3736987,
author = {Lu, Zhufeng and Jia, Chentao and Hu, Ming and Xie, Xiaofei and Chen, Mingsong},
title = {Gradients as An Action: Towards Communication-Efficient Federated Recommender Systems via Adaptive Action Sharing},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3736987},
doi = {10.1145/3711896.3736987},
abstract = {As a promising privacy-aware collaborative model training paradigm, Federated Learning (FL) is becoming popular in the design of distributed recommender systems. However, Federated Recommender Systems (FedRecs) greatly suffer from two major problems: i) extremely high communication overhead due to massive item embeddings involved in recommendation systems, and ii) intolerably low training efficiency caused by the entanglement of both heterogeneous network environments and client devices. Although existing methods attempt to employ various compression techniques to reduce communication overhead, due to the parameter errors introduced by model compression, they inevitably suffer from model performance degradation. To simultaneously address the above problems, this paper presents a communication-efficient FedRec framework named FedRAS, which adopts an action-sharing strategy to cluster the gradients of item embedding into a specific number of model updating actions for communication rather than directly compressing the item embeddings. In this way, the cloud server can use the limited actions from clients to update all the items. Since gradient values are significantly smaller than item embeddings, constraining the directions of gradients (i.e., the action space) introduces smaller errors compared to compressing the entire item embedding matrix into a reduced space. To accommodate heterogeneous devices and network environments, FedRAS incorporates an adaptive clustering mechanism that dynamically adjusts the number of actions. Comprehensive experiments on well-known datasets demonstrate that FedRAS can reduce the size of communication payloads by up to 96.88%, while not sacrificing recommendation performance within various heterogeneous scenarios. We have open-sourced FedRAS at https://github.com/mastlab-T3S/FedRAS.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {1999–2009},
numpages = {11},
keywords = {clustering, communication efficiency, federated learning, gradient robustness, recommender systems},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3447548.3467376,
author = {Zhu, Ziwei and He, Yun and Zhao, Xing and Caverlee, James},
title = {Popularity Bias in Dynamic Recommendation},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467376},
doi = {10.1145/3447548.3467376},
abstract = {Popularity bias is a long-standing challenge in recommender systems: popular items are overly recommended at the expense of less popular items that users may be interested in being under-recommended. Such a bias exerts detrimental impact on both users and item providers, and many efforts have been dedicated to studying and solving such a bias. However, most existing works situate the popularity bias in a static setting, where the bias is analyzed only for a single round of recommendation with logged data. These works fail to take account of the dynamic nature of real-world recommendation process, leaving several important research questions unanswered: how does the popularity bias evolve in a dynamic scenario? what are the impacts of unique factors in a dynamic recommendation process on the bias? and how to debias in this long-term dynamic process? In this work, we investigate the popularity bias in dynamic recommendation and aim to tackle these research gaps. Concretely, we conduct an empirical study by simulation experiments to analyze popularity bias in the dynamic scenario and propose a dynamic debiasing strategy and a novel False Positive Correction method utilizing false positive signals to debias, which show effective performance in extensive experiments.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2439–2449},
numpages = {11},
keywords = {dynamic recommendation, popularity bias},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3690624.3709335,
author = {Lv, Zheqi and Zhan, Tianyu and Wang, Wenjie and Lin, Xinyu and Zhang, Shengyu and Zhang, Wenqiao and Li, Jiwei and Kuang, Kun and Wu, Fei},
title = {Collaboration of Large Language Models and Small Recommendation Models for Device-Cloud Recommendation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709335},
doi = {10.1145/3690624.3709335},
abstract = {Large Language Models (LLMs) for Recommendation (LLM4Rec) is a promising research direction that has demonstrated exceptional performance in this field. However, its inability to capture real-time user preferences greatly limits the practical application of LLM4Rec because (i) LLMs are costly to train and infer frequently, and (ii) LLMs struggle to access real-time data (its large number of parameters poses an obstacle to deployment on devices). Fortunately, small recommendation models (SRMs) can effectively supplement these shortcomings of LLM4Rec diagrams by consuming minimal resources for frequent training and inference, and by conveniently accessing real-time data on devices.In light of this, we designed the Device-Cloud LLM-SRM Collaborative Recommendation Framework (LSC4Rec) under a device-cloud collaboration setting. LSC4Rec aims to integrate the advantages of both LLMs and SRMs, as well as the benefits of cloud and edge computing, achieving a complementary synergy. We enhance the practicability of LSC4Rec by designing three strategies: collaborative training, collaborative inference, and intelligent request. During training, LLM generates candidate lists to enhance the ranking ability of SRM in collaborative scenarios and enables SRM to update adaptively to capture real-time user interests. During inference, LLM and SRM are deployed on the cloud and on the device, respectively. LLM generates candidate lists and initial ranking results based on user behavior, and SRM get reranking results based on the candidate list, with final results integrating both LLM's and SRM's scores. The device determines whether a new candidate list is needed by comparing the consistency of the LLM's and SRM's sorted lists. Our comprehensive and extensive experimental analysis validates the effectiveness of each strategy in LSC4Rec.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {962–973},
numpages = {12},
keywords = {device-cloud collaboration, large language model, sequential recommendation},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3394486.3403207,
author = {Lu, Yuanfu and Fang, Yuan and Shi, Chuan},
title = {Meta-learning on Heterogeneous Information Networks for Cold-start Recommendation},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403207},
doi = {10.1145/3394486.3403207},
abstract = {Cold-start recommendation has been a challenging problem due to sparse user-item interactions for new users or items. Existing efforts have alleviated the cold-start issue to some extent, most of which approach the problem at the data level. Earlier methods often incorporate auxiliary data as user or item features, while more recent methods leverage heterogeneous information networks (HIN) to capture richer semantics via higher-order graph structures. On the other hand, recent meta-learning paradigm sheds light on addressing cold-start recommendation at the model level, given its ability to rapidly adapt to new tasks with scarce labeled data, or in the context of cold-start recommendation, new users and items with very few interactions. Thus, we are inspired to develop a novel meta-learning approach named MetaHIN to address cold-start recommendation on HINs, to exploit the power of meta-learning at the model level and HINs at the data level simultaneously. The solution is non-trivial, for how to capture HIN-based semantics in the meta-learning setting, and how to learn the general knowledge that can be easily adapted to multifaceted semantics, remain open questions. In MetaHIN, we propose a novel semantic-enhanced tasks constructor and a co-adaptation meta-learner to address the two questions. Extensive experiments demonstrate that MetaHIN significantly outperforms the state of the arts in various cold-start scenarios. (Code and dataset are available at https://github.com/rootlu/MetaHIN.)},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1563–1573},
numpages = {11},
keywords = {cold-start recommendation, heterogeneous information network, meta-learning},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3219819.3220044,
author = {Luo, Luo and Zhang, Wenpeng and Zhang, Zhihua and Zhu, Wenwu and Zhang, Tong and Pei, Jian},
title = {Sketched Follow-The-Regularized-Leader for Online Factorization Machine},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220044},
doi = {10.1145/3219819.3220044},
abstract = {Factorization Machine (FM) is a supervised machine learning model for feature engineering, which is widely used in many real-world applications. In this paper, we consider the case that the data samples arrive sequentially. The existing convex formulation for online FM has the strong theoretical guarantee and stable performance in practice, but the computational cost is typically expensive when the data is high-dimensional. To address this weakness, we devise a novel online learning algorithm called Sketched Follow-The-Regularizer-Leader (SFTRL). SFTRL presents the parameters of FM implicitly by maintaining low-rank matrices and updates the parameters via sketching. More specifically, we propose Generalized Frequent Directions to approximate indefinite symmetric matrices in a streaming way, making that the sum of historical gradients for FM could be estimated with tighter error bound efficiently. With mild assumptions, we prove that the regret bound of SFTRL is close to that of the standard FTRL. Experimental results show that SFTRL has better prediction quality than the state-of-the-art online FM algorithms in much lower time and space complexities.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1900–1909},
numpages = {10},
keywords = {convex online learning, factorization machine, follow-the-regularized-leader, sketching},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3097983.3098170,
author = {Bauman, Konstantin and Liu, Bing and Tuzhilin, Alexander},
title = {Aspect Based Recommendations: Recommending Items with the Most Valuable Aspects Based on User Reviews},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098170},
doi = {10.1145/3097983.3098170},
abstract = {In this paper, we propose a recommendation technique that not only can recommend items of interest to the user as traditional recommendation systems do but also specific aspects of consumption of the items to further enhance the user experience with those items. For example, it can recommend the user to go to a specific restaurant (item) and also order some specific foods there, e.g., seafood (an aspect of consumption). Our method is called Sentiment Utility Logistic Model (SULM). As its name suggests, SULM uses sentiment analysis of user reviews. It first predicts the sentiment that the user may have about the item based on what he/she might express about the aspects of the item and then identifies the most valuable aspects of the user's potential experience with that item. Furthermore, the method can recommend items together with those most important aspects over which the user has control and can potentially select them, such as the time to go to a restaurant, e.g. lunch vs. dinner, and what to order there, e.g., seafood. We tested the proposed method on three applications (restaurant, hotel, and beauty &amp; spa) and experimentally showed that those users who followed our recommendations of the most valuable aspects while consuming the items, had better experiences, as defined by the overall rating.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {717–725},
numpages = {9},
keywords = {aspects of user experience, recommender systems, sentiment analysis, user experience, user reviews, user-controlled aspects},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3394486.3403121,
author = {Sakhi, Otmane and Bonner, Stephen and Rohde, David and Vasile, Flavian},
title = {BLOB: A Probabilistic Model for Recommendation that Combines Organic and Bandit Signals},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403121},
doi = {10.1145/3394486.3403121},
abstract = {A common task for recommender systems is to build a profile of the interests of a user from items in their browsing history and later to recommend items to the user from the same catalog. The users' behavior consists of two parts: the sequence of items that they viewed without intervention (the organic part) and the sequences of items recommended to them and their outcome (the bandit part).In this paper, we propose Bayesian Latent Organic Bandit model (BLOB), a probabilistic approach to combine the 'organic' and 'bandit' signals in order to improve the estimation of recommendation quality. The bandit signal is valuable as it gives direct feedback of recommendation performance, but the signal quality is very uneven, as it is highly concentrated on the recommendations deemed optimal by the past version of the recommender system. In contrast, the organic signal is typically strong and covers most items, but is not always relevant to the recommendation task. In order to leverage the organic signal to efficiently learn the bandit signal in a Bayesian model we identify three fundamental types of distances, namely action-history, action-action and history-history distances. We implement a scalable approximation of the full model using variational auto-encoders and the local re-paramerization trick. We show using extensive simulation studies that our method out-performs or matches the value of both state-of-the-art organic-based recommendation algorithms, and of bandit-based methods (both value and policy-based) both in organic and bandit-rich environments.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {783–793},
numpages = {11},
keywords = {Bayesian inference, latent variable models, recommender systems},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3690624.3709319,
author = {Gu, Hengnian and Luo, Guoqian and Dong, Xiaoxiao and Li, Shulin and Zhou, Dongdai},
title = {Revisiting Cognition in Neural Cognitive Diagnosis},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709319},
doi = {10.1145/3690624.3709319},
abstract = {Cognitive diagnosis is a fundamental task in intelligent education, aiming to measure students' proficiency on knowledge concepts based on practice data. Traditional methods utilize a broadly-defined latent trait θ to represent knowledge proficiency with some cognitive factors like skill or ability. However, existing methods simplify this to a narrowly-defined latent trait θ, which focuses only on knowledge or treats these cognitive factors as implicit features inferred from data. They fail to explicitly model these cognitive factors, resulting in limited performance and interpretability. To this end, we revisit essence of cognition in Educational Psychology Theory and propose a novel Cognition-aware Cognitive Diagnosis (CCD) model, where we first introduce the Cognition factor as a bridge into the long-standing three-basic-factors (Student, Exercise, Knowledge concept) paradigm. CCD has two main parts: cognition representations and a two-stage diagnostic process. In the first part, we explicitly model cognitive process (CP) dimensions from Bloom's Taxonomy of Educational Objectives, leading to two innovative concepts proposed: the student's Subjective Cognitive Ability (SCA) and the exercise's Objective Cognitive Attribute (OCA), derived by regulating the CP through S-K and E-K interactions, respectively. Then, the SCA and OCA are formed into a new cognition-aware latent trait θ. In the second part, we employ a basic interaction function and a slip and guess influence function, inputting our new θ, a continuous Q-matrix (generated by a siamese PLMs), and other features to obtain the ideal result, followed by feeding it into the slip and guess influence function to obtain the actual result. Extensive experiments on real-world datasets demonstrates the superior effectiveness and good interpretability.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {402–412},
numpages = {11},
keywords = {cognitive diagnosis, educational data mining, intelligent education},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3637528.3671901,
author = {Wu, Junda and Chang, Cheng-Chun and Yu, Tong and He, Zhankui and Wang, Jianing and Hou, Yupeng and McAuley, Julian},
title = {CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671901},
doi = {10.1145/3637528.3671901},
abstract = {The long-tail recommendation is a challenging task for traditional recommender systems, due to data sparsity and data imbalance issues. The recent development of large language models (LLMs) has shown their abilities in complex reasoning, which can help to deduce users' preferences based on very few previous interactions. However, since most LLM-based systems rely on items' semantic meaning as the sole evidence for reasoning, the collaborative information of user-item interactions is neglected, which can cause the LLM's reasoning to be misaligned with task-specific collaborative information of the dataset. To further align LLMs' reasoning to task-specific user-item interaction knowledge, we introduce collaborative retrieval-augmented LLMs, CoRAL, which directly incorporate collaborative evidence into the prompts. Based on the retrieved user-item interactions, the LLM can analyze shared and distinct preferences among users, and summarize the patterns indicating which types of users would be attracted by certain items. The retrieved collaborative evidence prompts the LLM to align its reasoning with the user-item interaction patterns in the dataset. However, since the capacity of the input prompt is limited, finding the minimally-sufficient collaborative information for recommendation tasks can be challenging. We propose to find the optimal interaction set through a sequential decision-making process and develop a retrieval policy learned through a reinforcement learning (RL) framework, CoRAL. Our experimental results show that CoRAL can significantly improve LLMs' reasoning abilities on specific recommendation tasks. Our analysis also reveals that CoRAL can more efficiently explore collaborative information through reinforcement learning.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3391–3401},
numpages = {11},
keywords = {collaborative filtering, large language models, long-tail recommendation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671958,
author = {Sun, Youchen and Sun, Zhu and Du, Yingpeng and Zhang, Jie and Ong, Yew Soon},
title = {Self-Supervised Denoising through Independent Cascade Graph Augmentation for Robust Social Recommendation},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671958},
doi = {10.1145/3637528.3671958},
abstract = {Social Recommendation (SR) typically exploits neighborhood influence in the social network to enhance user preference modeling. However, users' intricate social behaviors may introduce noisy social connections for user modeling and harm the models' robustness. Existing solutions to alleviate social noise either filter out the noisy connections or generate new potential social connections. Due to the absence of labels, the former approaches may retain uncertain connections for user preference modeling while the latter methods may introduce additional social noise. Through data analysis, we discover that (1) social noise likely comes from the connected users with low preference similarity; and (2) Opinion Leaders (OLs) play a pivotal role in influence dissemination, surpassing high-similarity neighbors, regardless of their preference similarity with trusting peers. Guided by these observations, we propose a novel Self-Supervised Denoising approach through Independent Cascade Graph Augmentation, for more robust SR. Specifically, we employ the independent cascade diffusion model to generate an augmented graph view, which traverses the social graph and activates the edges in sequence to simulate the cascading influence spread. To steer the augmentation towards a denoised social graph, we (1) introduce a hierarchical contrastive loss to prioritize the activation of OLs first, followed by high-similarity neighbors, while weakening the low-similarity neighbors; and (2) integrate an information bottleneck based contrastive loss, aiming to minimize mutual information between original and augmented graphs yet preserve sufficient information for improved SR. Experiments conducted on two public datasets demonstrate that our model outperforms the state-of-the-art while also exhibiting higher robustness to different extents of social noise.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2806–2817},
numpages = {12},
keywords = {graph denoising, independent cascade, self-supervised learning, social recommender system},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671795,
author = {Wang, Zongwei and Yu, Junliang and Gao, Min and Yin, Hongzhi and Cui, Bin and Sadiq, Shazia},
title = {Unveiling Vulnerabilities of Contrastive Recommender Systems to Poisoning Attacks},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671795},
doi = {10.1145/3637528.3671795},
abstract = {Contrastive learning (CL) has recently gained prominence in the domain of recommender systems due to its great ability to enhance recommendation accuracy and improve model robustness. Despite its advantages, this paper identifies a vulnerability of CL-based recommender systems that they are more susceptible to poisoning attacks aiming to promote individual items. Our analysis indicates that this vulnerability is attributed to the uniform spread of representations caused by the InfoNCE loss. Furthermore, theoretical and empirical evidence shows that optimizing this loss favors smooth spectral values of representations. This finding suggests that attackers could facilitate this optimization process of CL by encouraging a more uniform distribution of spectral values, thereby enhancing the degree of representation dispersion. With these insights, we attempt to reveal a potential poisoning attack against CL-based recommender systems, which encompasses a dual-objective framework: one that induces a smoother spectral value distribution to amplify the InfoNCE loss's inherent dispersion effect, named dispersion promotion; and the other that directly elevates the visibility of target items, named rank promotion. We validate the threats of our attack model through extensive experimentation on four datasets. By shedding light on these vulnerabilities, our goal is to advance the development of more robust CL-based recommender systems. The code is available at https://github.com/CoderWZW/ARLib.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3311–3322},
numpages = {12},
keywords = {contrastive learning, poisoning attacks, recommender systems, self-supervised learning},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3292500.3330880,
author = {Chen, Yihong and Chen, Bei and He, Xiangnan and Gao, Chen and Li, Yong and Lou, Jian-Guang and Wang, Yue},
title = {λOpt: Learn to Regularize Recommender Models in Finer Levels},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330880},
doi = {10.1145/3292500.3330880},
abstract = {Recommendation models mainly deal with categorical variables, such as user/item ID and attributes. Besides the high-cardinality issue, the interactions among such categorical variables are usually long-tailed, with the head made up of highly frequent values and a long tail of rare ones. This phenomenon results in the data sparsity issue, making it essential to regularize the models to ensure generalization. The common practice is to employ grid search to manually tune regularization hyperparameters based on the validation data. However, it requires non-trivial efforts and large computation resources to search the whole candidate space; even so, it may not lead to the optimal choice, for which different parameters should have different regularization strengths. In this paper, we propose a hyperparameter optimization method, lambdaOpt, which automatically and adaptively enforces regularization during training. Specifically, it updates the regularization coefficients based on the performance of validation data. With lambdaOpt, the notorious tuning of regularization hyperparameters can be avoided; more importantly, it allows fine-grained regularization (i.e. each parameter can have an individualized regularization coefficient), leading to better generalized models. We show how to employ lambdaOpt on matrix factorization, a classical model that is representative of a large family of recommender models. Extensive experiments on two public benchmarks demonstrate the superiority of our method in boosting the performance of top-K recommendation.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {978–986},
numpages = {9},
keywords = {matrix factorization, regularization hyperparameter, top-k recommendation},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/3711896.3737176,
author = {Jin, Jiahui and Song, Yifan and Kan, Dong and Zhu, Haojia and Sun, Xiangguo and Li, Zhicheng and Sun, Xigang and Zhang, Jinghui},
title = {Urban Region Pre-training and Prompting: A Graph-based Approach},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737176},
doi = {10.1145/3711896.3737176},
abstract = {Urban region representation is crucial for various urban downstream tasks. However, despite the proliferation of methods and their success, acquiring general urban region knowledge and adapting to different tasks remains challenging. Existing work pays limited attention to the fine-grained functional layout semantics in urban regions, limiting their ability to capture transferable knowledge across regions. Further, inadequate handling of the unique features and relationships required for different downstream tasks may also hinder effective task adaptation. In this paper, we propose a Graph-based Urban Region Pre-training and Prompting framework (GURPP) for region representation learning. Specifically, we first construct an urban region graph and develop a subgraph-centric urban region pre-training model to capture the heterogeneous and transferable patterns of entity interactions. This model pre-trains knowledge-rich region embeddings using contrastive learning and multi-view learning methods. To further refine these representations, we design two graph-based prompting methods: a manually-defined prompt to incorporate explicit task knowledge and a task-learnable prompt to discover hidden knowledge, which enhances the adaptability of these embeddings to different tasks. Extensive experiments on various urban region prediction tasks and different cities demonstrate the superior performance of our framework.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {1071–1082},
numpages = {12},
keywords = {graph prompt, region representation, urban foundation model},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/2487575.2487656,
author = {Niemann, Katja and Wolpers, Martin},
title = {A new collaborative filtering approach for increasing the aggregate diversity of recommender systems},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487656},
doi = {10.1145/2487575.2487656},
abstract = {In order to satisfy and positively surprise the users, a recommender system needs to recommend items the users will like and most probably would not have found on their own. This requires the recommender system to recommend a broader range of items including niche items as well. Such an approach also support online-stores that often offer more items than traditional stores and need recommender systems to enable users to find the not so popular items as well. However, popular items that hold a lot of usage data are more easy to recommend and, thus, niche items are often excluded from the recommendations. In this paper, we propose a new collaborative filtering approach that is based on the items' usage contexts. The approach increases the rating predictions for niche items with fewer usage data available and improves the aggragate diversity of the recommendations.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {955–963},
numpages = {9},
keywords = {aggregate diversity, item-item similarity, long tail, niche items, recommender systems, usage context},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@inproceedings{10.1145/3637528.3671523,
author = {Fu, Cong and Wang, Kun and Wu, Jiahua and Chen, Yizhou and Huzhang, Guangda and Ni, Yabo and Zeng, Anxiang and Zhou, Zhiming},
title = {Residual Multi-Task Learner for Applied Ranking},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671523},
doi = {10.1145/3637528.3671523},
abstract = {Modern e-commerce platforms rely heavily on modeling diverse user feedback to provide personalized services. Consequently, multi-task learning has become an integral part of their ranking systems. However, existing multi-task learning methods encounter two main challenges: some lack explicit modeling of task relationships, resulting in inferior performance, while others have limited applicability due to being computationally intensive, having scalability issues, or relying on strong assumptions. To address these limitations and better fit our real-world scenario, pre-rank in Shopee Search, we introduce in this paper ResFlow, a lightweight multi-task learning framework that enables efficient cross-task information sharing via residual connections between corresponding layers of task networks. Extensive experiments on datasets from various scenarios and modalities demonstrate its superior performance and adaptability over state-of-the-art methods. The online A/B tests in Shopee Search showcase its practical value in large-scale industrial applications, evidenced by a 1.29% increase in OPU (order-per-user) without additional system latency. ResFlow is now fully deployed in the pre-rank module of Shopee Search. To facilitate efficient online deployment, we propose a novel offline metric Weighted Recall@K, which aligns well with our online metric OPU, addressing the longstanding online-offline metric misalignment issue. Besides, we propose to fuse scores from the multiple tasks additively when ranking items, which outperforms traditional multiplicative fusion.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4974–4985},
numpages = {12},
keywords = {e-commerce, multi-task learning, ranking system, residual learning},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3487351.3488555,
author = {Chen, Ninghan and Chen, Xihui and Zhong, Zhiqiang and Pang, Jun},
title = {From #jobsearch to #mask: improving COVID-19 cascade prediction with spillover effects},
year = {2022},
isbn = {9781450391283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487351.3488555},
doi = {10.1145/3487351.3488555},
abstract = {An information outbreak occurs on social media along with the COVID-19 pandemic and leads to infodemic. Predicting the popularity of online content, known as cascade prediction, allows for not only catching in advance hot information that deserves attention, but also identifying false information that will widely spread and require quick response to mitigate its impact. Among the various information diffusion patterns leveraged in previous works, the spillover effect of the information exposed to users on their decision to participate in diffusing certain information is still not studied. In this paper, we focus on the diffusion of information related to COVID-19 preventive measures. Through our collected Twitter dataset, we validated the existence of this spillover effect. Building on the finding, we proposed extensions to three cascade prediction methods based on Graph Neural Networks (GNNs). Experiments conducted on our dataset demonstrated that the use of the identified spillover effect significantly improves the state-of-the-art GNNs methods in predicting the popularity of not only preventive measure messages, but also other COVID-19 related messages.},
booktitle = {Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {455–462},
numpages = {8},
location = {Virtual Event, Netherlands},
series = {ASONAM '21}
}

@inproceedings{10.1145/3637528.3671976,
author = {Chen, Zonghao and Guo, Ruocheng and Ton, Jean-Francois and Liu, Yang},
title = {Conformal Counterfactual Inference under Hidden Confounding},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671976},
doi = {10.1145/3637528.3671976},
abstract = {Personalized decision making requires the knowledge of potential outcomes under different treatments, and confidence intervals about the potential outcomes further enrich this decision-making process and improve its reliability in high-stakes scenarios. Predicting potential outcomes along with its uncertainty in a counterfactual world poses the foundamental challenge in causal inference. Existing methods that construct confidence intervals for counterfactuals either rely on the assumption of strong ignorability that completely ignores hidden confounders, or need access to un-identifiable lower and upper bounds that characterize the difference between observational and interventional distributions. In this paper, to overcome these limitations, we first propose a novel approach wTCP-DR based on transductive weighted conformal prediction, which provides confidence intervals for counterfactual outcomes with marginal converage guarantees, even under hidden confounding. With less restrictive assumptions, our approach requires access to a fraction of interventional data (from randomized controlled trials) to account for the covariate shift from observational distributoin to interventional distribution. Theoretical results explicitly demonstrate the conditions under which our algorithm is strictly advantageous to the naive method that only uses interventional data. Since transductive conformal prediction is notoriously costly, we propose wSCP-DR, a two-stage variant of wTCP-DR, based on split conformal prediction with same marginal coverage guarantees but at a significantly lower computational cost. After ensuring valid intervals on counterfactuals, it is straightforward to construct intervals for individual treatment effects (ITEs). We demonstrate our method across synthetic and real-world data, including recommendation systems, to verify the superiority of our methods compared against state-of-the-art baselines in terms of both coverage and efficiency. Our code can be found at https://github.com/rguo12/KDD24-Conformal.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {397–408},
numpages = {12},
keywords = {causal inference, conformal prediction, uncertainty quantification},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3097983.3098063,
author = {Zhao, Huan and Yao, Quanming and Li, Jianda and Song, Yangqiu and Lee, Dik Lun},
title = {Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098063},
doi = {10.1145/3097983.3098063},
abstract = {Heterogeneous Information Network (HIN) is a natural and general representation of data in modern large commercial recommender systems which involve heterogeneous types of data. HIN based recommenders face two problems: how to represent the high-level semantics of recommendations and how to fuse the heterogeneous information to make recommendations. In this paper, we solve the two problems by first introducing the concept of meta-graph to HIN-based recommendation, and then solving the information fusion problem with a "matrix factorization (MF) + factorization machine (FM)" approach. For the similarities generated by each meta-graph, we perform standard MF to generate latent features for both users and items. With different meta-graph based features, we propose to use FM with Group lasso (FMG) to automatically learn from the observed ratings to effectively select useful meta-graph based features. Experimental results on two real-world datasets, Amazon and Yelp, show the effectiveness of our approach compared to state-of-the-art FM and other HIN-based recommendation algorithms.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {635–644},
numpages = {10},
keywords = {collaborative filtering, factorization machine, heterogeneous information networks, recommendation system},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3580305.3599834,
author = {Chen, Xiaohui and Sun, Jiankai and Wang, Taiqing and Guo, Ruocheng and Liu, Li-Ping and Zhang, Aonan},
title = {Graph-Based Model-Agnostic Data Subsampling for Recommendation Systems},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599834},
doi = {10.1145/3580305.3599834},
abstract = {Data subsampling is widely used to speed up the training of large-scale recommendation systems. Most subsampling methods are model-based and often require a pre-trained pilot model to measure data importance via e.g. sample hardness. However, when the pilot model is misspecified, model-based subsampling methods deteriorate. Since model misspecification is persistent in real recommendation systems, we instead propose model-agnostic data subsampling methods by only exploring input data structure represented by graphs. Specifically, we study the topology of the user-item graph to estimate the importance of each user-item interaction (an edge in the user-item graph) via graph conductance, followed by a propagation step on the network to smooth out the estimated importance value. Since our proposed method is model-agnostic, we can marry the merits of both model-agnostic and model-based subsampling methods. Empirically, we show that combing the two consistently improves over any single method on the used datasets. Experimental results on KuaiRec and MIND datasets demonstrate that our proposed methods achieve superior results compared to baseline approaches.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3865–3876},
numpages = {12},
keywords = {data subsampling, network analysis, recommender systems},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3219819.3219965,
author = {Hu, Binbin and Shi, Chuan and Zhao, Wayne Xin and Yu, Philip S.},
title = {Leveraging Meta-path based Context for Top- N Recommendation with A Neural Co-Attention Model},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219965},
doi = {10.1145/3219819.3219965},
abstract = {Heterogeneous information network (HIN) has been widely adopted in recommender systems due to its excellence in modeling complex context information. Although existing HIN based recommendation methods have achieved performance improvement to some extent, they have two major shortcomings. First, these models seldom learn an explicit representation for path or meta-path in the recommendation task. Second, they do not consider the mutual effect between the meta-path and the involved user-item pair in an interaction. To address these issues, we develop a novel deep neural network with the co-attention mechanism for leveraging rich meta-path based context for top-N recommendation. We elaborately design a three-way neural interaction model by explicitly incorporating meta-path based context. To construct the meta-path based context, we propose to use a priority based sampling technique to select high-quality path instances. Our model is able to learn effective representations for users, items and meta-path based context for implementing a powerful interaction function. The co-attention mechanism improves the representations for meta-path based con- text, users and items in a mutual enhancement way. Extensive experiments on three real-world datasets have demonstrated the effectiveness of the proposed model. In particular, the proposed model performs well in the cold-start scenario and has potentially good interpretability for the recommendation results.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1531–1540},
numpages = {10},
keywords = {attention mechanism, deep learning, heterogeneous information network, recommender system},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3341161.3343672,
author = {Pourali, Alireza and Zarrinkalam, Fattane and Bagheri, Ebrahim},
title = {Neural embedding features for point-of-interest recommendation},
year = {2020},
isbn = {9781450368681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341161.3343672},
doi = {10.1145/3341161.3343672},
abstract = {The focus of point-of-interest recommendation techniques is to suggest a venue to a given user that would match the users' interests and is likely to be adopted by the user. Given the multitude of venues and the sparsity of user check-ins, the problem of recommending venues has shown to be a difficult task. Existing literature has already explored various types of features such as geographical distribution, social structure and temporal behavioral patterns to make a recommendation. In this paper, we propose a new set of features derived based on the neural embeddings of venues and users. We show how the neural embeddings for users and venues can be jointly learnt based on the prior check-in sequence of users and then be used to define three types of features, namely user, venue, and user-venue interaction features. These features are integrated into a feature-based matrix factorization model. Our experiments show that the features defined over the user and venue embeddings are effective for venue recommendation.},
booktitle = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {657–662},
numpages = {6},
keywords = {feature-based matrix factorization, neural embedding, point-of-interest recommendation},
location = {Vancouver, British Columbia, Canada},
series = {ASONAM '19}
}

@inproceedings{10.1145/2623330.2623657,
author = {Li, Chung-Yi and Lin, Shou-De},
title = {Matching users and items across domains to improve the recommendation quality},
year = {2014},
isbn = {9781450329569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2623330.2623657},
doi = {10.1145/2623330.2623657},
abstract = {Given two homogeneous rating matrices with some overlapped users/items whose mappings are unknown, this paper aims at answering two questions. First, can we identify the unknown mapping between the users and/or items? Second, can we further utilize the identified mappings to improve the quality of recommendation in either domain? Our solution integrates a latent space matching procedure and a refining process based on the optimization of prediction to identify the matching. Then, we further design a transfer-based method to improve the recommendation performance. Using both synthetic and real data, we have done extensive experiments given different real life scenarios to verify the effectiveness of our models. The code and other materials are available at http://www.csie.ntu.edu.tw/~r00922051/matching/},
booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {801–810},
numpages = {10},
keywords = {collaborative filtering, matrix factorization, transfer learning},
location = {New York, New York, USA},
series = {KDD '14}
}

@inproceedings{10.1145/3580305.3599919,
author = {Lin, Xiao and Chen, Xiaokai and Song, Linfeng and Liu, Jingwei and Li, Biao and Jiang, Peng},
title = {Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599919},
doi = {10.1145/3580305.3599919},
abstract = {An accurate prediction of watch time has been of vital importance to enhance user engagement in video recommender systems. To achieve this, there are four properties that a watch time prediction framework should satisfy: first, despite its continuous value, watch time is also an ordinal variable and the relative ordering between its values reflects the differences in user preferences. Therefore the ordinal relations should be reflected in watch time predictions. Second, the conditional dependence between the video-watching behaviors should be captured in the model. For instance, one has to watch half of the video before he/she finishes watching the whole video. Third, modeling watch time with a point estimation ignores the fact that models might give results with high uncertainty and this could cause bad cases in recommender systems. Therefore the framework should be aware of prediction uncertainty. Forth, the real-life recommender systems suffer from severe bias amplifications thus an estimation without bias amplification is expected.How to design a framework that solves these four issues simultaneously remain unexplored. Therefore we propose TPM (Tree-based Progressive regression Model) for watch time prediction. Specifically, the ordinal ranks of watch time are introduced into TPM and the problem is decomposed into a series of conditional dependent classification tasks which are organized into a tree structure. The expectation of watch time can be generated by traversing the tree and the variance of watch time predictions is explicitly introduced into the objective function as a measurement for uncertainty. Moreover, we illustrate that backdoor adjustment can be seamlessly incorporated into TPM, which alleviates bias amplifications.Extensive offline evaluations have been conducted in public datasets and TPM have been deployed in a real-world video app Kuaishou with over 300 million DAUs. The results indicate that TPM outperforms state-of-the-art approaches and indeed improves video consumption significantly.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4497–4506},
numpages = {10},
keywords = {ordinal regression, recommender system, tree based model, watch time prediction},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599826,
author = {Wang, Jianling and Lu, Haokai and Zhang, Sai and Locanthi, Bart and Wang, Haoting and Greaves, Dylan and Lipshitz, Benjamin and Badam, Sriraj and Chi, Ed H. and Goodrow, Cristos J. and Wu, Su-Lin and Baugher, Lexi and Chen, Minmin},
title = {Fresh Content Needs More Attention: Multi-funnel Fresh Content Recommendation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599826},
doi = {10.1145/3580305.3599826},
abstract = {Recommendation system serves as a conduit connecting users to an incredibly large, diverse and ever growing collection of contents. In practice, missing information on fresh (and tail) contents needs to be filled in order for them to be exposed and discovered by their audience. We here share our success stories in building a dedicated fresh content recommendation stack on a large commercial platform. To nominate fresh contents, we built a multi-funnel nomination system that combines (i) a two-tower model with strong generalization power for coverage, and (ii) a sequence model with near real-time update on user feedback for relevance. The multi-funnel setup effectively balances between coverage and relevance. An in-depth study uncovers the relationship between user activity level and their proximity toward fresh contents, which further motivates a contextual multi-funnel setup. Nominated fresh candidates are then scored and ranked by systems considering prediction uncertainty to further bootstrap content with less exposure. We evaluate the benefits of the dedicated fresh content recommendation stack, and the multi-funnel nomination system in particular, through user corpus co-diverted live experiments. We conduct multiple rounds of live experiments on a commercial platform serving billion of users demonstrating efficacy of our proposed methods.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5082–5091},
numpages = {10},
keywords = {cold-start recommendation, content generalization, hybrid recommendation systems, real-time learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3637528.3671837,
author = {Ning, Liang-bo and Wang, Shijie and Fan, Wenqi and Li, Qing and Xu, Xin and Chen, Hao and Huang, Feiran},
title = {CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671837},
doi = {10.1145/3637528.3671837},
abstract = {Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2284–2295},
numpages = {12},
keywords = {adversarial attacks, large language models, llm-empowered recommender systems, llms-based agent, recommender systems},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3534678.3542896,
author = {Corizzo, Roberto and Ge, Junfeng and Bellinger, Colin and Zhu, Xiaoqiang and Branco, Paula and Lee, Kuang-chih and Japkowicz, Nathalie and Tang, Ruiming and Zhuang, Tao and Zhu, Han and Jiang, Biye and Mao, Jiaxin and Zhang, Weinan},
title = {4th Workshop on Deep Learning Practice and Theory for High-Dimensional Sparse and Imbalanced Data with KDD 2022},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3542896},
doi = {10.1145/3534678.3542896},
abstract = {Recently, we have witnessed that deep learning-based approaches have been widely applied. Particularly, some applications involve data that are high dimensional, sparse or imbalanced, which are different from those applications with dense data processing, such as image classification and speech recognition, where deep learning-based approaches have been extensively studied. One of the main applications is the user-centric platform that consists of great deal of users, items and user generated tabular data which are quite high-dimensional. The characteristics of such data pose unique challenges to the adoption of deep learning in these applications, including modeling, training, and online serving, etc. More and more communities from both academia and industry have initiated the endeavors to solve these challenges. This workshop will provide a venue for both the research and engineering communities to discuss and formulate the challenges, utilize opportunities, and propose new ideas in the practice and theory of deep learning on high-dimensional, sparse and imbalanced data.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4860–4861},
numpages = {2},
keywords = {deep learning, high-dimensional, imbalanced data, sparse data},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3625007.3627520,
author = {Mohammadinodooshan, Alireza and Holmgren, William and Christensson, Martin and Carlsson, Niklas},
title = {A Clone-based Analysis of the Content-Agnostic Factors Driving News Article Popularity on Twitter},
year = {2024},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625007.3627520},
doi = {10.1145/3625007.3627520},
abstract = {The significant impact of Twitter in news dissemination underscores the need to understand what drives tweet popularity. While the content of an article plays a role, several "content-agnostic" factors also influence tweet popularity. Previous studies have faced challenges in differentiating the effects of content-agnostic factors from content variations. To address this, the paper presents a comprehensive analysis of tweet popularity using a "clone-based" approach. The methodology involves identifying tweets linking the same or similar articles (clones) and studying the factors that make some tweets within clone sets more successful in attracting retweets. The analysis reveals insights into clone set characteristics, winners' success patterns, retweet dynamics over time, domain-based competition, and predictors of success. The findings shed light on the complex nature of popularity and success in social media, providing a deeper understanding of the content-agnostic factors that influence tweet popularity.},
booktitle = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {17–24},
numpages = {8},
location = {Kusadasi, Turkiye},
series = {ASONAM '23}
}

@inproceedings{10.5555/3382225.3382300,
author = {Sharma, Vishal and Lee, Kyumin},
title = {Predicting highly rated crowdfunded products},
year = {2020},
isbn = {9781538660515},
publisher = {IEEE Press},
abstract = {Online crowdfunding platforms have given creators new opportunities to obtain funding. Despite the popularity and success of many projects on the platforms, the quality of crowd-funded products in the market (e.g., Amazon) was not statistically and scientifically evaluated yet. To fill the gap, in this paper, we (i) compare crowdfunded products with traditional products in terms of their ratings in the largest e-commerce market, Amazon; (ii) analyze characteristics of the successful products (received ≥ 4 star) and unsuccessful products (received &lt; 4 star); and (iii) build machine learning models in three different stages, which predict whether a crowdfunded product will receive high star ratings or not. Our experimental results show that crowdfunded products, on average, received lower rating than traditional products. Our predictive models effectively identify which product will receive high star-ratings from customers on Amazon. The datasets used in this paper will be available at http://web.cs.wpi.edu/~kmlee/data.html.},
booktitle = {Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {357–362},
numpages = {6},
location = {Barcelona, Spain},
series = {ASONAM '18}
}

@inproceedings{10.1145/3580305.3599550,
author = {Li, Haoxuan and Zheng, Chunyuan and Wu, Peng and Kuang, Kun and Liu, Yue and Cui, Peng},
title = {Who Should Be Given Incentives? Counterfactual Optimal Treatment Regimes Learning for Recommendation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599550},
doi = {10.1145/3580305.3599550},
abstract = {Effective personalized incentives can improve user experience and increase platform revenue, resulting in a win-win situation between users and e-commerce companies. Previous studies have used uplift modeling methods to estimate the conditional average treatment effects of users' incentives, and then placed the incentives by maximizing the sum of estimated treatment effects under a limited budget. However, some users will always buy whether incentives are given or not, and they will actively collect and use incentives if provided, named "Always Buyers". Identifying and predicting these "Always Buyers" and reducing incentive delivery to them can lead to a more rational incentive allocation. In this paper, we first divide users into five strata from an individual counterfactual perspective, and reveal the failure of previous uplift modeling methods to identify and predict the "Always Buyers". Then, we propose principled counterfactual identification and estimation methods and prove their unbiasedness. We further propose a counterfactual entire-space multi-task learning approach to accurately perform personalized incentive policy learning with a limited budget. We also theoretically derive a lower bound on the reward of the learned policy. Extensive experiments are conducted on three real-world datasets with two common incentive scenarios, and the results demonstrate the effectiveness of the proposed approaches.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1235–1247},
numpages = {13},
keywords = {counterfactual, optimal treatment regime, recommender system.},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3219819.3219894,
author = {Christakopoulou, Konstantina and Beutel, Alex and Li, Rui and Jain, Sagar and Chi, Ed H.},
title = {Q&amp;R: A Two-Stage Approach toward Interactive Recommendation},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219894},
doi = {10.1145/3219819.3219894},
abstract = {Recommendation systems, prevalent in many applications, aim to surface to users the right content at the right time. Recently, researchers have aspired to develop conversational systems that offer seamless interactions with users, more effectively eliciting user preferences and offering better recommendations. Taking a step towards this goal, this paper explores the two stages of a single round of conversation with a user: which question to ask the user, and how to use their feedback to respond with a more accurate recommendation. Following these two stages, first, we detail an RNN-based model for generating topics a user might be interested in, and then extend a state-of-the-art RNN-based video recommender to incorporate the user's selected topic. We describe our proposed system Q&amp;R, i.e., Question &amp; Recommendation, and the surrogate tasks we utilize to bootstrap data for training our models. We evaluate different components of Q&amp;R on live traffic in various applications within YouTube: User Onboarding, Homepage Recommendation, and Notifications. Our results demonstrate that our approach improves upon state-of-the-art recommendation models, including RNNs, and makes these applications more useful, such as a &gt;1% increase in video notifications opened. Further, our design choices can be useful to practitioners wanting to transition to more conversational recommendation systems.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {139–148},
numpages = {10},
keywords = {bootstrapping conversations, engaging casual users, interactive recommendation, question and recommendation},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3394486.3403113,
author = {Dong, Manqing and Yuan, Feng and Yao, Lina and Xu, Xiwei and Zhu, Liming},
title = {MAMO: Memory-Augmented Meta-Optimization for Cold-start Recommendation},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403113},
doi = {10.1145/3394486.3403113},
abstract = {A common challenge for most current recommender systems is the cold-start problem. Due to the lack of user-item interactions, the fine-tuned recommender systems are unable to handle situations with new users or new items. Recently, some works introduce the meta-optimization idea into the recommendation scenarios, i.e. predicting the user preference by only a few of past interacted items. The core idea is learning a global sharing initialization parameter for all users and then learning the local parameters for each user separately. However, most meta-learning based recommendation approaches adopt model-agnostic meta-learning for parameter initialization, where the global sharing parameter may lead the model into local optima for some users. In this paper, we design two memory matrices that can store task-specific memories and feature-specific memories. Specifically, the feature-specific memories are used to guide the model with personalized parameter initialization, while the task-specific memories are used to guide the model fast predicting the user preference. And we adopt a meta-optimization approach for optimizing the proposed method. We test the model on two widely used recommendation datasets and consider four cold-start situations. The experimental results show the effectiveness of the proposed methods.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {688–697},
numpages = {10},
keywords = {cold-start problem, meta learning, recommender systems},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3394486.3403051,
author = {Wang, Nan and Wang, Hongning},
title = {Directional Multivariate Ranking},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403051},
doi = {10.1145/3394486.3403051},
abstract = {User-provided multi-aspect evaluations manifest users' detailed feedback on the recommended items and enable fine-grained understanding of their preferences. Extensive studies have shown that modeling such data greatly improves the effectiveness and explainability of the recommendations. However, as ranking is essential in recommendation, there is no principled solution yet for collectively generating multiple item rankings over different aspects.In this work, we propose a directional multi-aspect ranking criterion to enable a holistic ranking of items with respect to multiple aspects. Specifically, we view multi-aspect evaluation as an integral effort from a user that forms a vector of his/her preferences over aspects. Our key insight is that the direction of the difference vector between two multi-aspect preference vectors reveals the pairwise order of comparison. Hence, it is necessary for a multi-aspect ranking criterion to preserve the observed directions from such pairwise comparisons. We further derive a complete solution for the multi-aspect ranking problem based on a probabilistic multivariate tensor factorization model. Comprehensive experimental analysis on a large TripAdvisor multi-aspect rating dataset and a Yelp review text dataset confirms the effectiveness of our solution.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {85–94},
numpages = {10},
keywords = {directional statistics, multi-aspect ranking},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3580305.3599428,
author = {Wei, Chunyu and Liang, Jian and Liu, Di and Dai, Zehui and Li, Mang and Wang, Fei},
title = {Meta Graph Learning for Long-tail Recommendation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599428},
doi = {10.1145/3580305.3599428},
abstract = {Highly skewed long-tail item distribution commonly hurts model performance on tail items in recommendation systems, especially for graph-based recommendation models. We propose a novel idea to learn relations among items as an auxiliary graph to enhance the graph-based representation learning and make recommendations collectively in a coupled framework. This raises two challenges, 1) the long-tail downstream information may also bias the auxiliary graph learning, and 2) the learned auxiliary graph may cause negative transfer to the original user-item bipartite graph. We innovatively propose a novel Meta Graph Learning framework for long-tail recommendation (MGL) for solving both challenges. The meta-learning strategy is introduced to the learning of an edge generator, which is first tuned to reconstruct a debiased item co-occurrence matrix, and then virtually evaluated on generating item relations for recommendation. Moreover, we propose a popularity-aware contrastive learning strategy to prevent negative transfer by aligning the confident head item representations with those of the learned auxiliary graph. Experiments on public datasets demonstrate that our proposed model significantly outperforms strong baselines for tail items without compromising the overall performance.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2512–2522},
numpages = {11},
keywords = {graph learning, long-tail recommendation, meta-learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.5555/3382225.3382337,
author = {Rajapaksha, Praboda and Farahbakhsh, Reza and Crespi, No\"{e}l and Defude, Bruno},
title = {Inspecting interactions: online news media synergies in social media},
year = {2020},
isbn = {9781538660515},
publisher = {IEEE Press},
abstract = {The rising popularity of social media has radically changed the way news content is propagated, including interactive attempts with new dimensions. To date, traditional news media such as newspapers, television and radio have already adapted their activities to the online news media by utilizing social media, blogs, websites etc. This paper provides some insight into the social media presence of worldwide popular news media outlets. Despite the fact that these large news media propagate content via social media environments to a large extent and very little is known about the news item producers, providers and consumers in the news media community in social media. To better understand these interactions, this work aims to analyze news items in two large social media, Twitter and Facebook. Towards that end, we collected all published posts on Twitter and Facebook from 48 news media to perform descriptive and predictive analyses using the dataset of 152K tweets and 80K Facebook posts. We explored a set of news media that originate content by themselves in social media, those who distribute their news items to other news media and those who consume news content from other news media and/or share replicas. We propose a predictive model to increase news media popularity among readers based on the number of posts, number of followers and number of interactions performed within the news media community. The results manifested that, news media should disperse their own content and they should publish first in social media in order to become a popular news media and receive more attractions to their news items from news readers.},
booktitle = {Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {535–539},
numpages = {5},
keywords = {Facebook, News media, Twitter, authorship, content propagation, originality, social media},
location = {Barcelona, Spain},
series = {ASONAM '18}
}

@inproceedings{10.1145/3637528.3671516,
author = {He, Bowei and Weng, Yunpeng and Tang, Xing and Cui, Ziqiang and Sun, Zexu and Chen, Liang and He, Xiuqiang and Ma, Chen},
title = {Rankability-enhanced Revenue Uplift Modeling Framework for Online Marketing},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671516},
doi = {10.1145/3637528.3671516},
abstract = {Uplift modeling has been widely employed in online marketing by predicting the response difference between the treatment and control groups, so as to identify the sensitive individuals toward interventions like coupons or discounts. Compared with traditional conversion uplift modeling,revenue uplift modeling exhibits higher potential due to its direct connection with the corporate income. However, previous works can hardly handle the continuous long-tail response distribution in revenue uplift modeling. Moreover, they have neglected to optimize the uplift ranking among different individuals, which is actually the core of uplift modeling. To address such issues, in this paper, we first utilize the zero-inflated lognormal (ZILN) loss to regress the responses and customize the corresponding modeling network, which can be adapted to different existing uplift models. Then, we study the ranking-related uplift modeling error from the theoretical perspective and propose two tighter error bounds as the additional loss terms to the conventional response regression loss. Finally, we directly model the uplift ranking error for the entire population with a listwise uplift ranking loss. The experiment results on offline public and industrial datasets validate the effectiveness of our method for revenue uplift modeling. Furthermore, we conduct large-scale experiments on a prominent online fintech marketing platform, Tencent FiT, which further demonstrates the superiority of our method in real-world applications.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5093–5104},
numpages = {12},
keywords = {online marketing, rankability, revenue uplift modeling},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3534678.3539161,
author = {Masud, Sarah and Bedi, Manjot and Khan, Mohammad Aflah and Akhtar, Md Shad and Chakraborty, Tanmoy},
title = {Proactively Reducing the Hate Intensity of Online Posts via Hate Speech Normalization},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539161},
doi = {10.1145/3534678.3539161},
abstract = {Curbing online hate speech has become the need of the hour; however, a blanket ban on such activities is infeasible for several geopolitical and cultural reasons. To reduce the severity of the problem, in this paper, we introduce a novel task, hate speech normalization, that aims to weaken the intensity of hatred exhibited by an online post. The intention of hate speech normalization is not to support hate but instead to provide the users with a stepping stone towards non-hate while giving online platforms more time to monitor any improvement in the user's behavior. To this end, we manually curated a parallel corpus - hate texts and their normalized counterparts (a normalized text is less hateful and more benign). We introduce NACL, a simple yet efficient hate speech normalization model that operates in three stages - first, it measures the hate intensity of the original sample; second, it identifies the hate span(s) within it; and finally, it reduces hate intensity by paraphrasing the hate spans. We perform extensive experiments to measure the efficacy of NACL via three-way evaluation (intrinsic, extrinsic, and human-study). We observe that NACL outperforms six baselines - NACL yields a score of 0.1365 RMSE for the intensity prediction, 0.622 F1-score in the span identification, and 82.27 BLEU and 80.05 perplexity for the normalized text generation. We further show the generalizability of NACL across other platforms (Reddit, Facebook, Gab). An interactive prototype of NACL was put together for the user study. Further, the tool is being deployed in a real-world setting at Wipro AI as a part of its mission to tackle harmful content on online platforms.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3524–3534},
numpages = {11},
keywords = {cross-platform tool, hate intensity reduction, hate normalization, online hate speech, proactive strategy, span detection},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3326937.3341250,
author = {Jia, Yugang and Wang, Xin and Zhang, Jinting},
title = {Collaborative filtering via learning characteristics of neighborhood based on convolutional neural networks},
year = {2019},
isbn = {9781450367837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326937.3341250},
doi = {10.1145/3326937.3341250},
abstract = {Collaborative filtering (CF) is an extensively studied topic in Recommender System. Recent approaches use the statistical framework based on local Taylor approximations to unify both user based and item based CF algorithms and improve the performance of estimating unknown ratings. In this paper, we propose a new Machine Learning approach based on Convolutional Neural Networks to exploit complex latent user-item relations, using features extracted from the neighborhood of unknown rating via local approximations. Experimental results on two benchmark data sets demonstrate the effectiveness of the proposed approach via comparing to state-of-the-art methods.},
booktitle = {Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data},
articleno = {1},
numpages = {4},
keywords = {collaborative filtering, convolutional neural networks, local taylor approximation},
location = {Anchorage, Alaska},
series = {DLP-KDD '19}
}

@inproceedings{10.1145/2339530.2339574,
author = {Tang, Jiliang and Gao, Huiji and Liu, Huan and Das Sarma, Atish},
title = {eTrust: understanding trust evolution in an online world},
year = {2012},
isbn = {9781450314626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2339530.2339574},
doi = {10.1145/2339530.2339574},
abstract = {Most existing research about online trust assumes static trust relations between users. As we are informed by social sciences, trust evolves as humans interact. Little work exists studying trust evolution in an online world. Researching online trust evolution faces unique challenges because more often than not, available data is from passive observation. In this paper, we leverage social science theories to develop a methodology that enables the study of online trust evolution. In particular, we propose a framework of evolution trust, eTrust, which exploits the dynamics of user preferences in the context of online product review. We present technical details about modeling trust evolution, and perform experiments to show how the exploitation of trust evolution can help improve the performance of online applications such as rating and trust prediction.},
booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {253–261},
numpages = {9},
keywords = {multi-faceted trust, trust evolution, user preference},
location = {Beijing, China},
series = {KDD '12}
}

@inproceedings{10.1145/3447548.3469444,
author = {Zhu, Xiaoqiang and Lee, Kuang-chih and Zhou, Guorui and Jiang, Biye and Wang, Zhe and Tang, Ruiming and Ren, Kan and Ai, Qingyao and Zhang, Weinan},
title = {3rd International Workshop on Deep Learning Practice for High-Dimensional Sparse Data with KDD 2021},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3469444},
doi = {10.1145/3447548.3469444},
abstract = {Recently, we have witnessed that deep learning-based approaches has been widely applied to empower many internet-scale applications. However, the data in these internet-scale applications are high dimensional and extremely sparse, which makes it different from those applications with dense data processing, such as image classification and speech recognition, where deep learning-based approaches have been extensively studied. One of the main applications is the user-centric platform that consists of great deal of users, items and user generated tabular data which are quite high-dimensional. The characteristics of such data pose unique challenges to the adoption of deep learning in these applications, including modeling, training, and online serving, etc. More and more communities from both academia and industry have initiated the endeavors to solve these challenges. This workshop will provide a venue for both the research and engineering communities to discuss and formulate the challenges, utilize opportunities, and propose new ideas in the practice of deep learning on high-dimensional sparse data.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4187–4188},
numpages = {2},
keywords = {deep learning, high-dimensional, sparse data},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3110025.3110090,
author = {Gilani, Zafar and Farahbakhsh, Reza and Tyson, Gareth and Wang, Liang and Crowcroft, Jon},
title = {Of Bots and Humans (on Twitter)},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3110090},
doi = {10.1145/3110025.3110090},
abstract = {Recent research has shown a substantial active presence of bots in online social networks (OSNs). In this paper we utilise our previous work (Stweeler) to comparatively analyse the usage and impact of bots and humans on Twitter, one of the largest OSNs in the world. We collect a large-scale Twitter dataset and define various metrics based on tweet metadata. Using a human annotation task we assign 'bot' and 'human' ground-truth labels to the dataset, and compare the annotations against an online bot detection tool for evaluation. We then ask a series of questions to discern important behavioural characteristics of bots and humans using metrics within and among four popularity groups. From the comparative analysis we draw differences and interesting similarities between the two entities, thus paving the way for reliable classification of bots, and studying automated political infiltration and advertisement campaigns.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {349–354},
numpages = {6},
keywords = {behavioural analysis, bot characterisation, content propagation, social network analysis},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@inproceedings{10.1145/2659480.2659501,
author = {Badaro, Gilbert and Hajj, Hazem and Haddad, Ali and El-Hajj, Wassim and Shaban, Khaled Bashir},
title = {A Multiresolution Approach to Recommender Systems},
year = {2014},
isbn = {9781450331920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2659480.2659501},
doi = {10.1145/2659480.2659501},
abstract = {Recommender systems face performance challenges when dealing with sparse data. This paper addresses these challenges and proposes the use of Harmonic Analysis. The method provides a novel approach to the user-item matrix and extracts the interplay between users and items at multiple resolution levels. New affinity matrices are defined to measure similarities among users, among items, and across items and users. Furthermore, the similarities are assessed at multiple levels of granularity allowing individual and group level similarities. These affinity matrices thus produce multiresolution groupings of items and users, and in turn lead to higher accuracy in matching similar context for ratings, and more accurate prediction of new ratings. Evaluation results show superiority of the approach compared to state of the art solutions.},
booktitle = {Proceedings of the 8th Workshop on Social Network Mining and Analysis},
articleno = {9},
numpages = {5},
keywords = {Coupled Geometry, Haar Basis, Multiresolution Analysis, Partition Tree, Recommender System, Sparse Matrix},
location = {New York, NY, USA},
series = {SNAKDD'14}
}

@inproceedings{10.1145/3219819.3220004,
author = {Wang, Qinyong and Yin, Hongzhi and Hu, Zhiting and Lian, Defu and Wang, Hao and Huang, Zi},
title = {Neural Memory Streaming Recommender Networks with Adversarial Training},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220004},
doi = {10.1145/3219819.3220004},
abstract = {With the increasing popularity of various social media and E-commerce platforms, large volumes of user behaviour data (e.g., user transaction data, rating and review data) are being continually generated at unprecedented and ever-increasing scales. It is more realistic and practical to study recommender systems with inputs of streaming data. User-generated streaming data presents unique properties such as temporally ordered, continuous and high-velocity, which poses tremendous new challenges for the once very successful recommendation techniques. Although a few temporal or sequential recommender models have recently been developed based on recurrent neural models, most of them can only be applied to the session-based recommendation scenario, due to their short-term memories and the limited capability of capturing users' long-term stable interests. In this paper, we propose a streaming recommender model based on neural memory networks with external memories to capture and store both long-term stable interests and short-term dynamic interests in a unified way. An adaptive negative sampling framework based on Generative Adversarial Nets (GAN) is developed to optimize our proposed streaming recommender model, which effectively overcomes the limitations of classical negative sampling approaches and improves both effectiveness and efficiency of the model parameter inference. Extensive experiments have been conducted on two large-scale recommendation datasets, and the experimental results show the superiority of our proposed streaming recommender model in the streaming recommendation scenario.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2467–2475},
numpages = {9},
keywords = {collaborative filtering, memory networks, streaming recommender systems},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3447548.3467192,
author = {Xu, Da and Ruan, Chuanwei and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan},
title = {Towards the D-Optimal Online Experiment Design for Recommender Selection},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467192},
doi = {10.1145/3447548.3467192},
abstract = {Selecting the optimal recommender via online exploration-exploitation is catching increasing attention where the traditional A/B testing can be slow and costly, and offline evaluations are prone to the bias of history data. Finding the optimal online experiment is nontrivial since both the users and displayed recommendations carry contextual features that are informative to the reward. While the problem can be formalized via the lens of multi-armed bandits, the existing solutions are found less satisfactorily because the general methodologies do not account for the case-specific structures, particularly for the e-commerce recommendation we study. To fill in the gap, we leverage the D-optimal design from the classical statistics literature to achieve the maximum information gain during exploration, and reveal how it fits seamlessly with the modern infrastructure of online inference. To demonstrate the effectiveness of the optimal designs, we provide semi-synthetic simulation studies with published code and data for reproducibility purposes. We then use our deployment example on Walmart.com to fully illustrate the practical insights and effectiveness of the proposed methods.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3817–3825},
numpages = {9},
keywords = {deployment infrastructure, exploration-exploitation, multi-armed bandit, optimal design, recommender system},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3534678.3539342,
author = {Yang, Yuhao and Huang, Chao and Xia, Lianghao and Liang, Yuxuan and Yu, Yanwei and Li, Chenliang},
title = {Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539342},
doi = {10.1145/3534678.3539342},
abstract = {Learning dynamic user preference has become an increasingly important component for many online platforms (e.g., video-sharing sites, e-commerce systems) to make sequential recommendations. Previous works have made many efforts to model item-item transitions over user interaction sequences, based on various architectures, e.g., recurrent neural networks and self-attention mechanism. Recently emerged graph neural networks also serve as useful backbone models to capture item dependencies in sequential recommendation scenarios. Despite their effectiveness, existing methods have far focused on item sequence representation with singular type of interactions, and thus are limited to capture dynamic heterogeneous relational structures between users and items (e.g., page view, add-to-favorite, purchase). To tackle this challenge, we design a Multi-Behavior Hypergraph-enhanced T ransformer framework (MBHT) to capture both short-term and long-term cross-type behavior dependencies. Specifically, a multi-scale Transformer is equipped with low-rank self-attention to jointly encode behavior-aware sequential patterns from fine-grained and coarse-grained levels. Additionally,we incorporate the global multi-behavior dependency into the hypergraph neural architecture to capture the hierarchical long-range item correlations in a customized manner. Experimental results demonstrate the superiority of our MBHT over various state-of- the-art recommendation solutions across different settings. Further ablation studies validate the effectiveness of our model design and benefits of the new MBHT framework. Our implementation code is released at: https://github.com/yuh-yang/MBHT-KDD22.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2263–2274},
numpages = {12},
keywords = {graph neural networks, hypergraph learning, multi-behavior recommendation, sequential recommendation},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3110025.3116192,
author = {Yang, Jun and Wang, Zhaoguo and Di, Fangchun and Chen, Liyue and Yi, Chengqi and Xue, Yibo and Li, Jun},
title = {Propagator or Influencer? A Data-driven Approach for Evaluating Emotional Effect in Online Information Diffusion},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3116192},
doi = {10.1145/3110025.3116192},
abstract = {Reposting is the basic and key behavior for information diffusion in online social networks. It would be beneficial to understand the influence factors of reposting behavior and predict future reposting status, which could be practically applied in breaking news detection, marketing, social media researches and so on. Existing reposting analytics and prediction approaches mainly focus on factors related to the original information content and the social influence of the information publishers. However, online information diffuses by viral cascades instead of single-source broadcast in social network, which means some reposting behavior actually occurs in information propagators rather than the original publishers. In some social networks, users are allowed to comment when they repost, which represents their views and attitudes to the information they propagate. In this paper, we evaluate how emotional tendencies of information propagators influence future reposting. We first propose a modified sentiment analysis method and present emotional analysis on the user-generated content in online diffusion. Experiments are conducted with a real-world dataset and the results indicate the effectiveness of our fine-grained emotional features in reposting prediction.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {836–843},
numpages = {8},
keywords = {Information diffusion, feature selection, online social networks, retweet, sentiment analysis},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@inproceedings{10.1145/2487575.2487589,
author = {Kabbur, Santosh and Ning, Xia and Karypis, George},
title = {FISM: factored item similarity models for top-N recommender systems},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487589},
doi = {10.1145/2487575.2487589},
abstract = {The effectiveness of existing top-N recommendation methods decreases as the sparsity of the datasets increases. To alleviate this problem, we present an item-based method for generating top-N recommendations that learns the item-item similarity matrix as the product of two low dimensional latent factor matrices. These matrices are learned using a structural equation modeling approach, wherein the value being estimated is not used for its own estimation. A comprehensive set of experiments on multiple datasets at three different sparsity levels indicate that the proposed methods can handle sparse datasets effectively and outperforms other state-of-the-art top-N recommendation methods. The experimental results also show that the relative performance gains compared to competing methods increase as the data gets sparser.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {659–667},
numpages = {9},
keywords = {item similarity, recommender systems, sparse data, topn},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@inproceedings{10.1145/3394486.3403282,
author = {Ghosh, Aritra and Heffernan, Neil and Lan, Andrew S.},
title = {Context-Aware Attentive Knowledge Tracing},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403282},
doi = {10.1145/3394486.3403282},
abstract = {Knowledge tracing (KT) refers to the problem of predicting future learner performance given their past performance in educational applications. Recent developments in KT using flexible deep neural network-based models excel at this task. However, these models often offer limited interpretability, thus making them insufficient for personalized learning, which requires using interpretable feedback and actionable recommendations to help learners achieve better learning outcomes. In this paper, we propose attentive knowledge tracing (AKT), which couples flexible attention-based neural network models with a series of novel, interpretable model components inspired by cognitive and psychometric models. AKT uses a novel monotonic attention mechanism that relates a learner's future responses to assessment questions to their past responses; attention weights are computed using exponential decay and a context-aware relative distance measure, in addition to the similarity between questions. Moreover, we use the Rasch model to regularize the concept and question embeddings; these embeddings are able to capture individual differences among questions on the same concept without using an excessive number of parameters. We conduct experiments on several real-world benchmark datasets and show that AKT outperforms existing KT methods (by up to $6%$ in AUC in some cases) on predicting future learner responses. We also conduct several case studies and show that AKT exhibits excellent interpretability and thus has potential for automated feedback and personalization in real-world educational settings.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2330–2339},
numpages = {10},
keywords = {item response theory, knowledge tracing, monotonic attention, personalized learning},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/2020408.2020439,
author = {Chen, Bee-Chung and Guo, Jian and Tseng, Belle and Yang, Jie},
title = {User reputation in a comment rating environment},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020408.2020439},
doi = {10.1145/2020408.2020439},
abstract = {Reputable users are valuable assets of a web site. We focus on user reputation in a comment rating environment, where users make comments about content items and rate the comments of one another. Intuitively, a reputable user posts high quality comments and is highly rated by the user community. To our surprise, we find that the quality of a comment judged editorially is almost uncorrelated with the ratings that it receives, but can be predicted using standard text features, achieving accuracy as high as the agreement between two editors! However, extracting a pure reputation signal from ratings is difficult because of data sparseness and several confounding factors in users' voting behavior. To address these issues, we propose a novel bias-smoothed tensor model and empirically show that our model significantly outperforms a number of alternatives based on Yahoo! News, Yahoo! Buzz and Epinions datasets.},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {159–167},
numpages = {9},
keywords = {bias removal, hierarchical smoothing, latent factor model, tensor factorization, text quality},
location = {San Diego, California, USA},
series = {KDD '11}
}

@inproceedings{10.1145/3292500.3330715,
author = {Gupta, Rupesh and Chen, Guangde and Yu, Shipeng},
title = {Internal Promotion Optimization},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330715},
doi = {10.1145/3292500.3330715},
abstract = {Most large Internet companies run internal promotions to cross-promote their different products and/or to educate members on how to obtain additional value from the products that they already use. This in turn drives engagement and/or revenue for the company. However, since these internal promotions can distract a member away from the product or page where these are shown, there is a non-zero cannibalization loss incurred for showing these internal promotions. This loss has to be carefully weighed against the gain from showing internal promotions. This can be a complex problem if different internal promotions optimize for different objectives. In that case, it is difficult to compare not just the gain from a conversion through an internal promotion against the loss incurred for showing that internal promotion, but also the gains from conversions through different internal promotions. Hence, we need a principled approach for deciding which internal promotion (if any) to serve to a member in each opportunity to serve an internal promotion. This approach should optimize not just for the net gain to the company, but also for the member's experience. In this paper, we discuss our approach for optimization of internal promotions at LinkedIn. In particular, we present a cost-benefit analysis of showing internal promotions, our formulation of internal promotion optimization as a constrained optimization problem, the architecture of the system for solving the optimization problem and serving internal promotions in real-time, and experimental results from online A/B tests.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2358–2366},
numpages = {9},
keywords = {internal cross-promotion, internal promotion, machine learning, optimization},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/2020408.2020505,
author = {Wang, Hongning and Lu, Yue and Zhai, ChengXiang},
title = {Latent aspect rating analysis without aspect keyword supervision},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020408.2020505},
doi = {10.1145/2020408.2020505},
abstract = {Mining detailed opinions buried in the vast amount of review text data is an important, yet quite challenging task with widespread applications in multiple domains. Latent Aspect Rating Analysis (LARA) refers to the task of inferring both opinion ratings on topical aspects (e.g., location, service of a hotel) and the relative weights reviewers have placed on each aspect based on review content and the associated overall ratings. A major limitation of previous work on LARA is the assumption of pre-specified aspects by keywords. However, the aspect information is not always available, and it may be difficult to pre-define appropriate aspects without a good knowledge about what aspects are actually commented on in the reviews.In this paper, we propose a unified generative model for LARA, which does not need pre-specified aspect keywords and simultaneously mines 1) latent topical aspects, 2) ratings on each identified aspect, and 3) weights placed on different aspects by a reviewer. Experiment results on two different review data sets demonstrate that the proposed model can effectively perform the Latent Aspect Rating Analysis task without the supervision of aspect keywords. Because of its generality, the proposed model can be applied to explore all kinds of opinionated text data containing overall sentiment judgments and support a wide range of interesting application tasks, such as aspect-based opinion summarization, personalized entity ranking and recommendation, and reviewer behavior analysis.},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {618–626},
numpages = {9},
keywords = {aspect identification, latent rating analysis, review mining},
location = {San Diego, California, USA},
series = {KDD '11}
}

@inproceedings{10.1145/3219819.3220112,
author = {Christakopoulou, Evangelia and Karypis, George},
title = {Local Latent Space Models for Top-N Recommendation},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220112},
doi = {10.1145/3219819.3220112},
abstract = {Users' behaviors are driven by their preferences across various aspects of items they are potentially interested in purchasing, viewing, etc. Latent space approaches model these aspects in the form of latent factors. Although such approaches have been shown to lead to good results, the aspects that are important to different users can vary. In many domains, there may be a set of aspects for which all users care about and a set of aspects that are specific to different subsets of users. To explicitly capture this, we consider models in which there are some latent factors that capture the shared aspects and some user subset specific latent factors that capture the set of aspects that the different subsets of users care about.In particular, we propose two latent space models: rGLSVD and sGLSVD, that combine such a global and user subset specific sets of latent factors. The rGLSVD model assigns the users into different subsets based on their rating patterns and then estimates a global and a set of user subset specific local models whose number of latent dimensions can vary.The sGLSVD model estimates both global and user subset specific local models by keeping the number of latent dimensions the same among these models but optimizes the grouping of the users in order to achieve the best approximation. Our experiments on various real-world datasets show that the proposed approaches significantly outperform state-of-the-art latent space top-N recommendation approaches.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1235–1243},
numpages = {9},
keywords = {clustering, collaborative filtering, latent space models, local models},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3447548.3467151,
author = {Yu, Sanshi and Jiang, Zhuoxuan and Chen, Dong-Dong and Feng, Shanshan and Li, Dongsheng and Liu, Qi and Yi, Jinfeng},
title = {Leveraging Tripartite Interaction Information from Live Stream E-Commerce for Improving Product Recommendation},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467151},
doi = {10.1145/3447548.3467151},
abstract = {Recently, a new form of online shopping becomes more and more popular, which combines live streaming with E-Commerce activity. The streamers introduce products and interact with their audiences, and hence greatly improve the performance of selling products. Despite of the successful applications in industries, the live stream E-commerce has not been well studied in the data science community. To fill this gap, we investigate this brand-new scenario and collect a real-world Live Stream E-Commerce (LSEC) dataset. Different from conventional E-commerce activities, the streamers play a pivotal role in the LSEC events. Hence, the key is to make full use of rich interaction information among streamers, users, and products. We first conduct data analysis on the tripartite interaction data and quantify the streamer's influence on users' purchase behavior. Based on the analysis results, we model the tripartite information as a heterogeneous graph, which can be decomposed to multiple bipartite graphs in order to better capture the influence. We propose a novel Live Stream E-Commerce Graph Neural Network framework (LSEC-GNN) to learn the node representations of each bipartite graph, and further design a multi-task learning approach to improve product recommendation. Extensive experiments on two real-world datasets with different scales show that our method can significantly outperform various baseline approaches.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3886–3894},
numpages = {9},
keywords = {graph representation learning, live streaming e-commence, multi-task learning, product recommendation},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.5555/3382225.3382459,
author = {Ahmadian, Sajad and Joorabloo, Nima and Jalili, Mahdi and Meghdadi, Majid and Afsharchi, Mohsen and Ren, Yongli},
title = {A temporal clustering approach for social recommender systems},
year = {2020},
isbn = {9781538660515},
publisher = {IEEE Press},
abstract = {Recommender systems aim to suggest relevant items to users among a large number of available items. They have been successfully applied in various industries, such as e-commerce, education and digital health. On the other hand, clustering approaches can help the recommender systems to group users into appropriate clusters, which are considered as neighborhoods in prediction process. Although it is a fact that preferences of users vary over time, traditional clustering approaches fail to consider this important factor. To address this problem, a social recommender system is proposed in this paper, which is based on a temporal clustering approach. Specifically, the temporal information of ratings provided by users on items and also social information among the users are considered in the proposed method. Experimental results on a benchmark dataset show that the quality of recommendations based on the proposed method is significantly higher than the state-of-the-art methods in terms of both accuracy and coverage metrics.},
booktitle = {Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {1139–1144},
numpages = {6},
keywords = {clustering, graph, recommender system, social information, temporal},
location = {Barcelona, Spain},
series = {ASONAM '18}
}

@inproceedings{10.1145/3110025.3110144,
author = {Forsati, Rana and Barjasteh, Iman and Esfahanian, Abdol-Hossein},
title = {Semi-supervised Collaborative Ranking with Push at the Top},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3110144},
doi = {10.1145/3110025.3110144},
abstract = {Existing collaborative ranking based recommender systems tend to perform best when there is enough observed ratings for each user, and the observed data is uniformly sampled at random. However, when the observed ratings are extremely sparse (e.g. in the case of cold-start item where no rating data is available), and are not sampled uniformly at random, existing ranking methods fail to effectively leverage side information to transduct the knowledge from existing ratings to unobserved ones. We propose a semi-supervised collaborative ranking model, dubbed S2COR, to improve the quality of cold-start item recommendation. S2COR mitigates the sparsity issue by leveraging side information about both observed and missing ratings by collaboratively learning the ranking model. This enables it to deal with the case of data missing not at random, but to also effectively incorporate the available side information in transduction. We experimentally evaluated our proposed algorithm on a number of challenging real-world datasets and compared our results against state-of-the-art models for cold-start recommendation. We show significantly higher quality recommendations with our algorithm when compared to other state-of-the-art methods.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {401–408},
numpages = {8},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@inproceedings{10.1145/3447548.3467428,
author = {Jin, Ruoming and Li, Dong and Gao, Jing and Liu, Zhi and Chen, Li and Zhou, Yang},
title = {Towards a Better Understanding of Linear Models for Recommendation},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467428},
doi = {10.1145/3447548.3467428},
abstract = {Recently, linear regression models have shown to often produce rather competitive results against more sophisticated deep learning models. Meanwhile, the (weighted) matrix factorization approaches have been popular choices for recommendation in the past and widely adopted in the industry. In this work, we aim to theoretically understand the relationship between these two approaches, which are the cornerstones of model-based recommendations. Through the derivation and analysis of the closed-form solutions for two basic regression and matrix factorization approaches, we found these two approaches are indeed inherently related but also diverge in how they "scale-down" the singular values of the original user-item interaction matrix. We further introduce a new learning algorithm in searching (hyper)parameters for the closed-form solution and utilize it to discover the nearby models of the existing solutions. The experimental results demonstrate that the basic models and their closed-form solutions are indeed quite competitive against the state-of-the-art models, thus, confirming the validity of studying the basic models. The effectiveness of exploring the nearby models are also experimentally validated.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {776–785},
numpages = {10},
keywords = {hyper-parameter search, linear model, low-rank regression, matrix factorization, recommender systems},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3341161.3342940,
author = {Song, Yo-Der and Gong, Mingwei and Mahanti, Aniket},
title = {Measurement and analysis of an adult video streaming service},
year = {2020},
isbn = {9781450368681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341161.3342940},
doi = {10.1145/3341161.3342940},
abstract = {Pornography can be distributed in multiple forms on the Internet. Online pornography forms a non-negligible fraction of the total Internet traffic, with adult video streaming gaining significant traction among the most visited global websites. Similar to the rise of User Generated Content (UGC) on general Web 2.0 services, adult video service providers have also promoted social interaction and UGC in what is called 'Porn 2.0'. Discovering the characteristics of Porn 2.0 allows for better understanding of both Internet traffic in general and specifically UGC services. In this paper, using trace-driven analysis, we examined the characteristics of one of the most well-known Porn 2.0 service providers, XHamster. We found that a large proportion of the currently available videos were uploaded in recent years and this has coincided with a rapid growth in the use of video categories. Compared to non-adult UGC services, we found user interaction on XHamster to revolve more strongly around ratings than comments and the average duration and views per video were higher.},
booktitle = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {489–492},
numpages = {4},
location = {Vancouver, British Columbia, Canada},
series = {ASONAM '19}
}

@inproceedings{10.1109/ASONAM55673.2022.10068628,
author = {Linhares, Renan S. and Rosa, Jos\'{e} M. and Ferreira, Carlos H. G. and Murai, Fabricio and Nobre, Gabriel and Almeida, Jussara},
title = {Uncovering Coordinated Communities on Twitter during the 2020 U.S. Election},
year = {2023},
isbn = {9781665456616},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASONAM55673.2022.10068628},
doi = {10.1109/ASONAM55673.2022.10068628},
abstract = {A large volume of content related to claims of election fraud, often associated with hate speech and extremism, was reported on Twitter during the 2020 US election, with evidence that coordinated efforts took place to promote such content on the platform. In response, Twitter announced the suspension of thousands of user accounts allegedly involved in such actions. Motivated by these events, we here propose a novel network-based approach to uncover evidence of coordination in a set of user interactions. Our approach is designed to address the challenges incurred by the often sheer volume of noisy edges in the network (i.e., edges that are unrelated to coordination) and the effects of data sampling. To that end, it exploits the joint use of two network backbone extraction techniques, namely Disparity Filter and Neighborhood Overlap, to reveal strongly tied groups of users (here referred to as communities) exhibiting repeatedly common behavior, consistent with coordination. We employ our strategy to a large dataset of tweets related to the aforementioned fraud claims, in which users were labeled as suspended, deleted or active, according to their accounts status after the election. Our findings reveal well-structured communities, with strong evidence of coordination to promote (i.e., retweet) the aforementioned fraud claims. Moreover, many of those communities are formed not only by suspended and deleted users, but also by users who, despite exhibiting very similar sharing patterns, remained active in the platform. This observation suggests that a significant number of users who were potentially involved in the coordination efforts went unnoticed by the platform, and possibly remained actively spreading this content on the system.},
booktitle = {Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {80–87},
numpages = {8},
keywords = {coordinated behavior, Twitter, backbone extraction, community detection},
location = {Istanbul, Turkey},
series = {ASONAM '22}
}

@inproceedings{10.1145/3394486.3403251,
author = {Dutta, Subhabrata and Masud, Sarah and Chakrabarti, Soumen and Chakraborty, Tanmoy},
title = {Deep Exogenous and Endogenous Influence Combination for Social Chatter Intensity Prediction},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403251},
doi = {10.1145/3394486.3403251},
abstract = {Modeling user engagement dynamics on social media has compelling applications in market trend analysis, user-persona detection, and political discourse mining. Most existing approaches depend heavily on knowledge of the underlying user network. However, a large number of discussions happen on platforms that either lack any reliable social network (news portal, blogs, Buzzfeed) or reveal only partially the inter-user ties (Reddit, Stackoverflow). Many approaches require observing a discussion for some considerable period before they can make useful predictions. In real-time streaming scenarios, observations incur costs. Lastly, most models do not capture complex interactions between exogenous events (such as news articles published externally) and in-network effects (such as follow-up discussions on Reddit) to determine engagement levels. To address the three limitations noted above, we propose a novel framework, ChatterNet, which, to our knowledge, is the first that can model and predict user engagement without considering the underlying user network. Given streams of timestamped news articles and discussions, the task is to observe the streams for a short period leading up to a time horizon, then predict chatter: the volume of discussions through a specified period after the horizon. ChatterNet processes text from news and discussions using a novel time-evolving recurrent network architecture that captures both temporal properties within news and discussions, as well as influence of news on discussions. We report on extensive experiments using a two-month-long discussion corpus of Reddit, and a contemporaneous corpus of online news articles from the Common Crawl. ChatterNet shows considerable improvements beyond recent state-of-the-art models of engagement prediction. Detailed studies controlling observation and prediction windows, over 43 different subreddits, yield further useful insights.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1999–2008},
numpages = {10},
keywords = {chatter prediction, deep learning, exogenous influence, reddit},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3219819.3219880,
author = {Gao, Yan and Gupta, Viral and Yan, Jinyun and Shi, Changji and Tao, Zhongen and Xiao, PJ and Wang, Curtis and Yu, Shipeng and Rosales, Romer and Muralidharan, Ajith and Chatterjee, Shaunak},
title = {Near Real-time Optimization of Activity-based Notifications},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219880},
doi = {10.1145/3219819.3219880},
abstract = {In recent years, social media applications (e.g., Facebook, LinkedIn) have created mobile applications (apps) to give their members instant and real-time access from anywhere. To keep members informed and drive timely engagement, these mobile apps send event notifications. However, sending notifications for every possible event would result in too many notifications which would in turn annoy members and create a poor member experience.In this paper, we present our strategy of optimizing notifications to balance various utilities (e.g., engagement, send volume) by formulating the problem using constrained optimization. To guarantee freshness of notifications, we implement the solution in a stream computing system in which we make multi-channel send decisions in near real-time. Through online A/B test results, we show the effectiveness of our proposed approach on tens of millions of members.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {283–292},
numpages = {10},
keywords = {machine learning, notifications, optimization, stream computing},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3341161.3343527,
author = {Spiliotopoulos, Dimitris and Vassilakis, Costas and Margaris, Dionisis},
title = {Data-driven country safety monitoring terrorist attack prediction},
year = {2020},
isbn = {9781450368681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341161.3343527},
doi = {10.1145/3341161.3343527},
abstract = {Terrorism is a key risk for prospective visitors of tourist destinations. This work reports on the analysis of past terrorist attack data, focusing on tourist-related attacks and attack types in Mediterranean EU area and the development of algorithms to predict terrorist attack risk levels. Data on attacks in 10 countries have been analyzed to quantify the threat level of tourism-related terrorism based on the data from 2000 to 2017 and formulate predictions for subsequent periods. Results show that predictions on potential target types can be derived with adequate accuracy. Such results are useful for initiating, shifting and validating active terrorism surveillance based on predicted attack and target types per country from real past data.},
booktitle = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {1128–1135},
numpages = {8},
keywords = {data analysis, risk calculation, safety perception, terrorist attacks, threat ranking},
location = {Vancouver, British Columbia, Canada},
series = {ASONAM '19}
}

@inproceedings{10.1145/3394486.3403147,
author = {Ma, Chen and Ma, Liheng and Zhang, Yingxue and Tang, Ruiming and Liu, Xue and Coates, Mark},
title = {Probabilistic Metric Learning with Adaptive Margin for Top-K Recommendation},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403147},
doi = {10.1145/3394486.3403147},
abstract = {Personalized recommender systems are playing an increasingly important role as more content and services become available and users struggle to identify what might interest them. Although matrix factorization and deep learning based methods have proved effective in user preference modeling, they violate the triangle inequality and fail to capture fine-grained preference information. To tackle this, we develop a distance-based recommendation model with several novel aspects: (i) each user and item are parameterized by Gaussian distributions to capture the learning uncertainties; (ii) an adaptive margin generation scheme is proposed to generate the margins regarding different training triplets; (iii) explicit user-user/item-item similarity modeling is incorporated in the objective function. The Wasserstein distance is employed to determine preferences because it obeys the triangle inequality and can measure the distance between probabilistic distributions. Via a comparison using five real-world datasets with state-of-the-art methods, the proposed model outperforms the best existing models by 4-22% in terms of recall@K on Top-K recommendation.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1036–1044},
numpages = {9},
keywords = {adaptive learning, margin ranking loss, metric learning, recommender systems},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3447548.3467109,
author = {Katz, Yaniv and Vainas, Oded},
title = {Addressing Non-Representative Surveys using Multiple Instance Learning},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467109},
doi = {10.1145/3447548.3467109},
abstract = {In recent years, non representative survey sampling and non response bias constitute major obstacles in obtaining a reliable population quantity estimate from finite survey samples. As such, researchers have been focusing on identifying methods to resolve these biases. In this paper, we look at this well known problem from a fresh perspective, and formulate it as a learning problem. To meet this challenge, we suggest solving the learning problem using a multiple instance learning (MIL) paradigm. We devise two different MIL based neural network topologies, each based on a different implementation of an attention pooling layer. These models are trained to accurately infer the population quantity of interest even when facing a biased sample. To the best of our knowledge, this is the first time MIL has ever been suggested as a solution to this problem. In contrast to commonly used statistical methods, this approach can be accomplished without having to collect sensitive personal data of the respondents and without having to access population level statistics of the same sensitive data. To validate the effectiveness of our approaches, we test them on a real-world movie rating dataset which is used to mimic a biased survey by experimentally contaminating it with different kinds of survey bias. We show that our suggested topologies outperform other MIL architectures, and are able to partly counter the adverse effect of biased sampling on the estimation quality. We also demonstrate how these methods can be easily adapted to perform well even when part of the survey is based on a small number of respondents.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3117–3127},
numpages = {11},
keywords = {attention pooling, bag representation, instance representation, multiple instance learning, multiple instance regression, neural networks},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3394486.3403176,
author = {Muhammad, Khalil and Wang, Qinqin and O'Reilly-Morgan, Diarmuid and Tragos, Elias and Smyth, Barry and Hurley, Neil and Geraci, James and Lawlor, Aonghus},
title = {FedFast: Going Beyond Average for Faster Training of Federated Recommender Systems},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403176},
doi = {10.1145/3394486.3403176},
abstract = {Federated learning (FL) is quickly becoming the de facto standard for the distributed training of deep recommendation models, using on-device user data and reducing server costs. In a typical FL process, a central server tasks end-users to train a shared recommendation model using their local data. The local models are trained over several rounds on the users' devices and the server combines them into a global model, which is sent to the devices for the purpose of providing recommendations. Standard FL approaches use randomly selected users for training at each round, and simply average their local models to compute the global model. The resulting federated recommendation models require significant client effort to train and many communication rounds before they converge to a satisfactory accuracy. Users are left with poor quality recommendations until the late stages of training. We present a novel technique, FedFast, to accelerate distributed learning which achieves good accuracy for all users very early in the training process. We achieve this by sampling from a diverse set of participating clients in each training round and applying an active aggregation method that propagates the updated model to the other clients. Consequently, with FedFast the users benefit from far lower communication costs and more accurate models that can be consumed anytime during the training process even at the very early stages. We demonstrate the efficacy of our approach across a variety of benchmark datasets and in comparison to state-of-the-art recommendation techniques.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1234–1242},
numpages = {9},
keywords = {active sampling, communication costs, faster training, federated learning, recommender systems},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3447548.3467408,
author = {Huang, Tinglin and Dong, Yuxiao and Ding, Ming and Yang, Zhen and Feng, Wenzheng and Wang, Xinyu and Tang, Jie},
title = {MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467408},
doi = {10.1145/3447548.3467408},
abstract = {Graph neural networks (GNNs) have recently emerged as state-of-the-art collaborative filtering (CF) solution. A fundamental challenge of CF is to distill negative signals from the implicit feedback, but negative sampling in GNN-based CF has been largely unexplored. In this work, we propose to study negative sampling by leveraging both the user-item graph structure and GNNs' aggregation process. We present the MixGCF method---a general negative sampling plugin that can be directly used to train GNN-based recommender systems. In MixGCF, rather than sampling raw negatives from data, we design the hop mixing technique to synthesize hard negatives. Specifically, the idea of hop mixing is to generate the synthetic negative by aggregating embeddings from different layers of raw negatives' neighborhoods. The layer and neighborhood selection process are optimized by a theoretically-backed hard selection strategy. Extensive experiments demonstrate that by using MixGCF, state-of-the-art GNN-based recommendation models can be consistently and significantly improved, e.g., 26% for NGCF and 22% for LightGCN in terms of NDCG@20.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {665–674},
numpages = {10},
keywords = {collaborative filtering, graph neural networks, negative sampling, recommender systems},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3110025.3110126,
author = {Xu, Jian and Chawla, Nitesh V.},
title = {Mining Features Associated with Effective Tweets},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3110126},
doi = {10.1145/3110025.3110126},
abstract = {What tweet features are associated with higher effectiveness in tweets? Through the mining of 122 million engagements of 2.5 million original tweets, we present a systematic review of tweet time, entities, composition, and user account features. We show that the relationship between various features and tweeting effectiveness is non-linear; for example, tweets that use a few hashtags have higher effectiveness than using no or too many hashtags. This research closely relates to various industrial applications that are based on tweet features, including the analysis of advertising campaigns, the prediction of user engagement, the extraction of signals for automated trading, etc.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {525–532},
numpages = {8},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@inproceedings{10.1145/3341161.3342894,
author = {Cui, Limeng and Wang, Suhang and Lee, Dongwon},
title = {SAME: sentiment-aware multi-modal embedding for detecting fake news},
year = {2020},
isbn = {9781450368681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341161.3342894},
doi = {10.1145/3341161.3342894},
abstract = {How to effectively detect fake news and prevent its diffusion on social media has gained much attention in recent years. However, relatively little focus has been given on exploiting user comments left for posts and latent sentiments therein in detecting fake news. Inspired by the rich information available in user comments on social media, therefore, we investigate whether the latent sentiments hidden in user comments can potentially help distinguish fake news from reliable content. We incorporate users' latent sentiments into an end-to-end deep embedding framework for detecting fake news, named as SAME. First, we use multi-modal networks to deal with heterogeneous data modalities. Second, to learn semantically meaningful spaces per data source, we adopt an adversarial mechanism. Third, we define a novel regularization loss to bring embeddings of relevant pairs closer. Our comprehensive validation using two real-world datasets, PolitiFact and GossipCop, demonstrates the effectiveness of SAME in detecting fake news, significantly outperforming state-of-the-art methods.},
booktitle = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {41–48},
numpages = {8},
keywords = {fake news detection, multi-modal, social media},
location = {Vancouver, British Columbia, Canada},
series = {ASONAM '19}
}

@inproceedings{10.1145/2501221.2501230,
author = {Krauss, Christopher and George, Lars and Arbanowski, Stefan},
title = {TV predictor: personalized program recommendations to be displayed on SmartTVs},
year = {2013},
isbn = {9781450323246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2501221.2501230},
doi = {10.1145/2501221.2501230},
abstract = {Switching through the variety of available TV channels to find the most acceptable program at the current time can be very time-consuming. Especially at the prime time when there are lots of different channels offering quality content it is hard to find the best fitting channel.This paper introduces the TV Predictor, a new application that allows for obtaining personalized program recommendations without leaving the lean back position in front of the TV. Technically the usage of common Standards and Specifications, such as HbbTV, OIPF and W3C, leverage the convergence of broadband and broadcast media. Hints and details can overlay the broadcasting signal and so the user gets predictions in appropriate situations, for instance the most suitable movies playing tonight. Additionally the TV Predictor Autopilot enables the TV set to automatically change the currently viewed channel. A Second Screen Application mirrors the TV screen or displays additional content on tablet PCs and Smartphones.Based on the customers viewing behavior and explicit given ratings the server side application predicts what the viewer is going to favor. Different data mining approaches are combined in order to calculate the users preferences: Content Based Filtering algorithms for similar items, Collaborative Filtering algorithms for rating predictions, Clustering for increasing the performance, Association Rules for analyzing item relations and Support Vector Machines for the identification of behavior patterns. A ten fold cross validation shows an accuracy in prediction of about 80%.TV specialized User Interfaces, user generated feedback data and calculated algorithm results, such as Association Rules, are analyzed to underline the characteristics of such a TV based application.},
booktitle = {Proceedings of the 2nd International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications},
pages = {63–70},
numpages = {8},
keywords = {SmartTV, algorithms, collaborative filtering, content-based filtering, hybrid TV, offline, online, recommendation},
location = {Chicago, Illinois},
series = {BigMine '13}
}

@inproceedings{10.1145/3394486.3403344,
author = {Cen, Yukuo and Zhang, Jianwei and Zou, Xu and Zhou, Chang and Yang, Hongxia and Tang, Jie},
title = {Controllable Multi-Interest Framework for Recommendation},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403344},
doi = {10.1145/3394486.3403344},
abstract = {Recently, neural networks have been widely used in e-commerce recommender systems, owing to the rapid development of deep learning. We formalize the recommender system as a sequential recommendation problem, intending to predict the next items that the user might be interacted with. Recent works usually give an overall embedding from a user's behavior sequence. However, a unified user embedding cannot reflect the user's multiple interests during a period. In this paper, we propose a novel controllable multi-interest framework for the sequential recommendation, called ComiRec. Our multi-interest module captures multiple interests from user behavior sequences, which can be exploited for retrieving candidate items from the large-scale item pool. These items are then fed into an aggregation module to obtain the overall recommendation. The aggregation module leverages a controllable factor to balance the recommendation accuracy and diversity. We conduct experiments for the sequential recommendation on two real-world datasets, Amazon and Taobao. Experimental results demonstrate that our framework achieves significant improvements over state-of-the-art models. Our framework has also been successfully deployed on the offline Alibaba distributed cloud platform.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2942–2951},
numpages = {10},
keywords = {multi-interest framework, recommender system, sequential recommendation},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/2487575.2487646,
author = {Zhang, Wei and Wang, Jianyong and Feng, Wei},
title = {Combining latent factor model with location features for event-based group recommendation},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487646},
doi = {10.1145/2487575.2487646},
abstract = {Groups play an essential role in many social websites which promote users' interactions and accelerate the diffusion of information. Recommending groups that users are really interested to join is significant for both users and social media. While traditional group recommendation problem has been extensively studied, we focus on a new type of the problem, i.e., event-based group recommendation. Unlike the other forms of groups, users join this type of groups mainly for participating offline events organized by group members or inviting other users to attend events sponsored by them. These characteristics determine that previously proposed approaches for group recommendation cannot be adapted to the new problem easily as they ignore the geographical influence and other explicit features of groups and users.In this paper, we propose a method called Pairwise Tag enhAnced and featuRe-based Matrix factorIzation for Group recommendAtioN (PTARMIGAN), which considers location features, social features, and implicit patterns simultaneously in a unified model. More specifically, we exploit matrix factorization to model interactions between users and groups. Meanwhile, we incorporate their profile information into pairwise enhanced latent factors respectively. We also utilize the linear model to capture explicit features. Due to the reinforcement between explicit features and implicit patterns, our approach can provide better group recommendations. We conducted a comprehensive performance evaluation on real word data sets and the experimental results demonstrate the effectiveness of our method.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {910–918},
numpages = {9},
keywords = {event-based group recommendation, latent factor model, location feature},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@inproceedings{10.1145/3326937.3341251,
author = {Wen, Ying and Chen, Tianyao and Wang, Jun and Zhang, Weinan},
title = {Pairwise multi-layer nets for learning distributed representation of multi-field categorical data},
year = {2019},
isbn = {9781450367837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326937.3341251},
doi = {10.1145/3326937.3341251},
abstract = {This paper presents a method of pairwise multi-layer networks for multi-field categorical data, which widely exists with various applications such as web search, recommender systems, social link prediction, and computational advertising. The success of non-linear models, e.g., factorization machines, boosted trees, has proved the potential of exploring the interactions among inter-field discrete categories. Inspired by Word2Vec, the distributed representation for natural language, we propose a PMLN (Pairwise Multi-Layer Nets) model to learn the distributed representation for multi-field categorical data. In PMLN, a low-dimensional continuous vector is automatically learned for each category in each field. The interactions among inter-field categories are explored by different neural gates and the most informative ones are selected by pooling layers. Such combined categories can be further explored by performing more gate interactions with another category and then selected by additional pooling operations. In our experiments, with the exploration of the interactions between pairwise categories over layers, the model outperforms state-of-the-art models in a supervised learning task, i.e., ad click prediction, while capturing the most significant interactions from the data in an unsupervised fashion.},
booktitle = {Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data},
articleno = {2},
numpages = {8},
location = {Anchorage, Alaska},
series = {DLP-KDD '19}
}

@inproceedings{10.1145/2783258.2783260,
author = {Kawamae, Noriaki},
title = {Real Time Recommendations from Connoisseurs},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2783260},
doi = {10.1145/2783258.2783260},
abstract = {The information overload problem remains serious for both consumers and service/content providers, leading to heightened demands for personalized recommendations. For recommender systems, updating user models is one of the most important tasks to keep up with their changing preferences and trends. Especially since new consumers and items emerge every day, which are promptly rated or reviewed, updating lists of items and rankings is crucial. In this paper, we set the goal of real time recommendation, to present these items instantly. Unlike standard collaborative filtering algorithms, our offline approach focuses only innovative consumers for these predictions, and then uses as few consumers as possible while keeping the same precision. Since innovators exist in many communities, and their opinions will spread and then stimulate their followers to adopt the same behavior, our approach is based on the hypothesis that a set of innova- tive consumers is sufficient to represent the most representative opinions in each community. Following this hypothesis, we derive a scalable method to detect both communities and innovative consumers in each community from a web- scale data from a behavior log. Our evaluation shows that our proposed weighting method can accurately sample given logs, and be compatible only with previous algorithms for real time recommendations.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {537–546},
numpages = {10},
keywords = {nonparametric models, personalization, real time recommendations, recommendations, serendipitous, topic models},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.1145/3292500.3330928,
author = {Dey, Sanjoy and Zhang, Ping and Sow, Daby and Ng, Kenney},
title = {PerDREP: Personalized Drug Effectiveness Prediction from Longitudinal Observational Data},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330928},
doi = {10.1145/3292500.3330928},
abstract = {In contrast to the one-size-fits-all approach to medicine, precision medicine will allow targeted prescriptions based on the specific profile of the patient thereby avoiding adverse reactions and ineffective but expensive treatments. Longitudinal observational data such as Electronic Health Records (EHRs) have become an emerging data source for personalized medicine. In this paper, we propose a unified computational framework, called PerDREP, to predict the unique response patterns of each individual patient from EHR data. PerDREP models individual responses of each patient to the drug exposure by introducing a linear system to account for patients' heterogeneity, and incorporates a patient similarity graph as a network regularization. We formulate PerDREP as a convex optimization problem and develop an iterative gradient descent method to solve it. In the experiments, we identify the effect of drugs on Glycated hemoglobin test results. The experimental results provide evidence that the proposed method is not only more accurate than state-of-the-art methods, but is also able to automatically cluster patients into multiple coherent groups, thus paving the way for personalized medicine.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1258–1268},
numpages = {11},
keywords = {data mining, healthcare informatics, personalized model},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/2339530.2339563,
author = {Shi, Kent and Ali, Kamal},
title = {GetJar mobile application recommendations with very sparse datasets},
year = {2012},
isbn = {9781450314626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2339530.2339563},
doi = {10.1145/2339530.2339563},
abstract = {The Netflix competition of 2006 [2] has spurred significant activity in the recommendations field, particularly in approaches using latent factor models [3,5,8,12] However, the near ubiquity of the Netflix and the similar MovieLens datasets1 may be narrowing the generality of lessons learned in this field. At GetJar, our goal is to make appealing recommendations of mobile applications (apps). For app usage, we observe a distribution that has higher kurtosis (heavier head and longer tail) than that for the aforementioned movie datasets. This happens primarily because of the large disparity in resources available to app developers and the low cost of app publication relative to movies.In this paper we compare a latent factor (PureSVD) and a memory-based model with our novel PCA-based model, which we call Eigenapp. We use both accuracy and variety as evaluation metrics. PureSVD did not perform well due to its reliance on explicit feedback such as ratings, which we do not have. Memory-based approaches that perform vector operations in the original high dimensional space over-predict popular apps because they fail to capture the neighborhood of less popular apps. They have high accuracy due to the concentration of mass in the head, but did poorly in terms of variety of apps exposed. Eigenapp, which exploits neighborhood information in low dimensional spaces, did well both on precision and variety, underscoring the importance of dimensionality reduction to form quality neighborhoods in high kurtosis distributions.},
booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {204–212},
numpages = {9},
keywords = {PCA, evaluation, mobile application, recommender system, sparse data},
location = {Beijing, China},
series = {KDD '12}
}

@inproceedings{10.5555/3191835.3191956,
author = {Xue, Huan and Guo, Jiafeng and Lan, Yanyan and Cao, Lei},
title = {Personalized paper recommendation in online social scholar system},
year = {2014},
isbn = {9781479958764},
publisher = {IEEE Press},
abstract = {This paper presents a practical paper recommender system, which aims to provide personalized research paper recommendations to users within an online social scholar system. As an online recommender system, there are three basic problems we need to tackle: 1) How to formalize and solve the recommendation problem; 2) How to achieve real time recommendation; and 3) How to interact with users. In our work, we take the personalized paper recommendation as a ranking problem with respect to users' research interests, and employ a supervised learning to rank approach to solve the problem. However, most previous learning to rank methods rely on manually labeled training data which are both expensive and limited in size. We propose automatical training data construction by mining the existing large scale academic network, and extract various heterogeneous features for learning. With the learned model, we conduct real time personalized recommendation based on our novel efficient candidate generation approach. In addition, update recommendation is employed to interact with users according to different types of user feedbacks. Finally, we demonstrate the effectiveness of our system by both offline and online evaluation.},
booktitle = {Proceedings of the 2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {612–619},
numpages = {8},
keywords = {heterogeneous academic network, learning to rank, paper recommender system, user feedback},
location = {Beijing, China},
series = {ASONAM '14}
}

@inproceedings{10.1145/3447548.3467172,
author = {Ramanath, Rohan and Salomatin, Konstantin and Gee, Jeffrey D. and Talanine, Kirill and Dalal, Onkar and Polatkan, Gungor and Smoot, Sara and Kumar, Deepak},
title = {Lambda Learner: Fast Incremental Learning on Data Streams},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467172},
doi = {10.1145/3447548.3467172},
abstract = {One of the most well-established applications of machine learning is in deciding what content to show website visitors. When observation data comes from high-velocity, user-generated data streams, machine learning methods perform a balancing act between model complexity, training time, and computational costs. Furthermore, when model freshness is critical, the training of models becomes time-constrained. Parallelized batch offline training, although horizontally scalable, is often not time-considerate or cost-effective. In this paper, we propose Lambda Learner, a new framework for training models by incremental updates in response to mini-batches from data streams. We show that the resulting model of our framework closely estimates a periodically updated model trained on offline data and outperforms it when model updates are time-sensitive. We provide theoretical proof that the incremental learning updates improve the loss-function over a stale batch model. We present a large-scale deployment on the sponsored content platform for a large social network, serving hundreds of millions of users across different channels (e.g., desktop, mobile). We address challenges and complexities from both algorithms and infrastructure perspectives, illustrate the system details for computation, storage, stream processing training data, and open-source the system.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3492–3502},
numpages = {11},
keywords = {incremental online learning, mixed-effect models, personalization, recommender systems, reinforcement learning},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3110025.3110083,
author = {Ganesh, J. and Gupta, Manish and Varma, Vasudeva},
title = {Interpretation of Semantic Tweet Representations},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3110083},
doi = {10.1145/3110025.3110083},
abstract = {Research in analysis of microblogging platforms is experiencing a renewed surge with a large number of works applying representation learning models for applications like sentiment analysis, semantic textual similarity computation, hashtag prediction, etc. Although the performance of the representation learning models has been better than the traditional baselines for such tasks, little is known about the elementary properties of a tweet encoded within these representations, or why particular representations work better for certain tasks. Our work presented here constitutes the first step in opening the black-box of vector embeddings for tweets.Traditional feature engineering methods for high-level applications have exploited various elementary properties of tweets. We believe that a tweet representation is effective for an application because it meticulously encodes the application-specific elementary properties of tweets. To understand the elementary properties encoded in a tweet representation, we evaluate the representations on the accuracy to which they can model each of those properties such as tweet length, presence of particular words, hashtags, mentions, capitalization, etc.Our systematic extensive study of nine supervised and four unsupervised tweet representations against most popular eight textual and five social elementary properties reveal that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors (STV) best encode the textual and social properties of tweets respectively. FastText is the best model for low resource settings, providing very little degradation with reduction in embedding size. Finally, we draw interesting insights by correlating the model performance obtained for elementary property prediction tasks with the high-level downstream applications.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {95–102},
numpages = {8},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@inproceedings{10.1145/2623330.2623720,
author = {Wang, Ting and Wang, Dashun and Wang, Fei},
title = {Quantifying herding effects in crowd wisdom},
year = {2014},
isbn = {9781450329569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2623330.2623720},
doi = {10.1145/2623330.2623720},
abstract = {In many diverse settings, aggregated opinions of others play an increasingly dominant role in shaping individual decision making. One key prerequisite of harnessing the "crowd wisdom" is the independency of individuals' opinions, yet in real settings collective opinions are rarely simple aggregations of independent minds. Recent experimental studies document that disclosing prior collective opinions distorts individuals' decision making as well as their perceptions of quality and value, highlighting a fundamental disconnect from current modeling efforts: How to model social influence and its impact on systems that are constantly evolving? In this paper, we develop a mechanistic framework to model social influence of prior collective opinions (e.g., online product ratings) on subsequent individual decision making. We find our method successfully captures the dynamics of rating growth, helping us separate social influence bias from inherent values. Using large-scale longitudinal customer rating datasets, we demonstrate that our model not only effectively assesses social influence bias, but also accurately predicts long-term cumulative growth of ratings solely based on early rating trajectories. We believe our framework will play an increasingly important role as our understanding of social processes deepens. It promotes strategies to untangle manipulations and social biases and provides insights towards a more reliable and effective design of social platforms.},
booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1087–1096},
numpages = {10},
keywords = {crowd wisdom, herding effect, social influence},
location = {New York, New York, USA},
series = {KDD '14}
}

@inproceedings{10.1145/1722149.1722154,
author = {Celma, \`{O}scar and Cano, Pedro},
title = {From hits to niches? or how popular artists can bias music recommendation and discovery},
year = {2008},
isbn = {9781605582658},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1722149.1722154},
doi = {10.1145/1722149.1722154},
abstract = {This paper presents some experiments to analyse the popularity effect in music recommendation. Popularity is measured in terms of total playcounts, and the Long Tail model is used in order to rank music artists. Furthermore, metrics derived from complex network analysis are used to detect the influence of the most popular artists in the network of similar artists.The results from the experiments reveal that---as expected by its inherent social component---the collaborative filtering approach is prone to popularity bias. This has some consequences on the discovery ratio as well as in the navigation through the Long Tail. On the other hand, in both audio content--based and human expert--based approaches artists are linked independently of their popularity. This allows one to navigate from a mainstream artist to a Long Tail artist in just two or three clicks.},
booktitle = {Proceedings of the 2nd KDD Workshop on Large-Scale Recommender Systems and the Netflix Prize Competition},
articleno = {5},
numpages = {8},
keywords = {complex network analysis, evaluation, long tail, popularity, recommender systems},
location = {Las Vegas, Nevada},
series = {NETFLIX '08}
}

@inproceedings{10.1145/3097983.3098048,
author = {Tata, Sandeep and Popescul, Alexandrin and Najork, Marc and Colagrosso, Mike and Gibbons, Julian and Green, Alan and Mah, Alexandre and Smith, Michael and Garg, Divanshu and Meyer, Cayden and Kan, Reuben},
title = {Quick Access: Building a Smart Experience for Google Drive},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098048},
doi = {10.1145/3097983.3098048},
abstract = {Google Drive is a cloud storage and collaboration service used by hundreds of millions of users around the world. Quick Access is a new feature in Google Drive that surfaces the most relevant documents when a user visits the home screen. Our metrics show that users locate their documents in half the time with this feature compared to previous approaches. The development of Quick Access illustrates many general challenges and constraints associated with practical machine learning such as protecting user privacy, working with data services that are not designed with machine learning in mind, and evolving product definitions. We believe that the lessons learned from this experience will be useful to practitioners tackling a wide range of applied machine learning problems.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1643–1651},
numpages = {9},
keywords = {applied machine learning, neural networks, private data},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3292500.3330873,
author = {Wang, Qinyong and Yin, Hongzhi and Wang, Hao and Nguyen, Quoc Viet Hung and Huang, Zi and Cui, Lizhen},
title = {Enhancing Collaborative Filtering with Generative Augmentation},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330873},
doi = {10.1145/3292500.3330873},
abstract = {Collaborative filtering (CF) has become one of the most popular and widely used methods in recommender systems, but its performance degrades sharply for users with rare interaction data. Most existing hybrid CF methods try to incorporate side information such as review texts to alleviate the data sparsity problem. However, the process of exploiting and integrating side information is computationally expensive. Existing hybrid recommendation methods treat each user equally and ignore that the pure CF methods have already achieved both effective and efficient recommendation performance for active users with sufficient interaction records and the little improvement brought by side information to these active users is ignorable. Therefore, they are not cost-effective solutions. One cost-effective idea to bypass this dilemma is to generate sufficient "real" interaction data for the inactive users with the help of side information, and then a pure CF method could be performed on this augmented dataset effectively. However, there are three major challenges to implement this idea. Firstly, how to ensure the correctness of the generated interaction data. Secondly, how to combine the data augmentation process and recommendation process into a unified model and train the model end-to-end. Thirdly, how to make the solution generalizable for various side information and recommendation tasks. In light of these challenges, we propose a generic and effective CF model called AugCF that supports a wide variety of recommendation tasks. AugCF is based on Conditional Generative Adversarial Nets that additionally consider the class (like or dislike) as a feature to generate new interaction data, which can be a sufficiently real augmentation to the original dataset. Also, AugCF adopts a novel discriminator loss and Gumbel-Softmax approximation to enable end-to-end training. Finally, extensive experiments are conducted on two large-scale recommendation datasets, and the experimental results show the superiority of our proposed model.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {548–556},
numpages = {9},
keywords = {adversarial training, collaborative filtering, data sparsit},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/2783258.2783340,
author = {Li, Liangyue and Tong, Hanghang},
title = {The Child is Father of the Man: Foresee the Success at the Early Stage},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2783340},
doi = {10.1145/2783258.2783340},
abstract = {Understanding the dynamic mechanisms that drive the high-impact scientific work (e.g., research papers, patents) is a long-debated research topic and has many important implications, ranging from personal career development and recruitment search, to the jurisdiction of research resources. Recent advances in characterizing and modeling scientific success have made it possible to forecast the long-term impact of scientific work, where data mining techniques, supervised learning in particular, play an essential role. Despite much progress, several key algorithmic challenges in relation to predicting long-term scientific impact have largely remained open. In this paper, we propose a joint predictive model to forecast the long-term scientific impact at the early stage, which simultaneously addresses a number of these open challenges, including the scholarly feature design, the non-linearity, the domain-heterogeneity and dynamics. In particular, we formulate it as a regularized optimization problem and propose effective and scalable algorithms to solve it. We perform extensive empirical evaluations on large, real scholarly data sets to validate the effectiveness and the efficiency of our method.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {655–664},
numpages = {10},
keywords = {joint predictive model, long term impact prediction},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.1145/2939672.2939692,
author = {Gupta, Rupesh and Liang, Guanfeng and Tseng, Hsiao-Ping and Holur Vijay, Ravi Kiran and Chen, Xiaoyu and Rosales, Romer},
title = {Email Volume Optimization at LinkedIn},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939692},
doi = {10.1145/2939672.2939692},
abstract = {Online social networking services distribute various types of messages to their members. Common types of messages include news, connection requests, membership notifications, promotions and event notifications. Such communication, if used judiciously, can provide an enormous value to members thereby keeping them engaged. However sending a message for every instance of news, connection request, or the like can result in an overwhelming number of messages in a member's mailbox. This may result in reduced effectiveness of communication if the messages are not sufficiently relevant to the member's interests. It may also result in a poor brand perception of the networking service. In this paper we discuss our strategy and experience with regard to the problem of email volume optimization at LinkedIn. In particular, we present a cost-benefit analysis of sending emails, the key factors to administer an effective volume optimization, our algorithm for volume optimization, the architecture of the supporting system and experimental results from online A/B tests.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {97–106},
numpages = {10},
keywords = {email, machine learning, optimization},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/3580305.3599764,
author = {Wang, Chao and Shi, Xiaowei and Xu, Shuai and Wang, Zhe and Fan, Zhiqiang and Feng, Yan and You, An and Chen, Yu},
title = {A Multi-stage Framework for Online Bonus Allocation Based on Constrained User Intent Detection},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599764},
doi = {10.1145/3580305.3599764},
abstract = {With the explosive development of e-commerce for service, tens of millions of orders are generated every day on the Meituan platform. By allocating bonuses to new customers when they pay, the Meituan platform encourages them to use its own payment service for a better experience in the future. It can be formulated as a multi-choice knapsack problem (MCKP), and the mainstream solution is usually a two-stage method. The first stage is user intent detection, predicting the effect for each bonus treatment. Then, it serves as the objective of the MCKP, and the problem is solved in the second stage to obtain the optimal allocation strategy. However, this solution usually faces the following challenges: (1) In the user intent detection stage, due to the sparsity of interaction and noise, the traditional multi-treatment effect estimation methods lack interpretability, which may violate the domain knowledge that the marginal gain is non-negative with the increase of the bonus amount in economic theory. (2) There is an optimality gap between the two stages, which limits the upper bound of the optimal value obtained in the second stage. (3) Due to changes in the distribution of orders online, the actual cost consumption often violates the given budget limit. To solve the above challenges, we propose a framework that consists of three modules, i.e., User Intent Detection Module, Online Allocation Module, and Feedback Control Module. In the User Intent Detection Module, we implicitly model the treatment increment based on deep representation learning and constrain it to be non-negative to achieve monotonicity constraints. Then, in order to reduce the optimality gap, we further propose a convex constrained model to increase the upper bound of the optimal value. For the third challenge, to cope with the fluctuation of online bonus consumption, we leverage a feedback control strategy in the framework to make the actual cost more accurately approach the given budget limit. Finally, we conduct extensive offline and online experiments, demonstrating the superiority of our proposed framework, which reduced customer acquisition costs by 5.07% and is still running online.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5028–5038},
numpages = {11},
keywords = {bonus allocation, convex constraint, e-commerce, monotonic constraint, multi-treatment effect estimation},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/2339530.2339728,
author = {Yang, Xiwang and Steck, Harald and Liu, Yong},
title = {Circle-based recommendation in online social networks},
year = {2012},
isbn = {9781450314626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2339530.2339728},
doi = {10.1145/2339530.2339728},
abstract = {Online social network information promises to increase recommendation accuracy beyond the capabilities of purely rating/feedback-driven recommender systems (RS). As to better serve users' activities across different domains, many online social networks now support a new feature of "Friends Circles", which refines the domain-oblivious "Friends" concept. RS should also benefit from domain-specific "Trust Circles". Intuitively, a user may trust different subsets of friends regarding different domains. Unfortunately, in most existing multi-category rating datasets, a user's social connections from all categories are mixed together. This paper presents an effort to develop circle-based RS. We focus on inferring category-specific social trust circles from available rating data combined with social network data. We outline several variants of weighting friends within circles based on their inferred expertise levels. Through experiments on publicly available data, we demonstrate that the proposed circle-based recommendation models can better utilize user's social trust information, resulting in increased recommendation accuracy.},
booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1267–1275},
numpages = {9},
keywords = {collaborative filtering, friends circles, online social networks, recommender systems},
location = {Beijing, China},
series = {KDD '12}
}

@inproceedings{10.1145/3110025.3110071,
author = {Kolli, Naimisha and Balakrishnan, N. and Ramakrishnan, K. R.},
title = {On Quantifying Predictability in Online Social Media Cascades Using Entropy},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3110071},
doi = {10.1145/3110025.3110071},
abstract = {Predicting cascade volumes in social media communication is an important topic in furthering the use of social media for viral marketing, impact of political campaigns and in home-land security. Several techniques have been reported in the literature to estimate the cascade volumes. These algorithms use a variety of information such as Content, Structural and Temporal features, depending on their availability. Due to the spread of information infused into the algorithms the prediction accuracy has been shown in the literature to be different for different algorithms.Entropy based measures that are tailored for the differing situations of information availability have been successfully applied in the prediction scenarios in many fields including network traffic, human mobility and radio spectrum state dynamics as well as in atmospheric science. In this paper we adopt a multitude of entropy based measures for quantifying the predictability of cascade volumes in online social media communications. The limit derived from the entropy measures discussed in this paper has also been used to explain the difference in accuracies of some of the algorithms for cascade volume predictions reported in the literature. For the purpose of illustration and to demonstrate the utility of the entropy based predictability limits we have used two data sets, the MemeTracker dataset and Twitter Hashtags dataset. The results obtained in this paper demonstrate clearly the utility of entropy based measures for quantifying the predictability in online social media cascades. We have also shown that temporal relevancy is a dominant contributing factor in cascade predictability and how additional features such as the knowledge of a small number of large media sites and blogs can have significant influence on the prediction performance.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {109–114},
numpages = {6},
keywords = {Cascade Volume Predictions, cascade entropy measures, maximal predictability, social media cascades},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@inproceedings{10.1145/3110025.3110107,
author = {Srijith, P. K. and Lukasik, Michal and Bontcheva, Kalina and Cohn, Trevor},
title = {Longitudinal Modeling of Social Media with Hawkes Process Based on Users and Networks},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3110107},
doi = {10.1145/3110025.3110107},
abstract = {Online social media provide a platform for rapid network propagation of information at an unprecedented scale. In this paper, we study the evolution of information cascades in Twitter using a point process model of user activity. Twitter is rich with heterogenous information on users and network structure. We develop several Hawkes process models considering various properties of Twitter including conversational structure, users' connections and general features of users including the textual information, and show how they are helpful in modeling the social network activity. Evaluation on Twitter data sets shows that incorporating richer properties improves the performance in predicting future activity of users and memes.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {195–202},
numpages = {8},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@inproceedings{10.1145/1557019.1557029,
author = {Agarwal, Deepak and Chen, Bee-Chung},
title = {Regression-based latent factor models},
year = {2009},
isbn = {9781605584959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1557019.1557029},
doi = {10.1145/1557019.1557029},
abstract = {We propose a novel latent factor model to accurately predict response for large scale dyadic data in the presence of features. Our approach is based on a model that predicts response as a multiplicative function of row and column latent factors that are estimated through separate regressions on known row and column features. In fact, our model provides a single unified framework to address both cold and warm start scenarios that are commonplace in practical applications like recommender systems, online advertising, web search, etc. We provide scalable and accurate model fitting methods based on Iterated Conditional Mode and Monte Carlo EM algorithms. We show our model induces a stochastic process on the dyadic space with kernel (covariance) given by a polynomial function of features. Methods that generalize our procedure to estimate factors in an online fashion for dynamic applications are also considered. Our method is illustrated on benchmark datasets and a novel content recommendation application that arises in the context of Yahoo! Front Page. We report significant improvements over several commonly used methods on all datasets.},
booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {19–28},
numpages = {10},
keywords = {dyadic data, interaction, latent factor, predictive, recommender systems, sparse},
location = {Paris, France},
series = {KDD '09}
}

@inproceedings{10.1145/1722149.1722153,
author = {T\"{o}scher, Andreas and Jahrer, Michael and Legenstein, Robert},
title = {Improved neighborhood-based algorithms for large-scale recommender systems},
year = {2008},
isbn = {9781605582658},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1722149.1722153},
doi = {10.1145/1722149.1722153},
abstract = {Neighborhood-based algorithms are frequently used modules of recommender systems. Usually, the choice of the similarity measure used for evaluation of neighborhood relationships is crucial for the success of such approaches. In this article we propose a way to calculate similarities by formulating a regression problem which enables us to extract the similarities from the data in a problem-specific way. Another popular approach for recommender systems is regularized matrix factorization (RMF). We present an algorithm -- neighborhood-aware matrix factorization -- which efficiently includes neighborhood information in a RMF model. This leads to increased prediction accuracy. The proposed methods are tested on the Netflix dataset.},
booktitle = {Proceedings of the 2nd KDD Workshop on Large-Scale Recommender Systems and the Netflix Prize Competition},
articleno = {4},
numpages = {6},
keywords = {KNN, Netflix, collaborative filtering, ensemble performance, latent factor model, matrix factorization, recommender systems, similarity matrix},
location = {Las Vegas, Nevada},
series = {NETFLIX '08}
}

@inproceedings{10.1145/2783258.2788615,
author = {Xu, Jian and Lee, Kuang-chih and Li, Wentong and Qi, Hang and Lu, Quan},
title = {Smart Pacing for Effective Online Ad Campaign Optimization},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2788615},
doi = {10.1145/2783258.2788615},
abstract = {In targeted online advertising, advertisers look for maximizing campaign performance under delivery constraint within budget schedule. Most of the advertisers typically prefer to impose the delivery constraint to spend budget smoothly over the time in order to reach a wider range of audiences and have a sustainable impact. Since lots of impressions are traded through public auctions for online advertising today, the liquidity makes price elasticity and bid landscape between demand and supply change quite dynamically. Therefore, it is challenging to perform smooth pacing control and maximize campaign performance simultaneously. In this paper, we propose a smart pacing approach in which the delivery pace of each campaign is learned from both offline and online data to achieve smooth delivery and optimal performance goals. The implementation of the proposed approach in a real DSP system is also presented. Experimental evaluations on both real online ad campaigns and offline simulations show that our approach can effectively improve campaign performance and achieve delivery goals.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {2217–2226},
numpages = {10},
keywords = {budget pacing, campaign optimization, demand-side platform},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.1145/2939672.2939792,
author = {Trouleau, William and Ashkan, Azin and Ding, Weicong and Eriksson, Brian},
title = {Just One More: Modeling Binge Watching Behavior},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939792},
doi = {10.1145/2939672.2939792},
abstract = {Easy accessibility can often lead to over-consumption, as seen in food and alcohol habits. On video on-demand (VOD) services, this has recently been referred to as binge watching, where potentially entire seasons of TV shows are consumed in a single viewing session. While a user viewership model may reveal this binging behavior, creating an accurate model has several challenges, including censored data, deviations in the population, and the need to consider external influences on consumption habits. In this paper, we introduce a novel statistical mixture model that incorporates these factors and presents a first of its kind characterization of viewer consumption behavior using a real-world dataset that includes playback data from a VOD service. From our modeling, we tackle various predictive tasks to infer the consumption decisions of a user in a viewing session, including estimating the number of episodes they watch and classifying if they continue watching another episode. Using these insights, we then identify binge watching sessions based on deviation from normal viewing behavior. We observe different types of binging behavior, that binge watchers often view certain content out-of-order, and that binge watching is not a consistent behavior among our users. These insights and our findings have application in VOD revenue generation, consumer health applications, and customer retention analysis.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1215–1224},
numpages = {10},
keywords = {binge watching, censored poisson regression, mixture model},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/2808797.2809311,
author = {Doran, Derek and Yelne, Samir and Massari, Luisa and Calzarossa, Maria-Carla and Jackson, LaTrelle and Moriarty, Glen},
title = {Stay Awhile and Listen: User Interactions in a Crowdsourced Platform Offering Emotional Support},
year = {2015},
isbn = {9781450338547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2808797.2809311},
doi = {10.1145/2808797.2809311},
abstract = {Internet and online-based social systems are rising as the dominant mode of communication in society. However, the public or semi-private environment under which most online communications operate under do not make them suitable channels for speaking with others about personal or emotional problems. This has led to the emergence of online platforms for emotional support offering free, anonymous, and confidential conversations with live listeners. Yet very little is known about the way these platforms are utilized, and if their features and design foster strong user engagement. This paper explores the utilization and the interaction features of hundreds of thousands of users on 7 Cups of Tea, a leading online platform offering online emotional support. It dissects the user's activity levels, the patterns by which they engage in conversation with each other, and uses machine learning methods to find factors promoting engagement. The study may be the first to measure activities and interactions in a large-scale online social system that fosters peer-to-peer emotional support.},
booktitle = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015},
pages = {667–674},
numpages = {8},
location = {Paris, France},
series = {ASONAM '15}
}

@inproceedings{10.1145/3292500.3330764,
author = {Tu, Ye and Lo, Chun and Yuan, Yiping and Chatterjee, Shaunak},
title = {Feedback Shaping: A Modeling Approach to Nurture Content Creation},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330764},
doi = {10.1145/3292500.3330764},
abstract = {Social media platforms bring together content creators and content consumers through recommender systems like newsfeed. The focus of such recommender systems has thus far been primarily on modeling the content consumer preferences and optimizing for their experience. However, it is equally critical to nurture content creation by prioritizing the creators' interests, as quality content forms the seed for sustainable engagement and conversations, bringing in new consumers while retaining existing ones. In this work, we propose a modeling approach to predict how feedback from content consumers incentivizes creators. We then leverage this model to optimize the newsfeed experience for content creators by reshaping the feedback distribution, leading to a more active content ecosystem. Practically, we discuss how we balance the user experience for both consumers and creators, and how we carry out online A/B tests with strong network effects. We present a deployed use case on the LinkedIn newsfeed, where we used this approach to improve content creation significantly without compromising the consumers' experience.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2241–2250},
numpages = {10},
keywords = {content creation optimization, feed ranking, machine learning, recommendation system, social network},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/3219819.3220061,
author = {Liu, Xinyue and Kong, Xiangnan and Yu, Philip S.},
title = {Active Opinion Maximization in Social Networks},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220061},
doi = {10.1145/3219819.3220061},
abstract = {Influence maximization (IM) targets at maximizing the number of users being aware of a product by finding a set of seed users to expose in a social network. Previous IM models mainly focus on optimizing the spread of product consumption, which assumes that all users are potential customers and more exposures lead to better profit. However, in the real-world scenario, some people may not like the product and may express negative opinions after consuming, which damage the product reputation and harm the long-term profit. Only a portion of users in the social network, called the target user, is the potential customer that likes the product and will spread positive opinion. In this paper, we consider a problem called AcTive Opinion Maximization (ATOM), where the goal is to find a set of seed users to maximize the overall opinion spread toward a target product in a multi-round campaign. Different from previous works, we do not assume the user opinion is known before consumption, but should be derived from user preference data. The ATOM problem has essential applications in viral marketing, such as reputation building and precision advertising. Given its significance, ATOM problem is profoundly challenging due to the hardness of estimating user opinion in a multi-round campaign. Moreover, the process of opinion estimation and influence propagation intertwine with each other, which requires the model to consider the two components collectively. We propose an active learning framework called CONE (aCtive OpinioN Estimator) to address above challenges. Experimental results on two real-world datasets demonstrate that CONE improves the total opinion spread in a social network.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1840–1849},
numpages = {10},
keywords = {active learning, influence maximization, matrix factorization, opinion maximization, social networks, viral marketing},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.5555/3382225.3382371,
author = {Thukral, Sachin and Meisheri, Hardik and Kataria, Tushar and Agarwal, Aman and Verma, Ishan and Chatterjee, Arnab and Dey, Lipika},
title = {Analyzing behavioral trends in community driven discussion platforms like reddit},
year = {2020},
isbn = {9781538660515},
publisher = {IEEE Press},
abstract = {The aim of this paper is to present methods to systematically analyze individual and group behavioral patterns observed in community driven discussion platforms like Reddit where users exchange information and views on various topics of current interest. We conduct this study by analyzing the statistical behavior of posts and modeling user interactions around them. We have chosen Reddit as an example, since it has grown exponentially from a small community to one of the biggest social network platforms in the recent times. Due to its large user base and popularity, a variety of behavior is present among users in terms of their activity. Our study provides interesting insights about a large number of inactive posts which fail to gather attention despite their authors exhibiting Cyborg-like behavior to draw attention. We also present interesting insights about shortlived but extremely active posts emulating a phenomenon like Mayfly Buzz. Further, we present methods to find the nature of activity around highly active posts to determine the presence of Limelight hogging activity, if any. We analyzed over 2 million posts and more than 7 million user responses to them during entire 2008 and over 63 million posts and over 608 million user responses to them from August 2014 to July 2015 amounting to two one-year periods, in order to understand how social media space has evolved over the years.},
booktitle = {Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {662–669},
numpages = {8},
keywords = {behavioral analysis, reddit, social network analysis},
location = {Barcelona, Spain},
series = {ASONAM '18}
}

@inproceedings{10.1145/3097983.3098104,
author = {Manzoor, Emaad and Akoglu, Leman},
title = {RUSH! Targeted Time-limited Coupons via Purchase Forecasts},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098104},
doi = {10.1145/3097983.3098104},
abstract = {Time-limited promotions that exploit consumers' sense of urgency to boost sales account for billions of dollars in consumer spending each year. However, it is challenging to discover the right timing and duration of a promotion to increase its chances of being redeemed. In this work, we consider the problem of delivering time-limited discount coupons, where we partner with a large national bank functioning as a commission-based third-party coupon provider. Specifically, we use large-scale anonymized transaction records to model consumer spending and forecast future purchases, based on which we generate data-driven, personalized coupons. Our proposed model RUSH! (1) predicts {both the time and category} of the next event; (2) captures correlations between purchases in different categories (such as shopping triggering dining purchases); (3) incorporates temporal dynamics of purchase behavior (such as increased spending on weekends); (4) is composed of additive factors that are easily interpretable; and finally (5) scales linearly to millions of transactions. We design a cost-benefit framework that facilitates systematic evaluation in terms of our application, and show that RUSH! provides higher expected value than various baselines that do not jointly model time and category information.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1923–1931},
numpages = {9},
keywords = {cost-benefit analysis, targeted promotions and discounts, temporal point processes, transaction data},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3219819.3220036,
author = {Lu, Pan and Ji, Lei and Zhang, Wei and Duan, Nan and Zhou, Ming and Wang, Jianyong},
title = {R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220036},
doi = {10.1145/3219819.3220036},
abstract = {Recently, Visual Question Answering (VQA) has emerged as one of the most significant tasks in multimodal learning as it requires understanding both visual and textual modalities. Existing methods mainly rely on extracting image and question features to learn their joint feature embedding via multimodal fusion or attention mechanism. Some recent studies utilize external VQA-independent models to detect candidate entities or attributes in images, which serve as semantic knowledge complementary to the VQA task. However, these candidate entities or attributes might be unrelated to the VQA task and have limited semantic capacities. To better utilize semantic knowledge in images, we propose a novel framework to learn visual relation facts for VQA. Specifically, we build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset via a semantic similarity module, in which each data consists of an image, a corresponding question, a correct answer and a supporting relation fact. A well-defined relation detector is then adopted to predict visual question-related relation facts. We further propose a multi-step attention model composed of visual attention and semantic attention sequentially to extract related visual knowledge and semantic knowledge. We conduct comprehensive experiments on the two benchmark datasets, demonstrating that our model achieves state-of-the-art performance and verifying the benefit of considering visual relation facts.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1880–1889},
numpages = {10},
keywords = {attention network, question answering, relation fact mining, semantic knowledge, visual question answering},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3219819.3219821,
author = {Yang, Carl and Shi, Xiaolin and Jie, Luo and Han, Jiawei},
title = {I Know You'll Be Back: Interpretable New User Clustering and Churn Prediction on a Mobile Social Application},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219821},
doi = {10.1145/3219819.3219821},
abstract = {As online platforms are striving to get more users, a critical challenge is user churn, which is especially concerning for new users. In this paper, by taking the anonymous large-scale real-world data from Snapchat as an example, we develop ClusChurn , a systematic two-step framework for interpretable new user clustering and churn prediction, based on the intuition that proper user clustering can help understand and predict user churn. Therefore, ClusChurn firstly groups new users into interpretable typical clusters, based on their activities on the platform and ego-network structures. Then we design a novel deep learning pipeline based on LSTM and attention to accurately predict user churn with very limited initial behavior data, by leveraging the correlations among users' multi- dimensional activities and the underlying user types. ClusChurn is also able to predict user types, which enables rapid reactions to different types of user churn. Extensive data analysis and experiments show that ClusChurn provides valuable insight into user behaviors, and achieves state-of-the-art churn prediction performance. The whole framework is deployed as a data analysis pipeline, delivering real-time data analysis and prediction results to multiple relevant teams for business intelligence uses. It is also general enough to be readily adopted by any online systems with user behavior data.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {914–922},
numpages = {9},
keywords = {churn prediction, interpretable model, user clustering},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3580305.3599774,
author = {Xue, Bing and Said, Ahmed Sameh and Xu, Ziqi and Liu, Hanyang and Shah, Neel and Yang, Hanqing and Payne, Philip and Lu, Chenyang},
title = {Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599774},
doi = {10.1145/3580305.3599774},
abstract = {Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting modality for COVID-19 patients who are refractory to conventional therapies. However, the proper treatment decision has been the subject of significant debate and it remains controversial about who benefits from this scarcely available and technically complex treatment option. To support clinical decisions, it is a critical need to predict the treatment need and the potential treatment and no-treatment responses. Targeting this clinical challenge, we propose Treatment Variational AutoEncoder (TVAE), a novel approach for individualized treatment analysis. TVAE is specifically designed to address the modeling challenges like ECMO with strong treatment selection bias and scarce treatment cases. TVAE conceptualizes the treatment decision as a multi-scale problem. We model a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics that can be represented by a deep latent variable model. The factual and counterfactual prediction errors are alleviated via a reconstruction regularization scheme together with semi-supervision, and the selection bias and the scarcity of treatment cases are mitigated by the disentangled and distribution-matched latent space and the label-balancing generative strategy. We evaluate TVAE on two real-world COVID-19 datasets: an international dataset collected from 1651 hospitals across 63 countries, and a institutional dataset collected from 15 hospitals. The results show that TVAE outperforms state-of-the-art treatment effect models in predicting both the propensity scores and factual outcomes on heterogeneous COVID-19 datasets. Additional experiments also show TVAE outperforms the best existing models in individual treatment effect estimation on the synthesized IHDP benchmark dataset.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5360–5371},
numpages = {12},
keywords = {causal inference, covid analysis, deep latent variable models, generative ai, machine learning for healthcare, representation learning, semi-supervised learning, treatment effect estimation, variational autoencoder},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3534678.3539193,
author = {Prabhakar, Prakruthi and Yuan, Yiping and Yang, Guangyu and Sun, Wensheng and Muralidharan, Ajith},
title = {Multi-objective Optimization of Notifications Using Offline Reinforcement Learning},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539193},
doi = {10.1145/3534678.3539193},
abstract = {Mobile notification systems play a major role in a variety of applications to communicate, send alerts and reminders to the users to inform them about news, events or messages. In this paper, we formulate the near-real-time notification decision problem as a Markov Decision Process where we optimize for multiple objectives in the rewards. We propose an end-to-end offline reinforcement learning framework to optimize sequential notification decisions. We address the challenge of offline learning using a Double Deep Q-network method based on Conservative Q-learning that mitigates the distributional shift problem and Q-value overestimation. We illustrate our fully-deployed system and demonstrate the performance and benefits of the proposed approach through both offline and online experiments.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3752–3760},
numpages = {9},
keywords = {mobile notifications, offline evaluation, reinforcement learning},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3292500.3330959,
author = {Wu, Qitian and Gao, Yirui and Gao, Xiaofeng and Weng, Paul and Chen, Guihai},
title = {Dual Sequential Prediction Models Linking Sequential Recommendation and Information Dissemination},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330959},
doi = {10.1145/3292500.3330959},
abstract = {Sequential recommendation and information dissemination are two traditional problems for sequential information retrieval. The common goal of the two problems is to predict future user-item interactions based on past observed interactions. The difference is that the former deals with users' histories of clicked items, while the latter focuses on items' histories of infected users.In this paper, we take a fresh view and propose dual sequential prediction models that unify these two thinking paradigms. One user-centered model takes a user's historical sequence of interactions as input, captures the user's dynamic states, and approximates the conditional probability of the next interaction for a given item based on the user's past clicking logs. By contrast, one item-centered model leverages an item's history, captures the item's dynamic states, and approximates the conditional probability of the next interaction for a given user based on the item's past infection records. To take advantage of the dual information, we design a new training mechanism which lets the two models play a game with each other and use the predicted score from the opponent to design a feedback signal to guide the training. We show that the dual models can better distinguish false negative samples and true negative samples compared with single sequential recommendation or information dissemination models. Experiments on four real-world datasets demonstrate the superiority of proposed model over some strong baselines as well as the effectiveness of dual training mechanism between two models.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {447–457},
numpages = {11},
keywords = {information dissemination, semi-supervised learning, sequential prediction model, sequential recommendation},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/3097983.3098008,
author = {Lian, Defu and Liu, Rui and Ge, Yong and Zheng, Kai and Xie, Xing and Cao, Longbing},
title = {Discrete Content-aware Matrix Factorization},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098008},
doi = {10.1145/3097983.3098008},
abstract = {Precisely recommending relevant items from massive candidates to a large number of users is an indispensable yet computationally expensive task in many online platforms (e.g., Amazon.com and Netflix.com). A promising way is to project users and items into a Hamming space and then recommend items via Hamming distance. However, previous studies didn't address the cold-start challenges and couldn't make the best use of preference data like implicit feedback. To fill this gap, we propose a Discrete Content-aware Matrix Factorization (DCMF) model, 1) to derive compact yet informative binary codes at the presence of user/item content information; 2) to support the classification task based on a local upper bound of logit loss; 3) to introduce an interaction regularization for dealing with the sparsity issue. We further develop an efficient discrete optimization algorithm for parameter learning. Based on extensive experiments on three real-world datasets, we show that DCFM outperforms the state-of-the-arts on both regression and classification tasks.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {325–334},
numpages = {10},
keywords = {collaborative filtering, content-based filtering, discrete hashing, recommendation},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/2939672.2939713,
author = {Zhang, Weinan and Zhou, Tianxiong and Wang, Jun and Xu, Jian},
title = {Bid-aware Gradient Descent for Unbiased Learning with Censored Data in Display Advertising},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939713},
doi = {10.1145/2939672.2939713},
abstract = {In real-time display advertising, ad slots are sold per impression via an auction mechanism. For an advertiser, the campaign information is incomplete --- the user responses (e.g, clicks or conversions) and the market price of each ad impression are observed only if the advertiser's bid had won the corresponding ad auction. The predictions, such as bid landscape forecasting, click-through rate (CTR) estimation, and bid optimisation, are all operated in the pre-bid stage with full-volume bid request data. However, the training data is gathered in the post-bid stage with a strong bias towards the winning impressions. A common solution for learning over such censored data is to reweight data instances to correct the discrepancy between training and prediction. However, little study has been done on how to obtain the weights independent of previous bidding strategies and consequently integrate them into the final CTR prediction and bid generation steps. In this paper, we formulate CTR estimation and bid optimisation under such censored auction data. Derived from a survival model, we show that historic bid information is naturally incorporated to produce Bid-aware Gradient Descents (BGD) which controls both the importance and the direction of the gradient to achieve unbiased learning. The empirical study based on two large-scale real-world datasets demonstrates remarkable performance gains from our solution. The learning framework has been deployed on Yahoo!'s real-time bidding platform and provided 2.97% AUC lift for CTR estimation and 9.30% eCPC drop for bid optimisation in an online A/B test.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {665–674},
numpages = {10},
keywords = {censored data, display advertising, real-time bidding, unbiased learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/2339530.2339732,
author = {Shen, Yelong and Jin, Ruoming},
title = {Learning personal + social latent factor model for social recommendation},
year = {2012},
isbn = {9781450314626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2339530.2339732},
doi = {10.1145/2339530.2339732},
abstract = {Social recommendation, which aims to systematically leverage the social relationships between users as well as their past behaviors for automatic recommendation, attract much attention recently. The belief is that users linked with each other in social networks tend to share certain common interests or have similar tastes (homophily principle); such similarity is expected to help improve the recommendation accuracy and quality. There have been a few studies on social recommendations; however, they almost completely ignored the heterogeneity and diversity of the social relationship.In this paper, we develop a joint personal and social latent factor (PSLF) model for social recommendation. Specifically, it combines the state-of-the-art collaborative filtering and the social network modeling approaches for social recommendation. Especially, the PSLF extracts the social factor vectors for each user based on the state-of-the-art mixture membership stochastic blockmodel, which can explicitly express the varieties of the social relationship. To optimize the PSLF model, we develop a scalable expectation-maximization (EM) algorithm, which utilizes a novel approximate mean-field technique for fast expectation computation. We compare our approach with the latest social recommendation approaches on two real datasets, Flixter and Douban (both with large social networks). With similar training cost, our approach has shown a significant improvement in terms of prediction accuracy criteria over the existing approaches.},
booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1303–1311},
numpages = {9},
keywords = {personal + social factor, social recommender system},
location = {Beijing, China},
series = {KDD '12}
}

@inproceedings{10.1145/2783258.2788562,
author = {Jiang, Peng and Zhu, Yadong and Zhang, Yi and Yuan, Quan},
title = {Life-stage Prediction for Product Recommendation in E-commerce},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2788562},
doi = {10.1145/2783258.2788562},
abstract = {Although marketing researchers and sociologists have recognized the large impact of life stage on consumer's purchasing behaviors, existing recommender systems have not taken this impact into consideration. In this paper, we found obvious correlation between life stage and purchasing behavior in many E-commerce categories. For example, a mum may look for different suitable products when her baby is at different ages. Motivated by this, we introduce the conception of life stage into recommender systems and propose to predict a user's current life-stage and recommend products correspondingly. We propose a new Maximum Entropy Semi Markov Model to segment and label consumer life stage based on the observed purchasing data over time. In the mom-baby product category where the life stage transition is deterministic, we develop an efficient approximate solution using large scale logistic regression and a Viterbi-like algorithm. We also propose a Gaussian mixture model to efficiently handle multi-kids life stage prediction problem. We integrate the life stage information predicted into the recommender system behind the largest online shopping website taobao.com. Both offline and online experiments demonstrate the effectiveness of the proposed life-stage based recommendation approach.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1879–1888},
numpages = {10},
keywords = {e-commerce, life stage, recommender system},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.5555/3382225.3382276,
author = {Motamedi, Reza and Rezayi, Saed and Rejaie, Reza and Willinger, Walter},
title = {On characterizing the Twitter elite network},
year = {2020},
isbn = {9781538660515},
publisher = {IEEE Press},
abstract = {The most-followed Twitter users and their pairwise relationships form a sub-graph of all Twitter users that we call the Twitter elite network. The connectivity patterns and influence (in terms of reply and retweet activity) among these elite users illustrate how the "important" users connect and interact with one another on Twitter. Such an elite-focused view also provides valuable information about the structure of the Twitter network as a whole.This paper presents the first detailed characterization of the top-10K Twitter elite network. We describe a new technique to efficiently and accurately capture the Twitter elite network along with social attributes of individual elite accounts. We show that a sufficiently large elite network is typically composed of 15--20 resilient and socially cohesive communities representing "socially meaningful" components of the elite network. We then characterize the community-level structure of the elite network in terms of bias in directed pairwise connectivity and relative reachability. We demonstrate that both the retweet and reply activity between elite users are effectively contained within individual elite communities. Finally, we illustrate that a majority of the elite friends of regular Twitter users tend to belong to a single elite community. This finding offers a promising criterion to group regular users into "shadow partitions" based on their association with elite communities. We show that the level of overall inter-connectivity between shadow partitions mirrors the inter-connectivity of the elite communities. This suggests that these shadow partitions can be viewed as extensions of their corresponding elite communities.},
booktitle = {Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {234–241},
numpages = {8},
location = {Barcelona, Spain},
series = {ASONAM '18}
}

@inproceedings{10.1145/3097983.3098071,
author = {Wu, Liwei and Hsieh, Cho-Jui and Sharpnack, James},
title = {Large-scale Collaborative Ranking in Near-Linear Time},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098071},
doi = {10.1145/3097983.3098071},
abstract = {In this paper, we consider the Collaborative Ranking (CR) problem for recommendation systems. Given a set of pairwise preferences between items for each user, collaborative ranking can be used to rank un-rated items for each user, and this ranking can be naturally used for recommendation. It is observed that collaborative ranking algorithms usually achieve better performance since they directly minimize the ranking loss; however, they are rarely used in practice due to the poor scalability. All the existing CR algorithms have time complexity at least O(|Ω|r) per iteration, where r is the target rank and |Ω| is number of pairs which grows quadratically with number of ratings per user. For example, the Netflix data contains totally 20 billion rating pairs, and at this scale all the current algorithms have to work with significant subsampling, resulting in poor prediction on testing data.In this paper, we propose a new collaborative ranking algorithm called Primal-CR that reduces the time complexity to O(|Ω|+d1 |d2 r), where d1 is number of users and |d2 is the averaged number of items rated by a user. Note that d1 |d2 is strictly smaller and often much smaller than |Ω|.Furthermore, by exploiting the fact that most data is in the form of numerical ratings instead of pairwise comparisons, we propose Primal-CR++ with O(d1|d2 (r+ log |d2)) time complexity. Both algorithms have better theoretical time complexity than existing approaches and also outperform existing approaches in terms of NDCG and pairwise error on real data sets. To the best of our knowledge, this is the first collaborative ranking algorithm capable of working on the full Netflix dataset using all the 20 billion rating pairs, and this leads to a model with much better recommendation compared with previous models trained on subsamples. Finally, compared with classical matrix factorization algorithm which also requires O(d1d2r) time, our algorithm has almost the same efficiency while making much better recommendations since we consider the ranking loss.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {515–524},
numpages = {10},
keywords = {collaborative ranking, large-scale, recommendation systems},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3110025.3110075,
author = {Magdy, Walid and Elkhatib, Yehia and Tyson, Gareth and Joglekar, Sagar and Sastry, Nishanth},
title = {Fake it till you make it: Fishing for Catfishes},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3110075},
doi = {10.1145/3110025.3110075},
abstract = {Many adult content websites incorporate social networking features. Although these are popular, they raise significant challenges, including the potential for users to "catfish", i.e., to create fake profiles to deceive other users. This paper takes an initial step towards automated catfish detection. We explore the characteristics of the different age and gender groups, identifying a number of distinctions. Through this, we train models based on user profiles and comments, via the ground truth of specially verified profiles. When applying our models for age and gender estimation to unverified profiles, 38% of profiles are classified as lying about their age, and 25% are predicted to be lying about their gender. The results suggest that women have a greater propensity to catfish than men. Our preliminary work has notable implications on operators of such online social networks, as well as users who may worry about interacting with catfishes.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {497–504},
numpages = {8},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@inproceedings{10.1145/2939672.2939673,
author = {Zhang, Fuzheng and Yuan, Nicholas Jing and Lian, Defu and Xie, Xing and Ma, Wei-Ying},
title = {Collaborative Knowledge Base Embedding for Recommender Systems},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939673},
doi = {10.1145/2939672.2939673},
abstract = {Among different recommendation techniques, collaborative filtering usually suffer from limited performance due to the sparsity of user-item interactions. To address the issues, auxiliary information is usually used to boost the performance. Due to the rapid collection of information on the web, the knowledge base provides heterogeneous information including both structured and unstructured data with different semantics, which can be consumed by various applications. In this paper, we investigate how to leverage the heterogeneous information in a knowledge base to improve the quality of recommender systems. First, by exploiting the knowledge base, we design three components to extract items' semantic representations from structural content, textual content and visual content, respectively. To be specific, we adopt a heterogeneous network embedding method, termed as TransR, to extract items' structural representations by considering the heterogeneity of both nodes and relationships. We apply stacked denoising auto-encoders and stacked convolutional auto-encoders, which are two types of deep learning based embedding techniques, to extract items' textual representations and visual representations, respectively. Finally, we propose our final integrated framework, which is termed as Collaborative Knowledge Base Embedding (CKE), to jointly learn the latent representations in collaborative filtering as well as items' semantic representations from the knowledge base. To evaluate the performance of each embedding component as well as the whole system, we conduct extensive experiments with two real-world datasets from different scenarios. The results reveal that our approaches outperform several widely adopted state-of-the-art recommendation methods.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {353–362},
numpages = {10},
keywords = {collaborative joint learning, knowledge base embedding, recommender systems},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/2939672.2939688,
author = {Poyarkov, Alexey and Drutsa, Alexey and Khalyavin, Andrey and Gusev, Gleb and Serdyukov, Pavel},
title = {Boosted Decision Tree Regression Adjustment for Variance Reduction in Online Controlled Experiments},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939688},
doi = {10.1145/2939672.2939688},
abstract = {Nowadays, the development of most leading web services is controlled by online experiments that qualify and quantify the steady stream of their updates achieving more than a thousand concurrent experiments per day. Despite the increasing need for running more experiments, these services are limited in their user traffic. This situation leads to the problem of finding a new or improving existing key performance metric with a higher sensitivity and lower variance. We focus on the problem of variance reduction for engagement metrics of user loyalty that are widely used in A/B testing of web services. We develop a general framework that is based on evaluation of the mean difference between the actual and the approximated values of the key performance metric (instead of the mean of this metric). On the one hand, it allows us to incorporate the state-of-the-art techniques widely used in randomized experiments of clinical and social research, but limitedly used in online evaluation. On the other hand, we propose a new class of methods based on advanced machine learning algorithms, including ensembles of decision trees, that, to the best of our knowledge, have not been applied earlier to the problem of variance reduction. We validate the variance reduction approaches on a very large set of real large-scale A/B experiments run at Yandex for different engagement metrics of user loyalty. Our best approach demonstrates $63%$ average variance reduction (which is equivalent to 63% saved user traffic) and detects the treatment effect in $2$ times more A/B experiments.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {235–244},
numpages = {10},
keywords = {A/B test, prediction, variance reduction},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/3097983.3098202,
author = {Chen, Ting and Sun, Yizhou and Shi, Yue and Hong, Liangjie},
title = {On Sampling Strategies for Neural Network-based Collaborative Filtering},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098202},
doi = {10.1145/3097983.3098202},
abstract = {Recent advances in neural networks have inspired people to design hybrid recommendation algorithms that can incorporate both (1) user-item interaction information and (2) content information including image, audio, and text. Despite their promising results, neural network-based recommendation algorithms pose extensive computational costs, making it challenging to scale and improve upon. In this paper, we propose a general neural network-based recommendation framework, which subsumes several existing state-of-the-art recommendation algorithms, and address the efficiency issue by investigating sampling strategies in the stochastic gradient descent training for the framework. We tackle this issue by first establishing a connection between the loss functions and the user-item interaction bipartite graph, where the loss function terms are defined on links while major computation burdens are located at nodes. We call this type of loss functions "graph-based" loss functions, for which varied mini-batch sampling strategies can have different computational costs. Based on the insight, three novel sampling strategies are proposed, which can significantly improve the training efficiency of the proposed framework (up to $times 30$ times speedup in our experiments), as well as improving the recommendation performance. Theoretical analysis is also provided for both the computational cost and the convergence. We believe the study of sampling strategies have further implications on general graph-based loss functions, and would also enable more research under the neural network-based recommendation framework.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {767–776},
numpages = {10},
keywords = {collaborative filtering, neural networks, sampling strategies},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/2939672.2939746,
author = {Christakopoulou, Konstantina and Radlinski, Filip and Hofmann, Katja},
title = {Towards Conversational Recommender Systems},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939746},
doi = {10.1145/2939672.2939746},
abstract = {People often ask others for restaurant recommendations as a way to discover new dining experiences. This makes restaurant recommendation an exciting scenario for recommender systems and has led to substantial research in this area. However, most such systems behave very differently from a human when asked for a recommendation. The goal of this paper is to begin to reduce this gap. In particular, humans can quickly establish preferences when asked to make a recommendation for someone they do not know. We address this cold-start recommendation problem in an online learning setting. We develop a preference elicitation framework to identify which questions to ask a new user to quickly learn their preferences. Taking advantage of latent structure in the recommendation space using a probabilistic latent factor model, our experiments with both synthetic and real world data compare different types of feedback and question selection strategies. We find that our framework can make very effective use of online user feedback, improving personalized recommendations over a static model by 25% after asking only 2 questions. Our results demonstrate dramatic benefits of starting from offline embeddings, and highlight the benefit of bandit-based explore-exploit strategies in this setting.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {815–824},
numpages = {10},
keywords = {cold-start, online learning, recommender systems},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@proceedings{10.1145/3625007,
title = {ASONAM '23: Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
year = {2023},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The ASONAM conference series brings together researchers from around the world to share the latest advances in the attractive field of Social Networks Analysis and Mining.},
location = {Kusadasi, Turkiye}
}

@inproceedings{10.1145/3580305.3599516,
author = {Kim, Sein and Lee, Namkyeong and Kim, Donghyun and Yang, Minchul and Park, Chanyoung},
title = {Task Relation-aware Continual User Representation Learning},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599516},
doi = {10.1145/3580305.3599516},
abstract = {User modeling, which learns to represent users into a low-dimensional representation space based on their past behaviors, got a surge of interest from the industry for providing personalized services to users. Previous efforts in user modeling mainly focus on learning a task-specific user representation that is designed for a single task. However, since learning task-specific user representations for every task is infeasible, recent studies introduce the concept of universal user representation, which is a more generalized representation of a user that is relevant to a variety of tasks. Despite their effectiveness, existing approaches for learning universal user representations are impractical in real-world applications due to the data requirement, catastrophic forgetting and the limited learning capability for continually added tasks. In this paper, we propose a novel continual user representation learning method, called TERACON, whose learning capability is not limited as the number of learned tasks increases while capturing the relationship between the tasks. The main idea is to introduce an embedding for each task, i.e., task embedding, which is utilized to generate task-specific soft masks that not only allow the entire model parameters to be updated until the end of training sequence, but also facilitate the relationship between the tasks to be captured. Moreover, we introduce a novel knowledge retention module with pseudo-labeling strategy that successfully alleviates the long-standing problem of continual learning, i.e., catastrophic forgetting. Extensive experiments on public and proprietary real-world datasets demonstrate the superiority and practicality of TERACON. Our code is available at https://github.com/Sein-Kim/TERACON.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1107–1119},
numpages = {13},
keywords = {continual learning, recommender system, universal user representation},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3110025.3110091,
author = {Gilani, Zafar and Kochmar, Ekaterina and Crowcroft, Jon},
title = {Classification of Twitter Accounts into Automated Agents and Human Users},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3110091},
doi = {10.1145/3110025.3110091},
abstract = {Online social networks (OSNs) have seen a remarkable rise in the presence of surreptitious automated accounts. Massive human user-base and business-supportive operating model of social networks (such as Twitter) facilitates the creation of automated agents. In this paper we outline a systematic methodology and train a classifier to categorise Twitter accounts into 'automated' and 'human' users. To improve classification accuracy we employ a set of novel steps. First, we divide the dataset into four popularity bands to compensate for differences in types of accounts. Second, we create a large ground truth dataset using human annotations and extract relevant features from raw tweets. To judge accuracy of the procedure we calculate agreement among human annotators as well as with a bot detection research tool. We then apply a Random Forests classifier that achieves an accuracy close to human agreement. Finally, as a concluding step we perform tests to measure the efficacy of our results.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {489–496},
numpages = {8},
keywords = {account classification, automated agents, bot detection, social network analysis},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@inproceedings{10.1145/2623330.2623700,
author = {Gu, Yupeng and Sun, Yizhou and Jiang, Ning and Wang, Bingyu and Chen, Ting},
title = {Topic-factorized ideal point estimation model for legislative voting network},
year = {2014},
isbn = {9781450329569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2623330.2623700},
doi = {10.1145/2623330.2623700},
abstract = {Ideal point estimation that estimates legislators' ideological positions and understands their voting behavior has attracted studies from political science and computer science. Typically, a legislator is assigned a global ideal point based on her voting or other social behavior. However, it is quite normal that people may have different positions on different policy dimensions. For example, some people may be more liberal on economic issues while more conservative on cultural issues. In this paper, we propose a novel topic-factorized ideal point estimation model for a legislative voting network in a unified framework. First, we model the ideal points of legislators and bills for each topic instead of assigning them to a global one. Second, the generation of topics are guided by the voting matrix in addition to the text information contained in bills. A unified model that combines voting behavior modeling and topic modeling is presented, and an iterative learning algorithm is proposed to learn the topics of bills as well as the topic-factorized ideal points of legislators and bills. By comparing with the state-of-the-art ideal point estimation models, our method has a much better explanation power in terms of held-out log-likelihood and other measures. Besides, case studies show that the topic-factorized ideal points coincide with human intuition. Finally, we illustrate how to use these topic-factorized ideal points to predict voting results for unseen bills.},
booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {183–192},
numpages = {10},
keywords = {ideal point estimation, legislative voting network, topic model, voting prediction},
location = {New York, New York, USA},
series = {KDD '14}
}

@inproceedings{10.1145/2939672.2939683,
author = {Luo, Ping and Yan, Su and Liu, Zhiqiang and Shen, Zhiyong and Yang, Shengwen and He, Qing},
title = {From Online Behaviors to Offline Retailing},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939683},
doi = {10.1145/2939672.2939683},
abstract = {To combat the ease of online shopping in pajamas, offline mall owners focus increasingly on driving satisfaction and improving retention by identifying customers' preferences. However, most of these studies are based on customers' offline consuming history only. Benefiting from the internet, we can also get customers' online behaviors, such as the search logs, web browsing logs, online shopping logs, and so on. Might these seemingly irrelevant information from two different modalities (i.e. online and offline) be somehow interrelated? How can we make use of the online behaviors and offline actions jointly to promote recommendation for offline retailing? In this study, we formulate this task as a cross-modality recommendation problem, and present its solution via a proposed probabilistic graphical model, called Online-to-Offline Topic Modeling (O2OTM). Specifically, this method explicitly models the relationships between online and offline topics so that the likelihood of both online and offline behaviors is maximized. Then, the recommendation is made only based on the pairs of online and offline topics, denoted by (t,l), with high values of lift, such that the existence of the online topic $t$ greatly increases the response on the corresponding offline topic $l$ compared with the average response for the population without the online topic t. Furthermore, we evaluate this solution in both live and retrospect experiments. The real-world deployment of this model for the anniversary promotion campaign of a famous shopping mall in Beijing shows that our approach increases the occurred customer purchases per promotion message by 29.75% compared with the baseline. Also, our model finds some interesting interpretable relationships between the online search topics and offline brand topics.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {175–184},
numpages = {10},
keywords = {brands recommendation, recommendation explanation, topic modeling},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/2783258.2783358,
author = {Song, Dongjin and Meyer, David A. and Tao, Dacheng},
title = {Efficient Latent Link Recommendation in Signed Networks},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2783358},
doi = {10.1145/2783258.2783358},
abstract = {Signed networks, in which the relationship between two nodes can be either positive (indicating a relationship such as trust) or negative (indicating a relationship such as distrust), are becoming increasingly common. A plausible model for user behavior analytics in signed networks can be based upon the assumption that more extreme positive and negative relationships are explored and exploited before less extreme ones. Such a model implies that a personalized ranking list of latent links should place positive links on the top, negative links at the bottom, and unknown status links in between. Traditional ranking metrics, e.g., area under the receiver operating characteristic curve (AUC), are however not suitable for quantifying such a ranking list which includes positive, negative, and unknown status links. To address this issue, a generalized AUC (GAUC) which can measure both the head and tail of a ranking list has been introduced. Since GAUC weights each pairwise comparison equally and the calculation of GAUC requires quadratic time, we derive two lower bounds of GAUC which can be computed in linear time and put more emphasis on ranking positive links on the top and negative links at the bottom of a ranking list. Next, we develop two efficient latent link recommendation (ELLR) algorithms in order to recommend links by directly optimizing these two lower bounds, respectively. Finally, we compare these two ELLR algorithms with top-performing baseline methods over four benchmark datasets, among which the largest network has more than 100 thousand nodes and seven million entries. Thorough empirical studies demonstrate that the proposed ELLR algorithms outperform state-of-the-art approaches for link recommendation in signed networks at no cost in efficiency.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1105–1114},
numpages = {10},
keywords = {gauc, link recommendation, recommender systems, signed networks},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.1145/2939672.2939873,
author = {Kim, Joon Hee and Mantrach, Amin and Jaimes, Alejandro and Oh, Alice},
title = {How to Compete Online for News Audience: Modeling Words that Attract Clicks},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939873},
doi = {10.1145/2939672.2939873},
abstract = {Headlines are particularly important for online news outlets where there are many similar news stories competing for users' attention. Traditionally, journalists have followed rules-of-thumb and experience to master the art of crafting catchy headlines, but with the valuable resource of large-scale click-through data of online news articles, we can apply quantitative analysis and text mining techniques to acquire an in-depth understanding of headlines. In this paper, we conduct a large-scale analysis and modeling of 150K news articles published over a period of four months on the Yahoo home page. We define a simple method to measure click-value of individual words, and analyze how temporal trends and linguistic attributes affect click-through rate (CTR). We then propose a novel generative model, headline click-based topic model (HCTM), that extends latent Dirichlet allocation (LDA) to reveal the effect of topical context on the click-value of words in headlines. HCTM leverages clicks in aggregate on previously published headlines to identify words for headlines that will generate more clicks in the future. We show that by jointly taking topics and clicks into account we can detect changes in user interests within topics. We evaluate HCTM in two different experimental settings and compare its performance with ALDA (adapted LDA), LDA, and TextRank. The first task, full headline, is to retrieve full headline used for a news article given the body of news article. The second task, good headline, is to specifically identify words in the headline that have high click values for current news audience. For full headline task, our model performs on par with ALDA, a state-of-the art web-page summarization method that utilizes click-through information. For good headline task, which is of more practical importance to both individual journalists and online news outlets, our model significantly outperforms all other comparative methods.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1645–1654},
numpages = {10},
keywords = {click-through rate, headline prediction, large-scale analysis, online news analysis},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/2492517.2500273,
author = {Rehman, Nafees Ur and Weiler, Andreas and Scholl, Marc H.},
title = {OLAPing social media: the case of Twitter},
year = {2013},
isbn = {9781450322409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2492517.2500273},
doi = {10.1145/2492517.2500273},
abstract = {Social networks are platforms where millions of users interact frequently and share variety of digital content with each other. Users express their feelings and opinions on every topic of interest. These opinions carry import value for personal, academic and commercial applications, but the volume and the speed at which these are produced make it a challenging task for researchers and the underlying technologies to provide useful insights to such data. We attempt to extend the established OLAP(On-line Analytical Processing) technology to allow multidimensional analysis of social media data by integrating text and opinion mining methods into the data warehousing system and by exploiting various knowledge discovery techniques to deal with semi-structured and unstructured data from social media.The capabilities of OLAP are extended by semantic enrichment of the underlying dataset to discover new measures and dimensions for building data cubes and by supporting up-to-date analysis of the evolving as well as the historical social media data. The benefits of such an analysis platform are demonstrated by building a data warehouse for a social network of Twitter, dynamically enriching the underlying dataset and enabling multidimensional analysis.},
booktitle = {Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {1139–1146},
numpages = {8},
location = {Niagara, Ontario, Canada},
series = {ASONAM '13}
}

@inproceedings{10.1145/2783258.2783346,
author = {Devooght, Robin and Kourtellis, Nicolas and Mantrach, Amin},
title = {Dynamic Matrix Factorization with Priors on Unknown Values},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2783346},
doi = {10.1145/2783258.2783346},
abstract = {Advanced and effective collaborative filtering methods based on explicit feedback assume that unknown ratings do not follow the same model as the observed ones not missing at random). In this work, we build on this assumption, and introduce a novel dynamic matrix factorization framework that allows to set an explicit prior on unknown values. When new ratings, users, or items enter the system, we can update the factorization in time independent of the size of data (number of users, items and ratings). Hence, we can quickly recommend items even to very recent users. We test our methods on three large datasets, including two very sparse ones, in static and dynamic conditions. In each case, we outrank state-of-the-art matrix factorization methods that do not use a prior on unknown ratings.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {189–198},
numpages = {10},
keywords = {collaborative filtering, matrix factorization, recommender systems},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.1145/2783258.2783348,
author = {Cai, Yongjie and Tong, Hanghang and Fan, Wei and Ji, Ping and He, Qing},
title = {Facets: Fast Comprehensive Mining of Coevolving High-order Time Series},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2783348},
doi = {10.1145/2783258.2783348},
abstract = {Mining time series data has been a very active research area in the past decade, exactly because of its prevalence in many high-impact applications, ranging from environmental monitoring, intelligent transportation systems, computer network forensics, to smart buildings and many more. It has posed many fascinating research questions. Among others, three prominent challenges shared by a variety of real applications are (a) high-order; (b) contextual constraints and (c) temporal smoothness. The state-of-the-art mining algorithms are rich in addressing each of these challenges, but relatively short of comprehensiveness in attacking the coexistence of multiple or even all of these three challenges.In this paper, we propose a comprehensive method, FACETS, to simultaneously model all these three challenges. We formulate it as an optimization problem from a dynamic graphical model perspective. The key idea is to use tensor factorization to address multi-aspect challenges, and perform careful regularizations to attack both contextual and temporal challenges. Based on that, we propose an effective and scalable algorithm to solve the problem. Our experimental evaluations on three real datasets demonstrate that our method (1) outperforms its competitors in two common data mining tasks (imputation and prediction); and (2) enjoys a linear scalability w.r.t. the length of time series.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {79–88},
numpages = {10},
keywords = {a network of time series, tensor factorization},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.1145/2487575.2487673,
author = {Liu, Bin and Fu, Yanjie and Yao, Zijun and Xiong, Hui},
title = {Learning geographical preferences for point-of-interest recommendation},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487673},
doi = {10.1145/2487575.2487673},
abstract = {The problem of point of interest (POI) recommendation is to provide personalized recommendations of places of interests, such as restaurants, for mobile users. Due to its complexity and its connection to location based social networks (LBSNs), the decision process of a user choose a POI is complex and can be influenced by various factors, such as user preferences, geographical influences, and user mobility behaviors. While there are some studies on POI recommendations, it lacks of integrated analysis of the joint effect of multiple factors. To this end, in this paper, we propose a novel geographical probabilistic factor analysis framework which strategically takes various factors into consideration. Specifically, this framework allows to capture the geographical influences on a user's check-in behavior. Also, the user mobility behaviors can be effectively exploited in the recommendation model. Moreover, the recommendation model can effectively make use of user check-in count data as implicity user feedback for modeling user preferences. Finally, experimental results on real-world LBSNs data show that the proposed recommendation method outperforms state-of-the-art latent factor models with a significant margin.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1043–1051},
numpages = {9},
keywords = {human mobility, location-based social networks, point-of-interest, recommender systems, user profiling},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@inproceedings{10.1145/3447548.3467103,
author = {Liu, Xiangyu and Yu, Chuan and Zhang, Zhilin and Zheng, Zhenzhe and Rong, Yu and Lv, Hongtao and Huo, Da and Wang, Yiqing and Chen, Dagui and Xu, Jian and Wu, Fan and Chen, Guihai and Zhu, Xiaoqiang},
title = {Neural Auction: End-to-End Learning of Auction Mechanisms for E-Commerce Advertising},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467103},
doi = {10.1145/3447548.3467103},
abstract = {In e-commerce advertising, it is crucial to jointly consider various performance metrics, e.g., user experience, advertiser utility, and platform revenue. Traditional auction mechanisms, such as GSP and VCG auctions, can be suboptimal due to their fixed allocation rules to optimize a single performance metric (e.g., revenue or social welfare). Recently, data-driven auctions, learned directly from auction outcomes to optimize multiple performance metrics, have attracted increasing research interests. However, the procedure of auction mechanisms involves various discrete calculation operations, making it challenging to be compatible with continuous optimization pipelines in machine learning. In this paper, we design Deep Neural Auctions (DNAs) to enable end-to-end auction learning by proposing a differentiable model to relax the discrete sorting operation, a key component in auctions. We optimize the performance metrics by developing deep models to efficiently extract contexts from auctions, providing rich features for auction design. We further integrate the game theoretical conditions within the model design, to guarantee the stability of the auctions. DNAs have been successfully deployed in the e-commerce advertising system at Taobao. Experimental evaluation results on both large-scale data set as well as online A/B test demonstrated that DNAs significantly outperformed other mechanisms widely adopted in industry.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3354–3364},
numpages = {11},
keywords = {e-commerce advertising, learning-based mechanism design, neural auction},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/2939672.2939852,
author = {Alves, Rodrigo Augusto da Silva and Assuncao, Renato Martins and Vaz de Melo, Pedro Olmo Stancioli},
title = {Burstiness Scale: A Parsimonious Model for Characterizing Random Series of Events},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939852},
doi = {10.1145/2939672.2939852},
abstract = {The problem to accurately and parsimoniously characterize random series of events (RSEs) seen in the Web, such as Yelp reviews or Twitter hashtags, is not trivial. Reports found in the literature reveal two apparent conflicting visions of how RSEs should be modeled. From one side, the Poissonian processes, of which consecutive events follow each other at a relatively regular time and should not be correlated. On the other side, the self-exciting processes, which are able to generate bursts of correlated events. The existence of many and sometimes conflicting approaches to model RSEs is a consequence of the unpredictability of the aggregated dynamics of our individual and routine activities, which sometimes show simple patterns, but sometimes results in irregular rising and falling trends. In this paper we propose a parsimonious way to characterize general RSEs, namely the Burstiness Scale (BuSca) model. BuSca views each RSE as a mix of two independent process: a Poissonian and a self-exciting one. Here we describe a fast method to extract the two parameters of BuSca that, together, gives the burstiness scale ψ, which represents how much of the RSE is due to bursty and viral effects. We validated our method in eight diverse and large datasets containing real random series of events seen in Twitter, Yelp, e-mail conversations, Digg, and online forums. Results showed that, even using only two parameters, BuSca is able to accurately describe RSEs seen in these diverse systems, what can leverage many applications.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1405–1414},
numpages = {10},
keywords = {communication dynamics, self-exciting point process, social media},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/2492517.2500234,
author = {Perez, Charles and Birregah, Babiga and Layton, Robert and Lemercier, Marc and Watters, Paul},
title = {REPLOT: REtrieving profile links on Twitter for suspicious networks detection},
year = {2013},
isbn = {9781450322409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2492517.2500234},
doi = {10.1145/2492517.2500234},
abstract = {In the last few decades social networking sites have encountered their first large-scale security issues. The high number of users associated with the presence of sensitive data (personal or professional) is certainly an unprecedented opportunity for malicious activities. As a result, one observes that malicious users are progressively turning their attention from traditional e-mail to online social networks to carry out their attacks. Moreover, it is now observed that attacks are not only performed by individual profiles, but that on a larger scale, a set of profiles can act in coordination in making such attacks. The latter are referred to as malicious social campaigns. In this paper, we present a novel approach that combines authorship attribution techniques with a behavioural analysis for detecting and characterizing social campaigns. The proposed approach is performed in three steps: first, suspicious profiles are identified from a behavioural analysis; second, connections between suspicious profiles are retrieved using a combination of authorship attribution and temporal similarity; third, a clustering algorithm is performed to identify and characterise the suspicious campaigns obtained. We provide a real-life application of the methodology on a sample of 1,000 suspicious Twitter profiles tracked over a period of forty days. Our results show that a large set of suspicious profiles behaves in coordination (70%) and propagates mainly, but not only, trustworthy URLs on the online social network. Among the three largest detected campaigns, we have highlighted that one represents an important security issue for the platform by promoting a significant set of malicious URLs.},
booktitle = {Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {1307–1314},
numpages = {8},
keywords = {Twitter, authorship attribution, clustering, malicious campaigns, online social networks, suspicious profiles},
location = {Niagara, Ontario, Canada},
series = {ASONAM '13}
}

@inproceedings{10.1145/2939672.2939801,
author = {Kannan, Anjuli and Kurach, Karol and Ravi, Sujith and Kaufmann, Tobias and Tomkins, Andrew and Miklos, Balint and Corrado, Greg and Lukacs, Laszlo and Ganea, Marina and Young, Peter and Ramavajjala, Vivek},
title = {Smart Reply: Automated Response Suggestion for Email},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939801},
doi = {10.1145/2939672.2939801},
abstract = {In this paper we propose and investigate a novel end-to-end method for automatically generating short email responses, called Smart Reply. It generates semantically diverse suggestions that can be used as complete email responses with just one tap on mobile. The system is currently used in Inbox by Gmail and is responsible for assisting with 10% of all mobile responses. It is designed to work at very high throughput and process hundreds of millions of messages daily. The system exploits state-of-the-art, large-scale deep learning.We describe the architecture of the system as well as the challenges that we faced while building it, like response diversity and scalability. We also introduce a new method for semantic clustering of user-generated content that requires only a modest amount of explicitly labeled data.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {955–964},
numpages = {10},
keywords = {clustering, deep learning, email, lstm, semantics},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/2487575.2487632,
author = {Chen, Shuo and Xu, Jiexun and Joachims, Thorsten},
title = {Multi-space probabilistic sequence modeling},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487632},
doi = {10.1145/2487575.2487632},
abstract = {Learning algorithms that embed objects into Euclidean space have become the methods of choice for a wide range of problems, ranging from recommendation and image search to playlist prediction and language modeling. Probabilistic embedding methods provide elegant approaches to these problems, but can be expensive to train and store as a large monolithic model. In this paper, we propose a method that trains not one monolithic model, but multiple local embeddings for a class of pairwise conditional models especially suited for sequence and co-occurrence modeling. We show that computation and memory for training these multi-space models can be efficiently parallelized over many nodes of a cluster. Focusing on sequence modeling for music playlists, we show that the method substantially speeds up training while maintaining high model quality.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {865–873},
numpages = {9},
keywords = {embedding, music playlists, parallel computing, recommendation, sequences},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@inproceedings{10.1145/2623330.2623752,
author = {Bi, Bin and Kao, Ben and Wan, Chang and Cho, Junghoo},
title = {Who are experts specializing in landscape photography? analyzing topic-specific authority on content sharing services},
year = {2014},
isbn = {9781450329569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2623330.2623752},
doi = {10.1145/2623330.2623752},
abstract = {With the rapid growth of Web 2.0, a variety of content sharing services, such as Flickr, YouTube, Blogger, and TripAdvisor etc, have become extremely popular over the last decade. On these websites, users have created and shared with each other various kinds of resources, such as photos, video, and travel blogs. The sheer amount of user-generated content varies greatly in quality, which calls for a principled method to identify a set of authorities, who created high-quality resources, from a massive number of contributors of content. Since most previous studies only infer global authoritativeness of a user, there is no way to differentiate the authoritativeness in different aspects of life (topics).In this paper, we propose a novel model of Topic-specific Authority Analysis (TAA), which addresses the limitations of the previous approaches, to identify authorities specific to given query topic(s) on a content sharing service. This model jointly leverages the usage data collected from the sharing log and the favorite log. The parameters in TAA are learned from a constructed training dataset, for which a novel logistic likelihood function is specifically designed. To perform Bayesian inference for TAA with the new logistic likelihood, we extend typical Gibbs sampling by introducing auxiliary variables. Thorough experiments with two real-world datasets demonstrate the effectiveness of TAA in topic-specific authority identification as well as the generalizability of the TAA generative model.},
booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1506–1515},
numpages = {10},
keywords = {bayesian model, content sharing services, topic-specific authority analysis},
location = {New York, New York, USA},
series = {KDD '14}
}

@inproceedings{10.1145/2487575.2487614,
author = {Kuo, Tsung-Ting and Yan, Rui and Huang, Yu-Yang and Kung, Perng-Hwa and Lin, Shou-De},
title = {Unsupervised link prediction using aggregative statistics on heterogeneous social networks},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487614},
doi = {10.1145/2487575.2487614},
abstract = {The concern of privacy has become an important issue for online social networks. In services such as Foursquare.com, whether a person likes an article is considered private and therefore not disclosed; only the aggregative statistics of articles (i.e., how many people like this article) is revealed. This paper tries to answer a question: can we predict the opinion holder in a heterogeneous social network without any labeled data? This question can be generalized to a link prediction with aggregative statistics problem. This paper devises a novel unsupervised framework to solve this problem, including two main components: (1) a three-layer factor graph model and three types of potential functions; (2) a ranked-margin learning and inference algorithm. Finally, we evaluate our method on four diverse prediction scenarios using four datasets: preference (Foursquare), repost (Twitter), response (Plurk), and citation (DBLP). We further exploit nine unsupervised models to solve this problem as baselines. Our approach not only wins out in all scenarios, but on the average achieves 9.90% AUC and 12.59% NDCG improvement over the best competitors. The resources are available at http://www.csie.ntu.edu.tw/~d97944007/aggregative/},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {775–783},
numpages = {9},
keywords = {heterogeneous social network, link prediction, probabilistic graphical model, social network mining},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@inproceedings{10.1145/2020408.2020568,
author = {Ge, Yong and Liu, Qi and Xiong, Hui and Tuzhilin, Alexander and Chen, Jian},
title = {Cost-aware travel tour recommendation},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020408.2020568},
doi = {10.1145/2020408.2020568},
abstract = {Advances in tourism economics have enabled us to collect massive amounts of travel tour data. If properly analyzed, this data can be a source of rich intelligence for providing real-time decision making and for the provision of travel tour recommendations. However, tour recommendation is quite different from traditional recommendations, because the tourist's choice is directly affected by the travel cost, which includes the financial cost and the time. To that end, in this paper, we provide a focused study of cost-aware tour recommendation. Along this line, we develop two cost-aware latent factor models to recommend travel packages by considering both the travel cost and the tourist's interests. Specifically, we first design a cPMF model, which models the tourist's cost with a 2-dimensional vector. Also, in this cPMF model, the tourist's interests and the travel cost are learnt by exploring travel tour data. Furthermore, in order to model the uncertainty in the travel cost, we further introduce a Gaussian prior into the cPMF model and develop the GcPMF model, where the Gaussian prior is used to express the uncertainty of the travel cost. Finally, experiments on real-world travel tour data show that the cost-aware recommendation models outperform state-of-the-art latent factor models with a significant margin. Also, the GcPMF model with the Gaussian prior can better capture the impact of the uncertainty of the travel cost, and thus performs better than the cPMF model.},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {983–991},
numpages = {9},
keywords = {cost-aware recommendation, matrix factorization},
location = {San Diego, California, USA},
series = {KDD '11}
}

@inproceedings{10.1145/2623330.2623744,
author = {Lu, Wei and Ioannidis, Stratis and Bhagat, Smriti and Lakshmanan, Laks V.S.},
title = {Optimal recommendations under attraction, aversion, and social influence},
year = {2014},
isbn = {9781450329569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2623330.2623744},
doi = {10.1145/2623330.2623744},
abstract = {People's interests are dynamically evolving, often affected by external factors such as trends promoted by the media or adopted by their friends. In this work, we model interest evolution through dynamic interest cascades: we consider a scenario where a user's interests may be affected by (a) the interests of other users in her social circle, as well as (b) suggestions she receives from a recommender system. In the latter case, we model user reactions through either attraction or aversion towards past suggestions. We study this interest evolution process, and the utility accrued by recommendations, as a function of the system's recommendation strategy. We show that, in steady state, the optimal strategy can be computed as the solution of a semi-definite program (SDP). Using datasets of user ratings, we provide evidence for the existence of aversion and attraction in real-life data, and show that our optimal strategy can lead to significantly improved recommendations over systems that ignore aversion and attraction.},
booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {811–820},
numpages = {10},
keywords = {attraction, aversion, interest evolution, recommender systems},
location = {New York, New York, USA},
series = {KDD '14}
}

@inproceedings{10.1145/1830252.1830256,
author = {Desrosiers, Christian and Karypis, George},
title = {Enhancing link-based similarity through the use of non-numerical labels and prior information},
year = {2010},
isbn = {9781450302142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1830252.1830256},
doi = {10.1145/1830252.1830256},
abstract = {Several key applications like recommender systems require to compute similarities between the nodes (objects or entities) of a bipartite network. These similarities serve many important purposes, such as finding users sharing common interests or items with similar characteristics, as well as the automated recommendation and categorization of items. While a broad range of methods have been proposed to compute similarities in networks, such methods have two limitations: (1) they require the link values to be in the form of numerical weights representing the strength of the corresponding relation, and (2) they do not take into account prior information on the similarities. This paper presents a novel approach, based on the SimRank algorithm, to compute similarities between the nodes of a bipartite network. Unlike current methods, this approach allows one to model the agreement between link values using any desired function, and provides a simple way to integrate prior information on the similarity values directly in the computations. To evaluate its usefulness, we test this approach on the problem of predicting the ratings of users for movies and jokes.},
booktitle = {Proceedings of the Eighth Workshop on Mining and Learning with Graphs},
pages = {26–33},
numpages = {8},
keywords = {SimRank, item recommendation, link-based similarity, networks},
location = {Washington, D.C.},
series = {MLG '10}
}

@inproceedings{10.1145/2783258.2788586,
author = {Ikonomovska, Elena and Jafarpour, Sina and Dasdan, Ali},
title = {Real-Time Bid Prediction using Thompson Sampling-Based Expert Selection},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2788586},
doi = {10.1145/2783258.2788586},
abstract = {We study online meta-learners for real-time bid prediction that predict by selecting a single best predictor among several subordinate prediction algorithms, here called "experts". These predictors belong to the family of context-dependent past performance estimators that make a prediction only when the instance to be predicted falls within their areas of expertise. Within the advertising ecosystem, it is very common for the contextual information to be incomplete, hence, it is natural for some of the experts to abstain from making predictions on some of the instances. Experts' areas of expertise can overlap, which makes their predictions less suitable for merging; as such, they lend themselves better to the problem of best expert selection. In addition, their performance varies over time, which gives the expert selection problem a non-stochastic, adversarial flavor. In this paper we propose to use probability sampling (via Thompson Sampling) as a meta-learning algorithm that samples from the pool of experts for the purpose of bid prediction. We show performance results from the comparison of our approach to multiple state-of-the-art algorithms using exploration scavenging on a log file of over 300 million ad impressions, as well as comparison to a baseline rule-based model using production traffic from a leading DSP platform.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1869–1878},
numpages = {10},
keywords = {bayesian online learning, multi-armed bandits, online advertising, online algorithms, randomized probability matching},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.1145/2808797.2809395,
author = {Maruf, Hasan Al and Meshkat, Nagib and Ali, Mohammed Eunus and Mahmud, Jalal},
title = {Human behaviour in different social medias: A case study of Twitter and Disqus},
year = {2015},
isbn = {9781450338547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2808797.2809395},
doi = {10.1145/2808797.2809395},
abstract = {Contemporary modern world has witnessed the widespread emergence of online social media and similar technologies. Peoples' behaviour over different social network platform has become an interesting topic of research. In this study, we investigate whether people express analogous identity over different platforms and analysis of different social platform usage contributes to reveal more of a person. We analyse people's usage pattern in two major online platforms, the most widely used social media platform Twitter and a major online commenting platform Disqus. We extract linguistic features and infer personality traits from both of these platforms. Our study reveals differential relationship between personality traits and Disqus and Twitter usage. We also find that social media has an influence on a person's discussion topic. People share opinion on varieties of topics and entities exclusively in Twitter and Disqus. Moreover Disqus provides stronger assessment of a person's sentiment over a topic or entity. Combination of these two profiles gives an extensive view of a user's interest and sensitivity which justify the inference that people use different social network for different purposes and single social network analysis is not enough to build a comprehensive virtual identity of a person.},
booktitle = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015},
pages = {270–273},
numpages = {4},
location = {Paris, France},
series = {ASONAM '15}
}

@inproceedings{10.1145/2339530.2339552,
author = {Wang, Yu and Agichtein, Eugene and Benzi, Michele},
title = {TM-LDA: efficient online modeling of latent topic transitions in social media},
year = {2012},
isbn = {9781450314626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2339530.2339552},
doi = {10.1145/2339530.2339552},
abstract = {Latent topic analysis has emerged as one of the most effective methods for classifying, clustering and retrieving textual data. However, existing models such as Latent Dirichlet Allocation (LDA) were developed for static corpora of relatively large documents. In contrast, much of the textual content on the web, and especially social media, is temporally sequenced, and comes in short fragments, including microblog posts on sites such as Twitter and Weibo, status updates on social networking sites such as Facebook and LinkedIn, or comments on content sharing sites such as YouTube. In this paper we propose a novel topic model, Temporal-LDA or TM-LDA, for efficiently mining text streams such as a sequence of posts from the same author, by modeling the topic transitions that naturally arise in these data. TM-LDA learns the transition parameters among topics by minimizing the prediction error on topic distribution in subsequent postings. After training, TM-LDA is thus able to accurately predict the expected topic distribution in future posts. To make these predictions more efficient for a realistic online setting, we develop an efficient updating algorithm to adjust the topic transition parameters, as new documents stream in. Our empirical results, over a corpus of over 30 million microblog posts, show that TM-LDA significantly outperforms state-of-the-art static LDA models for estimating the topic distribution of new documents over time. We also demonstrate that TM-LDA is able to highlight interesting variations of common topic transitions, such as the differences in the work-life rhythm of cities, and factors associated with area-specific problems and complaints.},
booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {123–131},
numpages = {9},
keywords = {mining social media data, temporal language models, topic transition modeling},
location = {Beijing, China},
series = {KDD '12}
}

@inproceedings{10.1145/1835804.1835896,
author = {Xiang, Liang and Yuan, Quan and Zhao, Shiwan and Chen, Li and Zhang, Xiatian and Yang, Qing and Sun, Jimeng},
title = {Temporal recommendation on graphs via long- and short-term preference fusion},
year = {2010},
isbn = {9781450300551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835804.1835896},
doi = {10.1145/1835804.1835896},
abstract = {Accurately capturing user preferences over time is a great practical challenge in recommender systems. Simple correlation over time is typically not meaningful, since users change their preferences due to different external events. User behavior can often be determined by individual's long-term and short-term preferences. How to represent users' long-term and short-term preferences? How to leverage them for temporal recommendation? To address these challenges, we propose Session-based Temporal Graph (STG) which simultaneously models users' long-term and short-term preferences over time. Based on the STG model framework, we propose a novel recommendation algorithm Injected Preference Fusion (IPF) and extend the personalized Random Walk for temporal recommendation. Finally, we evaluate the effectiveness of our method using two real datasets on citations and social bookmarking, in which our proposed method IPF gives 15%-34% improvement over the previous state-of-the-art.},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {723–732},
numpages = {10},
keywords = {graph, temporal recommendation, user preference},
location = {Washington, DC, USA},
series = {KDD '10}
}

@inproceedings{10.1145/1150402.1150508,
author = {Zhang, Sheng and Chakrabarti, Amit and Ford, James and Makedon, Fillia},
title = {Attack detection in time series for recommender systems},
year = {2006},
isbn = {1595933395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1150402.1150508},
doi = {10.1145/1150402.1150508},
abstract = {Recent research has identified significant vulnerabilities in recommender systems. Shilling attacks, in which attackers introduce biased ratings in order to influence future recommendations, have been shown to be effective against collaborative filtering algorithms. We postulate that the distribution of item ratings in time can reveal the presence of a wide range of shilling attacks given reasonable assumptions about their duration. To construct a time series of ratings for an item, we use a window size of k to group consecutive ratings for the item into disjoint windows and compute the sample average and sample entropy in each window. We derive a theoretically optimal window size to best detect an attack event if the number of attack profiles is known. For practical applications where this number is unknown, we propose a heuristic algorithm that adaptively changes the window size. Our experimental results demonstrate that monitoring rating distributions in time series is an effective approach for detecting shilling attacks.},
booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {809–814},
numpages = {6},
keywords = {anomaly detection, recommender systems, shilling attacks, time series},
location = {Philadelphia, PA, USA},
series = {KDD '06}
}

@inproceedings{10.1145/2020408.2020504,
author = {Agarwal, Deepak and Chen, Bee-Chung and Long, Bo},
title = {Localized factor models for multi-context recommendation},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020408.2020504},
doi = {10.1145/2020408.2020504},
abstract = {Combining correlated information from multiple contexts can significantly improve predictive accuracy in recommender problems. Such information from multiple contexts is often available in the form of several incomplete matrices spanning a set of entities like users, items, features, and so on. Existing methods simultaneously factorize these matrices by sharing a single set of factors for entities across all contexts. We show that such a strategy may introduce significant bias in estimates and propose a new model that ameliorates this issue by positing local, context-specific factors for entities. To avoid over-fitting in contexts with sparse data, the local factors are connected through a shared global model. This sharing of parameters allows information to flow across contexts through multivariate regressions among local factors, instead of enforcing exactly the same factors for an entity, everywhere. Model fitting is done in an EM framework, we show that the E-step can be fitted through a fast multi-resolution Kalman filter algorithm that ensures scalability. Experiments on benchmark and real-world Yahoo! datasets clearly illustrate the usefulness of our approach. Our model significantly improves predictive accuracy, especially in cold-start scenarios.},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {609–617},
numpages = {9},
keywords = {data fusion, epinions, kalman filter, meta-analysis, recommender systems},
location = {San Diego, California, USA},
series = {KDD '11}
}

@inproceedings{10.1145/1557019.1557140,
author = {Daruru, Srivatsava and Marin, Nena M. and Walker, Matt and Ghosh, Joydeep},
title = {Pervasive parallelism in data mining: dataflow solution to co-clustering large and sparse Netflix data},
year = {2009},
isbn = {9781605584959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1557019.1557140},
doi = {10.1145/1557019.1557140},
abstract = {All Netflix Prize algorithms proposed so far are prohibitively costly for large-scale production systems. In this paper, we describe an efficient dataflow implementation of a collaborative filtering (CF) solution to the Netflix Prize problem [1] based on weighted coclustering [5]. The dataflow library we use facilitates the development of sophisticated parallel programs designed to fully utilize commodity multicore hardware, while hiding traditional difficulties such as queuing, threading, memory management, and deadlocks.The dataflow CF implementation first compresses the large, sparse training dataset into co-clusters. Then it generates recommendations by combining the average ratings of the co-clusters with the biases of the users and movies. When configured to identify 20x20 co-clusters in the Netflix training dataset, the implementation predicted over 100 million ratings in 16.31 minutes and achieved an RMSE of 0.88846 without any fine-tuning or domain knowledge. This is an effective real-time prediction runtime of 9.7 us per rating which is far superior to previously reported results. Moreover, the implemented co-clustering framework supports a wide variety of other large-scale data mining applications and forms the basis for predictive modeling on large, dyadic datasets [4, 7].},
booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1115–1124},
numpages = {10},
keywords = {co-clustering, dataflow, predictive modeling, scalability},
location = {Paris, France},
series = {KDD '09}
}

@inproceedings{10.1145/1835804.1835917,
author = {Chua, Freddy Chong Tat and Lim, Ee-Peng},
title = {Trust network inference for online rating data using generative models},
year = {2010},
isbn = {9781450300551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835804.1835917},
doi = {10.1145/1835804.1835917},
abstract = {In an online rating system, raters assign ratings to objects contributed by other users. In addition, raters can develop trust and distrust on object contributors depending on a few rating and trust related factors. Previous study has shown that ratings and trust links can influence each other but there has been a lack of a formal model to relate these factors together. In this paper, we therefore propose Trust Antecedent Factor (TAF) Model, a novel probabilistic model that generate ratings based on a number of rater's and contributor's factors. We demonstrate that parameters of the model can be learnt by Collapsed Gibbs Sampling. We then apply the model to predict trust and distrust between raters and review contributors using a real data-set. Our experiments have shown that the proposed model is capable of predicting both trust and distrust in a unified way. The model can also determine user factors which otherwise cannot be observed from the rating and trust data.},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {889–898},
numpages = {10},
keywords = {probability, social network, statistics, trust prediction},
location = {Washington, DC, USA},
series = {KDD '10}
}

@inproceedings{10.1145/3219819.3219847,
author = {Agarwal, Deepak and Basu, Kinjal and Ghosh, Souvik and Xuan, Ying and Yang, Yang and Zhang, Liang},
title = {Online Parameter Selection for Web-based Ranking Problems},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219847},
doi = {10.1145/3219819.3219847},
abstract = {Web-based ranking problems involve ordering different kinds of items in a list or grid to be displayed in mediums like a website or a mobile app. In most cases, there are multiple objectives or metrics like clicks, viral actions, job applications, advertising revenue and others that we want to balance. Constructing a serving algorithm that achieves the desired tradeoff among multiple objectives is challenging, especially for more than two objectives. In addition, it is often not possible to estimate such a serving scheme using offline data alone for non-stationary systems with frequent online interventions. We consider a large-scale online application where metrics for multiple objectives are continuously available and can be controlled in a desired fashion by changing certain control parameters in the ranking model. We assume that the desired balance of metrics is known from business considerations. Our approach models the balance criteria as a composite utility function via a Gaussian process over the space of control parameters. We show that obtaining a solution can be equated to finding the maximum of the Gaussian process, practically obtainable via Bayesian optimization. However, implementing such a scheme for large-scale applications is challenging. We provide a novel framework to do so and illustrate its efficacy in the context of LinkedIn Feed. In particular, we show the effectiveness of our method by using both offline simulations as well as promising online A/B testing results. At the time of writing this paper, the method described was fully deployed on the LinkedIn Feed.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {23–32},
numpages = {10},
keywords = {bayesian optimization, gaussian processes, online feed ranking, thompson sampling},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/2492517.2492551,
author = {Yang, Tao and Lee, Dongwon and Yan, Su},
title = {Steeler nation, 12th man, and boo birds: classifying Twitter user interests using time series},
year = {2013},
isbn = {9781450322409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2492517.2492551},
doi = {10.1145/2492517.2492551},
abstract = {The problem of Twitter user classification using the contents of tweets is studied. We generate time series from tweets by exploiting the latent temporal information and solve the classification problem in time series domain. Our approach is inspired by the fact that Twitter users sometimes exhibit the periodicity pattern when they share their activities or express their opinions. We apply our proposed methods to both binary and multi-class classification of sports and political interests of Twitter users and compare the performance against eight conventional classification methods using textual features. Experimental results using 2.56 million tweets show that our best binary and multi-class approaches improve the classification accuracy over the best baseline binary and multi-class approaches by 15% and 142%, respectively.},
booktitle = {Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {684–691},
numpages = {8},
location = {Niagara, Ontario, Canada},
series = {ASONAM '13}
}

@inproceedings{10.1145/3219819.3220048,
author = {Tay, Yi and Tuan, Luu Anh and Hui, Siu Cheung},
title = {Multi-Cast Attention Networks},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220048},
doi = {10.1145/3219819.3220048},
abstract = {Attention is typically used to select informative sub-phrases that are used for prediction. This paper investigates the novel use of attention as a form of feature augmentation, i.e, casted attention. We propose Multi-Cast Attention Networks (MCAN), a new attention mechanism and general model architecture for a potpourri of ranking tasks in the conversational modeling and question answering domains. Our approach performs a series of soft attention operations, each time casting a scalar feature upon the inner word embeddings. The key idea is to provide a real-valued hint (feature) to a subsequent encoder layer and is targeted at improving the representation learning process. There are several advantages to this design, e.g., it allows an arbitrary number of attention mechanisms to be casted, allowing for multiple attention types (e.g., co-attention, intra-attention) and attention variants (e.g., alignment-pooling, max-pooling, mean-pooling) to be executed simultaneously. This not only eliminates the costly need to tune the nature of the co-attention layer, but also provides greater extents of explainability to practitioners. Via extensive experiments on four well-known benchmark datasets, we show that MCAN achieves state-of-the-art performance. On the Ubuntu Dialogue Corpus, MCAN outperforms existing state-of-the-art models by 9%. MCAN also achieves the best performing score to date on the well-studied TrecQA dataset.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2299–2308},
numpages = {10},
keywords = {attention mechanism, co-attention, conversation modeling, deep learning, information retrieval, intra-attention, learning to rank, neural networks, neural ranking models, qa, question answering},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/2623330.2623670,
author = {Tsytsarau, Mikalai and Palpanas, Themis and Castellanos, Malu},
title = {Dynamics of news events and social media reaction},
year = {2014},
isbn = {9781450329569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2623330.2623670},
doi = {10.1145/2623330.2623670},
abstract = {The analysis of social sentiment expressed on the Web is becoming increasingly relevant to a variety of applications, and it is important to understand the underlying mechanisms which drive the evolution of sentiments in one way or another, in order to be able to predict these changes in the future. In this paper, we study the dynamics of news events and their relation to changes of sentiment expressed on relevant topics. We propose a novel framework, which models the behavior of news and social media in response to events as a convolution between event's importance and media response function, specific to media and event type. This framework is suitable for detecting time and duration of events, as well as their impact and dynamics, from time series of publication volume. These data can greatly enhance events analysis; for instance, they can help distinguish important events from unimportant, or predict sentiment and stock market shifts. As an example of such application, we extracted news events for a variety of topics and then correlated this data with the corresponding sentiment time series, revealing the connection between sentiment shifts and event dynamics.},
booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {901–910},
numpages = {10},
keywords = {information spread, news dynamics, sentiment analysis, social media},
location = {New York, New York, USA},
series = {KDD '14}
}

@inproceedings{10.1145/1081870.1081945,
author = {Jin, Xin and Zhou, Yanzan and Mobasher, Bamshad},
title = {A maximum entropy web recommendation system: combining collaborative and content features},
year = {2005},
isbn = {159593135X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1081870.1081945},
doi = {10.1145/1081870.1081945},
abstract = {Web users display their preferences implicitly by navigating through a sequence of pages or by providing numeric ratings to some items. Web usage mining techniques are used to extract useful knowledge about user interests from such data. The discovered user models are then used for a variety of applications such as personalized recommendations. Web site content or semantic features of objects provide another source of knowledge for deciphering users' needs or interests. We propose a novel Web recommendation system in which collaborative features such as navigation or rating data as well as the content features accessed by the users are seamlessly integrated under the maximum entropy principle. Both the discovered user patterns and the semantic relationships among Web objects are represented as sets of constraints that are integrated to fit the model. In the case of content features, we use a new approach based on Latent Dirichlet Allocation (LDA) to discover the hidden semantic relationships among items and derive constraints used in the model. Experiments on real Web site usage data sets show that this approach can achieve better recommendation accuracy, when compared to systems using only usage information. The integration of semantic information also allows for better interpretation of the generated recommendations.},
booktitle = {Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining},
pages = {612–617},
numpages = {6},
keywords = {maximum entropy, recommendation, user profiling, web usage mining},
location = {Chicago, Illinois, USA},
series = {KDD '05}
}

@inproceedings{10.1145/1835804.1835893,
author = {Jahrer, Michael and T\"{o}scher, Andreas and Legenstein, Robert},
title = {Combining predictions for accurate recommender systems},
year = {2010},
isbn = {9781450300551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835804.1835893},
doi = {10.1145/1835804.1835893},
abstract = {We analyze the application of ensemble learning to recommender systems on the Netflix Prize dataset. For our analysis we use a set of diverse state-of-the-art collaborative filtering (CF) algorithms, which include: SVD, Neighborhood Based Approaches, Restricted Boltzmann Machine, Asymmetric Factor Model and Global Effects. We show that linearly combining (blending) a set of CF algorithms increases the accuracy and outperforms any single CF algorithm. Furthermore, we show how to use ensemble methods for blending predictors in order to outperform a single blending algorithm. The dataset and the source code for the ensemble blending are available online.},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {693–702},
numpages = {10},
keywords = {Netflix, ensemble learning, recommender systems, supervised learning},
location = {Washington, DC, USA},
series = {KDD '10}
}

@inproceedings{10.1145/1557019.1557100,
author = {Rendle, Steffen and Balby Marinho, Leandro and Nanopoulos, Alexandros and Schmidt-Thieme, Lars},
title = {Learning optimal ranking with tensor factorization for tag recommendation},
year = {2009},
isbn = {9781605584959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1557019.1557100},
doi = {10.1145/1557019.1557100},
abstract = {Tag recommendation is the task of predicting a personalized list of tags for a user given an item. This is important for many websites with tagging capabilities like last.fm or delicious. In this paper, we propose a method for tag recommendation based on tensor factorization (TF). In contrast to other TF methods like higher order singular value decomposition (HOSVD), our method RTF ('ranking with tensor factorization') directly optimizes the factorization model for the best personalized ranking. RTF handles missing values and learns from pairwise ranking constraints. Our optimization criterion for TF is motivated by a detailed analysis of the problem and of interpretation schemes for the observed data in tagging systems. In all, RTF directly optimizes for the actual problem using a correct interpretation of the data. We provide a gradient descent algorithm to solve our optimization problem. We also provide an improved learning and prediction method with runtime complexity analysis for RTF. The prediction runtime of RTF is independent of the number of observations and only depends on the factorization dimensions. Besides the theoretical analysis, we empirically show that our method outperforms other state-of-the-art tag recommendation methods like FolkRank, PageRank and HOSVD both in quality and prediction runtime.},
booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {727–736},
numpages = {10},
keywords = {ranking, tag recommendation, tensor factorization},
location = {Paris, France},
series = {KDD '09}
}

@inproceedings{10.1145/1557019.1557072,
author = {Koren, Yehuda},
title = {Collaborative filtering with temporal dynamics},
year = {2009},
isbn = {9781605584959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1557019.1557072},
doi = {10.1145/1557019.1557072},
abstract = {Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance-decay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset.},
booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {447–456},
numpages = {10},
keywords = {collaborative filtering, concept drift, recommender systems},
location = {Paris, France},
series = {KDD '09}
}

@inproceedings{10.1145/1835804.1835834,
author = {Agarwal, Deepak and Agrawal, Rahul and Khanna, Rajiv and Kota, Nagaraj},
title = {Estimating rates of rare events with multiple hierarchies through scalable log-linear models},
year = {2010},
isbn = {9781450300551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835804.1835834},
doi = {10.1145/1835804.1835834},
abstract = {We consider the problem of estimating rates of rare events for high dimensional, multivariate categorical data where several dimensions are hierarchical. Such problems are routine in several data mining applications including computational advertising, our main focus in this paper. We propose LMMH, a novel log-linear modeling method that scales to massive data applications with billions of training records and several million potential predictors in a map-reduce framework. Our method exploits correlations in aggregates observed at multiple resolutions when working with multiple hierarchies; stable estimates at coarser resolution provide informative prior information to improve estimates at finer resolutions. Other than prediction accuracy and scalability, our method has an inbuilt variable screening procedure based on a "spike and slab prior" that provides parsimony by removing non-informative predictors without hurting predictive accuracy. We perform large scale experiments on data from real computational advertising applications and illustrate our approach on datasets with several billion records and hundreds of millions of predictors. Extensive comparisons with other benchmark methods show significant improvements in prediction accuracy.},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {213–222},
numpages = {10},
keywords = {computational advertising, count data, display advertising, gamma-poisson, spars contingency tables, spike and slab prior},
location = {Washington, DC, USA},
series = {KDD '10}
}

@inproceedings{10.1145/3097983.3098089,
author = {Yang, Hongxia and Zhu, Yada and He, Jingrui},
title = {Local Algorithm for User Action Prediction Towards Display Ads},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098089},
doi = {10.1145/3097983.3098089},
abstract = {User behavior modeling is essential in computational advertisement, which builds users' profiles by tracking their online behaviors and then delivers the relevant ads according to each user's interests and needs. Accurate models will lead to higher targeting accuracy and thus improved advertising performance. Intuitively, similar users tend to have similar behaviors towards the displayed ads (e.g., impression, click, conversion). However, to the best of our knowledge, there is not much previous work that explicitly investigates such similarities of various types of user behaviors, and incorporates them into ad response targeting and prediction, largely due to the prohibitive scale of the problem.To bridge this gap, in this paper, we use bipartite graphs to represent historical user behaviors, which consist of both user nodes and advertiser campaign nodes, as well as edges reflecting various types of user-campaign interactions in the past. Based on this representation, we study random-walk-based local algorithms for user behavior modeling and action prediction, whose computational complexity depends only on the size of the output cluster, rather than the entire graph. Our goal is to improve action prediction by leveraging historical user-user, campaign-campaign, and user-campaign interactions. In particular, we propose the bipartite graphs AdvUserGraph accompanied with the ADNI algorithm. ADNI extends the NIBBLE algorithm to AdvUserGraph, and it is able to find the local cluster consisting of interested users towards a specific advertiser campaign. We also propose two extensions of ADNI with improved efficiencies. The performance of the proposed algorithms is demonstrated on both synthetic data and a world leading Demand Side Platform (DSP), showing that they are able to discriminate extremely rare events in terms of their action propensity.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {2091–2099},
numpages = {9},
keywords = {computational advertisement, large scale, local graph algorithm, user action prediction},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/502512.502525,
author = {Domingos, Pedro and Richardson, Matt},
title = {Mining the network value of customers},
year = {2001},
isbn = {158113391X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/502512.502525},
doi = {10.1145/502512.502525},
abstract = {One of the major applications of data mining is in helping companies determine which potential customers to market to. If the expected profit from a customer is greater than the cost of marketing to her, the marketing action for that customer is executed. So far, work in this area has considered only the intrinsic value of the customer (i.e, the expected profit from sales to her). We propose to model also the customer's network value: the expected profit from sales to other customers she may influence to buy, the customers those may influence, and so on recursively. Instead of viewing a market as a set of independent entities, we view it as a social network and model it as a Markov random field. We show the advantages of this approach using a social network mined from a collaborative filtering database. Marketing that exploits the network value of customers---also known as viral marketing---can be extremely effective, but is still a black art. Our work can be viewed as a step towards providing a more solid foundation for it, taking advantage of the availability of large relevant databases.},
booktitle = {Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {57–66},
numpages = {10},
keywords = {Markov random fields, collaborative filtering, dependency networks, direct marketing, social networks, viral marketing},
location = {San Francisco, California},
series = {KDD '01}
}

@inproceedings{10.1145/2020408.2020435,
author = {Agarwal, Deepak and Chen, Bee-Chung and Elango, Pradheep and Wang, Xuanhui},
title = {Click shaping to optimize multiple objectives},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020408.2020435},
doi = {10.1145/2020408.2020435},
abstract = {Recommending interesting content to engage users is important for web portals (e.g. AOL, MSN, Yahoo!, and many others). Existing approaches typically recommend articles to optimize for a single objective, i.e., number of clicks. However a click is only the starting point of a user's journey and subsequent downstream utilities such as time-spent and revenue are important. In this paper, we call the problem of recommending links to jointly optimize for clicks and post-click downstream utilities click shaping. We propose a multi-objective programming approach in which multiple objectives are modeled in a constrained optimization framework. Such a formulation can naturally incorporate various application-driven requirements. We study several variants that model different requirements as constraints and discuss some of the subtleties involved. We conduct our experiments on a large dataset from a real system by using a newly proposed unbiased evaluation methodology [17]. Through extensive experiments we quantify the tradeoff between different objectives under various constraints. Our experimental results show interesting characteristics of different formulations and our findings may provide valuable guidance to the design of recommendation engines for web portals.},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {132–140},
numpages = {9},
keywords = {click shaping, constrained optimization, multi-objective},
location = {San Diego, California, USA},
series = {KDD '11}
}

@inproceedings{10.1145/2783258.2788614,
author = {Agarwal, Deepak and Chen, Bee-Chung and He, Qi and Hua, Zhenhao and Lebanon, Guy and Ma, Yiming and Shivaswamy, Pannagadatta and Tseng, Hsiao-Ping and Yang, Jaewon and Zhang, Liang},
title = {Personalizing LinkedIn Feed},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2788614},
doi = {10.1145/2783258.2788614},
abstract = {LinkedIn dynamically delivers update activities from a user's interpersonal network to more than 300 million members in the personalized feed that ranks activities according their "relevance" to the user. This paper discloses the implementation details behind this personalized feed system at LinkedIn which can not be found from related work, and addresses the scalability and data sparsity challenges for deploying the system online. More specifically, we focus on the personalization models by generating three kinds of affinity scores: Viewer-ActivityType Affinity, Viewer-Actor Affinity, and Viewer-Actor-ActivityType Affinity. Extensive experiments based on online bucket tests (A/B experiments) and offline evaluation illustrate the effect of our personalization models in LinkedIn feed.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1651–1660},
numpages = {10},
keywords = {feed relevance, large scale learning, personalization},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@proceedings{10.1145/3711896,
title = {KDD '25: Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 2025 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining will be held in Toronto, Canada from August 3 - 7, 2025. This year's conference continues its tradition of being the premier forum for presentation of research results and experience reports on leading issues in Data Mining as well as in Data Science and Machine Learning. The large attendance of the KDD conference, and the high impact of the KDD publications, give researchers and practitioners a unique opportunity to share novel perspectives.},
location = {Toronto ON, Canada}
}

@inproceedings{10.1145/1557019.1557036,
author = {Backstrom, Lars and Kleinberg, Jon and Kumar, Ravi},
title = {Optimizing web traffic via the media scheduling problem},
year = {2009},
isbn = {9781605584959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1557019.1557036},
doi = {10.1145/1557019.1557036},
abstract = {Website traffic varies through time in consistent and predictable ways, with highest traffic in the middle of the day. When providing media content to visitors, it is important to present repeat visitors with new content so that they keep coming back. In this paper we present an algorithm to balance the need to keep a website fresh with new content with the desire to present the best content to the most visitors at times of peak traffic. We formulate this as the media scheduling problem, where we attempt to maximize total clicks, given the overall traffic pattern and the time varying clickthrough rates of available media content. We present an efficient algorithm to perform this scheduling under certain conditions and apply this algorithm to real data obtained from server logs, showing evidence of significant improvements in traffic from our algorithmic schedules. Finally, we analyze the click data, presenting models for why and how the clickthrough rate for new content declines as it ages.},
booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {89–98},
numpages = {10},
keywords = {human response, media scheduling, user interaction},
location = {Paris, France},
series = {KDD '09}
}

@inproceedings{10.1145/1348549.1348555,
author = {Lerman, Kristina},
title = {Dynamics of collaborative document rating systems},
year = {2007},
isbn = {9781595938480},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1348549.1348555},
doi = {10.1145/1348549.1348555},
abstract = {The rise of social media sites, such as blogs, wikis, Digg and Flickr among others, underscores a transformation of the Web to a participatory medium in which users are actively creating, evaluating and distributing information. The social news aggregator Digg allows users to submit links to and vote on news stories. Like other social media sites, Digg also allows users to designate others as "friends" and easily track friends' activities: what new stories they submitted, commented on or liked. Each day Digg selects a handful of stories to feature on its front page. Rather than rely on the opinion of a few editors, Digg aggregates opinions of thousands of its users to decide which stories to promote to the front page. We construct a mathematical model to study how collaborative rating and promotion of news stories emerges from independent decisions made by many users. The model takes into account user behavior: e.g., whether they read stories on the front page or through the Friends interface. Solutions of the model qualitatively reproduce the observed dynamics of votes received by actual stories on Digg.Digg also ranks users according to how successful they are in getting their stories promoted to the front page. We create a model that describes how a user's rank changes in time as he gets more stories to the front page and becomes more influential in the community. We find qualitative agreement between predictions of the model and the evolution of rank for Digg users.The Digg model of allowing users to collectively evaluate how interesting the news stories are can be generalized to collaborative evaluation of the quality of information. Mathematical analysis can be used as a tool to explore different voting methods to select the most effective one before the method is ever implemented in a real system.},
booktitle = {Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 Workshop on Web Mining and Social Network Analysis},
pages = {46–55},
numpages = {10},
keywords = {collaborative rating, mathematical analysis, news aggregation, social networks},
location = {San Jose, California},
series = {WebKDD/SNA-KDD '07}
}

@inproceedings{10.1145/1281192.1281206,
author = {Bell, Robert and Koren, Yehuda and Volinsky, Chris},
title = {Modeling relationships at multiple scales to improve accuracy of large recommender systems},
year = {2007},
isbn = {9781595936097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1281192.1281206},
doi = {10.1145/1281192.1281206},
abstract = {The collaborative filtering approach to recommender systems predicts user preferences for products or services by learning past user-item relationships. In this work, we propose novel algorithms for predicting user ratings of items by integrating complementary models that focus on patterns at different scales. At a local scale, we use a neighborhood-based technique that infers ratings from observed ratings by similar users or of similar items. Unlike previous local approaches, our method is based on a formal model that accounts for interactions within the neighborhood, leading to improved estimation quality. At a higher, regional, scale, we use SVD-like matrix factorization for recovering the major structural patterns in the user-item rating matrix. Unlike previous approaches that require imputations in order to fill in the unknown matrix entries, our new iterative algorithm avoids imputation. Because the models involve estimation of millions, or even billions, of parameters, shrinkage of estimated values to account for sampling variability proves crucial to prevent overfitting. Both the local and the regional approaches, and in particular their combination through a unifying model, compare favorably with other approaches and deliver substantially better results than the commercial Netflix Cinematch recommender system on a large publicly available data set.},
booktitle = {Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {95–104},
numpages = {10},
keywords = {collaborative filtering, netflix prize, recommender systems},
location = {San Jose, California, USA},
series = {KDD '07}
}

@inproceedings{10.1145/312129.312230,
author = {Aggarwal, Charu C. and Wolf, Joel L. and Wu, Kun-Lung and Yu, Philip S.},
title = {Horting hatches an egg: a new graph-theoretic approach to collaborative filtering},
year = {1999},
isbn = {1581131437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/312129.312230},
doi = {10.1145/312129.312230},
booktitle = {Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {201–212},
numpages = {12},
location = {San Diego, California, USA},
series = {KDD '99}
}

@inproceedings{10.1145/502512.502576,
author = {Elkan, Charles},
title = {Magical thinking in data mining: lessons from CoIL challenge 2000},
year = {2001},
isbn = {158113391X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/502512.502576},
doi = {10.1145/502512.502576},
abstract = {CoIL challenge 2000 was a supervised learning contest that attracted 43 entries. The authors of 29 entries later wrote explanations of their work. This paper discusses these reports and reaches three main conclusions. First, naive Bayesian classifiers remain competitive in practice: they were used by both the winning entry and the next best entry. Second, identifying feature interactions correctly is important for maximizing predictive accuracy: this was the difference between the winning classifier and all others. Third and most important, too many researchers and practitioners in data mining do not appreciate properly the issue of statistical significance and the danger of overfitting. Given a dataset such as the one for the CoIL contest, it is pointless to apply a very complicated learning algorithm, or to perform a very time-consuming model search. In either ease, one is likely to overfit the training data and to fool oneself in estimating predictive accuracy and in discovering useful correlations.},
booktitle = {Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {426–431},
numpages = {6},
location = {San Francisco, California},
series = {KDD '01}
}

@proceedings{10.5555/3590145,
title = {ASONAM '22: Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
year = {2022},
isbn = {9781665456616},
publisher = {IEEE Press},
abstract = {We were delighted to welcome each participant at ASONAM 2022 and thank you for having contributed virtually or in person in Istanbul. ASONAM 2022 was the fourteenth annual conference in the successful ASONAM conferences series and also the first hybrid version of the conference. Previous ASONAM conferences were held in Athens (2009), Odense (2010), Kaohsiung (2011), Istanbul (2012), Niagara Falls (2013), Beijing (2014), Paris (2015), San Francisco (2016), Sydney (2017), Barcelona (2018), Vancouver (2019), Virtual (2020), Virtual (2021). The pre-pandemic locations of the conferences have enabled the participants to enjoy local sights and to engage in person-to-person interactions, making new contacts and form new scientific collaborations. These possibilities were only available in a limited form during the virtual conferences. As the covid pandemic seems to be moving towards an endemic form it was decided to have the conference in the hybrid form, as a move towards normal endemic in-person conferences.For more than a century, social networks have been studied in a variety of disciplines including sociology, anthropology, psychology, and economics. The Internet, the social Web, and other large-scale, sociotechnological infrastructures have triggered a growing interest and resulted in significant methodological advancements in social network analysis and mining. Method development in graph theory, statistics, data mining, machine learning, and AI have inspired new research problems and, in turn, opens up further possibilities for application. These spiraling trends have led to a rising prominence of social network analysis and mining methods and tools in academia, politics, security, and business.},
location = {Istanbul, Turkey}
}

