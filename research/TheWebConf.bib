@inproceedings{10.1145/3487553.3524231,
author = {Yang, Caipiao and Bao, Peng and Yan, Rong and Li, Jianian and Li, Xuanya},
title = {A Graph Temporal Information Learning Framework for Popularity Prediction},
year = {2022},
isbn = {9781450391306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487553.3524231},
doi = {10.1145/3487553.3524231},
abstract = {Effectively predicting the future popularity of online content has important implications in a wide range of areas, including online advertising, user recommendation, and fake news detection. Existing approaches mainly consider the popularity prediction task via path modeling or discrete graph modeling. However, most of them heavily exploit underlying diffusion structural and sequential information, while ignoring the temporal evolution information among different snapshots of cascades. In this paper, we propose a graph temporal information learning framework based on an improved graph convolutional network (GTGCN), which can capture both the temporal information governing the spread of information in a snapshot, and the inherent temporal dependencies among different snapshots. We validate the effectiveness of the GTGCN by applying it on a Sina Weibo dataset in the scenario of predicting retweet cascades. Experimental results demonstrate the superiority of our proposed method over the state-of-the-art approaches.},
booktitle = {Companion Proceedings of the Web Conference 2022},
pages = {239–242},
numpages = {4},
keywords = {popularity prediction, graph convolutional network, dynamic graph representation learning},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3487553.3524249,
author = {Cao, Qi and Shen, Huawei and Liu, Yuanhao and Gao, Jinhua and Cheng, Xueqi},
title = {PREP: Pre-training with Temporal Elapse Inference for Popularity Prediction},
year = {2022},
isbn = {9781450391306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487553.3524249},
doi = {10.1145/3487553.3524249},
abstract = {Predicting the popularity of online content is a fundamental problem in various applications. One practical challenge takes roots in the varying length of observation time or prediction horizon, i.e., a good model for popularity prediction is desired to handle various prediction settings. However, most existing methods adopt a separate training paradigm for each prediction setting and the obtained model for one setting is difficult to be generalized to others, causing a great waste of computational resources and a large demand for downstream labels. To solve the above issues, we propose a novel pre-training framework for popularity prediction, namely PREP, aiming to pre-train a general representation model from the readily available unlabeled diffusion data, which can be effectively transferred into various prediction settings. We design a novel pretext task for pre-training, i.e., temporal elapse inference for two randomly sampled time slices of popularity dynamics, impelling the representation model to learn intrinsic knowledge about popularity dynamics. Experimental results conducted on two real datasets demonstrate the generalization and efficiency of the pre-training framework for different popularity prediction task settings.},
booktitle = {Companion Proceedings of the Web Conference 2022},
pages = {243–247},
numpages = {5},
keywords = {Temporal Elapse Inference, Pre-training, Popularity Prediction},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3589335.3648340,
author = {Zhou, Haolin and Pan, Junwei and Zhou, Xinyi and Chen, Xihua and Jiang, Jie and Gao, Xiaofeng and Chen, Guihai},
title = {Temporal Interest Network for User Response Prediction},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3648340},
doi = {10.1145/3589335.3648340},
abstract = {User response prediction is essential in industrial recommendation systems, such as online display advertising. Among all the features in recommendation models, user behaviors are among the most critical. Many works have revealed that a user's behavior reflects her interest in the candidate item, owing to the semantic or temporal correlation between behaviors and the candidate. While the literature has individually examined each of these correlations, researchers have yet to analyze them in combination, that is, the semantic-temporal correlation. We empirically measure this correlation and observe intuitive yet robust patterns. We then examine several popular user interest models and find that, surprisingly, none of them learn such correlation well.To fill this gap, we propose a Temporal Interest Network (TIN) to capture the semantic-temporal correlation simultaneously between behaviors and the target. We achieve this by incorporating target-aware temporal encoding, in addition to semantic encoding, to represent behaviors and the target. Furthermore, we conduct explicit 4-way interaction by deploying target-aware attention and target-aware representation to capture both semantic and temporal correlation. We conduct comprehensive evaluations on two popular public datasets, and our proposed TIN outperforms the best-performing baselines by 0.43% and 0.29% on GAUC, respectively. During online A/B testing in Tencent's advertising platform, TIN achieves 1.65% cost lift and 1.93% GMV lift over the base model. It has been successfully deployed in production since October 2023, serving the WeChat Moments traffic. We have released our code at https://github.com/zhouxy1003/TIN.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {413–422},
numpages = {10},
keywords = {recommender systems, sequential recommender, target attention, user interest model},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3485447.3511934,
author = {Tang, Shisong and Li, Qing and Ma, Xiaoteng and Gao, Ci and Wang, Dingmin and Jiang, Yong and Ma, Qian and Zhang, Aoyang and Chen, Hechang},
title = {Knowledge-based Temporal Fusion Network for Interpretable Online Video Popularity Prediction},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3511934},
doi = {10.1145/3485447.3511934},
abstract = {Predicting the popularity of online videos has many real-world applications, such as recommendation, precise advertising, and edge caching strategies. Despite many efforts have been dedicated to the online video popularity prediction, there still exist several challenges: (1) The meta-data from online videos is usually sparse and noisy, which makes it difficult to learn a stable and robust representation. (2) The influence of content features and temporal features in different life cycles of online videos is dynamically changing, so it is necessary to build a model that can capture the dynamics. (3) Besides, there is a great need to interpret the predictive behavior of the model to assist administrators of video platforms in the subsequent decision-making. In this paper, we propose a Knowledge-based Temporal Fusion Network (KTFN) that incorporates knowledge graph representation to address the aforementioned challenges in the task of online video popularity prediction. To be more specific, we design a Tree Attention Network (TAN) to learn the embedding of online video entities in knowledge graphs via selectively aggregating local neighborhood information, thus enabling our model to learn the importance of different entities under the same relation. Besides, an Attention-based Long Short-Term Memory (ALSTM) is utilized to learn the temporal feature representation. Finally, we propose an Adaptively Temporal Feature Fusion (ATFF) scheme to adaptively fuse content features and temporal features, in which a learnable exponential decay function with the global attention mechanism is constructed. We collect two large-scale real-world datasets from the server logs of two popular Chinese online video platforms, and experimental results on the two datasets have demonstrated the superiority and interpretability of KTFN.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {2879–2887},
numpages = {9},
keywords = {Attention model, Graph neural networks, Knowledge graph, Video popularity prediction},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3366423.3380004,
author = {Xie, Jiayi and Zhu, Yaochen and Zhang, Zhibin and Peng, Jian and Yi, Jing and Hu, Yaosi and Liu, Hongyi and Chen, Zhenzhong},
title = {A Multimodal Variational Encoder-Decoder Framework for Micro-video Popularity Prediction},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380004},
doi = {10.1145/3366423.3380004},
abstract = {Predicting the popularity of a micro-video is a challenging task, due to a number of factors impacting the distribution such as the diversity of the video content and user interests, complex online interactions, etc. In this paper, we propose a multimodal variational encoder-decoder (MMVED) framework that considers the uncertain factors as the randomness for the mapping from the multimodal features to the popularity. Specifically, the MMVED first encodes features from multiple modalities in the observation space into latent representations and learns their probability distributions based on variational inference, where only relevant features in the input modalities can be extracted into the latent representations. Then, the modality-specific hidden representations are fused through Bayesian reasoning such that the complementary information from all modalities is well utilized. Finally, a temporal decoder implemented as a recurrent neural network is designed to predict the popularity sequence of a certain micro-video. Experiments conducted on a real-world dataset demonstrate the effectiveness of our proposed model in the micro-video popularity prediction task.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2542–2548},
numpages = {7},
keywords = {Variational inference, Multimodal learning, Micro-video popularity prediction, Deep neural networks, Deep information bottleneck},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3485447.3512024,
author = {Fei, Hao and Li, Jingye and Ren, Yafeng and Zhang, Meishan and Ji, Donghong},
title = {Making Decision like Human: Joint Aspect Category Sentiment Analysis and Rating Prediction with Fine-to-Coarse Reasoning},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512024},
doi = {10.1145/3485447.3512024},
abstract = {Joint aspect category sentiment analysis (ACSA) and rating prediction (RP) is a newly proposed task (namely ASAP) that integrates the characteristics of both fine-grained and coarse-grained sentiment analysis. However, the prior joint models for the ASAP task only consider the shallow interaction between the two granularities. In this work, we gain the inspiration from human intuition, presenting an innovative from-fine-to-coarse reasoning framework for better joint task performance. Our system advances mainly in three aspects. First, we additionally make use of the category label text features, co-encoding them with the input document texts, allowing to accurately capture the key clues of each category. Second, we build a fine-to-coarse hierarchical label graph, modeling the aspect categories and the overall rating as a hierarchical structure for full interaction of the two granularities. Third, we propose to perform global iterative reasoning with a cross-collaboration between the hierarchical label graph and the context graphs, enabling sufficient communication between categories and review contexts. Based on the ASAP dataset, experimental results demonstrate that our proposed framework outperforms state-of-the-art baselines by large margins. Further in-depth analyses prove that our method is effective on addressing both the unbalanced data distribution and the long-text issue.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {3042–3051},
numpages = {10},
keywords = {Fine-to-coarse reasoning, Natural language processing, Product rating, Sentiment analysis, Text mining},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3178876.3186148,
author = {Punjabi, Surabhi and Bhatt, Priyanka},
title = {Robust Factorization Machines for User Response Prediction},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186148},
doi = {10.1145/3178876.3186148},
abstract = {Factorization machines (FMs) are a state-of-the-art model class for user response prediction in the computational advertising domain. Rapid growth of internet and mobile device usage has given rise to multiple customer touchpoints. This coupled with factors like high cookie churn rate results in a fragmented view of user activity at the advertiser»s end. Current literature assumes procured user signals as the absolute truth, which is contested by the absence of deterministic identity linkage across a user's multiple avatars. In this work, we characterize the data uncertainty using Robust Optimization (RO) paradigm to design approaches that are immune against perturbations. We propose two novel algorithms: robust factorization machine (RFM) and its field-aware variant (RFFM), under interval uncertainty. These formulations are generic and can find applicability in any classification setting under noise. We provide a distributed and scalable Spark implementation using parallel stochastic gradient descent. In the experiments conducted on three real-world datasets, the robust counterparts outperform the baselines significantly under perturbed settings. Our experimental findings reveal interesting connections between choice of uncertainty set and the noise-proofness of resulting models.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {669–678},
numpages = {10},
keywords = {robust optimization, response prediction, interval uncertainty, field aware factorization machines, factorization machines, computational advertising},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3038912.3052581,
author = {Park, Chanyoung and Kim, Donghyun and Oh, Jinoh and Yu, Hwanjo},
title = {Do "Also-Viewed" Products Help User Rating Prediction?},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052581},
doi = {10.1145/3038912.3052581},
abstract = {For online product recommendation engines, learning high-quality product embedding that captures various aspects of the product is critical to improving the accuracy of user rating prediction. In recent research, in conjunction with user feedback, the appearance of a product as side information has been shown to be helpful for learning product embedding. However, since a product has a variety of aspects such as functionality and specifications, taking into account only its appearance as side information does not suffice to accurately learn its embedding. In this paper, we propose a matrix co-factorization method that leverages information hidden in the so-called "also-viewed" products, i.e., a list of products that has also been viewed by users who have viewed a target product. "Also-viewed" products reflect various aspects of a given product that have been overlooked by visually-aware recommendation methods proposed in past research. Experiments on multiple real-world datasets demonstrate that our proposed method outperforms state-of-the-art baselines in terms of user rating prediction. We also perform classification on the product embedding learned by our method, and compare it with a state-of-the-art baseline to demonstrate the superiority of our method in generating high-quality product embedding that better represents the product.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {1113–1122},
numpages = {10},
keywords = {product embedding, online shopping, collaborative filtering},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3366424.3382680,
author = {Liu, Feng and Guo, Wei and Guo, Huifeng and Tang, Ruiming and Ye, Yunming and He, Xiuqiang},
title = {Dual-attentional Factorization-Machines based Neural Network for User Response Prediction},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3382680},
doi = {10.1145/3366424.3382680},
abstract = {This paper proposes Dual-attentional Factorization-Machines (DFM), which incorporates global-wise attention and element-wise attention with FM for user response prediction. We further extend DFM with a deep neural network and name this new model Dual-attentional Factorization-machines based Network (DFNet). Comprehensive experiments are conducted on two real-world datasets to demonstrate the effectiveness of DFM and DFNet over the state-of-the-art models for user response prediction.},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {26–27},
numpages = {2},
keywords = {Feature Interactions, Factorization-Machines, Attention Network},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/2487788.2487877,
author = {Bao, Peng and Shen, Hua-Wei and Huang, Junming and Cheng, Xue-Qi},
title = {Popularity prediction in microblogging network: a case study on sina weibo},
year = {2013},
isbn = {9781450320382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487788.2487877},
doi = {10.1145/2487788.2487877},
abstract = {Predicting the popularity of content is important for both the host and users of social media sites. The challenge of this problem comes from the inequality of the popularity of content. Existing methods for popularity prediction are mainly based on the quality of content, the interface of social media site to highlight contents, and the collective behavior of users. However, little attention is paid to the structural characteristics of the networks spanned by early adopters, i.e., the users who view or forward the content in the early stage of content dissemination. In this paper, taking the Sina Weibo as a case, we empirically study whether structural characteristics can provide clues for the popularity of short messages. We find that the popularity of content is well reflected by the structural diversity of the early adopters. Experimental results demonstrate that the prediction accuracy is significantly improved by incorporating the factor of structural diversity into existing methods.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {177–178},
numpages = {2},
keywords = {structural diversity, social network, popularity prediction, microblogging, information diffusion},
location = {Rio de Janeiro, Brazil},
series = {WWW '13 Companion}
}

@inproceedings{10.1145/3178876.3186026,
author = {Zhang, Wei and Wang, Wen and Wang, Jun and Zha, Hongyuan},
title = {User-guided Hierarchical Attention Network for Multi-modal Social Image Popularity Prediction},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186026},
doi = {10.1145/3178876.3186026},
abstract = {Popularity prediction for the growing social images has opened unprecedented opportunities for wide commercial applications, such as precision advertising and recommender system. While a few studies have explored this significant task, little research has addressed its unstructured properties of both visual and textual modalities, and further considered to learn effective representation from multi-modalities for popularity prediction. To this end, we propose a model named User-guided Hierarchical Attention Network (UHAN) with two novel user-guided attention mechanisms to hierarchically attend both visual and textual modalities. It is capable of not only learning effective representation for each modality, but also fusing them to obtain an integrated multi-modal representation under the guidance of user embedding. As no benchmark dataset exists, we extend a publicly available social image dataset by adding the descriptions of images. The comprehensive experiments have demonstrated the rationality of our proposed UHAN and its better performance than several strong alternatives.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {1277–1286},
numpages = {10},
keywords = {social image popularity, multi-modal analysis, attention network},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/2567948.2577298,
author = {Bauckhage, Christian and Kersting, Kristian and Rastegarpanah, Bashir},
title = {Collective attention to social media evolves according to diffusion models},
year = {2014},
isbn = {9781450327459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567948.2577298},
doi = {10.1145/2567948.2577298},
abstract = {We investigate patterns of adoption of 175 social media services and Web businesses using data from Google Trends. For each service, we collect aggregated search frequencies from 45 countries as well as global averages. This results in more than 8.000 time series which we analyze using economic diffusion models. The models are found to provide accurate and statistically significant fits to the data and show that collective attention to social media grows and subsides in a highly regular manner. Regularities persist across regions, cultures, and topics and thus hint at general mechanisms that govern the adoption of Web-based services.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {223–224},
numpages = {2},
keywords = {trend prediction, social media services, collective attention},
location = {Seoul, Korea},
series = {WWW '14 Companion}
}

@inproceedings{10.1145/2187980.2188262,
author = {Ye, Mao and Sandholm, Thomas and Wang, Chunyan and Aperjis, Christina and Huberman, Bernardo A.},
title = {Collective attention and the dynamics of group deals},
year = {2012},
isbn = {9781450312301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187980.2188262},
doi = {10.1145/2187980.2188262},
abstract = {We present a study of the group purchasing behavior of daily deals in Groupon and LivingSocial and formulate a predictive dynamic model of collective attention for group buying behavior. Using large data sets from both Groupon and LivingSocial we show how the model is able to predict the success of group deals as a function of time.We find that Groupon deals are easier to predict accurately earlier in the deal lifecycle than LivingSocial deals due to the total number of deal purchases saturating quicker. One possible explanation for this is that the incentive to socially propagate a deal is based on an individual threshold in LivingSocial, whereas in Groupon it is based on a collective threshold which is reached very early. Furthermore, the personal benefit of propagating a deal is greater in LivingSocial.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {1205–1212},
numpages = {8},
keywords = {purchase dynamics, group deals, collective attention},
location = {Lyon, France},
series = {WWW '12 Companion}
}

@inproceedings{10.1145/3041021.3051153,
author = {Taheri, Seyed Mohammad and Mahyar, Hamidreza and Firouzi, Mohammad and Ghalebi K., Elahe and Grosu, Radu and Movaghar, Ali},
title = {Extracting Implicit Social Relation for Social Recommendation Techniques in User Rating Prediction},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051153},
doi = {10.1145/3041021.3051153},
abstract = {Recommendation plays an increasingly important role in our daily lives. Recommender systems automatically suggest items to users that might be interesting for them. Recent studies illustrate that incorporating social trust in Matrix Factorization methods demonstrably improves accuracy of rating prediction. Such approaches mainly use the trust scores explicitly expressed by users. However, it is often challenging to have users provide explicit trust scores of each other. There exist quite a few works, which propose Trust Metrics to compute and predict trust scores between users based on their interactions. In this paper, first we present how social relation can be extracted from users' ratings to items by describing Hellinger distance between users in recommender systems. Then, we propose to incorporate the predicted trust scores into social matrix factorization models. By analyzing social relation extraction from three well-known real-world datasets, which both: trust and recommendation data available, we conclude that using the implicit social relation in social recommendation techniques has almost the same performance compared to the actual trust scores explicitly expressed by users. Hence, we build our method, called Hell-TrustSVD, on top of the state-of-the-art social recommendation technique to incorporate both the extracted implicit social relations and ratings given by users on the prediction of items for an active user. To the best of our knowledge, this is the first work to extend TrustSVD with extracted social trust information. The experimental results support the idea of employing implicit trust into matrix factorization whenever explicit trust is not available, can perform much better than the state-of-the-art approaches in user rating prediction.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1343–1351},
numpages = {9},
keywords = {social recommendation techniques, social networks, recommender systems, matrix factorization},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/2567948.2577312,
author = {Gao, Shuai and Ma, Jun and Chen, Zhumin},
title = {Effective and effortless features for popularity prediction in microblogging network},
year = {2014},
isbn = {9781450327459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567948.2577312},
doi = {10.1145/2567948.2577312},
abstract = {Predicting popularity of online contents is of remarkable practical value in various business and administrative applications. Existing studies mainly focus on finding the most effective features for prediction. However, some effective features, such as structural features which are extracted from the underlying user network, are hard to access. In this paper, we aim to identify features that are both effective and effortless (easy to obtain or compute). Experiments on Sina Weibo show the effectiveness and effortlessness of the temporal features and satisfying prediction performance can be obtained based on only the temporal features of first 10 retweets.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {269–270},
numpages = {2},
keywords = {temporal features, social network, popularity prediction, microblogging, classification},
location = {Seoul, Korea},
series = {WWW '14 Companion}
}

@inproceedings{10.1145/2736277.2741116,
author = {Drutsa, Alexey and Gusev, Gleb and Serdyukov, Pavel},
title = {Future User Engagement Prediction and Its Application to Improve the Sensitivity of Online Experiments},
year = {2015},
isbn = {9781450334693},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2736277.2741116},
doi = {10.1145/2736277.2741116},
abstract = {Modern Internet companies improve their services by means of data-driven decisions that are based on online controlled experiments (also known as A/B tests). To run more online controlled experiments and to get statistically significant results faster are the emerging needs for these companies. The main way to achieve these goals is to improve the sensitivity of A/B experiments. We propose a novel approach to improve the sensitivity of user engagement metrics (that are widely used in A/B tests) by utilizing prediction of the future behavior of an individual user. This problem of prediction of the exact value of a user engagement metric is also novel and is studied in our work. We demonstrate the effectiveness of our sensitivity improvement approach on several real online experiments run at Yandex. Especially, we show how it can be used to detect the treatment effect of an A/B test faster with the same level of statistical significance.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {256–266},
numpages = {11},
keywords = {user engagement, sensitivity, quality metrics, online controlled experiment, engagement prediction},
location = {Florence, Italy},
series = {WWW '15}
}

@inproceedings{10.1145/2487788.2487805,
author = {Mukherjee, Subhabrata and Basu, Gaurab and Joshi, Sachindra},
title = {Incorporating author preference in sentiment rating prediction of reviews},
year = {2013},
isbn = {9781450320382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487788.2487805},
doi = {10.1145/2487788.2487805},
abstract = {Traditional works in sentiment analysis do not incorporate author preferences during sentiment classification of reviews. In this work, we show that the inclusion of author preferences in sentiment rating prediction of reviews improves the correlation with ground ratings, over a generic author independent rating prediction model. The overall sentiment rating prediction for a review has been shown to improve by capturing facet level rating. We show that this can be further developed by considering author preferences in predicting the facet level ratings, and hence the overall review rating. To the best of our knowledge, this is the first work to incorporate author preferences in rating prediction.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {47–48},
numpages = {2},
keywords = {sentiment analysis, author preference, aspect rating},
location = {Rio de Janeiro, Brazil},
series = {WWW '13 Companion}
}

@inproceedings{10.1145/2740908.2742566,
author = {Chapelle, Olivier},
title = {Offline Evaluation of Response Prediction in Online Advertising Auctions},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2742566},
doi = {10.1145/2740908.2742566},
abstract = {Click-through rates and conversion rates are two core machine learning problems in online advertising. The evaluation of such systems is often based on traditional supervised learning metrics that ignore how the predictions are used. These predictions are in fact part of bidding systems in online advertising auctions. We present here an empirical evaluation of a metric that is specifically tailored for auctions in online advertising and show that it correlates better than standard metrics with A/B test results.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {919–922},
numpages = {4},
keywords = {response prediction, online advertising, metrics, auction},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/2567948.2577342,
author = {Qiao, Zhi and Zhang, Peng and He, Jing and Cao, Yanan and Zhou, Chuan and Guo, Li},
title = {Combining geographical information of users and content of items for accurate rating prediction},
year = {2014},
isbn = {9781450327459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567948.2577342},
doi = {10.1145/2567948.2577342},
abstract = {Recommender systems have attracted attentions lately due to their wide and successful applications in online advertising. In this paper, we propose a bayesian generative model to describe the generative process of rating, which combines geographical information of users and content of items. The generative model consists of two interacting LDA models, where one LDA model for location-based user groups (user dimension) and the other for the topics of content of items(item dimension). A Gibbs sampling algorithm is proposed for parameter estimation. Experiments have shown our proposed method outperforms baseline methods.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {361–362},
numpages = {2},
keywords = {recommendation system, rating prediction, generative model},
location = {Seoul, Korea},
series = {WWW '14 Companion}
}

@inproceedings{10.1145/2187836.2187871,
author = {Lehmann, Janette and Gon\c{c}alves, Bruno and Ramasco, Jos\'{e} J. and Cattuto, Ciro},
title = {Dynamical classes of collective attention in twitter},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187871},
doi = {10.1145/2187836.2187871},
abstract = {Micro-blogging systems such as Twitter expose digital traces of social discourse with an unprecedented degree of resolution of individual behaviors. They offer an opportunity to investigate how a large-scale social system responds to exogenous or endogenous stimuli, and to disentangle the temporal, spatial and topical aspects of users' activity. Here we focus on spikes of collective attention in Twitter, and specifically on peaks in the popularity of hashtags. Users employ hashtags as a form of social annotation, to define a shared context for a specific event, topic, or meme. We analyze a large-scale record of Twitter activity and find that the evolution of hashtag popularity over time defines discrete classes of hashtags. We link these dynamical classes to the events the hashtags represent and use text mining techniques to provide a semantic characterization of the hashtag classes. Moreover, we track the propagation of hashtags in the Twitter social network and find that epidemic spreading plays a minor role in hashtag popularity, which is mostly driven by exogenous factors.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {251–260},
numpages = {10},
keywords = {online social networks, micro-blogging, content analysis},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/3589334.3645421,
author = {Ning, Wentao and Cheng, Reynold and Yan, Xiao and Kao, Ben and Huo, Nan and Haldar, Nur Al Hasan and Tang, Bo},
title = {Debiasing Recommendation with Personal Popularity},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645421},
doi = {10.1145/3589334.3645421},
abstract = {Global popularity (GP) bias is the phenomenon that popular items are recommended much more frequently than they should be, which goes against the goal of providing personalized recommendations and harms user experience and recommendation accuracy. Many methods have been proposed to reduce GP bias but they fail to notice the fundamental problem of GP, i.e., it considers popularity from a global perspective of all users and uses a single set of popular items, and thus cannot capture the interests of individual users. As such, we propose a user-aware version of item popularity named personal popularity (PP), which identifies different popular items for each user by considering the users that share similar interests. As PP models the preferences of individual users, it naturally helps to produce personalized recommendations and mitigate GP bias. To integrate PP into recommendation, we design a general personal popularity aware counterfactual (PPAC) framework, which adapts easily to existing recommendation models. In particular, PPAC recognizes that PP and GP have both direct and indirect effects on recommendations and controls direct effects with counterfactual inference techniques for unbiased recommendations. All codes and datasets are available at https://github.com/Stevenn9981/PPAC.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3400–3409},
numpages = {10},
keywords = {causal inference, item popularity, recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3178876.3186145,
author = {Cheng, Zhiyong and Ding, Ying and Zhu, Lei and Kankanhalli, Mohan},
title = {Aspect-Aware Latent Factor Model: Rating Prediction with Ratings and Reviews},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186145},
doi = {10.1145/3178876.3186145},
abstract = {Although latent factor models (e.g., matrix factorization) achieve good accuracy in rating prediction, they suffer from several problems including cold-start, non-transparency, and suboptimal recommendation for local users or items. In this paper, we employ textual review information with ratings to tackle these limitations. Firstly, we apply a proposed aspect-aware topic model (ATM) on the review text to model user preferences and item features from different aspects, and estimate the aspect importance of a user towards an item. The aspect importance is then integrated into a novel aspect-aware latent factor model (ALFM), which learns user's and item's latent factors based on ratings. In particular, ALFM introduces a weighted matrix to associate those latent factors with the same set of aspects discovered by ATM, such that the latent factors could be used to estimate aspect ratings. Finally, the overall rating is computed via a linear combination of the aspect ratings, which are weighted by the corresponding aspect importance. To this end, our model could alleviate the data sparsity problem and gain good interpretability for recommendation. Besides, an aspect rating is weighted by an aspect importance, which is dependent on the targeted user's preferences and targeted item's features. Therefore, it is expected that the proposed method can model a user's preferences on an item more accurately for each user-item pair locally. Comprehensive experimental studies have been conducted on 19 datasets from Amazon and Yelp 2017 Challenge dataset. Results show that our method achieves significant improvement compared with strong baseline methods, especially for users with only few ratings. Moreover, our model could interpret the recommendation results in depth.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {639–648},
numpages = {10},
keywords = {topic model, review-aware, recommendation, matrix factorization, aspect-aware},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3038912.3052626,
author = {Hoang, Minh X. and Dang, Xuan-Hong and Wu, Xiang and Yan, Zhenyu and Singh, Ambuj K.},
title = {GPOP: Scalable Group-level Popularity Prediction for Online Content in Social Networks},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052626},
doi = {10.1145/3038912.3052626},
abstract = {Predicting the popularity of online content in social networks is important in many applications, ranging from ad campaign design, web content caching and prefetching, to web-search result ranking. Earlier studies target this problem by learning models that either generalize behaviors of the entire network population or capture behaviors of each individual user. In this paper, we claim that a novel approach based on group-level popularity is necessary and more practical, given that users naturally organize themselves into clusters and that users within a cluster react to online content in a uniform manner. We develop a novel framework by first grouping users into cohesive clusters, and then adopt tensor decomposition to make predictions. In order to minimize the impact of noisy data and be more flexible in capturing changes in users' interests, our framework exploits both the network topology and interaction among users in learning a robust user clustering. The PARAFAC tensor decomposition is adapted to work with hierarchical constraint over user groups, and we show that optimizing this constrained function via gradient descent achieves faster convergence and leads to more stable solutions. Extensive experimental results over two social networks demonstrate that our framework is scalable, finds meaningful user groups, and significantly outperforms eight baseline methods in terms of prediction accuracy.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {725–733},
numpages = {9},
keywords = {tensor decomposition, graph clustering, content prediction},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3487553.3524647,
author = {Unal, Mesut Erhan and Kovashka, Adriana and Chung, Wen-Ting and Lin, Yu-Ru},
title = {Visual Persuasion in COVID-19 Social Media Content: A Multi-Modal Characterization},
year = {2022},
isbn = {9781450391306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487553.3524647},
doi = {10.1145/3487553.3524647},
abstract = {Social media content routinely incorporates multi-modal design to covey information and shape meanings, and sway interpretations toward desirable implications, but the choices and impacts of using both texts and visual images have not been sufficiently studied. This work proposes a computational approach to analyze the impacts of persuasive multi-modal content on popularity and reliability, in COVID-19-related news articles shared on Twitter. The two aspects are intertwined in the spread of misinformation: for example, an unreliable article that aims to misinform has to attain some popularity. This work has several contributions. First, we propose a multi-modal (image and text) approach to effectively identify popularity and reliability of information sources simultaneously. Second, we identify textual and visual elements that are predictive to information popularity and reliability. Third, by modeling cross-modal relations and similarity, we are able to uncover how unreliable articles construct multi-modal meaning in a distorted, biased fashion. Our work demonstrates how to use multi-modal analysis for understanding influential content and has implications to social media literacy and engagement.},
booktitle = {Companion Proceedings of the Web Conference 2022},
pages = {694–704},
numpages = {11},
keywords = {multi-modal learning, multi-modal content analysis, content reliability, content popularity},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3366424.3382677,
author = {Huang, Zhenhua and Wang, Zhenyu and Zhang, Rui and Zhao, Yangyang and Zheng, Fadong},
title = {Learning Bi-directional Social Influence in Information Cascades using Graph Sequence Attention Networks},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3382677},
doi = {10.1145/3366424.3382677},
abstract = {The online information cascades have spatial and temporal characteristics. Retweets in cascades have bi-directional social influence and temporal delay, e.g., a hub node influenced by a root node will further increase the exposure of information, enhance the influence of the root node, and cause subsequent retweets after a certain time. Existing deep learning approaches mostly consider only the decay effects of social influence, ignoring the bi-directional dependency and delay effects between graphs at different moments. Therefore, a novel method is presented here, namely the Graph Sequence Attention Networks (GSAN) , which addresses the bi-directional attention mechanism to learn temporal dynamics of social influence, as well as the cascading structure. A graph transformer block is designed to learn the complicated dependencies of spatial and temporal features in cascades. The proposed method could achieve state-of-the-art performance and large improvements in popularity prediction compared to strong baselines in real-world datasets.},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {19–21},
numpages = {3},
keywords = {social influence, popularity prediction, information cascades},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3308558.3313496,
author = {Li, Piji and Wang, Zihao and Bing, Lidong and Lam, Wai},
title = {Persona-Aware Tips Generation?},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313496},
doi = {10.1145/3308558.3313496},
abstract = {Tips, as a compacted and concise form of reviews, were paid less attention by researchers. In this paper, we investigate the task of tips generation by considering the “persona” information which captures the intrinsic language style of the users or the different characteristics of the product items. In order to exploit the persona information, we propose a framework based on adversarial variational auto-encoders (aVAE) for persona modeling from the historical tips and reviews of users and items. The latent variables from aVAE are regarded as persona embeddings. Besides representing persona using the latent embeddings, we design a persona memory for storing the persona related words for users and items. Pointer Network is used to retrieve persona wordings from the memory when generating tips. Moreover, the persona embeddings are used as latent factors by a rating prediction component to predict the sentiment of a user over an item. Finally, the persona embeddings and the sentiment information are incorporated into a recurrent neural networks based tips generation component. Extensive experimental results are reported and discussed to elaborate the peculiarities of our framework.},
booktitle = {The World Wide Web Conference},
pages = {1006–1016},
numpages = {11},
keywords = {Rating Prediction, Persona Modeling, Adversarial Variational Auto-Encoders., Abstractive Tips Generation},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3041021.3054242,
author = {Cao, Qi and Shen, Huawei and Gao, Hao and Gao, Jinhua and Cheng, Xueqi},
title = {Predicting the Popularity of Online Content with Group-specific Models},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054242},
doi = {10.1145/3041021.3054242},
abstract = {Predicting the popularity of online content is highly valuable in many applications and has been studied for several years. However, existing models either work in population level---all messages are assumed to follow similar popularity dynamics, lacking flexibility to capture the intrinsic complexity of popularity dynamics, or work in individual level---the popularity dynamics of messages are independent of each other, failing to leverage other messages to improve prediction accuracy. In this paper, we propose a divide and conquer framework for popularity prediction. We first divide messages into groups, anticipating each group of messages follow similar popularity dynamics, and then, we train a group-specific model for the messages of each group. Experiments demonstrate that group-specific models improve the population-level models by about 30% and outperform state-of-the-art individual-level model.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {765–766},
numpages = {2},
keywords = {social media, popularity prediction, information cascades},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3178876.3186064,
author = {Feng, Fuli and He, Xiangnan and Liu, Yiqun and Nie, Liqiang and Chua, Tat-Seng},
title = {Learning on Partial-Order Hypergraphs},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186064},
doi = {10.1145/3178876.3186064},
abstract = {Graph-based learning methods explicitly consider the relations between two entities (i.e., vertices) for learning the prediction function. They have been widely used in semi-supervised learning, manifold ranking, and clustering, among other tasks. Enhancing the expressiveness of simple graphs, hypergraphs formulate an edge as a link to multiple vertices, so as to model the higher-order relations among entities. For example, hyperedges in a hypergraph can be used to encode the similarity among vertices. To the best of our knowledge, all existing hypergraph structures represent the hyperedge as an unordered set of vertices, without considering the possible ordering relationship among vertices. In real-world data, ordering relations commonly exist, such as in graded categorical features (e.g., users» ratings on movies) and numerical features (e.g., monthly income of customers). When constructing a hypergraph, ignoring such ordering relations among entities will lead to severe information loss, resulting in suboptimal performance of the subsequent learning algorithms. In this work, we address the inherent limitation of existing hypergraphs by proposing a new data structure named Partial-Order Hypergraph, which specifically injects the partially ordering relations among vertices into a hyperedge. We develop regularization-based learning theories for partial-order hypergraphs, generalizing conventional hypergraph learning by incorporating logical rules that encode the partial-order relations. We apply our proposed method to two applications: university ranking from Web data and popularity prediction of online content. Extensive experiments demonstrate the superiority of our proposed partial-order hypergraphs, which consistently improve over conventional hypergraph methods.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {1523–1532},
numpages = {10},
keywords = {university ranking, popularity prediction, partial-order hypergraph, hypergraph, graph-based learning},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3485447.3512285,
author = {Wang, Lingzhi and Li, Jing and Zeng, Xingshan and Wong, Kam-Fai},
title = {Successful New-entry Prediction for Multi-Party Online Conversations via Latent Topics and Discourse Modeling},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512285},
doi = {10.1145/3485447.3512285},
abstract = {With the increasing popularity of social media, online interpersonal communication now plays an essential role in people’s everyday information exchange. Whether and how a newcomer can better engage in the community has attracted great interest due to its application in many scenarios. Although some prior works that explore early socialization have obtained salient achievements, they are focusing on sociological surveys based on the small group. To help individuals get through the early socialization period and engage well in online conversations, we study a novel task to foresee whether a newcomer’s message will be responded to by other participants in a multi-party conversation (henceforth Successful New-entry Prediction)1. The task would be an important part of the research in online assistants and social media. To further investigate the key factors indicating such engagement success, we employ an unsupervised neural network, Variational Auto-Encoder (VAE), to examine the topic content and discourse behavior from newcomer’s chatting history and conversation’s ongoing context. Furthermore, two large-scale datasets, from Reddit and Twitter, are collected to support further research on new-entries. Extensive experiments on both Twitter and Reddit datasets show that our model significantly outperforms all the baselines and popular neural models. Additional explainable and visual analyses on new-entry behavior shed light on how to better join in others’ discussions.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {1663–1672},
numpages = {10},
keywords = {latent variable learning, multi-party conversation, newcomer socialization, response prediction},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3701716.3719228,
author = {Zhang, Xinyu and Dou, Ran and Hu, Enrui and Zhao, Minjun and Ding, Yangkai and Dou, Zhicheng},
title = {Collaborative Optimization Approach for Workflow Agents in User Behavior Modeling},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3719228},
doi = {10.1145/3701716.3719228},
abstract = {User behavior modeling is increasingly critical for personalized services and decision-making systems, yet integrating diverse user and product features into a coherent review generation process remains challenging. Thus we propose a novel collaborative optimization approach for workflow agents in user behavior modeling that integrates user and product feature extraction with review and rating generation. Firstly, to solve the difficulty in determining the optimal structure of agent workflows, we employ Monte Carlo Tree Search (MCTS) to optimize the workflow architecture, establishing a high-performance baseline. Meanwhile, to tackle the challenges in generating and optimizing single-agent prompts and demonstrations, we implement a heuristic optimization strategy for joint automated tuning of system prompts and demo cases. Furthermore, through comprehensive analysis of data distributions, we construct a dynamic routing mechanism for the agent workflow, achieving enhanced performance across diverse scenario-specific datasets. We validate the effectiveness of our methods on three real-world datasets, demonstrating significant performance improvements across all proposed techniques. This approach secured second place overall (and first in star-rating prediction) in the user modeling track of the AgentSociety Challenge @ WWW 2025.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2988–2992},
numpages = {5},
keywords = {automatic prompt optimization, in-context learning, llm, user behavior modeling, workflow agents},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3184558.3191634,
author = {Zhang, Bowen and Lau, Wing Cheong},
title = {Temporal Modeling of Information Diffusion using MASEP: Multi-Actor Self-Exciting Processes},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3191634},
doi = {10.1145/3184558.3191634},
abstract = {Predicting the popularity of a discussion topic in an online social network (OSN) or the responses to an online fund-raising campaign is a practical challenge of immense value. Previous work tries to predict the popularity of an online campaign by modeling information diffusion as a homogeneous temporal point process within a network of a single-type of actors. However, real-world information propagation often involved multiple types of actors. In particular, there are the so-called opinion leaders, e.g. online celebrities or influential OSN users with a huge number of followers, who can create a great impact on the visibility and thus the final popularity of an event by simply mentioning it in their tweets or postings. In this paper, we propose MASEP, a Multi-actor Self-exciting Process, to model and predict the popularity of different online campaigns involving multiple types of actors. MASEP combines a self-exciting branching process with a periodical decay process to capture the dynamics and interdependent relationship between opinion leaders and ordinary users during an online campaign. A closed-form expression is derived for the temporal campaign popularity under the MASEP model. Based on this closed-form expression, we can efficiently perform regression against the empirical activity measurements of an online campaign during its early stage to estimate the parameters of the corresponding MASEP model. The final popularity of the campaign can then be predicted. To demonstrate the efficacy of the MASEP-based approach, we apply it to predict the popularity of three types of online campaigns from different large-scale real-world datasets, namely, the total number of posts in retweeting cascades, the overall count of individual hashtags in posting streams, and the final number of sponsors for crowd-funding campaigns. In particular, using the initial 30% of each campaign data trace for training, our approach can achieve absolute prediction error (APE) of 13.25%, 15.7%, and 36.9% respectively for datasets of 3 different types of campaigns. This corresponds to a 26.1% to 63.2% reduction in prediction error when comparing to state-of-the-art approaches including SEISMIC, SpikeM, and STRM.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1737–1742},
numpages = {6},
keywords = {multi-actor network, popularity prediction, temporal point process},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3701716.3717509,
author = {Aue, Tanja and Jatowt, Adam and F\"{a}rber, Michael},
title = {Predicting Company ESG Ratings from News Articles Using Multivariate Timeseries Analysis},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717509},
doi = {10.1145/3701716.3717509},
abstract = {In recent years, corporate environmental, social, and governance (ESG) engagement has received significant public attention. As mandatory ESG reporting is increasingly adopted and investors place greater emphasis on sustainability in their decisions, the demand for transparent and reliable ESG ratings is growing. However, existing automatic approaches to ESG rating prediction remain limited. Many rely on traditional machine learning methods like random forests or social network analysis, rather than leveraging incoming news article streams and large multivariate time series data, which, for the first time, enables capturing the dynamic relationships between topics, sentiments, and events. In this paper, we propose a novel approach to predicting ESG ratings from news articles by uniquely combining multivariate time series construction with advanced deep learning techniques. We create an extensive dataset of 3.7 million news articles spanning three years and covering 3,000 U.S. companies, providing a robust foundation for training and evaluating our approach. Our approach achieves high accuracy and outperforms existing approaches, underscoring its potential as a scalable, data-driven solution for ESG rating prediction.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1774–1780},
numpages = {7},
keywords = {esg ratings, financial applications, fintech, news articles},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696410.3714645,
author = {Gao, Weibo and Liu, Qi and Yue, Linan and Yao, Fangzhou and Huang, Zhenya and Zhang, Zheng and Lv, Rui},
title = {BoxCD: Leveraging Contrastive Probabilistic Box Embedding for Effective and Efficient Learner Modeling},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714645},
doi = {10.1145/3696410.3714645},
abstract = {In digital education, Cognitive Diagnosis (CD) is essential for modeling learners' cognitive states, such as problem-solving ability and knowledge proficiency, by analyzing their response data, like answer correctness. However, traditional CD methods struggle with effectiveness and efficiency. They fail to capture the diversity and uncertainty of learners' cognitive states. Additionally, response prediction can be time-consuming. To address these issues, we propose BoxCD, a contrastive probabilistic box embedding model for cognitive diagnosis. BoxCD utilizes high-dimensional axis-aligned hyper-rectangles (boxes) to represent learners and exercises, with the volume of intersecting boxes used to predict learners' responses. This approach effectively captures semantic diversity and uncertainty while enhancing diagnostic effectiveness. To stabilize box embeddings, we integrate contrastive learning objectives with response prediction goals, optimizing the distance between positive and negative samples of learner and exercise boxes to improve uniformity. Additionally, we develop a rank-based response prediction method that leverages the geometric properties of box embeddings to assess learners' response correctness efficiently. Comprehensive experiments on two real-world datasets demonstrate that BoxCD outperforms traditional CD models in effectiveness and efficiency. This showcases its potential to enhance personalized learning in digital education platforms.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3660–3671},
numpages = {12},
keywords = {box embedding, cognitive diagnosis, learner modeling},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/2740908.2742744,
author = {Bao, Peng and Shen, Hua-Wei and Jin, Xiaolong and Cheng, Xue-Qi},
title = {Modeling and Predicting Popularity Dynamics of Microblogs using Self-Excited Hawkes Processes},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2742744},
doi = {10.1145/2740908.2742744},
abstract = {The ability to model and predict the popularity dynamics of individual user generated items on online media has important implications in a wide range of areas. In this paper, we propose a probabilistic model using a Self-Excited Hawkes Process (SEHP) to characterize the process through which individual microblogs gain their popularity. This model explicitly captures the triggering effect of each forwarding, distinguishing itself from the reinforced Poisson process based model where all previous forwardings are simply aggregated as a single triggering effect. We validate the proposed model by applying it on Sina Weibo, the most popular microblogging network in China. Experimental results demonstrate that the SEHP model consistently outperforms the model based on reinforced Poisson process.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {9–10},
numpages = {2},
keywords = {popularity prediction, popularity dynamics, microblogs},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/3589334.3645331,
author = {Liu, Weiming and Chen, Chaochao and Liao, Xinting and Hu, Mengling and Su, Jiajie and Tan, Yanchao and Wang, Fan},
title = {User Distribution Mapping Modelling with Collaborative Filtering for Cross Domain Recommendation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645331},
doi = {10.1145/3589334.3645331},
abstract = {User cold-start recommendation aims to provide accurate items for the newly joint users and is a hot and challenging problem. Nowadays as people participant in different domains, how to recommend items in the new domain for users in an old domain has become more urgent. In this paper, we focus on the Dual Cold-Start Cross Domain Recommendation (Dual-CSCDR) problem. That is, providing the most relevant items for new users on the source and target domains. The prime task in Dual-CSCDR is to properly model user-item rating interactions and map user expressive embeddings across domains. However, previous approaches cannot solve Dual-CSCDR well, since they separate the collaborative filtering and distribution mapping process, leading to the error superimposition issue. Moreover, most of these methods fail to fully exploit the cross-domain relationship among large number of non-overlapped users, which strongly limits their performance. To fill this gap, we propose User Distribution Mapping model with Collaborative Filtering (UDMCF), a novel end-to-end cold-start cross-domain recommendation framework for the Dual-CSCDR problem. UDMCF includes two main modules, i.e., rating prediction module and distribution alignment module. The former module adopts one-hot ID vectors and multi-hot historical ratings for collaborative filtering via a contrastive loss. The latter module contains overlapped user embedding alignment and general user subgroup distribution alignment. Specifically, we innovatively propose unbalance distribution optimal transport with typical subgroup discovering algorithm to map the whole user distributions. Our empirical study on several datasets demonstrates that UDMCF significantly outperforms the state-of-the-art models under the Dual-CSCDR setting.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {334–343},
numpages = {10},
keywords = {cross domain recommendation, domain adaptation, optimal transport, recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/2872518.2889389,
author = {Gao, Jinhua and Shen, Huawei and Liu, Shenghua and Cheng, Xueqi},
title = {Modeling and Predicting Retweeting Dynamics via a Mixture Process},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2889389},
doi = {10.1145/2872518.2889389},
abstract = {Modeling and predicting retweeting dynamics in social media has important implications to an array of applications. Existing models either fail to model the triggering effect of retweeting dynamics, e.g., the model based on reinforced Poisson process, or are hard to be trained using only the retweeting dynamics of individual tweet, e.g., the model based on self-exciting Hawkes process. In this paper, motivated by the observation that each retweeting dynamics is generally dominated by a handful of key nodes that separately trigger a high number of retweets, we propose a mixture process to model and predict retweeting dynamics, with each subprocess capturing the retweeting dynamics initiated by a key node. Experiments demonstrate that the proposed model outperforms the state-of-the-art model.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {33–34},
numpages = {2},
keywords = {retweeting dynamics, popularity prediction, mixture process},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/2872518.2890096,
author = {Rizos, Georgios and Papadopoulos, Symeon and Kompatsiaris, Yiannis},
title = {Predicting News Popularity by Mining Online Discussions},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2890096},
doi = {10.1145/2872518.2890096},
abstract = {The paper presents a framework for the prediction of several news story popularity indicators, such as comment count, number of users, vote score and a measure of controversiality. The framework employs a feature engineering approach, focusing on features from two sources of social interactions inherent in online discussions: the comment tree and the user graph. We show that the proposed graph-based features capture the complexities of both these social interaction graphs and lead to improvements on the prediction of all popularity indicators in three online news post datasets and to significant improvement on the task of identifying controversial stories. Specifically, we noted a 5% relative improvement in mean square error for controversiality prediction on a news-focused Reddit dataset compared to a method employing only rudimentary comment tree features that were used by past studies.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {737–742},
numpages = {6},
keywords = {online discussion analysis, news popularity prediction},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3543507.3583247,
author = {Su, Jiajie and Chen, Chaochao and Liu, Weiming and Wu, Fei and Zheng, Xiaolin and Lyu, Haoming},
title = {Enhancing Hierarchy-Aware Graph Networks with Deep Dual Clustering for Session-based Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583247},
doi = {10.1145/3543507.3583247},
abstract = {Session-based Recommendation aims at predicting the next interacted item based on short anonymous behavior sessions. However, existing solutions neglect to model two inherent properties of sequential representing distributions, i.e., hierarchy structures resulted from item popularity and collaborations existing in both intra- and inter-session. Tackling with these two factors at the same time is challenging. On the one hand, traditional Euclidean space utilized in previous studies fails to capture hierarchy structures due to a restricted representation ability. On the other hand, the intuitive apply of hyperbolic geometry could extract hierarchical patterns but more emphasis on degree distribution weakens intra- and inter-session collaborations. To address the challenges, we propose a Hierarchy-Aware Dual Clustering Graph Network (HADCG) model for session-based recommendation. Towards the first challenge, we design the hierarchy-aware graph modeling module which converts sessions into hyperbolic session graphs, adopting hyperbolic geometry in propagation and attention mechanism so as to integrate chronological and hierarchical information. As for the second challenge, we introduce the deep dual clustering module which develops a two-level clustering strategy, i.e., information regularizer for intra-session clustering and contrastive learner for inter-session clustering, to enhance hyperbolic representation learning from collaborative perspectives and further promote recommendation performance. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed HADCG.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {165–176},
numpages = {12},
keywords = {Deep Dual Clustering, Graph Neural Network, Hyperbolic Learning, Session-based Recommendation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583280,
author = {Yao, Liuyi and Li, Yaliang and Ding, Bolin and Zhou, Jingren and Liu, Jinduo and Huai, Mengdi and Gao, Jing},
title = {Path-specific Causal Fair Prediction via Auxiliary Graph Structure Learning},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583280},
doi = {10.1145/3543507.3583280},
abstract = {With ubiquitous adoption of machine learning algorithms in web technologies, such as recommendation system and social network, algorithm fairness has become a trending topic, and it has a great impact on social welfare. Among different fairness definitions, path-specific causal fairness is a widely adopted one with great potentials, as it distinguishes the fair and unfair effects that the sensitive attributes exert on algorithm predictions. Existing methods based on path-specific causal fairness either require graph structure as the prior knowledge or have high complexity in the calculation of path-specific effect. To tackle these challenges, we propose a novel casual graph based fair prediction framework which integrates graph structure learning into fair prediction to ensure that unfair pathways are excluded in the causal graph. Furthermore, we generalize the proposed framework to the scenarios where sensitive attributes can be non-root nodes and affected by other variables, which is commonly observed in real-world applications, such as recommendation system, but hardly addressed by existing works. We provide theoretical analysis on the generalization bound for the proposed fair prediction method, and conduct a series of experiments on real-world datasets to demonstrate that the proposed framework can provide better prediction performance and algorithm fairness trade-off.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3680–3688},
numpages = {9},
keywords = {Causality, Fairness, Graph Structure Learning},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3696410.3714635,
author = {Li, Yichen and Shan, Yijing and Liu, Yi and Wang, Haozhao and Wang, Wei and Wang, Yi and Li, Ruixuan},
title = {Personalized Federated Recommendation for Cold-Start Users via Adaptive Knowledge Fusion},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714635},
doi = {10.1145/3696410.3714635},
abstract = {Federated Recommendation System (FRS) usually offers recommendation services for users while keeping their data locally to ensure privacy. Currently, most FRS literature assumes that fixed users participate in federated training with personal IoT devices (e.g., mobile phones and PC). However, users may join incrementally, and retraining the entire FRS for each new participating user is unfeasible due to the high training costs and the limited global knowledge contribution from a small number of new users. To guarantee the quality service for these new users, we take a dive into the federated recommendation for cold-start users, a novel scenario where the new participating users can directly obtain a promising recommendation without comprehensive training with all participating users by leveraging both transferred knowledge from the converged warm clients and the knowledge learned from the local data.Nevertheless, the efficient transfer of knowledge from warm clients remains controversial. On the one hand, cold clients may introduce new sparse items, resulting in a shift in the item embedding distribution compared to that converged on warm clients. On the other hand, cold-start users need to match similar user information from warm clients for a collaborative recommendation, but directly sharing user information is a violation of privacy and unacceptable. To tackle these challenges, we propose an efficient and privacy-enhanced federated recommendation for cold-start users (FR-CSU) that each client can adaptively transfer both user and item knowledge separately from warm clients and implement recommendations with local and transferred knowledge fusion. Specifically, each cold client will train a mapping function locally to transfer the aligned item embedding. Meanwhile, warm clients will maintain a user prototype network collaboratively that provides privacy-friendly yet effective user information for cold-start users. Then, a linear function system will integrate the transferred and local knowledge to improve recommendations. Extensive experiments show that FR-CSU achieves superior performance compared to state-of-the-art methods.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2700–2709},
numpages = {10},
keywords = {cold-start user, federated learning, knowledge fusion, recommendation system},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3589334.3645667,
author = {Zhang, An and Ma, Wenchang and Wei, Pengbo and Sheng, Leheng and Wang, Xiang},
title = {General Debiasing for Graph-based Collaborative Filtering via Adversarial Graph Dropout},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645667},
doi = {10.1145/3589334.3645667},
abstract = {Graph neural networks (GNNs) have shown impressive performance in recommender systems, particularly in collaborative filtering (CF). The key lies in aggregating neighborhood information on a user-item interaction graph to enhance user/item representations. However, we have discovered that this aggregation mechanism comes with a drawback - it amplifies biases present in the interaction graph. For instance, a user's interactions with items can be driven by both unbiased true interest and various biased factors like item popularity or exposure. However, the current aggregation approach combines all information, both biased and unbiased, leading to biased representation learning. Consequently, graph-based recommenders can learn distorted views of users/items, hindering the modeling of their true preferences and generalizations.To address this issue, we introduce a novel framework called Adversarial Graph Dropout (AdvDrop). It differentiates between unbiased and biased interactions, enabling unbiased representation learning. For each user/item, AdvDrop employs adversarial learning to split the neighborhood into two views: one with bias-mitigated interactions and the other with bias-aware interactions. After view-specific aggregation, AdvDrop ensures that the bias-mitigated and bias-aware representations remain invariant, shielding them from the influence of bias. We validate AdvDrop's effectiveness on five public datasets that cover both general and specific biases, demonstrating significant improvements. Furthermore, our method exhibits meaningful separation of subgraphs and achieves unbiased representations for graph-based CF models, as revealed by in-depth analysis. Our code is publicly available at https://github.com/Arthurma71/AdvDrop/tree/main.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3864–3875},
numpages = {12},
keywords = {collaborative filtering, debiasing, distribution shift},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3701716.3719232,
author = {Zhu, Shengmao and Xu, Bingbing and Yuan, Yige and Xie, Bin and Li, Yunfan and Shen, Huawei},
title = {Unveiling the Potential of LLMs in Simulated Society: A Knowledge-Driven LLM Agent Framework for User Modeling},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3719232},
doi = {10.1145/3701716.3719232},
abstract = {User modeling serves as the cornerstone of modern recommendation systems, focusing on the precise identification of user preferences and behavioral signatures to enable personalized service delivery. Existing recommendation methods face issues like sparse data and lack of transparency. The advent of large language models (LLMs) has brought new possibilities for inferring user preferences, which provides natural-language-based recommendation rationales and affective expressions. Motivated by AgentSociety Challenge @ WWW 2025 focused on simulating user-item interactions, we propose a knowledge-driven LLM agent framework for simulating user-item review interactions, which includes three modules: preference refinement, dual-signal injection, and category distinguisher. Specifically, preference refinement aims to model user and item profiles, enabling LLMs to perceive users and items comprehensively. Dual-signal Injection aims to incorporate external knowledge, such as collaborative filtering and distribution knowledge. Category distinguisher is designed to analyze the differences between true data and simulated data. Both online and offline experimental results demonstrate the effectiveness of this framework and prove the great potential of LLMs in user modeling.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2998–3002},
numpages = {5},
keywords = {knowledge-driven, llm agent, simulated society, user modeling},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3543507.3583260,
author = {Zhang, Jingsen and Chen, Xu and Tang, Jiakai and Shao, Weiqi and Dai, Quanyu and Dong, Zhenhua and Zhang, Rui},
title = {Recommendation with Causality enhanced Natural Language Explanations},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583260},
doi = {10.1145/3543507.3583260},
abstract = {Explainable recommendation has recently attracted increasing attention from both academic and industry communities. Among different explainable strategies, generating natural language explanations is an important method, which can deliver more informative, flexible and readable explanations to facilitate better user decisions. Despite the effectiveness, existing models are mostly optimized based on the observed datasets, which can be skewed due to the selection or exposure bias. To alleviate this problem, in this paper, we formulate the task of explainable recommendation with a causal graph, and design a causality enhanced framework to generate unbiased explanations. More specifically, we firstly define an ideal unbiased learning objective, and then derive a tractable loss for the observational data based on the inverse propensity score (IPS), where the key is a sample re-weighting strategy for equalizing the loss and ideal objective in expectation. Considering that the IPS estimated from the sparse and noisy recommendation datasets can be inaccurate, we introduce a fault tolerant mechanism by minimizing the maximum loss induced by the sample weights near the IPS. For more comprehensive modeling, we further analyze and infer the potential latent confounders induced by the complex and diverse user personalities. We conduct extensive experiments by comparing with the state-of-the-art methods based on three real-world datasets to demonstrate the effectiveness of our method.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {876–886},
numpages = {11},
keywords = {Explainable Recommendation, Natural Language Explanations},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583461,
author = {Zhang, An and Zheng, Jingnan and Wang, Xiang and Yuan, Yancheng and Chua, Tat-Seng},
title = {Invariant Collaborative Filtering to Popularity Distribution Shift},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583461},
doi = {10.1145/3543507.3583461},
abstract = {Collaborative Filtering (CF) models, despite their great success, suffer from severe performance drops due to popularity distribution shifts, where these changes are ubiquitous and inevitable in real-world scenarios. Unfortunately, most leading popularity debiasing strategies, rather than tackling the vulnerability of CF models to varying popularity distributions, require prior knowledge of the test distribution to identify the degree of bias and further learn the popularity-entangled representations to mitigate the bias. Consequently, these models result in significant performance benefits in the target test set, while dramatically deviating the recommendation from users’ true interests without knowing the popularity distribution in advance. In this work, we propose a novel learning framework, Invariant Collaborative Filtering (InvCF), to discover disentangled representations that faithfully reveal the latent preference and popularity semantics without making any assumption about the popularity distribution. At its core is the distillation of unbiased preference representations (i.e., user preference on item property), which are invariant to the change of popularity semantics, while filtering out the popularity feature that is unstable or outdated. Extensive experiments on five benchmark datasets and four evaluation settings (i.e., synthetic long-tail, unbiased, temporal split, and out-of-distribution evaluations) demonstrate that InvCF outperforms the state-of-the-art baselines in terms of popularity generalization ability on real recommendations. Visualization studies shed light on the advantages of InvCF for disentangled representation learning. Our codes are available at https://github.com/anzhang314/InvCF.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1240–1251},
numpages = {12},
keywords = {Collaborative Filtering, Debiasing, Popularity Distribution Shift},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3589334.3645492,
author = {Yin, Ming and Xu, Yichang and Fang, Minghong and Gong, Neil Zhenqiang},
title = {Poisoning Federated Recommender Systems with Fake Users},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645492},
doi = {10.1145/3589334.3645492},
abstract = {Federated recommendation is a prominent use case within federated learning, yet it remains susceptible to various attacks, from user to server-side vulnerabilities. Poisoning attacks are particularly notable among user-side attacks, as participants upload malicious model updates to deceive the global model, often intending to promote or demote specific targeted items. This study investigates strategies for executing promotion attacks in federated recommender systems.Current poisoning attacks on federated recommender systems often rely on additional information, such as the local training data of genuine users or item popularity. However, such information is challenging for the potential attacker to obtain. Thus, there is a need to develop an attack that requires no extra information apart from item embeddings obtained from the server. In this paper, we introduce a novel fake user based poisoning attack named PoisonFRS to promote the attacker-chosen targeted item in federated recommender systems without requiring knowledge about user-item rating data, user attributes, or the aggregation rule used by the server. Extensive experiments on multiple real-world datasets demonstrate that PoisonFRS can effectively promote the attacker-chosen targeted item to a large portion of genuine users and outperform current benchmarks that rely on additional information about the system. We further observe that the model updates from both genuine and fake users are indistinguishable within the latent space.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3555–3565},
numpages = {11},
keywords = {fake users, federated recommender systems, poisoning attacks},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3308558.3313463,
author = {Truong, Quoc-Tuan and Lauw, Hady},
title = {Multimodal Review Generation for Recommender Systems},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313463},
doi = {10.1145/3308558.3313463},
abstract = {Key to recommender systems is learning user preferences, which are expressed through various modalities. In online reviews, for instance, this manifests in numerical rating, textual content, as well as visual images. In this work, we hypothesize that modelling these modalities jointly would result in a more holistic representation of a review towards more accurate recommendations. Therefore, we propose Multimodal Review Generation (MRG), a neural approach that simultaneously models a rating prediction component and a review text generation component. We hypothesize that the shared user and item representations would augment the rating prediction with richer information from review text, while sensitizing the generated review text to sentiment features based on user and item of interest. Moreover, when review photos are available, visual features could inform the review text generation further. Comprehensive experiments on real-life datasets from several major US cities show that the proposed model outperforms comparable multimodal baselines, while an ablation analysis establishes the relative contributions of the respective components of the joint model.},
booktitle = {The World Wide Web Conference},
pages = {1864–1874},
numpages = {11},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3485447.3512166,
author = {Liu, Weiming and Zheng, Xiaolin and Hu, Mengling and Chen, Chaochao},
title = {Collaborative Filtering with Attribution Alignment for Review-based Non-overlapped Cross Domain Recommendation},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512166},
doi = {10.1145/3485447.3512166},
abstract = {Cross-Domain Recommendation (CDR) has been popularly studied to utilize different domain knowledge to solve the data sparsity and cold-start problem in recommender systems. In this paper, we focus on the Review-based Non-overlapped Recommendation (RNCDR) problem. The problem is commonly-existed and challenging due to two main aspects, i.e, there are only positive user-item ratings on the target domain and there is no overlapped user across different domains. Most previous CDR approaches cannot solve the RNCDR problem well, since (1) they cannot effectively combine review with other information (e.g., ID or ratings) to obtain expressive user or item embedding, (2) they cannot reduce the domain discrepancy on users and items. To fill this gap, we propose Collaborative Filtering with Attribution Alignment model (CFAA), a cross-domain recommendation framework for the RNCDR problem. CFAA&nbsp;includes two main modules, i.e., rating prediction module and embedding attribution alignment module. The former aims to jointly mine review, one-hot ID, and multi-hot historical ratings to generate expressive user and item embeddings. The later includes vertical attribution alignment and horizontal attribution alignment, tending to reduce the discrepancy based on multiple perspectives. Our empirical study on Douban and Amazon datasets demonstrates that CFAA&nbsp;significantly outperforms the state-of-the-art models under the RNCDR setting.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {1181–1190},
numpages = {10},
keywords = {Domain Adaptation, Recommendation, Transfer Learning},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3696410.3714583,
author = {Shimizu, Ryotaro and Wada, Takashi and Wang, Yu and Kruse, Johannes and O'Brien, Sean and HtaungKham, Sai and Song, Linxin and Yoshikawa, Yuya and Saito, Yuki and Tsung, Fugee and Goto, Masayuki and McAuley, Julian},
title = {Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714583},
doi = {10.1145/3696410.3714583},
abstract = {Recent research on explainable recommendation generally frames the task as a standard text generation problem, and evaluates models simply based on the textual similarity between the predicted and ground-truth explanations. However, this approach fails to consider one crucial aspect of the systems: whether their outputs accurately reflect the users' (post-purchase) sentiments, i.e., whether and why they would like and/or dislike the recommended items. To shed light on this issue, we introduce new datasets and evaluation methods that focus on the users' sentiments. Specifically, we construct the datasets by explicitly extracting users' positive and negative opinions from their post-purchase reviews using an LLM, and propose to evaluate systems based on whether the generated explanations 1) align well with the users' sentiments, and 2) accurately identify both positive and negative opinions of users on the target items. We benchmark several recent models on our datasets and demonstrate that achieving strong performance on existing metrics does not ensure that the generated explanations align well with the users' sentiments. Lastly, we find that existing models can provide more sentiment-aware explanations when the users' (predicted) ratings for the target items are directly fed into the models as input. The datasets and benchmark implementation are available at: https://github.com/jchanxtarov/sent_xrec.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4793–4809},
numpages = {17},
keywords = {explainable recommendation, large language model, personalization, recommender systems, sentiment analysis, transformer},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3543873.3584637,
author = {Zhao, Weiqi and Tang, Dian and Chen, Xin and Lv, Dawei and Ou, Daoli and Li, Biao and Jiang, Peng and Gai, Kun},
title = {Disentangled Causal Embedding With Contrastive Learning For Recommender System},
year = {2023},
isbn = {9781450394192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543873.3584637},
doi = {10.1145/3543873.3584637},
abstract = {Recommender systems usually rely on observed user interaction data to build personalized recommendation models, assuming that the observed data reflect user interest. However, user interacting with an item may also due to conformity, the need to follow popular items. Most previous studies neglect user’s conformity and entangle interest with it, which may cause the recommender systems fail to provide satisfying results. Therefore, from the cause-effect view, disentangling these interaction causes is a crucial issue. It also contributes to OOD problems, where training and test data are out-of-distribution. Nevertheless, it is quite challenging as we lack the signal to differentiate interest and conformity. The data sparsity of pure cause and the items’ long-tail problem hinder disentangled causal embedding. In this paper, we propose DCCL, a framework that adopts contrastive learning to disentangle these two causes by sample augmentation for interest and conformity respectively. Futhermore, DCCL is model-agnostic, which can be easily deployed in any industrial online system. Extensive experiments are conducted over two real-world datasets and DCCL outperforms state-of-the-art baselines on top of various backbone models in various OOD environments. We also demonstrate the performance improvements by online A/B testing on Kuaishou, a billion-user scale short-video recommender system.},
booktitle = {Companion Proceedings of the ACM Web Conference 2023},
pages = {406–410},
numpages = {5},
keywords = {causal embedding, contrastive learning, recommender systems},
location = {Austin, TX, USA},
series = {WWW '23 Companion}
}

@inproceedings{10.1145/1526709.1526728,
author = {Lu, Yue and Zhai, ChengXiang and Sundaresan, Neel},
title = {Rated aspect summarization of short comments},
year = {2009},
isbn = {9781605584874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1526709.1526728},
doi = {10.1145/1526709.1526728},
abstract = {Web 2.0 technologies have enabled more and more people to freely comment on different kinds of entities (e.g. sellers, products, services). The large scale of information poses the need and challenge of automatic summarization. In many cases, each of the user-generated short comments comes with an overall rating. In this paper, we study the problem of generating a ``rated aspect summary'' of short comments, which is a decomposed view of the overall ratings for the major aspects so that a user could gain different perspectives towards the target entity. We formally define the problem and decompose the solution into three steps. We demonstrate the effectiveness of our methods by using eBay sellers' feedback comments. We also quantitatively evaluate each step of our methods and study how well human agree on such a summarization task. The proposed methods are quite general and can be used to generate rated aspect summary automatically given any collection of short comments each associated with an overall rating.},
booktitle = {Proceedings of the 18th International Conference on World Wide Web},
pages = {131–140},
numpages = {10},
keywords = {short comments, rating prediction, rated aspect summarization},
location = {Madrid, Spain},
series = {WWW '09}
}

@inproceedings{10.1145/2187980.2188259,
author = {Kaytoue, Mehdi and Silva, Arlei and Cerf, Lo\"{\i}c and Meira, Wagner and Ra\"{\i}ssi, Chedy},
title = {Watch me playing, i am a professional: a first study on video game live streaming},
year = {2012},
isbn = {9781450312301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187980.2188259},
doi = {10.1145/2187980.2188259},
abstract = {"Electronic-sport" (E-Sport) is now established as a new entertainment genre. More and more players enjoy streaming their games, which attract even more viewers. In fact, in a recent social study, casual players were found to prefer watching professional gamers rather than playing the game themselves. Within this context, advertising provides a significant source of revenue to the professional players, the casters (displaying other people's games) and the game streaming platforms. For this paper, we crawled, during more than 100 days, the most popular among such specialized platforms: Twitch.tv. Thanks to these gigabytes of data, we propose a first characterization of a new Web community, and we show, among other results, that the number of viewers of a streaming session evolves in a predictable way, that audience peaks of a game are explainable and that a Condorcet method can be used to sensibly rank the streamers by popularity. Last but not least, we hope that this paper will bring to light the study of E-Sport and its growing community. They indeed deserve the attention of industrial partners (for the large amount of money involved) and researchers (for interesting problems in social network dynamics, personalized recommendation, sentiment analysis, etc.).},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {1181–1188},
numpages = {8},
keywords = {video game, twitch.tv, starcraft ii, social community, ranking, popularity prediction, e-sport},
location = {Lyon, France},
series = {WWW '12 Companion}
}

@inproceedings{10.1145/3308558.3313404,
author = {Pei, Changhua and Yang, Xinru and Cui, Qing and Lin, Xiao and Sun, Fei and Jiang, Peng and Ou, Wenwu and Zhang, Yongfeng},
title = {Value-aware Recommendation based on Reinforcement Profit Maximization},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313404},
doi = {10.1145/3308558.3313404},
abstract = {Existing recommendation algorithms mostly focus on optimizing traditional recommendation measures, such as the accuracy of rating prediction in terms of RMSE or the quality of top-k recommendation lists in terms of precision, recall, MAP, etc. However, an important expectation for commercial recommendation systems is to improve the final revenue/profit of the system. Traditional recommendation targets such as rating prediction and top-k recommendation are not directly related to this goal. In this work, we blend the fundamental concepts in online advertising and micro-economics into personalized recommendation for profit maximization. Specifically, we propose value-aware recommendation based on reinforcement learning, which directly optimizes the economic value of candidate items to generate the recommendation list. In particular, we generalize the basic concept of click conversion rate (CVR) in computational advertising into the conversation rate of an arbitrary user action (XVR) in E-commerce, where the user actions can be clicking, adding to cart, adding to wishlist, etc. In this way, each type of user action is mapped to its monetized economic value. Economic values of different user actions are further integrated as the reward of a ranking list, and reinforcement learning is used to optimize the recommendation list for the maximum total value. Experimental results in both offline benchmarks and online commercial systems verified the improved performance of our framework, in terms of both traditional top-k ranking tasks and the economic profits of the system.},
booktitle = {The World Wide Web Conference},
pages = {3123–3129},
numpages = {7},
keywords = {Reinforcement Learning, Recommender Systems, Economics of Data Science},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2488388.2488467,
author = {Moghaddam, Samaneh and Ester, Martin},
title = {The FLDA model for aspect-based opinion mining: addressing the cold start problem},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488467},
doi = {10.1145/2488388.2488467},
abstract = {Aspect-based opinion mining from online reviews has attracted a lot of attention recently. The main goal of all of the proposed methods is extracting aspects and/or estimating aspect ratings. Recent works, which are often based on Latent Dirichlet Allocation (LDA), consider both tasks simultaneously. These models are normally trained at the item level, i.e., a model is learned for each item separately. Learning a model per item is fine when the item has been reviewed extensively and has enough training data. However, in real-life data sets such as those from Epinions.com and Amazon.com more than 90% of items have less than 10 reviews, so-called cold start items. State-of-the-art LDA models for aspect-based opinion mining are trained at the item level and therefore perform poorly for cold start items due to the lack of sufficient training data. In this paper, we propose a probabilistic graphical model based on LDA, called Factorized LDA (FLDA), to address the cold start problem. The underlying assumption of FLDA is that aspects and ratings of a review are influenced not only by the item but also by the reviewer. It further assumes that both items and reviewers can be modeled by a set of latent factors which represent their aspect and rating distributions. Different from state-of-the-art LDA models, FLDA is trained at the category level and learns the latent factors using the reviews of all the items of a category, in particular the non cold start items, and uses them as prior for cold start items. Our experiments on three real-life data sets demonstrate the improved effectiveness of the FLDA model in terms of likelihood of the held-out test set. We also evaluate the accuracy of FLDA based on two application-oriented measures.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {909–918},
numpages = {10},
keywords = {user modeling, rating prediction, latent dirichlet allocation, cold start item, aspect-based opinion mining, aspect identification},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/3701716.3719226,
author = {Luo, Junhui and Song, Li and Sun, Ranrun},
title = {EvolutionAgent: A Large Model-Based Framework for User Behavior Modeling and Self-Evolving Intelligent Agents},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3719226},
doi = {10.1145/3701716.3719226},
abstract = {Large Language Models (LLMs) have demonstrated remarkable capabilities in simulating user behavior, offering significant potential for user modeling, behavior analysis, interest matching, and the extraction of unstructured features. However, the process of user simulation necessitates the identification of both unstructured and structured features, as well as the formulation of multi-stages workflow, which remains a challenging and labor-intensive task. To address this, we propose EvolutionAgent , a novel framework grounded in a discretized material repository, which employs self-reflective and evolutionary mechanisms to automate the search for unstructured features and the generation of simulation workflow. This framework establishes an efficient and robust simulation mechanism, achieving state-of-the-art performance across three distinct datasets. Notably, EvolutionAgent exhibits exceptional robustness, even in scenarios with limited historical data for users and products, underscoring its adaptability and reliability.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2973–2977},
numpages = {5},
keywords = {closed-loop adaptation, llm agent, llm-based simulation, self-evolving framework},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3589335.3651896,
author = {Chen, Xingming and Li, Qing},
title = {Causality-driven User Modeling for Sequential Recommendations over Time},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651896},
doi = {10.1145/3589335.3651896},
abstract = {Contemporary sequential recommendation systems predominantly leverage statistical correlations derived from user interaction histories to predict future preferences. However, these correlations often mask implicit challenges. On the one hand, user data is frequently plagued by implicit, noisy feedback, misdirecting users towards items that fail to align with their actual interests, which is magnified in sequential recommendation contexts. On the other hand, prevalent methods tend to over-rely on similarity-based attention mechanisms across item pairs, which are prone to utilizing heuristic shortcuts, thereby leading to suboptimal recommendation.To tackle these issues, we put forward a causality-driven user modeling approach for sequential recommendation, which pivots towards a causal perspective. Specifically, we involves the application of a causal graph to identify confounding factors that give rise to spurious correlations and to isolate conceptual variables that causally encapsulate user preferences. By learning the representation of these disentangled causal variables at the conceptual level, we can distinguish between causal and non-causal associations while preserving the inherent sequential nature of user behaviors. This enables us to ascertain which elements are critical and which may induce unintended biases. The framework of our method can be compatible with various mainstream sequential models, which offers a robust foundation for reconstructing more accurate and meaningful user and item representations driven by causality.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1400–1406},
numpages = {7},
keywords = {bias alleviation, causality learning, sequential recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645661,
author = {Zhou, Peilin and Huang, You-Liang and Xie, Yueqi and Gao, Jingqi and Wang, Shoujin and Kim, Jae Boum and Kim, Sunghun},
title = {Is Contrastive Learning Necessary? A Study of Data Augmentation vs Contrastive Learning in Sequential Recommendation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645661},
doi = {10.1145/3589334.3645661},
abstract = {Sequential recommender systems (SRS) are designed to predict users' future behaviors based on their historical interaction data. Recent research has increasingly utilized contrastive learning (CL) to leverage unsupervised signals to alleviate the data sparsity issue in SRS. In general, CL-based SRS first augments the raw sequential interaction data by using data augmentation strategies and employs a contrastive training scheme to enforce the representations of those sequences from the same raw interaction data to be similar. Despite the growing popularity of CL, data augmentation, as a basic component of CL, has not received sufficient attention. This raises the question: Is it possible to achieve superior recommendation results solely through data augmentation? To answer this question, we benchmark eight widely used data augmentation strategies, as well as state-of-the-art CL-based SRS methods, on four real-world datasets under both warm- and cold-start settings. Intriguingly, the conclusion drawn from our study is that, certain data augmentation strategies can achieve similar or even superior performance compared with some CL-based methods, demonstrating the potential to significantly alleviate the data sparsity issue with fewer computational overhead. We hope that our study can further inspire more fundamental studies on the key functional components of complex CL techniques. Our processed datasets and codes are available at https://github.com/AIM-SE/DA4Rec.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3854–3863},
numpages = {10},
keywords = {contrastive learning, data augmentation, sequential recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3543507.3583481,
author = {Kong, Quyu and Calderon, Pio and Ram, Rohit and Boichak, Olga and Rizoiu, Marian-Andrei},
title = {Interval-censored Transformer Hawkes: Detecting Information Operations using the Reaction of Social Systems},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583481},
doi = {10.1145/3543507.3583481},
abstract = {Social media is being increasingly weaponized by state-backed actors to elicit reactions, push narratives and sway public opinion. These are known as Information Operations (IO). The covert nature of IO makes their detection difficult. This is further amplified by missing data due to the user and content removal and privacy requirements. This work advances the hypothesis that the very reactions that Information Operations seek to elicit within the target social systems can be used to detect them. We propose an Interval-censored Transformer Hawkes (IC-TH) architecture and a novel data encoding scheme to account for both observed and missing data. We derive a novel log-likelihood function that we deploy together with a contrastive learning procedure. We showcase the performance of IC-TH on three real-world Twitter datasets and two learning tasks: future popularity prediction and item category prediction. The latter is particularly significant. Using the retweeting timing and patterns solely, we can predict the category of YouTube videos, guess whether news publishers are reputable or controversial and, most importantly, identify state-backed IO agent accounts. Additional qualitative investigations uncover that the automatically discovered clusters of Russian-backed agents appear to coordinate their behavior, activating simultaneously to push specific narratives.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1813–1821},
numpages = {9},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3308558.3313736,
author = {Sharma, Mohit and Karypis, George},
title = {Adaptive matrix completion for the users and the items in tail},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313736},
doi = {10.1145/3308558.3313736},
abstract = {Recommender systems are widely used to recommend the most appealing items to users. These recommendations can be generated by applying collaborative filtering methods. The low-rank matrix completion method is the state-of-the-art collaborative filtering method. In this work, we show that the skewed distribution of ratings in the user-item rating matrix of real-world datasets affects the accuracy of matrix-completion-based approaches. Also, we show that the number of ratings that an item or a user has positively correlates with the ability of low-rank matrix-completion-based approaches to predict the ratings for the item or the user accurately. Furthermore, we use these insights to develop four matrix completion-based approaches, i.e., Frequency Adaptive Rating Prediction (FARP), Truncated Matrix Factorization (TMF), Truncated Matrix Factorization with Dropout (TMF + Dropout) and Inverse Frequency Weighted Matrix Factorization (IFWMF), that outperforms traditional matrix-completion-based approaches for the users and the items with few ratings in the user-item rating matrix.},
booktitle = {The World Wide Web Conference},
pages = {3223–3229},
numpages = {7},
keywords = {Recommender systems, Matrix factorization, Matrix completion, Collaborative filtering},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3589334.3645473,
author = {Alves, Rodrigo and Ledent, Antoine and Assun\c{c}\~{a}o, Renato and Vaz-De-Melo, Pedro and Kloft, Marius},
title = {Unraveling the Dynamics of Stable and Curious Audiences in Web Systems},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645473},
doi = {10.1145/3589334.3645473},
abstract = {We propose the Burst-Induced Poisson Process (BPoP), a model designed to analyze time series data such as feeds or search queries. BPoP can distinguish between the slowly-varying regular activity of a stable audience and the bursty activity of a curious audience, often seen in viral threads. Our model consists of two hidden, interacting processes: a self-feeding process (SFP) that generates bursty behavior related to viral threads, and a non-homogeneous Poisson process (NHPP) with step function intensity that is influenced by the bursts from the SFP. The NHPP models the normal background behavior, driven solely by the overall popularity of the topic among the stable audience. Through extensive empirical work, we have demonstrated that our model fits and characterizes a large number of real datasets more effectively than state-of-the-art models. Most importantly, BPoP can quantify the stable audience of media channels over time, serving as a valuable indicator of their popularity.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2464–2475},
numpages = {12},
keywords = {EM-algorithm, temporal dynamics of web systems, time-series},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3366424.3383543,
author = {Wang, Xueting and Zhang, Yiwei and Yamasaki, Toshihiko},
title = {Earn More Social Attention: User Popularity Based Tag Recommendation System},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3383543},
doi = {10.1145/3366424.3383543},
abstract = {Enhancing social popularity of a post (i.e., the number of views or likes) on social network services is important for both ordinary users and companies who want to promote themselves. In this paper, we have implemented an online tagging support system to achieve this using an algorithm that recommends appropriate hashtags considering not only content popularity but also user popularity. The effectiveness of this technology has been verified by actually uploading photos with recommended hashtags on a real social network service.},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {212–216},
numpages = {5},
keywords = {user-aware, tagging system, tag recommendation, tag ranking, social popularity, social media},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3696410.3714524,
author = {Gao, Chongming and Chen, Ruijun and Yuan, Shuai and Huang, Kexin and Yu, Yuanqing and He, Xiangnan},
title = {SPRec: Self-Play to Debias LLM-based Recommendation},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714524},
doi = {10.1145/3696410.3714524},
abstract = {Large language models (LLMs) have attracted significant attention in recommendation systems. Current work primarily applies supervised fine-tuning (SFT) to adapt the model for recommendation tasks. However, SFT on positive examples only limits the model's ability to align with user preference. To address this, researchers recently introduced Direct Preference Optimization (DPO), which explicitly aligns LLMs with user preferences using offline preference ranking data. However, we found that DPO inherently biases the model towards a few items, exacerbating the filter bubble issue and ultimately degrading user experience.In this paper, we propose SPRec, a novel self-play framework designed to mitigate over-recommendation and improve fairness without requiring additional data or manual intervention. In each self-play iteration, the model undergoes an SFT step followed by a DPO step, treating offline interaction data as positive samples and the predicted outputs from the previous iteration as negative samples. This effectively re-weights the DPO loss function using the model's logits, adaptively suppressing biased items. Extensive experiments on multiple real-world datasets demonstrate SPRec's effectiveness in enhancing recommendation accuracy and fairness.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {5075–5084},
numpages = {10},
keywords = {direct preference optimization, fairness, homogeneity issue, large language model-based recommendation, self-play},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3487553.3524646,
author = {Rimjhim and Dandapat, Sourav},
title = {Predicting Spatial Spread on Social Media},
year = {2022},
isbn = {9781450391306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487553.3524646},
doi = {10.1145/3487553.3524646},
abstract = {Understanding and prediction of spreading phenomena are vital for numerous applications. The massive availability of social network data provides a platform for studying spreading phenomena. Past works studying and predicting spreading phenomena have explored the spread in dimensions of time and volume, such as predicting total infected users, predicting popularity, predicting the time when content receives a threshold number of infected users. However, as the information spreads from user to user, it also spreads from location to location. In this paper, we attempt to predict the spread in the dimension of geographic space. In accordance with the past spreading prediction problems, we design our problem to predict the spatial spread at an early stage. For this, we utilized spatial features, social features, and emotion features. We feed these features into existing classification algorithms and evaluate on three datasets from Twitter.},
booktitle = {Companion Proceedings of the Web Conference 2022},
pages = {656–659},
numpages = {4},
keywords = {Spreading Phenomena, Social Networks, Location, Geographic Information Retrieval},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3366423.3380303,
author = {Chen, Chong and Zhang, Min and Ma, Weizhi and Liu, Yiqun and Ma, Shaoping},
title = {Efficient Non-Sampling Factorization Machines for Optimal Context-Aware Recommendation},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380303},
doi = {10.1145/3366423.3380303},
abstract = {To provide more accurate recommendation, it is a trending topic to go beyond modeling user-item interactions and take context features into account. Factorization Machines (FM) with negative sampling is a popular solution for context-aware recommendation. However, it is not robust as sampling may lost important information and usually leads to non-optimal performances in practical. Several recent efforts have enhanced FM with deep learning architectures for modelling high-order feature interactions. While they either focus on rating prediction task only, or typically adopt the negative sampling strategy for optimizing the ranking performance. Due to the dramatic fluctuation of sampling, it is reasonable to argue that these sampling-based FM methods are still suboptimal for context-aware recommendation. In this paper, we propose to learn FM without sampling for ranking tasks that helps context-aware recommendation particularly. Despite effectiveness, such a non-sampling strategy presents strong challenge in learning efficiency of the model. Accordingly, we further design a new ideal framework named Efficient Non-Sampling Factorization Machines (ENSFM). ENSFM not only seamlessly connects the relationship between FM and Matrix Factorization (MF), but also resolves the challenging efficiency issue via novel memorization strategies. Through extensive experiments on three real-world public datasets, we show that 1) the proposed ENSFM consistently and significantly outperforms the state-of-the-art methods on context-aware Top-K recommendation, and 2) ENSFM achieves significant advantages in training efficiency, which makes it more applicable to real-world large-scale systems. Moreover, the empirical results indicate that a proper learning method is even more important than advanced neural network structures for Top-K recommendation task. Our implementation has been released 1 to facilitate further developments on efficient non-sampling methods.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2400–2410},
numpages = {11},
keywords = {Top-K Recommendation, Implicit Feedback, Factorization Machines, Efficient Learning, Context-aware},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3178876.3186155,
author = {Li, Dongsheng and Chen, Chao and Lv, Qin and Gu, Hansu and Lu, Tun and Shang, Li and Gu, Ning and Chu, Stephen M.},
title = {AdaError: An Adaptive Learning Rate Method for Matrix Approximation-based Collaborative Filtering},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186155},
doi = {10.1145/3178876.3186155},
abstract = {Gradient-based learning methods such as stochastic gradient descent are widely used in matrix approximation-based collaborative filtering algorithms to train recommendation models based on observed user-item ratings. One major difficulty in existing gradient-based learning methods is determining proper learning rates, since model convergence would be inaccurate or very slow if the learning rate is too large or too small, respectively. This paper proposes AdaError, an adaptive learning rate method for matrix approximation-based collaborative filtering. AdaError eliminates the need of manually tuning the learning rates by adaptively adjusting the learning rates based on the noisiness level of user-item ratings, using smaller learning rates for noisy ratings so as to reduce their impact on the learned models. Our theoretical and empirical analysis shows that AdaError can improve the generalization performance of the learned models. Experimental studies on the MovieLens and Netflix datasets also demonstrate that AdaError outperforms state-of-the-art adaptive learning rate methods in matrix approximation-based collaborative filtering. Furthermore, by applying AdaError to the standard matrix approximation method, we can achieve statistically significant improvements over state-of-the-art collaborative filtering methods in both rating prediction accuracy and top-N recommendation accuracy.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {741–751},
numpages = {11},
keywords = {matrix approximation, collaborative filtering},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3041021.3054255,
author = {Gilani, Zafar and Farahbakhsh, Reza and Crowcroft, Jon},
title = {Do Bots impact Twitter activity?},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054255},
doi = {10.1145/3041021.3054255},
abstract = {The WWW has seen massive growth in population of automated programs (bots) for a variety of exploits on online social networks (OSNs). In this paper we extend on our previous work to study the affects of bots on Twitter. By setting up a bot account on Twitter and conducting analysis on a click logs dataset from our web server, we show that despite bots being in smaller numbers, they exercise a profound impact on content popularity and activity on Twitter.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {781–782},
numpages = {2},
keywords = {information propagation, bot characterisation, bot activity analysis},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3543507.3583366,
author = {Liu, Weiming and Zheng, Xiaolin and Chen, Chaochao and Su, Jiajie and Liao, Xinting and Hu, Mengling and Tan, Yanchao},
title = {Joint Internal Multi-Interest Exploration and External Domain Alignment for Cross Domain Sequential Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583366},
doi = {10.1145/3543507.3583366},
abstract = {Sequential Cross-Domain Recommendation (CDR) has been popularly studied to utilize different domain knowledge and users’ historical behaviors for the next-item prediction. In this paper, we focus on the cross-domain sequential recommendation problem. This commonly exist problem is rather challenging from two perspectives, i.e., the implicit user historical rating sequences are difficult in modeling and the users/items on different domains are mostly non-overlapped. Most previous sequential CDR approaches cannot solve the cross-domain sequential recommendation problem well, since (1) they cannot sufficiently depict the users’ actual preferences, (2) they cannot leverage and transfer useful knowledge across domains. To tackle the above issues, we propose joint Internal multi-interest exploration and External domain alignment for cross domain Sequential Recommendation model (IESRec). IESRec&nbsp;includes two main modules, i.e., internal multi-interest exploration module and external domain alignment module. To reflect the users’ diverse characteristics with multi-interests evolution, we first propose internal temporal optimal transport method in the internal multi-interest exploration module. We further propose external alignment optimal transport method in the external domain alignment module to reduce domain discrepancy for the item embeddings. Our empirical studies on Amazon datasets demonstrate that IESRec&nbsp;significantly outperforms the state-of-the-art models.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {383–394},
numpages = {12},
keywords = {Domain Adaptation, Recommendation, Sequential Modelling},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3178876.3186070,
author = {Chen, Chong and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
title = {Neural Attentional Rating Regression with Review-level Explanations},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186070},
doi = {10.1145/3178876.3186070},
abstract = {Reviews information is dominant for users to make online purchasing decisions in e-commerces. However, the usefulness of reviews is varied. We argue that less-useful reviews hurt model's performance, and are also less meaningful for user's reference. While some existing models utilize reviews for improving the performance of recommender systems, few of them consider the usefulness of reviews for recommendation quality. In this paper, we introduce a novel attention mechanism to explore the usefulness of reviews, and propose a Neural Attentional Regression model with Review-level Explanations (NARRE) for recommendation. Specifically, NARRE can not only predict precise ratings, but also learn the usefulness of each review simultaneously. Therefore, the highly-useful reviews are obtained which provide review-level explanations to help users make better and faster decisions. Extensive experiments on benchmark datasets of Amazon and Yelp on different domains show that the proposed NARRE model consistently outperforms the state-of-the-art recommendation approaches, including PMF, NMF, SVD++, HFT, and DeepCoNN in terms of rating prediction, by the proposed attention model that takes review usefulness into consideration. Furthermore, the selected reviews are shown to be effective when taking existing review-usefulness ratings in the system as ground truth. Besides, crowd-sourcing based evaluations reveal that in most cases, NARRE achieves equal or even better performances than system's usefulness rating method in selecting reviews. And it is flexible to offer great help on the dominant cases in real e-commerce scenarios when the ratings on review-usefulness are not available in the system.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {1583–1592},
numpages = {10},
keywords = {review usefulness, recommender systems, neural attention network, explainable recommendation},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/2872427.2883087,
author = {KC, Santosh and Mukherjee, Arjun},
title = {On the Temporal Dynamics of Opinion Spamming: Case Studies on Yelp},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2883087},
doi = {10.1145/2872427.2883087},
abstract = {Recently, the problem of opinion spam has been widespread and has attracted a lot of research attention. While the problem has been approached on a variety of dimensions, the temporal dynamics in which opinion spamming operates is unclear. Are there specific spamming policies that spammers employ? What kind of changes happen with respect to the dynamics to the truthful ratings on entities. How do buffered spamming operate for entities that need spamming to retain threshold popularity and reduced spamming for entities making better success? We analyze these questions in the light of time-series analysis on Yelp. Our analyses discover various temporal patterns and their relationships with the rate at which fake reviews are posted. Building on our analyses, we employ vector autoregression to predict the rate of deception across different spamming policies. Next, we explore the effect of filtered reviews on (long-term and imminent) future rating and popularity prediction of entities. Our results discover novel temporal dynamics of spamming which are intuitive, arguable and also render confidence on Yelp's filtering. Lastly, we leverage our discovered temporal patterns in deception detection. Experimental results on large-scale reviews show the effectiveness of our approach that significantly improves the existing approaches.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {369–379},
numpages = {11},
keywords = {opinion spam, spam detection, time series},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1145/2872518.2889362,
author = {Park, Chanyoung and Kim, Donghyun and Oh, Jinoh and Yu, Hwanjo},
title = {TRecSo: Enhancing Top-k Recommendation With Social Information},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2889362},
doi = {10.1145/2872518.2889362},
abstract = {Due to the data sparsity problem, social network information is often additionally used to improve the performance of recommender system. While most existing works exploit social information to reduce the rating prediction error, e.g., RMSE, a few had aimed to improve the top-k ranking prediction accuracy. This paper proposes a novel top-k oriented recommendation method, TRecSo, which incorporates social information into recommendation by modeling two different roles of users as trusters and trustees while considering the structural information of the network. Empirical studies on real-world datasets demonstrate that TRecSo leads to remarkable improvement compared to previous methods in top-k recommendation.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {89–90},
numpages = {2},
keywords = {social network, recommender system, learning-to-rank},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3308560.3316702,
author = {Lu Jia, Adele and Shen, Xiaoxue and Shen, Siqi and Fu, Yongquan and Peng, Liwen},
title = {User Donations in a User Generated Video System},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3316702},
doi = {10.1145/3308560.3316702},
abstract = {User generated video systems like YouTube and Twitch.tv have been a major internet phenomenon. They have attracted a vast user base with their many and varied contents provided by their users, and a series of social features tailored for online viewing. In hoping for building a more lively community and encouraging the content creators to share more, recently many such systems have introduced crowdsourcing mechanisms wherein creators get tangible rewards through user donations. User donation is a very special form of user relationships. It influences user engagement in the community, and has a great impact on the success of these systems. However, user donations and donation relationships remain trade secrets for most enterprises and to date are still unexplored. It is not clear at what scale are the donations or how users donate in these systems. In this work, we attempt to fill this gap. We obtain and provide a publicly available dataset on user donations in BiliBili, a popular user generated video system in China with 76.4 million average monthly active users. Based on detailed information on over 5 million videos, over 700 thousand content creators, and over 1.5 million user donations, we quantitatively reveal the characteristics of user donations, we examine their correlations with the upload behavior and content popularity of the creators, and we adopt machine-learned classifiers to accurately predict the creators who will receive donations and who will donate in the future.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {1055–1062},
numpages = {8},
keywords = {user generated video systems, User donation, User Generated Content (UGC)},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3543507.3583362,
author = {Chen, Yizhou and Huzhang, Guangda and Zeng, Anxiang and Yu, Qingtao and Sun, Hui and Li, Heng-Yi and Li, Jingyi and Ni, Yabo and Yu, Han and Zhou, Zhiming},
title = {Clustered Embedding Learning for Recommender Systems},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583362},
doi = {10.1145/3543507.3583362},
abstract = {In recent years, recommender systems have advanced rapidly, where embedding learning for users and items plays a critical role. A standard method learns a unique embedding vector for each user and item. However, such a method has two important limitations in real-world applications: 1) it is hard to learn embeddings that generalize well for users and items with rare interactions; and 2) it may incur unbearably high memory costs when the number of users and items scales up. Existing approaches either can only address one of the limitations or have flawed overall performances. In this paper, we propose Clustered Embedding Learning (CEL) as an integrated solution to these two problems. CEL is a plug-and-play embedding learning framework that can be combined with any differentiable feature interaction model. It is capable of achieving improved performance, especially for cold users and items, with reduced memory cost. CEL enables automatic and dynamic clustering of users and items in a top-down fashion, where clustered entities jointly learn a shared embedding. The accelerated version of CEL has an optimal time complexity, which supports efficient online updates. Theoretically, we prove the identifiability and the existence of a unique optimal number of clusters for CEL in the context of nonnegative matrix factorization. Empirically, we validate the effectiveness of CEL on three public datasets and one business dataset, showing its consistently superior performance against current state-of-the-art methods. In particular, when incorporating CEL into the business model, it brings an improvement of in AUC, which translates into a significant revenue gain; meanwhile, the size of the embedding table gets 2650 times smaller.1},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1074–1084},
numpages = {11},
keywords = {Embedding learning, clustering, large-scale application, recommender system, sparse data},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3184558.3191588,
author = {Karypis, George},
title = {Recent Advances in Recommender Systems: Sets, Local Models, Coverage, and Errors},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3191588},
doi = {10.1145/3184558.3191588},
abstract = {Recommender systems are designed to identify the items that a user will like or find useful based on the user's prior preferences and activities. These systems have become ubiquitous and are an essential tool for information filtering and (e-)commerce. Over the years, collaborative filtering, which derive these recommendations by leveraging past activities of groups of users, has emerged as the most prominent approach for solving this problem. This talk will present some of our recent work towards improving the performance of collaborative filtering-based recommender systems and understanding some of their fundamental limitations and characteristics. It will start by analyzing how the ratings that users provide to a set of items relate to their ratings of the set's individual items and, using these insights, will present rating prediction approaches that utilize distant supervision. It will then discuss extensions to approaches based on sparse linear and latent factor models that postulate that users' preferences are a combination of global and local preferences, which are shown to lead to better user modeling and as such improved prediction performance. Finally, the talk will conclude by discussing what can be accurately predicted by latent factor approaches and by analyzing the estimation error of sparse linear and latent factor models and how its characteristics impacts the performance of top N recommendation algorithms.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1369},
numpages = {1},
keywords = {recommender systems, slim, svd},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/2872518.2890092,
author = {Menczer, Filippo},
title = {The Spread of Misinformation in Social Media},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2890092},
doi = {10.1145/2872518.2890092},
abstract = {As social media become major channels for the diffusion of news and information, they are also increasingly attractive and targeted for abuse and manipulation. This talk overviews ongoing network analytics, data mining, and modeling efforts to understand the spread of misinformation online and offline. I present machine learning methods to detect astroturf and social bots, and outline initial steps toward computational fact checking, as well as theoretical models to study how truthful and truthy facts compete for our collective attention. These efforts will be framed by a case study in which, ironically, our own research became the target of a coordinated disinformation campaign.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {717},
numpages = {1},
keywords = {astroturf, diffusion networks, echo chambers, fact checking, hoaxes, misinformation, social bots, social bubbles, social media, twitter},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3543507.3583538,
author = {Ying, Yuxin and Zhuang, Fuzhen and Zhu, Yongchun and Wang, Deqing and Zheng, Hongwei},
title = {CAMUS: Attribute-Aware Counterfactual Augmentation for Minority Users in Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583538},
doi = {10.1145/3543507.3583538},
abstract = {Embedding-based methods currently achieved impressive success in recommender systems. However, such methods are more likely to suffer from bias in data distribution, especially the attribute bias problem. For example, when a certain type of user, like the elderly, occupies the mainstream, the recommendation results of minority users would be seriously affected by the mainstream users’ attributes. To address this problem, most existing methods are proposed from the perspective of fairness, which focuses on eliminating unfairness but deteriorates the recommendation performance. Unlike these methods, in this paper, we focus on improving the recommendation performance for minority users of biased attributes. Along this line, we propose a novel attribute-aware Counterfactual Augmentation framework for Minority Users(CAMUS). Specifically, the CAMUS consists of a counterfactual augmenter, a confidence estimator, and a recommender. The counterfactual augmenter conducts data augmentation for the minority group by utilizing the interactions of mainstream users based on a universal counterfactual assumption. Besides, a tri-training-based confidence estimator is applied to ensure the effectiveness of augmentation. Extensive experiments on three real-world datasets have demonstrated the superior performance of the proposed methods. Further case studies verify the universality of the proposed CAMUS framework on different data sparsity, attributes, and models.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1396–1404},
numpages = {9},
keywords = {Attribute Bias, Counterfactual Reasoning, Data Augmentation, Recommender Systems},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3178876.3186079,
author = {Su, Ning and Liu, Yiqun and Li, Zhao and Liu, Yuli and Zhang, Min and Ma, Shaoping},
title = {Detecting Crowdturfing "Add to Favorites" Activities in Online Shopping},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186079},
doi = {10.1145/3178876.3186079},
abstract = {"Add to Favorites" is a popular function in online shopping sites which helps users to make a record of potentially interesting items for future purchases. It is usually regarded as a type of explicit feedback signal for item popularity and therefore also adopted as a ranking signal by many shopping search engines. With the increasing usage of crowdsourcing platforms, some malicious online sellers also organize crowdturfing activities to increase the numbers of "Add to Favorites" for their items. By this means, they expect the items to gain higher positions in search ranking lists and therefore boost sales. This kind of newly-appeared malicious activity proposes challenges to traditional search spam detection efforts because it involves the participation of many crowd workers who are normal online shopping users in most of the times, and these activities are composed of a series of behaviors including search, browse, click and add to favorites. To shed light on this research question, we are among the first to investigate this particular spamming activity by looking into both the task organization information in crowdsourcing platforms and the user behavior information from online shopping sites. With a comprehensive analysis of some ground truth spamming activities from the perspective of behavior, user and item, we propose a factor graph based model to identify this kind of spamming activity. Experimental results based on data collected in practical shopping search environment show that our model helps detect malicious "Add to Favorites" activities effectively.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {1673–1682},
numpages = {10},
keywords = {spam detection, online shopping, crowdsourcing manipulation},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3485447.3512105,
author = {Lee, Wonsung and Chun, Jaeyoon and Lee, Youngmin and Park, Kyoungsoo and Park, Sungrae},
title = {Contrastive Learning for Knowledge Tracing},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512105},
doi = {10.1145/3485447.3512105},
abstract = {Knowledge tracing is the task of understanding student’s knowledge acquisition processes by estimating whether to solve the next question correctly or not. Most deep learning-based methods tackle this problem by identifying hidden representations of knowledge states from learning histories. However, due to the sparse interactions between students and questions, the hidden representations can be easily over-fitted and often fail to capture student’s knowledge states accurately. This paper introduces a contrastive learning framework for knowledge tracing that reveals semantically similar or dissimilar examples of a learning history and stimulates to learn their relationships. To deal with the complexity of knowledge acquisition during learning, we carefully design the components of contrastive learning, such as architectures, data augmentation methods, and hard negatives, taking into account pedagogical rationales. Our extensive experiments on six benchmarks show statistically significant improvements from the previous methods. Further analysis shows how our methods contribute to improving knowledge tracing performances.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {2330–2338},
numpages = {9},
keywords = {contrastive learning, educational data mining, intelligent tutoring system, knowledge tracing, personalized learning},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3308558.3313695,
author = {Agrawal, Rakshit and de Alfaro, Luca},
title = {Learning Edge Properties in Graphs from Path Aggregations},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313695},
doi = {10.1145/3308558.3313695},
abstract = {Graph edges, along with their labels, can represent information of fundamental importance, such as links between web pages, friendship between users, the rating given by users to other users or items, and much more. We introduce LEAP, a trainable, general framework for predicting the presence and properties of edges on the basis of the local structure, topology, and labels of the graph. The LEAP framework is based on the exploration and machine-learning aggregation of the paths connecting nodes in a graph. We provide several methods for performing the aggregation phase by training path aggregators, and we demonstrate the flexibility and generality of the framework by applying it to the prediction of links and user ratings in social networks. We validate the LEAP framework on two problems: link prediction, and user rating prediction. On eight large datasets, among which the arXiv collaboration network, the Yeast protein-protein interaction, and the US airlines routes network, we show that the link prediction performance of LEAP is at least as good as the current state of the art methods, such as SEAL and WLNM. Next, we consider the problem of predicting user ratings on other users: this problem is known as the edge-weight prediction problem in weighted signed networks (WSN). On Bitcoin networks, and Wikipedia RfA, we show that LEAP performs consistently better than the Fairness &amp; Goodness based regression models, varying the amount of training edges between 10 to 90%. These examples demonstrate that LEAP, in spite of its generality, can match or best the performance of approaches that have been especially crafted to solve very specific edge prediction problems.},
booktitle = {The World Wide Web Conference},
pages = {15–25},
numpages = {11},
keywords = {Path Aggregation, Neural Networks, Edge Learning},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3701716.3719230,
author = {Yu, Yuanqing and Wang, Zhefan and Jiang, Chumeng and Li, Xinyi and Wang, Jiayin and Zhang, Min},
title = {Intelligent Agents with Adaptive Knowledge Fusion for Personalized Recommendation},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3719230},
doi = {10.1145/3701716.3719230},
abstract = {With powerful semantic understanding, planning, and decision-making capabilities, LLM-based agents have been applied to solve recommendation tasks. However, challenges remain in effectively evolving user preferences within agent modules and in leveraging external knowledge to improve recommendation accuracy. In this paper, we propose an innovative agent-based framework for personalized recommendation systems that integrates adaptive knowledge fusion to address these challenges. Our framework consists of two primary components: an intelligent agent and the fusion of external knowledge. The intelligent agent includes a memory module that simulates human-like retention of user-item interactions and a reasoning module that applies Chain-of-Thought (CoT) techniques to mimic human thought processes. Furthermore, we introduce two main strategies for knowledge fusion: (1) a preranking approach using external knowledge to reorder candidates and reduce bias, and (2) an ensemble method that combines multiple ranking signals for more accurate recommendations. Evaluations on three public datasets and the AgentSociety Challenge demonstrate the framework's effectiveness in enhancing recommendation quality and adaptability. The code is open-sourced.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2983–2987},
numpages = {5},
keywords = {agent, knowledge fusion, recommendation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/2566486.2567978,
author = {Rong, Yu and Wen, Xiao and Cheng, Hong},
title = {A Monte Carlo algorithm for cold start recommendation},
year = {2014},
isbn = {9781450327442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2566486.2567978},
doi = {10.1145/2566486.2567978},
abstract = {Recommendation systems have been widely used in E-commerce sites, social networks, etc. One of the core tasks in recommendation systems is to predict the users' ratings on items. Although many models and algorithms have been proposed, how to make accurate prediction for new users with extremely few rating records still remains a big challenge, which is called the cold start problem. Many existing methods utilize additional information, such as social graphs, to cope with the cold start problem. However, the side information may not always be available. In contrast to such methods, we propose a more general solution to address the cold start problem based on the observed user rating records only. Specifically we define a random walk on a bipartite graph of users and items to simulate the preference propagation among users, in order to alleviate the data sparsity problem for cold start users. Then we propose a Monte Carlo algorithm to estimate the similarity between different users. This algorithm takes a precomputation approach, and thus can efficiently compute the user similarity given any new user for rating prediction. In addition, our algorithm can easily handle dynamic updates and can be parallelized naturally, which are crucial for large recommendation systems. Theoretical analysis is presented to demonstrate the efficiency and effectiveness of our algorithm, and extensive experiments also confirm our theoretical findings.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {327–336},
numpages = {10},
keywords = {random walk on bipartite graph, preference propagation, monte carlo simulation, cold start},
location = {Seoul, Korea},
series = {WWW '14}
}

@inproceedings{10.1145/2740908.2742140,
author = {Chatzicharalampous, Evangelos and Christos, Zigkolis and Vakali, Athena},
title = {Exploriometer: Leveraging Personality Traits for Coverage and Diversity Aware Recommendations},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2742140},
doi = {10.1145/2740908.2742140},
abstract = {Since the first introduced Collaborative Filtering Recommenders (CFR) there have been many attempts to improve their performance by enhancing the prediction accuracy. Even though rating prediction is the prevailing paradigm in CFR, there are other issues which have gained significant attention with respect to the content and its variety. Coverage, which constitutes the degree to which recommendations cover the set of available items, is an important factor along with diversity of the items proposed to an individual, often measured by an average dissimilarity between all pairs of recommended items. In this paper, we argue that coverage and diversity cannot be effectively addressed by conventional CFR with pure similarity-based neighborhood creation processes, especially in sparse datasets. Motivated by the need for including wider content characteristics, we propose a novel neighbor selection technique which emphasizes on variety in preferences (to cover polyphony in selection). Our approach consists of a new metric, named "Exploriometer", which acts as a personality trait for users based on their rating behavior. We favor users who are explorers in order to increase polyphony, and subsequently coverage and diversity; but we still select similar users when we create neighborhoods as a solid basis in order to keep accuracy levels high. The proposed approach has been experimented by two real-world datasets (MovieLens and Yahoo! Music ) with coverage, diversity and accuracy aware recommendations extracted by both traditional CFR and CFR enhanced with our neighborhood creation process. We also introduce a new metric, inspired by the Pearson Correlation Coefficient, to estimate the diversity of recommended items. The derived results demonstrate that our neighbor selection technique can enhance coverage and diversity of the recommendations, especially on sparse datasets.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {1463–1468},
numpages = {6},
keywords = {neighbor selection, diversity, coverage, collaborative filtering systems},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/3696410.3714764,
author = {Zhou, Peilin and Liu, Chao and Ren, Jing and Zhou, Xinfeng and Xie, Yueqi and Cao, Meng and Rao, Zhongtao and Huang, You-Liang and Chong, Dading and Liu, Junling and Kim, Jae Boum and Wang, Shoujin and Wong, Raymond Chi-Wing and Kim, Sunghun},
title = {When Large Vision Language Models Meet Multimodal Sequential Recommendation: An Empirical Study},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714764},
doi = {10.1145/3696410.3714764},
abstract = {As multimedia content continues to grow on the web, the integration of visual and textual data has become a crucial challenge for web applications, particularly in recommendation systems. Large Vision Language Models (LVLMs) have demonstrated considerable potential in addressing this challenge across various tasks that require such multimodal integration. However, their application in multimodal sequential recommendation (MSR) has not been extensively studied. To bridge this gap, we introduce MSRBench, the first comprehensive benchmark designed to systematically evaluate different LVLM integration strategies in web-based recommendation scenarios. We benchmark three state-of-the-art LVLMs, i.e., GPT-4 Vision, GPT-4o, and Claude-3-Opus, on the next item prediction task using the constructed Amazon Review Plus dataset, which includes additional item descriptions generated by LVLMs. Our evaluation examines five integration strategies: using LVLMs as recommender, item enhancer, reranker, and various combinations of these roles. The benchmark results reveal that 1) using LVLMs as rerankers is the most effective strategy, significantly outperforming others that rely on LVLMs to directly generate recommendations or only enhance items; 2) GPT-4o consistently achieves the best performance across most scenarios, particularly when employed as a reranker; 3) the computational inefficiency of LVLMs presents a major barrier to their widespread adoption in real-time multimodal recommendation systems. Our code and datasets are available at https://github.com/PALIN2018/MSRBench.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {275–292},
numpages = {18},
keywords = {benchmark, large vision language model, multimodal recommendation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3442381.3450101,
author = {Sun, Jianing and Cheng, Zhaoyue and Zuberi, Saba and Perez, Felipe and Volkovs, Maksims},
title = {HGCF: Hyperbolic Graph Convolution Networks for Collaborative Filtering},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450101},
doi = {10.1145/3442381.3450101},
abstract = {Hyperbolic spaces offer a rich setup to learn embeddings with superior properties that have been leveraged in areas such as computer vision, natural language processing and computational biology. Recently, several hyperbolic approaches have been proposed to learn robust representations for users and items in the recommendation setting. However, these approaches don’t capture the higher order relationships that typically exist in the recommendation domain. Graph convolutional neural networks (GCNs) on the other hand excel at capturing higher order information by applying multiple levels of aggregation to local representations. In this paper we combine these frameworks in a novel way, by proposing a hyperbolic GCN model for collaborative filtering. We demonstrate that our model can be effectively learned with a margin ranking loss, and show that hyperbolic space has desirable properties under the rank margin setting. At test time, inference in our model is done using the hyperbolic distance which preserves the structure of the learned space. We conduct extensive empirical analysis on three public benchmarks and compare against a large set of baselines. Our approach achieves highly competitive results and outperforms leading baselines including the Euclidean GCN counterpart. We further study the properties of the learned hyperbolic embeddings and show that they offer meaningful insights into the data. Full code for this work is available here:&nbsp;https://github.com/layer6ai-labs/HGCF.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {593–601},
numpages = {9},
keywords = {Recommender Systems, Hyperbolic Embeddings, Graph Convolutions},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3543507.3583866,
author = {Liu, Zitao and Liu, Qiongqiong and Chen, Jiahao and Huang, Shuyan and Gao, Boyu and Luo, Weiqi and Weng, Jian},
title = {Enhancing Deep Knowledge Tracing with Auxiliary Tasks},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583866},
doi = {10.1145/3543507.3583866},
abstract = {Knowledge tracing (KT) is the problem of predicting students’ future performance based on their historical interactions with intelligent tutoring systems. Recent studies have applied multiple types of deep neural networks to solve the KT problem. However, there are two important factors in real-world educational data that are not well represented. First, most existing works augment input representations with the co-occurrence matrix of questions and knowledge components1 (KCs) but fail to explicitly integrate such intrinsic relations into the final response prediction task. Second, the individualized historical performance of students has not been well captured. In this paper, we proposed AT-DKT to improve the prediction performance of the original deep knowledge tracing model with two auxiliary learning tasks, i.e., question tagging (QT) prediction task and individualized prior knowledge (IK) prediction task. Specifically, the QT task helps learn better question representations by predicting whether questions contain specific KCs. The IK task captures students’ global historical performance by progressively predicting student-level prior knowledge that is hidden in students’ historical learning interactions. We conduct comprehensive experiments on three real-world educational datasets and compare the proposed approach to both deep sequential KT models and non-sequential models. Experimental results show that AT-DKT outperforms all sequential models with more than 0.9% improvements of AUC for all datasets, and is almost the second best compared to non-sequential models. Furthermore, we conduct both ablation studies and quantitative analysis to show the effectiveness of auxiliary tasks and the superior prediction outcomes of AT-DKT. To encourage reproducible research, we make our data and code publicly available at https://github.com/pykt-team/pykt-toolkit&nbsp; 2.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {4178–4187},
numpages = {10},
keywords = {AI in education, auxiliary learning, deep learning, knowledge tracing, student modeling},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/2566486.2568009,
author = {Whiting, Stewart and Jose, Joemon M.},
title = {Recent and robust query auto-completion},
year = {2014},
isbn = {9781450327442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2566486.2568009},
doi = {10.1145/2566486.2568009},
abstract = {Query auto-completion (QAC) is a common interactive feature that assists users in formulating queries by providing completion suggestions as they type. In order for QAC to minimise the user's cognitive and physical effort, it must: (i) suggest the user's intended query after minimal input keystrokes, and (ii) rank the user's intended query highly in completion suggestions. Typically, QAC approaches rank completion suggestions by their past popularity. Accordingly, QAC is usually very effective for previously seen and consistently popular queries. Users are increasingly turning to search engines to find out about unpredictable emerging and ongoing events and phenomena, often using previously unseen or unpopular queries. Consequently, QAC must be both robust and time-sensitive -- that is, able to sufficiently rank both consistently and recently popular queries in completion suggestions. To address this trade-off, we propose several practical completion suggestion ranking approaches, including: (i) a sliding window of query popularity evidence from the past 2-28 days, (ii) the query popularity distribution in the last N queries observed with a given prefix, and (iii) short-range query popularity prediction based on recently observed trends. Using real-time simulation experiments, we extensively investigated the parameters necessary to maximise QAC effectiveness for three openly available query log datasets with prefixes of 2-5 characters: MSN and AOL (both English), and Sogou 2008 (Chinese). Optimal parameters vary for each query log, capturing the differing temporal dynamics and querying distributions. Results demonstrate consistent and language-independent improvements of up to 9.2% over a non-temporal QAC baseline for all query logs with prefix lengths of 2-3 characters. This work is an important step towards more effective QAC approaches.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {971–982},
numpages = {12},
keywords = {time, text, temporal, recency, query, completion, auto-completion},
location = {Seoul, Korea},
series = {WWW '14}
}

@inproceedings{10.1145/3696410.3714530,
author = {Tang, Jiehao and Wang, Wenjun and Cheng, Dawei and Zhao, Hui and Jiang, Changjun},
title = {Dual Pairwise Pre-training and Prompt-tuning with Aligned Prototypes for Interbank Credit Rating},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714530},
doi = {10.1145/3696410.3714530},
abstract = {In the global financial market, assessing bank credit ratings is essential for evaluating financial health, managing risk, and safeguarding systemic stability. While risk can transmit rapidly within the interbank lending network, timely incorporation of the latest financial disclosures to update bank ratings is vital in the swiftly evolving financial markets. However, existing approaches primarily conduct credit rating tasks using end-to-end models trained on historical financial data, thereby overlooking the staggered timing of financial disclosure from banks. Limited excavation of the credit rating records and the temporal distribution shifts existed in different financial periods still pose challenges to improving the accuracy of the credit rating tasks. To address these challenges, in this work we propose a Dual Pairwise pre-training and prompt Tuning framework with Aligned Prototypes (DPTAP) for interbank credit rating, which enables dynamic credit updates. Specifically, the dual pairwise pre-training strategy allows the framework to capture direction and distance discrepancies between rating categories. To alleviate the adverse impact of temporal distribution shifts in quarters, the latest financial features are prompted to dynamically map the patterns of the corresponding banks in the last quarter. Furthermore, we integrate rating guides from two consecutive quarters into a set of aligned prototypes to enhance supervision during the prompt tuning process. We conducted extensive experiments on a real-world bank dataset globally in the latest 8 years. The results demonstrate the superiority of our proposed framework over various competitive models, highlighting its notable capabilities in early warning and risk contagion forecasting.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {5234–5243},
numpages = {10},
keywords = {credit rating, graph neural networks, pre-training, prompt},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3442381.3449788,
author = {Zheng, Yu and Gao, Chen and Li, Xiang and He, Xiangnan and Li, Yong and Jin, Depeng},
title = {Disentangling User Interest and Conformity for Recommendation with Causal Embedding},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449788},
doi = {10.1145/3442381.3449788},
abstract = {Recommendation models are usually trained on observational interaction data. However, observational interaction data could result from users’ conformity towards popular items, which entangles users’ real interest. Existing methods tracks this problem as eliminating popularity bias, e.g., by re-weighting training samples or leveraging a small fraction of unbiased data. However, the variety of user conformity is ignored by these approaches, and different causes of an interaction are bundled together as unified representations, hence robustness and interpretability are not guaranteed when underlying causes are changing. In this paper, we present DICE, a general framework that learns representations where interest and conformity are structurally disentangled, and various backbone recommendation models could be smoothly integrated. We assign users and items with separate embeddings for interest and conformity, and make each embedding capture only one cause by training with cause-specific data which is obtained according to the colliding effect of causal inference. Our proposed methodology outperforms state-of-the-art baselines with remarkable improvements on two real-world datasets on top of various backbone models. We further demonstrate that the learned embeddings successfully capture the desired causes, and show that DICE guarantees the robustness and interpretability of recommendation.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {2980–2991},
numpages = {12},
keywords = {popularity bias, causal embedding, Recommender systems},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3589334.3645525,
author = {Zhang, Chunxu and Long, Guodong and Zhou, Tianyi and Zhang, Zijian and Yan, Peng and Yang, Bo},
title = {When Federated Recommendation Meets Cold-Start Problem: Separating Item Attributes and User Interactions},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645525},
doi = {10.1145/3589334.3645525},
abstract = {Federated recommendation system usually trains a global model on the server without direct access to users' private data on their own devices. However, this separation of the recommendation model and users' private data poses a challenge in providing quality service, particularly when it comes to new items, namely cold-start recommendations in federated settings. This paper introduces a novel method called Item-aligned Federated Aggregation (IFedRec) to address this challenge. It is the first research work in federated recommendation to specifically study the cold-start scenario. The proposed method learns two sets of item representations by leveraging item attributes and interaction records simultaneously. Additionally, an item representation alignment mechanism is designed to align two item representations and learn the meta attribute network at the server within a federated learning framework. Experiments on four benchmark datasets demonstrate IFedRec's superior performance for cold-start scenarios. Furthermore, we also verify IFedRec owns good robustness when the system faces limited client participation and noise injection, which brings promising practical application potential in privacy-protection enhanced federated recommendation systems. The implementation code is available},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3632–3642},
numpages = {11},
keywords = {cold-start, federated learning, recommendation systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3366423.3380187,
author = {Lian, Defu and Liu, Qi and Chen, Enhong},
title = {Personalized Ranking with Importance Sampling},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380187},
doi = {10.1145/3366423.3380187},
abstract = {As the task of predicting a personalized ranking on a set of items, item recommendation has become an important way to address information overload. Optimizing ranking loss aligns better with the ultimate goal of item recommendation, so many ranking-based methods were proposed for item recommendation, such as collaborative filtering with Bayesian Personalized Ranking (BPR) loss, and Weighted Approximate-Rank Pairwise (WARP) loss. However, the ranking-based methods can not consistently beat regression-based models with the gravity regularizer. The key challenge in ranking-based optimization is difficult to fully use the limited number of negative samples, particularly when they are not so informative. To this end, we propose a new ranking loss based on importance sampling so that more informative negative samples can be better used. We then design a series of negative samplers from simple to complex, whose informativeness of negative samples is from less to more. With these samplers, the loss function is easy to use and can be optimized by popular solvers. The proposed algorithms are evaluated with five real-world datasets of varying size and difficulty. The results show that they consistently outperform the state-of-the-art item recommendation algorithms, and the relative improvements with respect to NDCG@50 are more than 19.2% on average. Moreover, the loss function is verified to make better use of negative samples and to require fewer negative samples when they are more informative.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {1093–1103},
numpages = {11},
keywords = {Personalized Ranking, Negative Sampling, Implicit Feedback},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3543507.3583361,
author = {Yang, Yuhao and Huang, Chao and Xia, Lianghao and Huang, Chunzhen and Luo, Da and Lin, Kangyi},
title = {Debiased Contrastive Learning for Sequential Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583361},
doi = {10.1145/3543507.3583361},
abstract = {Current sequential recommender systems are proposed to tackle the dynamic user preference learning with various neural techniques, such as Transformer and Graph Neural Networks (GNNs). However, inference from the highly sparse user behavior data may hinder the representation ability of sequential pattern encoding. To address the label shortage issue, contrastive learning (CL) methods are proposed recently to perform data augmentation in two fashions: (i) randomly corrupting the sequence data (e.g., stochastic masking, reordering); (ii) aligning representations across pre-defined contrastive views. Although effective, we argue that current CL-based methods have limitations in addressing popularity bias and disentangling of user conformity and real interest. In this paper, we propose a new Debiased Contrastive learning paradigm for Recommendation (DCRec) that unifies sequential pattern encoding with global collaborative relation modeling through adaptive conformity-aware augmentation. This solution is designed to tackle the popularity bias issue in recommendation systems. Our debiased contrastive learning framework effectively captures both the patterns of item transitions within sequences and the dependencies between users across sequences. Our experiments on various real-world datasets have demonstrated that DCRec significantly outperforms state-of-the-art baselines, indicating its efficacy for recommendation. To facilitate reproducibility of our results, we make our implementation of DCRec publicly available at: https://github.com/HKUDS/DCRec.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1063–1073},
numpages = {11},
keywords = {Contrastive Learning, Popularity Bias, Sequential Recommendation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3696410.3714759,
author = {Jiang, Chumeng and Wang, Jiayin and Ma, Weizhi and Clarke, Charles L. A. and Wang, Shuai and Wu, Chuhan and Zhang, Min},
title = {Beyond Utility: Evaluating LLM as Recommender},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714759},
doi = {10.1145/3696410.3714759},
abstract = {With the rapid development of Large Language Models (LLMs), recent studies employed LLMs as recommenders to provide personalized information services for distinct users. Despite efforts to improve the accuracy of LLM-based recommendation models, relatively little attention is paid to beyond-utility dimensions. Moreover, there are unique evaluation aspects of LLM-based recommendation models, which have been largely ignored. To bridge this gap, we explore four new evaluation dimensions and propose a multidimensional evaluation framework. The new evaluation dimensions include: 1) history length sensitivity, 2) candidate position bias, 3) generation-involved performance, and 4) hallucinations. All four dimensions have the potential to impact performance, but are largely unnecessary for consideration in traditional systems. Using this multidimensional evaluation framework, along with traditional aspects, we evaluate the performance of seven LLM-based recommenders, with three prompting strategies, comparing them with six traditional models on both ranking and re-ranking tasks on four datasets. We find that LLMs excel at handling tasks with prior knowledge and shorter input histories in the ranking setting, and perform better in the re-ranking setting, beating traditional models across multiple dimensions. However, LLMs exhibit substantial candidate position bias issues, and some models hallucinate nonexistent items much more often than others. We intend our evaluation framework and observations to benefit future research on the use of LLMs as recommenders. The code and data are available at https://github.com/JiangDeccc/EvaLLMasRecommender.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3850–3862},
numpages = {13},
keywords = {evaluation, large language model, recommendation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3589335.3651552,
author = {Jiao, Yang and Yang, Fan and Chen, Yetian and Gao, Yan and Liu, Jia and Sun, Yi},
title = {Rethinking Sequential Relationships: Improving Sequential Recommenders with Inter-Sequence Data Augmentation},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651552},
doi = {10.1145/3589335.3651552},
abstract = {Predicting customer preferences for each item is a prerequisite module for most recommender systems in e-commerce. However, the sparsity of behavioral data is often a challenge to learn accurate prediction models. Given millions of items, each customer may only be able to interact with a small subset of them over time. This sparse behavioral data is insufficient to represent item-customer and item-item relations for a machine learning model to digest, resulting in limited prediction accuracy that hinders recommendation performance. To mitigate this issue, this study introduces an inter-sequence data augmentation method, SDAinter, that enhances data density by leveraging cross-customer behavioral patterns to enrich item relations. Tested on three public and one proprietary e-commerce dataset, SDAinter significantly increases data density, leading to notable improvements in both evaluation and business metrics. Our findings demonstrate SDAinter's effectiveness and its potential to complement existing data augmentation strategies in recommender systems. See https://github.com/ML-apollo/SDA_inter.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {641–645},
numpages = {5},
keywords = {data augmentation, personalization, sequential recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3543873.3584657,
author = {Raul, Ameya and Porobo Dharwadker, Amey and Schumitsch, Brad},
title = {CAM2: Conformity-Aware Multi-Task Ranking Model for Large-Scale Recommender Systems},
year = {2023},
isbn = {9781450394192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543873.3584657},
doi = {10.1145/3543873.3584657},
abstract = {Learning large-scale industrial recommender system models by fitting them to historical user interaction data makes them vulnerable to conformity bias. This may be due to a number of factors, including the fact that user interests may be difficult to determine and that many items are often interacted with based on ecosystem factors other than their relevance to the individual user. In this work, we introduce CAM2, a conformity-aware multi-task ranking model to serve relevant items to users on one of the largest industrial recommendation platforms. CAM2 addresses these challenges systematically by leveraging causal modeling to disentangle users’ conformity to popular items from their true interests. This framework is generalizable and can be scaled to support multiple representations of conformity and user relevance in any large-scale recommender system. We provide deeper practical insights and demonstrate the effectiveness of the proposed model through improvements in offline evaluation metrics compared to our production multi-task ranking model. We also show through online experiments that the CAM2 model results in a significant 0.50% increase in aggregated user engagement, coupled with a 0.21% increase in daily active users on Facebook Watch, a popular video discovery and sharing platform serving billions of users.},
booktitle = {Companion Proceedings of the ACM Web Conference 2023},
pages = {513–517},
numpages = {5},
keywords = {Causal embedding, Conformity bias, Multi-task learning, Recommender system},
location = {Austin, TX, USA},
series = {WWW '23 Companion}
}

@inproceedings{10.1145/1526709.1526725,
author = {Stern, David H. and Herbrich, Ralf and Graepel, Thore},
title = {Matchbox: large scale online bayesian recommendations},
year = {2009},
isbn = {9781605584874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1526709.1526725},
doi = {10.1145/1526709.1526725},
abstract = {We present a probabilistic model for generating personalised recommendations of items to users of a web service. The Matchbox system makes use of content information in the form of user and item meta data in combination with collaborative filtering information from previous user behavior in order to predict the value of an item for a user. Users and items are represented by feature vectors which are mapped into a low-dimensional `trait space' in which similarity is measured in terms of inner products. The model can be trained from different types of feedback in order to learn user-item preferences. Here we present three alternatives: direct observation of an absolute rating each user gives to some items, observation of a binary preference (like/ don't like) and observation of a set of ordinal ratings on a user-specific scale. Efficient inference is achieved by approximate message passing involving a combination of Expectation Propagation (EP) and Variational Message Passing. We also include a dynamics model which allows an item's popularity, a user's taste or a user's personal rating scale to drift over time. By using Assumed-Density Filtering (ADF) for training, the model requires only a single pass through the training data. This is an on-line learning algorithm capable of incrementally taking account of new data so the system can immediately reflect the latest user preferences. We evaluate the performance of the algorithm on the MovieLens and Netflix data sets consisting of approximately 1,000,000 and 100,000,000 ratings respectively. This demonstrates that training the model using the on-line ADF approach yields state-of-the-art performance with the option of improving performance further if computational resources are available by performing multiple EP passes over the training data.},
booktitle = {Proceedings of the 18th International Conference on World Wide Web},
pages = {111–120},
numpages = {10},
keywords = {recommender system, online services, machine learning, collaborative filtering, bayesian inference, advertising},
location = {Madrid, Spain},
series = {WWW '09}
}

@inproceedings{10.1145/3589334.3645324,
author = {Huang, Xu and Lian, Jianxun and Wang, Hao and Liao, Hao and Lian, Defu and Xie, Xing},
title = {A Data-Centric Multi-Objective Learning Framework for Responsible Recommendation Systems},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645324},
doi = {10.1145/3589334.3645324},
abstract = {Recommendation systems guide users in locating their desired information within extensive content repositories. Usually, a recommendation model is optimized to enhance accuracy metrics from a user utility standpoint, such as click-through rate or matching relevance. However, a responsible industrial recommendation model must address not only user utility (responsibility to users) but also other objectives, including increasing platform revenue (responsibility to platforms), ensuring fairness (responsibility to content creators), and maintaining unbiasedness (responsibility to long-term healthy development). Multi-objective learning is a promising approach for achieving responsible recommendation models. Nevertheless, current methods encounter two challenges: difficulty in scaling to heterogeneous objectives within a unified framework, and inadequate controllability over objective priority during optimization, leading to uncontrollable solutions.In this paper, we present a data-centric optimization framework, MoRec, which unifies the learning of diverse objectives. MoRec is a tri-level framework: the outer level manages the balance between different objectives, utilizing a proportional-integral-derivative (PID)-based controller to ensure a preset regularization on the primary objective. The middle level transforms objective-aware optimization into data sampling weights using sign gradients. The inner level employs a standard optimizer to update model parameters with the sampled data. Consequently, MoRec can flexibly support various objectives while maintaining the original model intact. Comprehensive experiments on two public datasets and one industrial dataset showcase the effectiveness, controllability, flexibility, and Pareto efficiency of MoRec, making it highly suitable for real-world implementation.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3129–3138},
numpages = {10},
keywords = {data sampling, multi-objective learning, recommender system},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3648158,
author = {Jiang, Meng and Bao, Keqin and Zhang, Jizhi and Wang, Wenjie and Yang, Zhengyi and Feng, Fuli and He, Xiangnan},
title = {Item-side Fairness of Large Language Model-based Recommendation System},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3648158},
doi = {10.1145/3589334.3648158},
abstract = {Recommendation systems for Web content distribution intricately connect to the information access and exposure opportunities for vulnerable populations. The emergence of Large Language Models-based Recommendation System (LRS) may introduce additional societal challenges to recommendation systems due to the inherent biases in Large Language Models (LLMs). From the perspective of item-side fairness, there remains a lack of comprehensive investigation into the item-side fairness of LRS given the unique characteristics of LRS compared to conventional recommendation systems. To bridge this gap, this study examines the property of LRS with respect to item-side fairness and reveals the influencing factors of both historical users' interactions and inherent semantic biases of LLMs, shedding light on the need to extend conventional item-side fairness methods for LRS. Towards this goal, we develop a concise and effective framework called IFairLRS to enhance the item-side fairness of an LRS. IFairLRS covers the main stages of building an LRS with specifically adapted strategies to calibrate the recommendations of LRS. We utilize IFairLRS to fine-tune LLaMA, a representative LLM, on MovieLens and Steam datasets, and observe significant item-side fairness improvements. The code can be found in https://github.com/JiangM-C/IFairLRS.git.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4717–4726},
numpages = {10},
keywords = {item-side fairness, large language model, recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3696410.3714600,
author = {Xing, Haibo and Matsuyama, Kanefumi and Deng, Hao and Hu, Jinxin and Zhang, Yu and Zeng, Xiaoyi},
title = {ESANS: Effective and Semantic-Aware Negative Sampling for Large-Scale Retrieval Systems},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714600},
doi = {10.1145/3696410.3714600},
abstract = {Industrial recommendation systems typically involve a two-stage process: retrieval and ranking, which aims to match users with millions of items. In the retrieval stage, classic embedding-based retrieval (EBR) methods depend on effective negative sampling techniques to enhance both performance and efficiency. However, existing techniques often suffer from false negatives, high cost for ensuring sampling quality and semantic information deficiency. To address these limitations, we propose Effective and Semantic-Aware Negative Sampling (ESANS), which integrates two key components: Effective Dense Interpolation Strategy (EDIS) and Multimodal Semantic-Aware Clustering (MSAC). EDIS generates virtual samples within the low-dimensional embedding space to improve the diversity and density of the sampling distribution while minimizing computational costs. MSAC refines the negative sampling distribution by hierarchically clustering item representations based on multimodal information (visual, textual, behavioral), ensuring semantic consistency and reducing false negatives. Extensive offline and online experiments demonstrate the superior efficiency and performance of ESANS.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {462–471},
numpages = {10},
keywords = {embedding-based retrieval, negative sampling, recommendation systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701716.3715234,
author = {Zhao, Rui and Zhong, Rui and Zheng, Haoran and Yang, Wei and Lu, Chi and Jin, Beihong and Jiang, Peng and Gai, Kun},
title = {Hierarchical Sequence ID Representation of Large Language Models for Large-scale Recommendation Systems},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715234},
doi = {10.1145/3701716.3715234},
abstract = {Recently, large language models (LLMs) have shown great potential in recommendation systems (RS), however, there are still challenges in applying LLMs to large-scale RS. One major challenge is to effectively transform unique identities (IDs) in RS into a suitable training space for LLMs. Current approaches either lack collaborative signals of user behaviors, or they represent IDs with a single token, which fail to align with the autoregressive paradigm of LLMs. Consequently, the potential of IDs is not fully utilized in LLMs for recommendation, particularly in large-scale systems with numerous users, items, and sparse interactions. On the other hand, when enhancing large-scale RS, the high-dimensional representations from the last hidden layer of LLMs pose difficulties for meeting the low-latency requirements. In this paper, we propose a Hierarchical sequence ID representation method for applying LLMs to Recommender systems, called HI-RecM. Specifically, we design a tree-based ID encoding method that generates hierarchical sequence indices, then we embed the indices token-by-token into LLMs to align LLMs' autoregressive training paradigm. We design a joint dimension reduction (JDR) module to efficiently extract information, enabling lossless dimension reduction of high-dimensional LLM representations. Extensive experiments show that our method can outperform state-of-the-art methods. Moreover, HI-Rec has been deployed on Kuaishou's online advertising platform, achieving 2.1% increase of revenue. We also release the implementation code in https://github.com/Rita-73/HI-Rec.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {641–650},
numpages = {10},
keywords = {id representation, large language model, recommender systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696410.3714712,
author = {Pan, Zhiqiang and Gao, Chen and Cai, Fei and Chen, Wanyu and Zhang, Xin and Chen, Honghui and Li, Yong},
title = {On the Cross-Graph Transferability of Dynamic Link Prediction},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714712},
doi = {10.1145/3696410.3714712},
abstract = {Dynamic link prediction aims to predict the future links on dynamic graphs, which can be applied to wide scenarios such as recommender systems and social networks on the World Wide Web. Existing methods mainly (1) focus on the in-graph learning, which cannot generalize to graphs unobserved during training; or (2) achieve the cross-graph predictions in a many-many mechanism by training on multiple graphs across various domains, which results in a large computational cost. In this paper, we propose a cross-graph dynamic link predictor named CrossDyG, which achieves the cross-graph transferability in a one-many mechanism which trains on one single source graph and test on different target graphs. Specifically, we provide causal and empirical analysis on the structural bias caused by the graph-specific structural characteristics in cross-graph predictions. Then, we conduct deconfounded training to learn the universal network evolution pattern from one single source graph during training. Finally, we apply the causal intervention to leverage the graph-specific structural characteristics of each target graph during inference. Extensive experiments conducted on three benchmark data of dynamic graphs demonstrate that CrossDyG outperforms the state-of-the-art baselines by up to 11.01% and 17.02% in terms of AP and AUC, respectively. In addition, the improvements are especially significant when training on small source graphs.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4101–4110},
numpages = {10},
keywords = {dynamic link prediction, graph learning, network science},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3543507.3583529,
author = {Fan, Ziwei and Liu, Zhiwei and Peng, Hao and Yu, Philip S},
title = {Mutual Wasserstein Discrepancy Minimization for Sequential Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583529},
doi = {10.1145/3543507.3583529},
abstract = {Self-supervised sequential recommendation significantly improves recommendation performance by maximizing mutual information with well-designed data augmentations. However, the mutual information estimation is based on the calculation of Kullback–Leibler divergence with several limitations, including asymmetrical estimation, the exponential need of the sample size, and training instability. Also, existing data augmentations are mostly stochastic and can potentially break sequential correlations with random modifications. These two issues motivate us to investigate an alternative robust mutual information measurement capable of modeling uncertainty and alleviating KL divergence’s limitations. To this end, we propose a novel self-supervised learning framework based on the Mutual WasserStein discrepancy minimization&nbsp;(MStein) for the sequential recommendation. We propose the Wasserstein Discrepancy Measurement to measure the mutual information between augmented sequences. Wasserstein Discrepancy Measurement builds upon the 2-Wasserstein distance, which is more robust, more efficient in small batch sizes, and able to model the uncertainty of stochastic augmentation processes. We also propose a novel contrastive learning loss based on Wasserstein Discrepancy Measurement. Extensive experiments on four benchmark datasets demonstrate the effectiveness of MStein over baselines. More quantitative analyses show the robustness against perturbations and training efficiency in batch size. Finally, improvements analysis indicates better representations of popular users/items with significant uncertainty. The source code is in https://github.com/zfan20/MStein.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1375–1385},
numpages = {11},
keywords = {Mutual Information, Self-supervised Learning, Sequential Recommendation, Wasserstein Distance},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3701716.3715856,
author = {Hou, Yupeng and Zhang, An and Sheng, Leheng and Yang, Zhengyi and Wang, Xiang and Chua, Tat-Seng and McAuley, Julian},
title = {Generative Recommendation Models: Progress and Directions},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715856},
doi = {10.1145/3701716.3715856},
abstract = {Recommendation models typically follow a discriminative paradigm, predicting whether items should be retrieved. While effective, the expressive capabilities of these recommender systems are limited. Users can only passively browse the recommended items rather than actively express their needs and engage in an interactive experience. With recent advances in generative models such as large language models, a paradigm shift is happening in the study of recommender systems. Researchers propose building generative recommendation models either by aligning pre-trained generative models with user behaviors or designing recommendation models within a generative framework. These models enable the systems to receive and deliver more human-like content, such as natural language, images, and beyond. In this tutorial, we first provide an overview of the latest progress in generative recommendation models, covering approaches based on large language models, semantic IDs, diffusion models, and more. We then make an in-depth discussion on the challenges, open questions, and potential future directions in developing generative recommendation models.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {13–16},
numpages = {4},
keywords = {diffusion model, generative model, large language model, recommender system, semantic id},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3485447.3512029,
author = {Pan, Sicheng and Li, Dongsheng and Gu, Hansu and Lu, Tun and Luo, Xufang and Gu, Ning},
title = {Accurate and Explainable Recommendation via Review Rationalization},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512029},
doi = {10.1145/3485447.3512029},
abstract = {Auxiliary information, such as reviews, have been widely adopted to improve collaborative filtering (CF) algorithms, e.g., to boost the accuracy and provide explanations. However, most of the existing methods cannot distinguish between co-appearance and causality when learning from the reviews, so that they may rely on spurious correlations rather than causal relations in the recommendation — leading to poor generalization performance and unconvincing explanations. In this paper, we propose a Recommendation via Review Rationalization (R3) method including 1) a rationale generator to extract rationales from reviews to alleviate the effects of spurious correlations; 2) a rationale predictor to predict user ratings on items only from generated rationales; and 3) a correlation predictor upon both rationales and correlational features to ensure conditional independence between spurious correlations and rating predictions given causal rationales. Extensive experiments on real-world datasets show that the proposed method can achieve better generalization performance than state-of-the-art CF methods and provide causal-aware explanations even when the test data distribution changes.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {3092–3101},
numpages = {10},
keywords = {explainability, rationalization, recommendation},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3485447.3512077,
author = {Fan, Ziwei and Liu, Zhiwei and Wang, Yu and Wang, Alice and Nazari, Zahra and Zheng, Lei and Peng, Hao and Yu, Philip S.},
title = {Sequential Recommendation via Stochastic Self-Attention},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512077},
doi = {10.1145/3485447.3512077},
abstract = {Sequential recommendation models the dynamics of a user’s previous behaviors in order to forecast the next item, and has drawn a lot of attention. Transformer-based approaches, which embed items as vectors and use dot-product self-attention to measure the relationship between items, demonstrate superior capabilities among existing sequential methods. However, users’ real-world sequential behaviors are uncertain rather than deterministic, posing a significant challenge to present techniques. We further suggest that dot-product-based approaches cannot fully capture collaborative transitivity, which can be derived in item-item transitions inside sequences and is beneficial for cold start items. We further argue that BPR loss has no constraint on positive and sampled negative items, which misleads the optimization. We propose a novel STOchastic Self-Attention&nbsp;(STOSA) to overcome these issues. STOSA, in particular, embeds each item as a stochastic Gaussian distribution, the covariance of which encodes the uncertainty. We devise a novel Wasserstein Self-Attention module to characterize item-item position-wise relationships in sequences, which effectively incorporates uncertainty into model training. Wasserstein attentions also enlighten the collaborative transitivity learning as it satisfies triangle inequality. Moreover, we introduce a novel regularization term to the ranking loss, which assures the dissimilarity between positive and the negative items. Extensive experiments on five real-world benchmark datasets demonstrate the superiority of the proposed model over state-of-the-art baselines, especially on cold start items. The code is available in https://github.com/zfan20/STOSA.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {2036–2047},
numpages = {12},
keywords = {Self-Attention, Sequential Recommendation, Transformer, Uncertainty},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3442381.3450054,
author = {Van Balen, Jan and Goethals, Bart},
title = {High-dimensional Sparse Embeddings for Collaborative Filtering},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450054},
doi = {10.1145/3442381.3450054},
abstract = {A widely adopted paradigm in the design of recommender systems is to represent users and items as vectors, often referred to as latent factors or embeddings. Embeddings can be obtained using a variety of recommendation models and served in production using a variety of data engineering solutions. Embeddings also facilitate transfer learning, where trained embeddings from one model are reused in another. In contrast, some of the best-performing collaborative filtering models today are high-dimensional linear models that do not rely on factorization, and so they do not produce embeddings&nbsp;[27, 28]. They also require pruning, amounting to a trade-off between the model size and the density of the predicted affinities. This paper argues for the use of high-dimensional, sparse latent factor models, instead. We propose a new recommendation model based on a full-rank factorization of the inverse Gram matrix. The resulting high-dimensional embeddings can be made sparse while still factorizing a dense affinity matrix. We show how the embeddings combine the advantages of latent representations with the performance of high-dimensional linear models.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {575–581},
numpages = {7},
keywords = {sparse embeddings, high-dimensional embeddings, collaborative filtering, cholesky decomposition},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3442381.3450011,
author = {Hansen, Christian and Hansen, Casper and Simonsen, Jakob Grue and Lioma, Christina},
title = {Projected Hamming Dissimilarity for Bit-Level Importance Coding in Collaborative Filtering},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450011},
doi = {10.1145/3442381.3450011},
abstract = {When reasoning about tasks that involve large amounts of data, a common approach is to represent data items as objects in the Hamming space where operations can be done efficiently and effectively. Object similarity can then be computed by learning binary representations (hash codes) of the objects and computing their Hamming distance. While this is highly efficient, each bit dimension is equally weighted, which means that potentially discriminative information of the data is lost. A more expressive alternative is to use real-valued vector representations and compute their inner product; this allows varying the weight of each dimension but is many magnitudes slower. To fix this, we derive a new way of measuring the dissimilarity between two objects in the Hamming space with binary weighting of each dimension (i.e., disabling bits): we consider a field-agnostic dissimilarity that projects the vector of one object onto the vector of the other. When working in the Hamming space, this results in a novel projected Hamming dissimilarity, which by choice of projection, effectively allows a binary importance weighting of the hash code of one object through the hash code of the other. We propose a variational hashing model for learning hash codes optimized for this projected Hamming dissimilarity, and experimentally evaluate it in collaborative filtering experiments. The resultant hash codes lead to effectiveness gains of up to +7% in NDCG and +14% in MRR compared to state-of-the-art hashing-based collaborative filtering baselines, while requiring no additional storage and no computational overhead compared to using the Hamming distance.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {261–269},
numpages = {9},
keywords = {importance coding, hash codes, collaborative filtering},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3696410.3714860,
author = {Liu, Weiming and Chen, Chaochao and Xu, Jiahe and Liao, Xinting and Wang, Fan and Zheng, Xiaolin and Fu, Zhihui and Pei, Ruiguang and Wang, Jun},
title = {Joint Similarity Item Exploration and Overlapped User Guidance for Multi-Modal Cross-Domain Recommendation},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714860},
doi = {10.1145/3696410.3714860},
abstract = {Cross-Domain Recommendation (CDR) has been widely investi- gated for solving long-standing data sparsity problem via knowl- edge sharing across domains. In this paper, we focus on the Multi- Modal Cross-Domain Recommendation (MMCDR) problem where different items have multi-modal information while few users are overlapped across domains. MMCDR is particularly challenging in two aspects: fully exploiting diverse multi-modal information within each domain and leveraging useful knowledge transfer across domains. However, previous methods fail to cluster items with similar characteristics while filtering out inherit noises within different modalities, hurdling the model performance. What is worse, conventional CDR models primarily rely on overlapped users for domain adaptation, making them ill-equipped to handle scenarios where the majority of users are non-overlapped. To fill this gap, we propose Joint Similarity Item Exploration and Overlapped User Guidance (SIEOUG) for solving the MMCDR problem. SIEOUG first proposes similarity item exploration module, which not only obtains pair-wise and group-wise item-item graph knowledge, but also reduces irrelevant noise for multi-modal modeling. Then SIEOUG proposes user-item collaborative filtering module to aggregate user/item embeddings with the attention mechanism for collaborative filtering. Finally SIEOUG proposes overlapped user guidance module with optimal user matching for knowledge sharing across domains. Our empirical study on Amazon dataset with several different tasks demonstrates that SIEOUG significantly outperforms the state-of-the-art models under the MMCDR setting.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2882–2893},
numpages = {12},
keywords = {cross-domain recommendation, domain adaptation, multi-modal cross-domain recommendation, optimal transport},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701716.3719227,
author = {Zhao, Renhuo and Yang, Hailong and Gu, Mingxian and Wang, Jianqi and Long, Wu and Deng, Zhaohong},
title = {USHB: A Unified Framework for Simulating Human Behaviors in Agent Society through User-and-Item Modeling: Unified Framework for Simulating Human Behaviors},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3719227},
doi = {10.1145/3701716.3719227},
abstract = {Emulating real-world human behaviors within Artificial Intelligent (AI) agent systems continues to be a formidable challenge, as existing methodologies frequently have difficulty integrating the intricacies of real-world scenarios and personal preferences.To address this issue, we propose USHB, a mulit-agent framework that emphasizes advanced user and item modeling along with communication style simulation. USHB consists of 3 modules: a Knowledge-Mining Module (KMM), a User-and-Item Modeling Module (UIMM), and a Reasoning Module (RM). USHB utilizes Large Language Models (LLMs) to predict responses, reviews, and ratings tailored to individuals, guaranteeing results that are both coherent and contextually appropriate. USHB is capable of delivering precise, detailed simulations that closely mimic human behavior. We evaluated USHB using datasets from Yelp, Amazon, and Goodreads, where it consistently outperformed baseline methods. Moreover, USHB demonstrated strong generalization and maintained stable performance across a variety of model configurations. These advancements make USHB a valuable contribution to dynamic, context-aware behavior simulation, achieving a top-three ranking in the 2025 AgentSociety Challenge. Our codes are available at https://github.com/jnuaipr/AgentsChallenge.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2993–2997},
numpages = {5},
keywords = {agent, if-then rules, knowledge mining, large language model, reasoning, relationship graph, user-and-item modeling},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701716.3715486,
author = {Bin Rabiah, Ahmad and Sadeq, Nafis and McAuley, Julian},
title = {Bridging Conversational and Collaborative Signals for Conversational Recommendation},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715486},
doi = {10.1145/3701716.3715486},
abstract = {Conversational recommendation systems (CRS) leverage contextual information from conversations to generate recommendations but often struggle due to a lack of collaborative filtering (CF) signals, which capture user-item interaction patterns essential for accurate recommendations. We introduce Reddit-ML32M, a dataset that links Reddit conversations with interactions on MovieLens 32M, to enrich item representations by leveraging collaborative knowledge and addressing interaction sparsity in conversational datasets. We propose an LLM-based framework that uses Reddit-ML32M to align LLM-generated recommendations with CF embeddings, refining rankings for better performance. We evaluate our framework against three sets of baselines: CF-based recommenders using only interactions from CRS tasks, traditional CRS models, and LLM-based methods relying on conversational context without item representations. Our approach achieves consistent improvements, including a 12.32% increase in Hit Rate and a 9.9% improvement in NDCG, outperforming the best-performing baseline that relies on conversational context but lacks collaborative item representations.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {878–882},
numpages = {5},
keywords = {conversational recommendation, large language models},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696410.3714934,
author = {De, Soham and Bakker, Michiel A. and Baxter, Jay and Saveski, Martin},
title = {Supernotes: Driving Consensus in Crowd-Sourced Fact-Checking},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714934},
doi = {10.1145/3696410.3714934},
abstract = {X's Community Notes, a crowd-sourced fact-checking system, allows users to annotate potentially misleading posts. Notes rated as helpful by a diverse set of users are prominently displayed below the original post. While demonstrably effective at reducing misinformation's impact when notes are displayed, there is an opportunity for notes to appear on many more posts: for 91% of posts where at least one note is proposed, no notes ultimately achieve sufficient support from diverse users to be shown on the platform. This motivates the development of Supernotes: AI-generated notes that synthesize information from several existing community notes and are written to foster consensus among a diverse set of users. Our framework uses an LLM to generate many diverse Supernote candidates from existing proposed notes. These candidates are then evaluated by a novel scoring model, trained on millions of historical Community Notes ratings, selecting candidates that are most likely to be rated helpful by a diverse set of users. To test our framework, we ran a human subjects experiment in which we asked participants to compare the Supernotes generated by our framework to the best existing community notes for 100 sample posts. We found that participants rated the Supernotes as significantly more helpful, and when asked to choose between the two, preferred the Supernotes 75.2% of the time. Participants also rated the Supernotes more favorably than the best existing notes on quality, clarity, coverage, context, and argumentativeness. Finally, in a follow-up experiment, we asked participants to compare the Supernotes against LLM-generated summaries and found that the participants rated the Supernotes significantly more helpful, demonstrating that both the LLM-based candidate generation and the consensus-driven scoring play crucial roles in creating notes that effectively build consensus among diverse users.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3751–3761},
numpages = {11},
keywords = {community notes, crowd-sourced fact-checking, misinformation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696410.3714691,
author = {Hirsch, Sharon and Zitnitski, Lilach and Novgorodov, Slava and Guy, Ido and Shapira, Bracha},
title = {Graph Meets LLM for Review Personalization based on User Votes},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714691},
doi = {10.1145/3696410.3714691},
abstract = {Review personalization aims at presenting the most relevant reviews of a product according to the preferences of the individual user. Existing studies of review personalization use the reviews authored by the user as a proxy for their preferences, and henceforth as a means for learning and evaluating personalization quality. In this work, we suggest using review votes rather than authorship for personalization. We propose MAGLLM, an approach that leverages heterogeneous graphs for modeling the relationships among reviews, products, and users, with large language model (LLM) to enrich user representation on the graph. Our evaluation over a unique public dataset that includes user voting information indicates that the vote signal yields substantially higher personalization performance across a variety of recommendation methods and e-commerce domains. It also indicates that our graph-LLM approach outperforms comparative baselines and algorithmic alternatives. We conclude with concrete recommendations for e-commerce platforms seeking to enhance their review personalization experience.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2948–2958},
numpages = {11},
keywords = {e-commerce, large language models, product reviews, recommender systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3589334.3645598,
author = {Wang, Bohao and Chen, Jiawei and Li, Changdong and Zhou, Sheng and Shi, Qihao and Gao, Yang and Feng, Yan and Chen, Chun and Wang, Can},
title = {Distributionally Robust Graph-based Recommendation System},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645598},
doi = {10.1145/3589334.3645598},
abstract = {With the capacity to capture high-order collaborative signals, Graph Neural Networks (GNNs) have emerged as powerful methods in Recommender Systems (RS). However, their efficacy often hinges on the assumption that training and testing data share the same distribution (aka IID assumption), and exhibits significant declines under distribution shifts. Distribution shifts commonly arises in RS, often attributed to the dynamic nature of user preferences or ubiquitous biases during data collection in RS. Despite its significance, researches on GNN-based recommendation against distribution shift are still sparse. To bridge this gap, we propose Distributionally Robust GNN (DR-GNN) that incorporates Distributional Robust Optimization (DRO) into the GNN-based recommendation. DR-GNN addresses two core challenges: 1) To enable DRO to cater to graph data intertwined with GNN, we reinterpret GNN as a graph smoothing regularizer, thereby facilitating the nuanced application of DRO; 2) Given the typically sparse nature of recommendation data, which might impede robust optimization, we introduce slight perturbations in the training distribution to expand its support. Notably, while DR-GNN involves complex optimization, it can be implemented easily and efficiently. Our extensive experiments validate the effectiveness of DR-GNN against three typical distribution shifts. The code is available at https://github.com/WANGBohaO-jpg/DR-GNN.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3777–3788},
numpages = {12},
keywords = {graph recommendation, out of distribution, robust},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3543507.3583363,
author = {Chen, Jiawei and Wu, Junkang and Wu, Jiancan and Cao, Xuezhi and Zhou, Sheng and He, Xiangnan},
title = {Adap-τ : Adaptively Modulating Embedding Magnitude for Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583363},
doi = {10.1145/3543507.3583363},
abstract = {Recent years have witnessed the great successes of embedding-based methods in recommender systems. Despite their decent performance, we argue one potential limitation of these methods — the embedding magnitude has not been explicitly modulated, which may aggravate popularity bias and training instability, hindering the model from making a good recommendation. It motivates us to leverage the embedding normalization in recommendation. By normalizing user/item embeddings to a specific value, we empirically observe impressive performance gains (9% on average) on four real-world datasets. Although encouraging, we also reveal a serious limitation when applying normalization in recommendation — the performance is highly sensitive to the choice of the temperature τ which controls the scale of the normalized embeddings. To fully foster the merits of the normalization while circumvent its limitation, this work studied on how to adaptively set the proper τ. Towards this end, we first make a comprehensive analyses of τ to fully understand its role on recommendation. We then accordingly develop an adaptive fine-grained strategy Adap-τ for the temperature with satisfying four desirable properties including adaptivity, personalized, efficiency and model-agnostic. Extensive experiments have been conducted to validate the effectiveness of the proposal. The code is available at https://github.com/junkangwu/Adap_tau.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1085–1096},
numpages = {12},
keywords = {Adaptiveness, Recommendation system, Temperature},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3485447.3512010,
author = {Wan, Qi and He, Xiangnan and Wang, Xiang and Wu, Jiancan and Guo, Wei and Tang, Ruiming},
title = {Cross Pairwise Ranking for Unbiased Item Recommendation},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512010},
doi = {10.1145/3485447.3512010},
abstract = {Most recommender systems optimize the model on observed interaction data, which is affected by the previous exposure mechanism and exhibits many biases like popularity bias. The loss functions, such as the mostly used pointwise Binary Cross-Entropy and pairwise Bayesian Personalized Ranking, are not designed to consider the biases in observed data. As a result, the model optimized on the loss would inherit the data biases, or even worse, amplify the biases. For example, a few popular items take up more and more exposure opportunities, severely hurting the recommendation quality on niche items — known as the notorious Mathew effect. In this work, we develop a new learning paradigm named Cross Pairwise Ranking (CPR) that achieves unbiased recommendation without knowing the exposure mechanism. Distinct from inverse propensity scoring (IPS), we change the loss term of a sample — we innovatively sample multiple observed interactions once and form the loss as the combination of their predictions. We prove in theory that this way offsets the influence of user/item propensity on the learning, removing the influence of data biases caused by the exposure mechanism. Advantageous to IPS, our proposed CPR ensures unbiased learning for each training instance without the need of setting the propensity scores. Experimental results demonstrate the superiority of CPR over state-of-the-art debiasing solutions in both model generalization and training efficiency. The codes are available at https://github.com/Qcactus/CPR.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {2370–2378},
numpages = {9},
keywords = {Popularity Bias, Recommendation, Unbiased Learning-to-Rank},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3038912.3052569,
author = {He, Xiangnan and Liao, Lizi and Zhang, Hanwang and Nie, Liqiang and Hu, Xia and Chua, Tat-Seng},
title = {Neural Collaborative Filtering},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052569},
doi = {10.1145/3038912.3052569},
abstract = {In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback.Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items.By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {173–182},
numpages = {10},
keywords = {neural networks, matrix factorization, implicit feedback, deep learning, collaborative filtering},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3589334.3645601,
author = {Cho, Yoon-Sik},
title = {Decoupled Variational Graph Autoencoder for Link Prediction},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645601},
doi = {10.1145/3589334.3645601},
abstract = {Link prediction is an important learning task for graph-structured data, and has become increasingly popular due to its wide application areas. Graph Neural Network (GNN)-based approaches including Variational Graph Autoencoder (VGAE) have achieved promising performance on link prediction outperforming conventional models which use hand-crafted features. VGAE learns latent node representations and predicts links based on the similarities between nodes. While the inner product based decoder effectively utilizes the node representations for link prediction, it exhibits sub-optimal performance due to the intrinsic limitation of the inner product. We found that the the cosine similarity and norm simultaneously try to explain the link probability, which hinders the gradient flow during training. We also point out the message passing scheme is unexpectedly dominated by the nodes with large norm values. In this paper, we propose a stochastic VGAE-based method that can effectively decouple the norm and angle in the embeddings. Specifically, we relate the cosine similarity and norm to two fundamental principles in graph: homophily and node popularity respectively. Our learning scheme is based on a hard expectation maximization learning method; we infer which of the two has been exerted for link formation, and subsequently optimize based on this guess. Through extensive experiments on real-world datasets, we demonstrate our model outperforms the existing state-of-the-art methods on link prediction and achieves comparable performances on other downstream tasks such as node classification and clustering. Our code is at https://github.com/yoonsikcho/d-vgae.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {839–849},
numpages = {11},
keywords = {graph neural networks, link prediction, variational graph autoencoder},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645536,
author = {Yoo, Hyunsik and Zeng, Zhichen and Kang, Jian and Qiu, Ruizhong and Zhou, David and Liu, Zhining and Wang, Fei and Xu, Charlie and Chan, Eunice and Tong, Hanghang},
title = {Ensuring User-side Fairness in Dynamic Recommender Systems},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645536},
doi = {10.1145/3589334.3645536},
abstract = {User-side group fairness is crucial for modern recommender systems, alleviating performance disparities among user groups defined by sensitive attributes like gender, race, or age. In the everevolving landscape of user-item interactions, continual adaptation to newly collected data is crucial for recommender systems to stay aligned with the latest user preferences. However, we observe that such continual adaptation often worsen performance disparities. This necessitates a thorough investigation into user-side fairness in dynamic recommender systems. This problem is challenging due to distribution shifts, frequent model updates, and nondifferentiability of ranking metrics. To our knowledge, this paper presents the first principled study on ensuring user-side fairness in dynamic recommender systems. We start with theoretical analyses on fine-tuning v.s. retraining, showing that the best practice is incremental fine-tuning with restart. Guided by our theoretical analyses, we propose FAir Dynamic rEcommender (FADE), an end-to-end fine-tuning framework to dynamically ensure user-side fairness over time. To overcome the non-differentiability of recommendation metrics in the fairness loss, we further introduce Differentiable Hit (DH) as an improvement over the recent NeuralNDCG method, not only alleviating its gradient vanishing issue but also achieving higher efficiency. Besides that, we also address the instability issue of the fairness loss by leveraging the competing nature between the recommendation loss and the fairness loss. Through extensive experiments on real-world datasets, we demonstrate that FADE effectively and efficiently reduces performance disparities with little sacrifice in the overall recommendation performance.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3667–3678},
numpages = {12},
keywords = {dynamic updates, recommender systems, user-side fairness},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3696410.3714789,
author = {Zhang, Qi and Wu, Qian and Lai, Zeqi and Li, Jihao and Li, Hewu and Liu, Yuyu and Li, Yuanjie and Liu, Jun},
title = {Spache: Accelerating Ubiquitous Web Browsing via Schedule-Driven Space Caching},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714789},
doi = {10.1145/3696410.3714789},
abstract = {In this paper, we perform a systematic study to explore a pivotal problem facing the web community: is current distributed web cache ready for future satellite Internet? First, through a worldwide performance measurement based on the RIPE Atlas platform and Starlink, the largest low-earth orbit (LEO) satellite network (LSN) today, we identify that the uneven deployment of current distributed cache servers, inter-ISP meandering routes and the last-mile congestion on LEO links jointly prevent existing terrestrial web cache from providing low-latency web access for users in emerging LSNs. Second, we propose Spache, a novel web caching system which addresses the limitations of existing ground-only cache by exploiting a bold idea: integrating web cache into LEO satellites to achieve ubiquitous and low-latency web services. Specifically, Spache leverages a key feature of LSNs called communication schedule to efficiently prefetch web contents on satellites, and adopts a schedule-driven partitioning strategy to avoid cache pollution involved by LEO mobility. Finally, we implement a prototype of Spache, and evaluate it based on real-world HTTP traces and data-driven LSN simulation. Extensive evaluations demonstrate that as compared to existing distributed caching solutions, Spache can improve cache hit ratio by 19.8% on average, reduce latency by up to 17.7%, and maintains consistently low web browsing latency for global LSN users.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {740–750},
numpages = {11},
keywords = {caching., cdn performance, leo satellite networks},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701716.3715198,
author = {Farseev, Aleks and Nikolenko, Sergey and Yang, Qi and Lepikhin, Kirill and You, Da-Min and Chu-Farseeva, Yu-Yi and Gossoudarev, Ilia and Ongpin, Marlo},
title = {SOEX: Explainable AI for Competitor Communications Analytics},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715198},
doi = {10.1145/3701716.3715198},
abstract = {In this demonstration, we present SOEX, an advanced AI system tailored for enhancing online marketing through the strategic use of large language models and predictive analytics. SOEX excels in analyzing vast amounts of online content data, enabling marketers to effectively plan and refine their strategies by extracting and utilizing key insights from competitor content and market trends. The system specializes in identifying content pillars-such as target audiences, consumer needs, and product features-and leveraging these pillars to generate detailed customer personas and narratives. By focusing on the initial stages of marketing, such as strategic planning and content pillar analysis, SOEX helps marketers understand and segment their audience more precisely. The system's ability to generate data-driven stories and personas from analyzed content enhances the planning phase of marketing campaigns, ensuring that strategies are both impactful and aligned with audience expectations. Our evaluations show that SOEX significantly aids marketers in navigating and interpreting complex data, leading to more informed decision-making and optimized marketing planning.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2823–2826},
numpages = {4},
keywords = {digital marketing, explainable ai, large language models, marketing strategy},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3589334.3645518,
author = {Wang, Yifan and Sun, Peijie and Ma, Weizhi and Zhang, Min and Zhang, Yuan and Jiang, Peng and Ma, Shaoping},
title = {Intersectional Two-sided Fairness in Recommendation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645518},
doi = {10.1145/3589334.3645518},
abstract = {Fairness of recommender systems (RS) has attracted increasing attention recently. Based on the involved stakeholders, the fairness of RS can be divided into user fairness, item fairness, and two-sided fairness which considers both user and item fairness simultaneously. However, we argue that the intersectional two-sided unfairness may still exist even if the RS is two-sided fair, which is observed and shown by empirical studies on real-world data in this paper, and has not been well-studied previously. To mitigate this problem, we propose a novel approach called Intersectional Two-sided Fairness Recommendation (ITFR). Our method utilizes a sharpness-aware loss to perceive disadvantaged groups, and then uses collaborative loss balance to develop consistent distinguishing abilities for different intersectional groups. Additionally, predicted score normalization is leveraged to align positive predicted scores to fairly treat positives in different intersectional groups. Extensive experiments and analyses on three public datasets show that our proposed approach effectively alleviates the intersectional two-sided unfairness and consistently outperforms previous state-of-the-art methods.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3609–3620},
numpages = {12},
keywords = {fairness, intersectional group, recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645589,
author = {Liu, Shuo and Shen, Junhao and Qian, Hong and Zhou, Aimin},
title = {Inductive Cognitive Diagnosis for Fast Student Learning in Web-Based Intelligent Education Systems},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645589},
doi = {10.1145/3589334.3645589},
abstract = {Cognitive diagnosis aims to gauge students' mastery levels based on their response logs. Serving as a pivotal module in web-based online intelligent education systems (WOIESs), it plays an upstream and fundamental role in downstream tasks like learning item recommendation and computerized adaptive testing. WOIESs are open learning environment where numerous new students constantly register and complete exercises. In WOIESs, efficient cognitive diagnosis is crucial to fast feedback and accelerating student learning. However, the existing cognitive diagnosis methods always employ intrinsically transductive student-specific embeddings, which become slow and costly due to retraining when dealing with new students who are unseen during training. To this end, this paper proposes an inductive cognitive diagnosis model (ICDM) for fast new students' mastery levels inference in WOIESs. Specifically, in ICDM, we propose a novel student-centered graph (SCG). Rather than inferring mastery levels through updating student-specific embedding, we derive the inductive mastery levels as the aggregated outcomes of students' neighbors in SCG. Namely, SCG enables to shift the task from finding the most suitable student-specific embedding that fits the response logs to finding the most suitable representations for different node types in SCG, and the latter is more efficient since it no longer requires retraining. To obtain this representation, ICDM consists of a construction-aggregation-generation-transformation process to learn the final representation of students, exercises and concepts. Extensive experiments across real-world datasets show that, compared with the existing cognitive diagnosis methods that are always transductive, ICDM is much more faster while maintains the competitive inference performance for new students.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4260–4271},
numpages = {12},
keywords = {cognitive diagnosis, inductive learning, web-based online intelligent education systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3442442.3452341,
author = {Vardi, Elad and Muchnik, Lev and Conway, Alex and Breakstone, Micha},
title = {WikiShark: An Online Tool for Analyzing Wikipedia Traffic and Trends},
year = {2021},
isbn = {9781450383134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442442.3452341},
doi = {10.1145/3442442.3452341},
abstract = {Wikipedia is a major source of information utilized by internet users around the globe for fact-checking and access to general, encyclopedic information. For researchers, it offers an unprecedented opportunity to measure how societies respond to events and how our collective perception of the world evolves over time and in response to events. Wikipedia use and the reading patterns of its users reflect our collective interests and the way they are expressed in our search for information – whether as part of fleeting, zeitgeist-fed trends or long-term – on most every topic, from personal to business, through political, health-related, academic and scientific. In a very real sense, events are defined by how we interpret them and how they affect our perception of the context in which they occurred, rendering Wikipedia invaluable for understanding events and their context. This paper introduces WikiShark (www.wikishark.com) – an online tool that allows researchers to analyze Wikipedia traffic and trends quickly and effectively, by (1) instantly querying pageview traffic data; (2) comparing traffic across articles; (3) surfacing and analyzing trending topics; and (4) easily leveraging findings for use in their own research.},
booktitle = {Companion Proceedings of the Web Conference 2021},
pages = {558–571},
numpages = {14},
keywords = {Wikipedia Trends, Wikipedia Page Views, WikiShark, Data Dumps},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3589335.3648310,
author = {Zhang, Zhiyuan and Zhang, Qichao and Wu, Xiaoxu and Shi, Xiaowen and Liao, Guogang and Wang, Yongkang and Wang, Xingxing and Zhao, Dongbin},
title = {User Response Modeling in Reinforcement Learning for Ads Allocation},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3648310},
doi = {10.1145/3589335.3648310},
abstract = {User response modeling can enhance the learning of user representations and further improve the reinforcement learning (RL) recommender agent. However, as users' behaviors are influenced by their long-term preferences and short-term stochastic factors (e.g., weather, mood, or fashion trends), it remains challenging for previous works focusing on recurrent neural network-based user response modeling. Meanwhile, due to the dynamic interests of users, it is often unrealistic to assume the dynamics of users are stationary. Drawing inspiration from opponent modeling, we propose a novel network structure, Deep User Q-Network (DUQN), incorporating a user response probabilistic model into the Q-learning ads allocation strategy to capture the effect of the non-stationary user policy on Q-values. Moreover, we utilize the Recurrent State-Space Model (RSSM) to develop the user response model, which includes deterministic and stochastic components, enabling us to fully consider user long-term preferences and short-term stochastic factors. In particular, we design a RetNet version of RSSM (R-RSSM) to support parallel computation. The R-RSSM model can be further used for multi-step predictions to enable bootstrapping over multiple steps simultaneously. Finally, we conduct extensive experiments on a large-scale offline dataset from the Meituan food delivery platform and a public benchmark. Experimental results show that our method yields superior performance to state-of-the-art (SOTA) baselines. Moreover, our model demonstrates a significant improvement in the online A/B test and has been fully deployed on the industrial Meituan platform, serving more than 500 million customers.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {131–140},
numpages = {10},
keywords = {ads allocation, reinforcement learning, user response modeling},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3701716.3717850,
author = {Liu, Xinyi and Wang, Ruijie and Sun, Dachun and Hakkani Tur, Dilek and Abdelzaher, Tarek},
title = {Uncovering Cross-Domain Recommendation Ability of Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717850},
doi = {10.1145/3701716.3717850},
abstract = {Cross-Domain Recommendation (CDR) seeks to enhance item retrieval in low-resource domains by transferring knowledge from high-resource domains. While recent advancements in Large Language Models (LLMs) have demonstrated their potential in Recommender Systems (RS), their ability to effectively transfer domain knowledge for improved recommendations remains underexplored. To bridge this gap, we propose LLM4CDR, a novel CDR pipeline that constructs context-aware prompts by leveraging users' purchase history sequences from a source domain along with shared features between source and target domains. Through extensive experiments, we show that LLM4CDR achieves strong performance, particularly when using LLMs with large parameter sizes and when the source and target domains exhibit smaller domain gaps. For instance, incorporating CD &amp; Vinyl purchase history for recommendations in Movies &amp; TV yields a 64.28% MAP@1 improvement. We further investigate how key factors-source domain data, domain gap, prompt design, and LLM size-impact LLM4CDR's effectiveness in CDR tasks. Our results highlight that LLM4CDR excels when leveraging a single, closely related source domain and benefits significantly from larger LLMs. These insights pave the way for future research on LLM-driven cross-domain recommendations.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2736–2743},
numpages = {8},
keywords = {cross-domain recommendation, large language models, recommender systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3038912.3052684,
author = {Hessel, Jack and Lee, Lillian and Mimno, David},
title = {Cats and Captions vs. Creators and the Clock: Comparing Multimodal Content to Context in Predicting Relative Popularity},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052684},
doi = {10.1145/3038912.3052684},
abstract = {The content of today's social media is becoming more and more rich, increasingly mixing text, images, videos, and audio. It is an intriguing research question to model the interplay between these different modes in attracting user attention and engagement. But in order to pursue this study of multimodal content, we must also account for context: timing effects, community preferences, and social factors (e.g., which authors are already popular) also affect the amount of feedback and reaction that social-media posts receive. In this work, we separate out the influence of these non-content factors in several ways. First, we focus on ranking pairs of submissions posted to the same community in quick succession, e.g., within 30 seconds; this framing encourages models to focus on time-agnostic and community-specific content features. Within that setting, we determine the relative performance of author vs. content features. We find that victory usually belongs to "cats and captions," as visual and textual features together tend to outperform identity-based features. Moreover, our experiments show that when considered in isolation, simple unigram text features and deep neural network visual features yield the highest accuracy individually, and that the combination of the two modalities generally leads to the best accuracies overall.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {927–936},
numpages = {10},
keywords = {social media, reddit, multimodal, language modeling, image processing},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3442381.3450015,
author = {Wu, Le and Chen, Lei and Shao, Pengyang and Hong, Richang and Wang, Xiting and Wang, Meng},
title = {Learning Fair Representations for Recommendation: A Graph-based Perspective},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450015},
doi = {10.1145/3442381.3450015},
abstract = {As a key application of artificial intelligence, recommender systems are among the most pervasive computer aided systems to help users find potential items of interests. Recently, researchers paid considerable attention to fairness issues for artificial intelligence applications. Most of these approaches assumed independence of instances, and designed sophisticated models to eliminate the sensitive information to facilitate fairness. However, recommender systems differ greatly from these approaches as users and items naturally form a user-item bipartite graph, and are collaboratively correlated in the graph structure. In this paper, we propose a novel graph based technique for ensuring fairness of any recommendation models. Here, the fairness requirements refer to not exposing sensitive feature set in the user modeling process. Specifically, given the original embeddings from any recommendation models, we learn a composition of filters that transform each user’s and each item’s original embeddings into a filtered embedding space based on the sensitive feature set. For each user, this transformation is achieved under the adversarial learning of a user-centric graph, in order to obfuscate each sensitive feature between both the filtered user embedding and the sub graph structures of this user. Finally, extensive experimental results clearly show the effectiveness of our proposed model for fair recommendation. We publish the source code at https://github.com/newlei/FairGo.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {2198–2208},
numpages = {11},
keywords = {user modeling, graph based recommendation, fairness, fair Representation learning, fair Recommendation},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3701716.3715872,
author = {Pan, Junwei and Zhang, Zhilin and Zhu, Han and Xu, Jian and Jiang, Jie and Zheng, Bo},
title = {Computational Advertising: Recent Advances},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715872},
doi = {10.1145/3701716.3715872},
abstract = {Computational advertising is one of the most successful application scenarios of machine learning and artificial intelligence. This tutorial is designed to review the latest progress of several critical areas in computational advertising: matching, prediction, auction and bidding. Particularly, with the recent advances in generative AI such as large language models, there is a growing interest in further enhancing these areas with these techniques. In this tutorial, we first introduce the recent advances in matching, including its architecture alternatives, model developments, and how it co-evolves with the ad products which distinguishes itself from that in recommendation products. We then review the recent advances in prediction, with a focus on topics such as feature interactions, user interest models, and multi-task/domain learning. We will show how these building bricks constitute large prediction models and LLM-enhanced/LLM-based prediction models. Then, we discuss auction and bidding, a unique area in computational advertising. Both traditional and learning-based auctions will be introduced, followed by their applications in real-world ad products. Given the auction designs, we show how bidding evolves from control-based, to reinforcement learning-based, and most recently to generative AI-based. Our aim is to help the audience grasp the recent developments in computational advertising, as well as to spark inspiration for future research.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {37–40},
numpages = {4},
keywords = {auction, bidding, click-through rate prediction, generative models, matching, recommendation systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3308558.3313488,
author = {Fan, Wenqi and Ma, Yao and Li, Qing and He, Yuan and Zhao, Eric and Tang, Jiliang and Yin, Dawei},
title = {Graph Neural Networks for Social Recommendation},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313488},
doi = {10.1145/3308558.3313488},
abstract = {In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key. However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the user-user social graph and the user-item graph). To address the three aforementioned challenges simultaneously, in this paper, we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec, which coherently models two graphs and heterogeneous strengths. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework GraphRec.},
booktitle = {The World Wide Web Conference},
pages = {417–426},
numpages = {10},
keywords = {Social Recommendation, Social Network, Recommender Systems, Neural Networks, Graph Neural Networks},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3308558.3313449,
author = {Mukherjee, Subhabrata and Guennemann, Stephan},
title = {GhostLink: Latent Network Inference for Influence-aware Recommendation},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313449},
doi = {10.1145/3308558.3313449},
abstract = {Social influence plays a vital role in shaping a user's behavior in online communities dealing with items of fine taste like movies, food, and beer. For online recommendation, this implies that users' preferences and ratings are influenced due to other individuals. Given only time-stamped reviews of users, can we find out who-influences-whom, and characteristics of the underlying influence network? Can we use this network to improve recommendation? While prior works in social-aware recommendation have leveraged social interaction by considering the observed social network of users, many communities like Amazon, Beeradvocate, and Ratebeer do not have explicit user-user links. Therefore, we propose GhostLink, an unsupervised probabilistic graphical model, to automatically learn the latent influence network underlying a review community - given only the temporal traces (timestamps) of users' posts and their content. Based on extensive experiments with four real-world datasets with 13 million reviews, we show that GhostLink improves item recommendation by around 23% over state-of-the-art methods that do not consider this influence. As additional use-cases, we show that GhostLink can be used to differentiate between users' latent preferences and influenced ones, as well as to detect influential users based on the learned influence graph.},
booktitle = {The World Wide Web Conference},
pages = {1310–1320},
numpages = {11},
keywords = {Social Recommendation, Social Influence, Review Community, Generative Model, Content Analysis},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2566486.2567996,
author = {Khosla, Aditya and Das Sarma, Atish and Hamid, Raffay},
title = {What makes an image popular?},
year = {2014},
isbn = {9781450327442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2566486.2567996},
doi = {10.1145/2566486.2567996},
abstract = {Hundreds of thousands of photographs are uploaded to the internet every minute through various social networking and photo sharing platforms. While some images get millions of views, others are completely ignored. Even from the same users, different photographs receive different number of views. This begs the question: What makes a photograph popular? Can we predict the number of views a photograph will receive even before it is uploaded? These are some of the questions we address in this work. We investigate two key components of an image that affect its popularity, namely the image content and social context. Using a dataset of about 2.3 million images from Flickr, we demonstrate that we can reliably predict the normalized view count of images with a rank correlation of 0.81 using both image content and social cues. In this paper, we show the importance of image cues such as color, gradients, deep learning features and the set of objects present, as well as the importance of various social cues such as number of friends or number of photos uploaded that lead to high or low popularity of images.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {867–876},
numpages = {10},
keywords = {regression, popularity, images, flickr, deep learning},
location = {Seoul, Korea},
series = {WWW '14}
}

@inproceedings{10.1145/3442381.3449999,
author = {Kim, Jayoung and Jeon, Jinsung and Lee, Jaehoon and Hyeong, Jihyeon and Park, Noseong},
title = {OCT-GAN: Neural ODE-based Conditional Tabular GANs},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449999},
doi = {10.1145/3442381.3449999},
abstract = {Synthesizing tabular data is attracting much attention these days for various purposes. With sophisticate synthetic data, for instance, one can augment its training data. For the past couple of years, tabular data synthesis techniques have been greatly improved. Recent work made progress to address many problems in synthesizing tabular data, such as the imbalanced distribution and multimodality problems. However, the data utility of state-of-the-art methods is not satisfactory yet. In this work, we significantly improve the utility by designing our generator and discriminator based on neural ordinary differential equations (NODEs). After showing that NODEs have theoretically preferred characteristics for generating tabular data, we introduce our designs. The NODE-based discriminator performs a hidden vector evolution trajectory-based classification rather than classifying with a hidden vector at the last layer only. Our generator also adopts an ODE layer at the very beginning of its architecture to transform its initial input vector (i.e., the concatenation of a noisy vector and a condition vector in our case) onto another latent vector space suitable for the generation process. We conduct experiments with 13 datasets, including but not limited to insurance fraud detection, online news article prediction, and so on, and our presented method outperforms other state-of-the-art tabular data synthesis methods in many cases of our classification, regression, and clustering experiments.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {1506–1515},
numpages = {10},
keywords = {Tabular Data Synthesis, Neural Ordinary Differential Equations, Generative Adversarial Networks},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3543873.3587374,
author = {Haratinezhad Torbati, Ghazaleh and Weikum, Gerhard and Yates, Andrew},
title = {Search-based Recommendation: the Case for Difficult Predictions},
year = {2023},
isbn = {9781450394192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543873.3587374},
doi = {10.1145/3543873.3587374},
abstract = {Recommender systems have achieved impressive results on benchmark datasets. However, the numbers are often influenced by assumptions made on the data and evaluation mode. This work questions and revises these assumptions, to study and improve the quality, particularly for the difficult case of search-based recommendations. Users start with a personally liked item as a query and look for similar items that match their tastes. User satisfaction requires discovering truly unknown items: new authors of books rather than merely more books of known writers. We propose a unified system architecture that combines interaction-based and content-based signals and leverages language models for Transformer-powered predictions. We present new techniques for selecting negative training samples, and investigate their performance in the underexplored search-based evaluation mode.},
booktitle = {Companion Proceedings of the ACM Web Conference 2023},
pages = {318–321},
numpages = {4},
keywords = {language model, negative sampling, recommender system, search-based prediction, transformer},
location = {Austin, TX, USA},
series = {WWW '23 Companion}
}

@inproceedings{10.1145/3442381.3449926,
author = {Wu, Jinze and Liu, Qi and Huang, Zhenya and Ning, Yuting and Wang, Hao and Chen, Enhong and Yi, Jinfeng and Zhou, Bowen},
title = {Hierarchical Personalized Federated Learning for User Modeling},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449926},
doi = {10.1145/3442381.3449926},
abstract = {User modeling aims to capture the latent characteristics of users from their behaviors, and is widely applied in numerous applications. Usually, centralized user modeling suffers from the risk of privacy leakage. Instead, federated user modeling expects to provide a secure multi-client collaboration for user modeling through federated learning. Existing federated learning methods are mainly designed for consistent clients, which cannot be directly applied to practical scenarios, where different clients usually store inconsistent user data. Therefore, it is a crucial demand to design an appropriate federated solution that can better adapt to user modeling tasks, and however, meets following critical challenges: 1) Statistical heterogeneity. The distributions of user data in different clients are not always independently identically distributed which leads to personalized clients; 2) Privacy heterogeneity. User data contains both public and private information, which have different levels of privacy. It means we should balance different information to be shared and protected; 3) Model heterogeneity. The local user models trained with client records are heterogeneous which need flexible aggregation in the server. In this paper, we propose a novel client-server architecture framework, namely Hierarchical Personalized Federated Learning (HPFL) to serve federated learning in user modeling with inconsistent clients. In the framework, we first define hierarchical information to finely partition the data with privacy heterogeneity. On this basis, the client trains a user model which contains different components designed for hierarchical information. Moreover, client processes a fine-grained personalized update strategy to update personalized user model for statistical heterogeneity. Correspondingly, the server completes a differentiated component aggregation strategy to flexibly aggregate heterogeneous user models in the case of privacy and model heterogeneity. Finally, we conduct extensive experiments on real-world datasets, which demonstrate the effectiveness of the HPFL framework.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {957–968},
numpages = {12},
keywords = {User modeling, Privacy heterogeneity, Model personalization, Federated learning},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3308558.3313582,
author = {Chen, Jiawei and Wang, Can and Zhou, Sheng and Shi, Qihao and Feng, Yan and Chen, Chun},
title = {SamWalker: Social Recommendation with Informative Sampling Strategy},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313582},
doi = {10.1145/3308558.3313582},
abstract = {Recommendation from implicit feedback is a highly challenging task due to the lack of reliable negative feedback data. Only positive feedback are observed and the unobserved feedback can be attributed to two reasons: unknow or dislike. Existing methods address this challenge by treating all the un-observed data as negative (dislike) but downweight the confidence of these data. However, this treatment causes two problems: (1) Confidence weights of the unobserved data are usually assigned manually, which lack flexible and may create empirical bias in evaluating user's preference. (2) To handle massive volume of the unobserved feedback data, most of the existing methods rely on stochastic inference and data sampling strategies. However, since users are only aware of a very small fraction of items in a large dataset, it is difficult for existing samplers to select informative training instances in which the user really dislikes the item rather than does not know it. To address the above two problems, we propose a new recommendation method SamWalker that leverages social information to infer data confidence and guide the sampling process. By modeling data confidence with a social context-aware function, SamWalker can adaptively specify different weights to different data based on users' social contexts. Further, a personalized random-walk-based sampling strategy is developed to adaptively draw informative training instances, which can speed up gradient estimation and reduce sampling variance. Extensive experiments on three real-world datasets demonstrate the superiority of the proposed SamWalker method and its sampling strategy.},
booktitle = {The World Wide Web Conference},
pages = {228–239},
numpages = {12},
keywords = {Social recommendation, Sampling, Implicit feedback},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3589335.3648312,
author = {Chang, Bo and Meng, Changping and Ma, He and Chang, Shuo and Gu, Yang and Peng, Yajun and Feng, Jingchen and Zhang, Yaping and Bi, Shuchao and Chi, Ed H. and Chen, Minmin},
title = {Cluster Anchor Regularization to Alleviate Popularity Bias in Recommender Systems},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3648312},
doi = {10.1145/3589335.3648312},
abstract = {Recommender systems are essential for finding personalized content for users on online platforms. These systems are often trained on historical user interaction data, which collects user feedback on system recommendations. This creates a feedback loop leading to popularity bias; popular content is over-represented in the data, better learned, and thus recommended even more. Less popular content struggles to reach its potential audiences. Popularity bias limits the diversity of content that users are exposed to, and makes it harder for new creators to gain traction. Existing methods to alleviate popularity bias tend to trade off the performance of popular items. In this work, we propose a new method for alleviating popularity bias in recommender systems, called the cluster anchor regularization, which partitions the large item corpus into hierarchical clusters, and then leverages the cluster information of each item to facilitate transfer learning from head items to tail items. Our results demonstrate the effectiveness of the proposed method with offline analyses and live experiments on a large-scale industrial recommendation platform, where it significantly increases tail recommendation without hurting the overall user experience.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {151–160},
numpages = {10},
keywords = {hierarchical clustering, popularity bias, recommender systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3696410.3714849,
author = {Zhao, Chu and Yang, Enneng and Liang, Yuliang and Lan, Pengxiang and Liu, Yuting and Zhao, Jianzhe and Guo, Guibing and Wang, Xingwei},
title = {Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714849},
doi = {10.1145/3696410.3714849},
abstract = {Graph Neural Networks (GNNs)-based recommendation algorithms typically assume that training and testing data are drawn from independent and identically distributed (IID) spaces. However, this assumption often fails in the presence of out-of-distribution (OOD) data, resulting in significant performance degradation. In this study, we construct a Structural Causal Model (SCM) to analyze interaction data, revealing that environmental confounders (e.g., the COVID-19 pandemic) lead to unstable correlations in GNN-based models, thus impairing their generalization to OOD data. To address this issue, we propose a novel approach, graph representation learning via causal diffusion (CausalDiffRec) for OOD recommendation. This method enhances the model's generalization on OOD data by eliminating environmental confounding factors and learning invariant graph representations. Specifically, we use backdoor adjustment and variational inference to infer the real environmental distribution, thereby eliminating the impact of environmental confounders. This inferred distribution is then used as prior knowledge to guide the representation learning in the reverse phase of the diffusion process to learn the invariant representation. In addition,we provide a theoretical derivation that proves optimizing the objective function of CausalDiffRec can encourage the model to learn environment-invariant graph representations, thereby achieving excellent generalization performance in recommendations under distribution shifts. Our extensive experiments validate the effectiveness of CausalDiffRec in improving the generalization of OOD data, and the average improvement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and 11.65% on Douban datasets.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {334–346},
numpages = {13},
keywords = {distributionally robust optimization, graph recommendation, out-of-distribution},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3308558.3313725,
author = {Ge, Yingqiang and Xu, Shuyuan and Liu, Shuchang and Geng, Shijie and Fu, Zuohui and Zhang, Yongfeng},
title = {Maximizing Marginal Utility per Dollar for Economic Recommendation},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313725},
doi = {10.1145/3308558.3313725},
abstract = {Understanding the economic nature of consumer decisions in e-Commerce is important to personalized recommendation systems. Established economic theories claim that informed consumers always attempt to maximize their utility by choosing the items of the largest marginal utility per dollar (MUD) within their budgets. For example, gaining 5 dollars of extra benefit by spending 10 dollars makes a consumer much more satisfied than having the same amount of extra benefit by spending 20 dollars, although the second product may have higher absolute utility value. Meanwhile, making purchases online may be risky decisions that could cause dissatisfaction. For example, people may give low ratings towards purchased items that they thought they would like when placing the order. Therefore, the design of recommender systems should also take users' risk attitudes into consideration to better learn consumer behaviors. Motivated by the first consideration, in this paper, we propose a learning algorithm to maximize marginal utility per dollar for recommendations. With the second, economic theory shows that rational people can be arbitrarily close to risk neutral when stakes are arbitrarily small, and this is generally applicable to consumer online purchase behaviors because most people spend a small portion of their total wealth for a single purchase. To integrate this theory with machine learning, we propose to augment MUD optimization with approximate risk-neural constraint to generate personalized recommendations. Experiments on real-world e-Commerce datasets show that our approach is able to achieve better performance than many classical recommendation methods, in terms of both traditional recommendation measures such as precision and recall, as well as economic measures such as MUD.},
booktitle = {The World Wide Web Conference},
pages = {2757–2763},
numpages = {7},
keywords = {Risk Attitude, Recommendation Systems, Personalization, Marginal Utility per Dollar, Computational Economics},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3487553.3524215,
author = {Chia, Patrick John and Tagliabue, Jacopo and Bianchi, Federico and He, Chloe and Ko, Brian},
title = {Beyond NDCG: Behavioral Testing of Recommender Systems with RecList},
year = {2022},
isbn = {9781450391306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487553.3524215},
doi = {10.1145/3487553.3524215},
abstract = {As with most Machine Learning systems, recommender systems are typically evaluated through performance metrics computed over held-out data points. However, real-world behavior is undoubtedly nuanced: ad hoc error analysis and tests must be employed to ensure the desired quality in actual deployments. We introduce RecList, a testing methodology providing a general plug-and-play framework to scale up behavioral testing. We demonstrate its capabilities by analyzing known algorithms and black-box APIs, and we release it as an open source, extensible package for the community.},
booktitle = {Companion Proceedings of the Web Conference 2022},
pages = {99–104},
numpages = {6},
keywords = {recommender systems, open source, behavioral testing},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3589334.3645354,
author = {Ma, Chenglong and Ren, Yongli and Castells, Pablo and Sanderson, Mark},
title = {Temporal Conformity-aware Hawkes Graph Network for Recommendations},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645354},
doi = {10.1145/3589334.3645354},
abstract = {Many existing recommender systems (RSs) assume user behavior is governed solely by their interests. However, the peer effect often influences individual decision-making, which leads to conformity behavior. Conventional solutions that eliminate indiscriminately such bias may cause RSs to neglect valuable information and depersonalize the recommendation results. Also, conformity can transform into user interest, e.g., discovering new tastes after a glance at popular music. By better representing different forms of conformity influence, we can do a better job at interest mining and debiasing. In certain extreme circumstances, the herd effect may be exacerbated by user anxiety with uncertainty (e.g., panic buying during the COVID-19 pandemic). RSs may thus fail to respond in time due to sudden and dramatic changes. Moreover, many existing studies potentially conflate conformity bias with popularity bias and lump together various factors responsible for differences in popularity. In this paper, we identify two distinct types of conformity behavior: informational conformity and normative conformity. To address this, we introduce the TCHN model, which utilizes attentional Hawkes processes to disentangle user self-interest and conformity in a personalized manner. Our approach incorporates temporal graph attention networks to capture users' stable and volatile dynamics. We conduct experiments on three real-world datasets, which uncover diverse levels of conformity among users. The results show that TCHN excels in recommendation accuracy, diversity, and fairness across various user groups.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3185–3194},
numpages = {10},
keywords = {conformity, hawkes process, recommendations, temporal graph attention network, user interest},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3178876.3186153,
author = {Lichman, Moshe and Smyth, Padhraic},
title = {Prediction of Sparse User-Item Consumption Rates with Zero-Inflated Poisson Regression},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186153},
doi = {10.1145/3178876.3186153},
abstract = {In this paper we address the problem of building user models that can predict the rate at which individuals consume items from a finite set, including items they have consumed in the past and items that are new. This combination of repeat and new item consumption is common in applications such as listening to music, visiting web sites, and purchasing products. We use zero-inflated Poisson (ZIP) regression models as the basis for our modeling approach, leading to a general framework for modeling user-item consumption rates over time. We show that these models are more flexible in capturing user behavior than alternatives such as well-known latent factor models based on matrix factorization. We compare the performance of ZIP regression and latent factor models on three different data sets involving music, restaurant reviews, and social media. The ZIP regression models are systematically more accurate across all three data sets and across different prediction metrics.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {719–728},
numpages = {10},
keywords = {zero-inflated poisson, repeat consumption, explore-exploit, consumption rate modeling},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3696410.3714848,
author = {Zhao, Chu and Yang, Enneng and Liang, Yuliang and Zhao, Jianzhe and Guo, Guibing and Wang, Xingwei},
title = {Distributionally Robust Graph Out-of-Distribution Recommendation via Diffusion Model},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714848},
doi = {10.1145/3696410.3714848},
abstract = {The distributionally robust optimization (DRO)-based graph neural network methods improve recommendation systems' out-of-distribution (OOD) generalization by optimizing the model's worst-case performance. However, these studies fail to consider the impact of noisy samples in the training data, which results in diminished generalization capabilities and lower accuracy. Through experimental and theoretical analysis, this paper reveals that current DRO-based graph recommendation methods assign greater weight to noise distribution, leading to model parameter learning being dominated by it. When the model overly focuses on fitting noise samples in the training data, it may learn irrelevant or meaningless features that cannot be generalized to OOD data. To address this challenge, we design a Distributionally Robust Graph model for OOD recommendation (DRGO). Specifically, our method first employs a simple and effective diffusion paradigm to alleviate the noisy effect in the latent space. Additionally, an entropy regularization term is introduced in the DRO objective function to avoid extreme sample weights in the worst-case distribution. Finally, we provide a theoretical proof of the generalization error bound of DRGO as well as a theoretical analysis of how our approach mitigates noisy sample effects, which helps to better understand the proposed framework from a theoretical perspective. We conduct extensive experiments on four datasets to evaluate the effectiveness of our framework against three typical distribution shifts, and the results demonstrate its superiority in both independently and identically distributed distributions (IID) and OOD.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2018–2031},
numpages = {14},
keywords = {distributionally robust optimization, graph recommendation, out-of-distribution},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3485447.3512255,
author = {Wen, Hongyi and Yi, Xinyang and Yao, Tiansheng and Tang, Jiaxi and Hong, Lichan and Chi, Ed H.},
title = {Distributionally-robust Recommendations for Improving Worst-case User Experience},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512255},
doi = {10.1145/3485447.3512255},
abstract = {Modern recommender systems have evolved rapidly along with deep learning models that are well-optimized for overall performance, especially those trained under Empirical Risk Minimization (ERM). However, a recommendation algorithm that focuses solely on the average performance may reinforce the exposure bias and exacerbate the “rich-get-richer” effect, leading to unfair user experience. In a simulation study, we demonstrate that such performance gap among various user groups is enlarged by an ERM-trained recommender in the long-term. To mitigate such amplification effects, we propose to optimize for the worst-case performance under the Distributionally Robust Optimization (DRO) framework, with the goal of improving long-term fairness for disadvantaged subgroups. In addition, we propose a simple-yet-effective streaming optimization improvement called Streaming-DRO (S-DRO), which effectively reduces loss variances for recommendation problems with sparse and long-tailed data distributions. Our results on two large-scale datasets suggest that (1) DRO is a flexible and effective technique for improving worst-case performance, and (2) Streaming-DRO outperforms vanilla DRO and other strong baselines by improving the worst-case and overall performance at the same time.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {3606–3610},
numpages = {5},
keywords = {Distributional robustness, Recommendation., Robust learning},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3308560.3316706,
author = {Beck, Johannes and Huang, Roberta and Lindner, David and Guo, Tian and Ce, Zhang and Helbing, Dirk and Antulov-Fantulin, Nino},
title = {Sensing Social Media Signals for Cryptocurrency News},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3316706},
doi = {10.1145/3308560.3316706},
abstract = {The ability to track and monitor relevant and important news in real-time is of crucial interest in multiple industrial sectors. In this work, we focus on cryptocurrency news, which recently became of emerging interest to the general and financial audience. In order to track popular news in real-time, we (i) match news from the web with tweets from social media, (ii) track their intraday tweet activity and (iii) explore different machine learning models for predicting the number of article mentions on Twitter after its publication. We compare several machine learning models, such as linear extrapolation, linear and random forest autoregressive models, and a sequence-to-sequence neural network.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {1051–1054},
numpages = {4},
keywords = {mining and learning, cryptocurrency, Social media},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3442442.3452354,
author = {Tasnim Huq, Khandaker and Ciampaglia, Giovanni Luca},
title = {Characterizing Opinion Dynamics and Group Decision Making in Wikipedia Content Discussions},
year = {2021},
isbn = {9781450383134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442442.3452354},
doi = {10.1145/3442442.3452354},
abstract = {Wikipedia, the online encyclopedia, is a trusted source of knowledge for millions of individuals worldwide. As everyone can start a new article, it is often necessary to decide whether certain entries meet the standards for inclusion set forth by the community. These decisions (which are known as “Article for Deletion”, or AfD) are taken by groups of editors in a deliberative fashion, and are known for displaying a number of common biases associated to group decision making. Here, we present an analysis of 1,967,768 AfD discussions between 2005 and 2018. We perform a signed network analysis to capture the dynamics of agreement and disagreement among editors. We measure the preference of each editor for voting toward either inclusion or deletion. We further describe the evolution of individual editors and their voting preferences over time, finding four major opinion groups. Finally, we develop a predictive model of discussion outcomes based on latent factors. Our results shed light on an important, yet overlooked, aspect of curation dynamics in peer production communities, and could inform the design of improved processes of collective deliberation on the web.},
booktitle = {Companion Proceedings of the Web Conference 2021},
pages = {632–639},
numpages = {8},
keywords = {Wikipedia, Opinion dynamics, Group decision-making, Discussion outcome prediction, Computational Social Science, Article for Deletion},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3485447.3512093,
author = {He, Yun and Feng, Xue and Cheng, Cheng and Ji, Geng and Guo, Yunsong and Caverlee, James},
title = {MetaBalance: Improving Multi-Task Recommendations via Adapting Gradient Magnitudes of Auxiliary Tasks},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512093},
doi = {10.1145/3485447.3512093},
abstract = {In many personalized recommendation scenarios, the generalization ability of a target task can be improved via learning with additional auxiliary tasks alongside this target task on a multi-task network. However, this method often suffers from a serious optimization imbalance problem. On the one hand, one or more auxiliary tasks might have a larger influence than the target task and even dominate the network weights, resulting in worse recommendation accuracy for the target task. On the other hand, the influence of one or more auxiliary tasks might be too weak to assist the target task. More challenging is that this imbalance dynamically changes throughout the training process and varies across the parts of the same network. We propose a new method: MetaBalance to balance auxiliary losses via directly manipulating their gradients w.r.t the shared parameters in the multi-task network. Specifically, in each training iteration and adaptively for each part of the network, the gradient of an auxiliary loss is carefully reduced or enlarged to have a closer magnitude to the gradient of the target loss, preventing auxiliary tasks from being so strong that dominate the target task or too weak to help the target task. Moreover, the proximity between the gradient magnitudes can be flexibly adjusted to adapt MetaBalance to different scenarios. The experiments show that our proposed method achieves a significant improvement of 8.34% in terms of NDCG@10 upon the strongest baseline on two real-world datasets. The code of our approach can be found at here.1},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {2205–2215},
numpages = {11},
keywords = {Auxiliary Learning, Gradient-based Optimization, Multi-Task Learning, Personalized Recommendation},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3589334.3645573,
author = {Li, Xiping and Ma, Jianghong and Liu, Kangzhe and Feng, Shanshan and Zhang, Haijun and Wang, Yutong},
title = {Category-based and Popularity-guided Video Game Recommendation: A Balance-oriented Framework},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645573},
doi = {10.1145/3589334.3645573},
abstract = {In recent years, the video game industry has experienced substantial growth, presenting players with a vast array of game choices. This surge in options has spurred the need for a specialized recommender system tailored for video games. However, current video game recommendation approaches tend to prioritize accuracy over diversity, potentially leading to unvaried game suggestions. In addition, the existing game recommendation methods commonly lack the ability to establish strict connections between games to enhance accuracy. Furthermore, many existing diversity-focused methods fail to leverage crucial item information, such as item category and popularity during neighbor modeling and message propagation. To address these challenges, we introduce a novel framework, called CPGRec, comprising three modules, namely accuracy-driven, diversity-driven, and comprehensive modules. The first module extends the state-of-the-art accuracy-focused game recommendation method by connecting games in a more stringent manner to enhance recommendation accuracy. The second module connects neighbors with diverse categories within the proposed game graph and harnesses the advantages of popular game nodes to amplify the influence of long-tail games within the player-game bipartite graph, thereby enriching recommendation diversity. The third module combines the above two modules and employs a new negative-sample rating score reweighting method to balance accuracy and diversity. Experimental results on the Steam dataset demonstrate the effectiveness of our proposed method in improving game recommendations. The dataset and source codes are anonymously released at: https://github.com/CPGRec2024/CPGRec.git.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3734–3744},
numpages = {11},
keywords = {accuracy and diversity, item category and popularity, long-tail games, video game recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3366423.3380297,
author = {Fu, Xinyu and Zhang, Jiani and Meng, Ziqiao and King, Irwin},
title = {MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380297},
doi = {10.1145/3366423.3380297},
abstract = {A large number of real-world graphs or networks are inherently heterogeneous, involving a diversity of node types and relation types. Heterogeneous graph embedding is to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing models usually define multiple metapaths in a heterogeneous graph to capture the composite relations and guide neighbor selection. However, these models either omit node content features, discard intermediate nodes along the metapath, or only consider one metapath. To address these three limitations, we propose a new model named Metapath Aggregated Graph Neural Network (MAGNN) to boost the final performance. Specifically, MAGNN employs three major components, i.e., the node content transformation to encapsulate input node attributes, the intra-metapath aggregation to incorporate intermediate semantic nodes, and the inter-metapath aggregation to combine messages from multiple metapaths. Extensive experiments on three real-world heterogeneous graph datasets for node classification, node clustering, and link prediction show that MAGNN achieves more accurate prediction results than state-of-the-art baselines.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2331–2341},
numpages = {11},
keywords = {Heterogeneous graph, Graph neural network, Graph embedding},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3366423.3380013,
author = {Mao, Huiqiang and Li, Yanzhi and Li, Chenliang and Chen, Di and Wang, Xiaoqing and Deng, Yuming},
title = {PARS: Peers-aware Recommender System},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380013},
doi = {10.1145/3366423.3380013},
abstract = {The presence or absence of one item in a recommendation list will affect the demand for other items because customers are often willing to switch to other items if their most preferred items are not available. The cross-item influence, called “peers effect”, has been largely ignored in the literature. In this paper, we develop a peers-aware recommender system, named PARS. We apply a ranking-based choice model to capture the cross-item influence and solve the resultant MaxMin problem with a decomposition algorithm. The MaxMin model solves for the recommendation decision in the meanwhile of estimating users’ preferences towards the items, which yields high-quality recommendations robust to input data variation. Experimental results illustrate that PARS outperforms a few frequently used methods in practice. An online evaluation with a flash sales scenario at Taobao also shows that PARS delivers significant improvements in terms of both conversion rates and user value.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2606–2612},
numpages = {7},
keywords = {Recommender system, Ranking-based model, E-commerce, Demand substitution},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3543507.3583495,
author = {Li, Haoxuan and Xiao, Yanghao and Zheng, Chunyuan and Wu, Peng},
title = {Balancing Unobserved Confounding with a Few Unbiased Ratings in Debiased Recommendations},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583495},
doi = {10.1145/3543507.3583495},
abstract = {Recommender systems are seen as an effective tool to address information overload, but it is widely known that the presence of various biases makes direct training on large-scale observational data result in sub-optimal prediction performance. In contrast, unbiased ratings obtained from randomized controlled trials or A/B tests are considered to be the golden standard, but are costly and small in scale in reality. To exploit both types of data, recent works proposed to use unbiased ratings to correct the parameters of the propensity or imputation models trained on the biased dataset. However, the existing methods fail to obtain accurate predictions in the presence of unobserved confounding or model misspecification. In this paper, we propose a theoretically guaranteed model-agnostic balancing approach that can be applied to any existing debiasing method with the aim of combating unobserved confounding and model misspecification. The proposed approach makes full use of unbiased data by alternatively correcting model parameters learned with biased data, and adaptively learning balance coefficients of biased samples for further debiasing. Extensive real-world experiments are conducted along with the deployment of our proposal on four representative debiasing methods to demonstrate the effectiveness.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1305–1313},
numpages = {9},
keywords = {Bias, Debias, Recommender Systems, Unobserved Confounding},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3589334.3645711,
author = {Wu, Yihan and Song, Ruihua and Chen, Xu and Jiang, Hao and Cao, Zhao and Yu, Jin},
title = {Understanding Human Preferences: Towards More Personalized Video to Text Generation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645711},
doi = {10.1145/3589334.3645711},
abstract = {While previous video to text models have achieved remarkable successes, they mostly focus on how to understand the video contents in a general sense, but fail to capture the human personalized preferences, which is highly demanded for an engaging multimodal chatbots. Different from user modeling in collaborative filtering, there is no other user behaviors in inference as a real-time video stream is coming. In this paper, we formally define the task of personalized video commenting task and design an end-to-end personalized framework for solving this task. In specific, we argue that the personalization for video comment generation can be reflected in two aspects, that is, (1) for the same video, different users may comment on different clips, and (2) for the same clip, different people may also express various opinions with diverse commentary styles. Motivated by these considerations, we design our framework based on two components. The first one is a clip selector, which is responsible for predicting the clips that the user may comment in the video. The second one is a text generator, which aims to produce the comment based on the above predicted clips and the user's preference. In our framework, these two components are optimized in an end-to-end manner to mutually enhance each other, where we design confidence-aware scheduled sampling and iterative inference strategies to solve the problem that the ground truth clips are absent in the inference phase. As the absence of personalized video to text dataset, we collect and release a new dataset for studying this problem. We conduct extensive experiments to demonstrate the effectiveness of our model.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3952–3963},
numpages = {12},
keywords = {multimodal interaction, personalized content generation, user preference modeling, video comments dataset, video to text generation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645702,
author = {Nguyen, Ngoc-Hieu and Nguyen, Tuan-Anh and Nguyen, Tuan and Hoang, Vu Tien and Le, Dung D. and Wong, Kok-Seng},
title = {Towards Efficient Communication and Secure Federated Recommendation System via Low-rank Training},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645702},
doi = {10.1145/3589334.3645702},
abstract = {Federated Recommendation (FedRec) systems have emerged as a solution to safeguard users' data in response to growing regulatory concerns. However, one of the major challenges in these systems lies in the communication costs that arise from the need to transmit neural network models between user devices and a central server. Prior approaches to these challenges often lead to issues such as computational overheads, model specificity constraints, and compatibility issues with secure aggregation protocols. In response, we propose a novel framework, called Correlated Low-rank Structure (CoLR), which leverages the concept of adjusting lightweight trainable parameters while keeping most parameters frozen. Our approach substantially reduces communication overheads without introducing additional computational burdens. Critically, our framework remains fully compatible with secure aggregation protocols, including the robust use of Homomorphic Encryption. The approach resulted in a reduction of up to 93.75% in payload size, with only an approximate 8% decrease in recommendation performance across datasets. Code for reproducing our experiments can be found at https://github.com/NNHieu/CoLR-FedRec.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3940–3951},
numpages = {12},
keywords = {communication efficiency, federated learning, recommendation system},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3308560.3317303,
author = {Sun, Wenlong and Khenissi, Sami and Nasraoui, Olfa and Shafto, Patrick},
title = {Debiasing the Human-Recommender System Feedback Loop in Collaborative Filtering},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3317303},
doi = {10.1145/3308560.3317303},
abstract = {Recommender Systems (RSs) are widely used to help online users discover products, books, news, music, movies, courses, restaurants, etc. Because a traditional recommendation strategy always shows the most relevant items (thus with highest predicted rating), traditional RS’s are expected to make popular items become even more popular and non-popular items become even less popular which in turn further divides the haves (popular) from the have-nots (unpopular). Therefore, a major problem with RSs is that they may introduce biases affecting the exposure of items, thus creating a popularity divide of items during the feedback loop that occurs with users, and this may lead the RS to make increasingly biased recommendations over time. In this paper, we view the RS environment as a chain of events that are the result of interactions between users and the RS. Based on that, we propose several debiasing algorithms during this chain of events, and evaluate how these algorithms impact the predictive behavior of the RS, as well as trends in the popularity distribution of items over time. We also propose a novel blind-spot-aware matrix factorization (MF) algorithm to debias the RS. Results show that propensity matrix factorization achieved a certain level of debiasing of the RS while active learning combined with the propensity MF achieved a higher debiasing effect on recommendations.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {645–651},
numpages = {7},
keywords = {Recommender Systems (RSs), Propensity, Matrix Factorization, Active Learning (AL)},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3543507.3583240,
author = {Wei, Tianjun and Ma, Jianghong and Chow, Tommy W. S.},
title = {Fine-tuning Partition-aware Item Similarities for Efficient and Scalable Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583240},
doi = {10.1145/3543507.3583240},
abstract = {Collaborative filtering (CF) is widely searched in recommendation with various types of solutions. Recent success of Graph Convolution Networks (GCN) in CF demonstrates the effectiveness of modeling high-order relationships through graphs, while repetitive graph convolution and iterative batch optimization limit their efficiency. Instead, item similarity models attempt to construct direct relationships through efficient interaction encoding. Despite their great performance, the growing item numbers result in quadratic growth in similarity modeling process, posing critical scalability problems. In this paper, we investigate the graph sampling strategy adopted in latest GCN model for efficiency improving, and identify the potential item group structure in the sampled graph. Based on this, we propose a novel item similarity model which introduces graph partitioning to restrict the item similarity modeling within each partition. Specifically, we show that the spectral information of the original graph is well in preserving global-level information. Then, it is added to fine-tune local item similarities with a new data augmentation strategy acted as partition-aware prior knowledge, jointly to cope with the information loss brought by partitioning. Experiments carried out on 4 datasets show that the proposed model outperforms state-of-the-art GCN models with 10x speed-up and item similarity models with 95% parameter storage savings.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {823–832},
numpages = {10},
keywords = {Collaborative Filtering, Graph Partitioning, Recommender System, Similarity Measuring},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583337,
author = {Qu, Liang and Tang, Ningzhi and Zheng, Ruiqi and Nguyen, Quoc Viet Hung and Huang, Zi and Shi, Yuhui and Yin, Hongzhi},
title = {Semi-decentralized Federated Ego Graph Learning for Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583337},
doi = {10.1145/3543507.3583337},
abstract = {Collaborative filtering (CF) based recommender systems are typically trained based on personal interaction data (e.g., clicks and purchases) that could be naturally represented as ego graphs. However, most existing recommendation methods collect these ego graphs from all users to compose a global graph to obtain high-order collaborative information between users and items, and these centralized CF recommendation methods inevitably lead to a high risk of user privacy leakage. Although recently proposed federated recommendation systems can mitigate the privacy problem, they either restrict the on-device local training to an isolated ego graph or rely on an additional third-party server to access other ego graphs resulting in a cumbersome pipeline, which is hard to work in practice. In addition, existing federated recommendation systems require resource-limited devices to maintain the entire embedding tables resulting in high communication costs. In light of this, we propose a semi-decentralized federated ego graph learning framework for on-device recommendations, named SemiDFEGL, which introduces new device-to-device collaborations to improve scalability and reduce communication costs and innovatively utilizes predicted interacted item nodes to connect isolated ego graphs to augment local subgraphs such that the high-order user-item collaborative information could be used in a privacy-preserving manner. Furthermore, the proposed framework is model-agnostic, meaning that it could be seamlessly integrated with existing graph neural network-based recommendation methods and privacy protection techniques. To validate the effectiveness of the proposed SemiDFEGL, extensive experiments are conducted on three public datasets, and the results demonstrate the superiority of the proposed SemiDFEGL compared to other federated recommendation methods.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {339–348},
numpages = {10},
keywords = {federated ego graph learning, graph neural networks, recommender systems, semi-decentralized learning},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3038912.3052668,
author = {Zhao, Qian and Shi, Yue and Hong, Liangjie},
title = {GB-CENT: Gradient Boosted Categorical Embedding and Numerical Trees},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052668},
doi = {10.1145/3038912.3052668},
abstract = {Latent factor models and decision tree based models are widely used in tasks of prediction, ranking and recommendation. Latent factor models have the advantage of interpreting categorical features by a low-dimensional representation, while such an interpretation does not naturally fit numerical features. In contrast, decision tree based models enjoy the advantage of capturing the nonlinear interactions of numerical features, while their capability of handling categorical features is limited by the cardinality of those features. Since in real-world applications we usually have both abundant numerical features and categorical features with large cardinality (e.g. geolocations, IDs, tags etc.), we design a new model, called GB-CENT, which leverages latent factor embedding and tree components to achieve the merits of both while avoiding their demerits. With two real-world data sets, we demonstrate that GB-CENT can effectively (i.e. fast and accurately) achieve better accuracy than state-of-the-art matrix factorization, decision tree based models and their ensemble.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {1311–1319},
numpages = {9},
keywords = {recommender systems, numerical and categorical features, matrix factorization, low-dimensional embedding, large cardinality, gradient boosting, decision trees},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3589334.3645626,
author = {He, Xinrui and Liu, Shuo and Keung, Jacky and He, Jingrui},
title = {Co-clustering for Federated Recommender System},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645626},
doi = {10.1145/3589334.3645626},
abstract = {As data privacy and security attract increasing attention, Federated Recommender System (FRS) offers a solution that strikes a balance between providing high-quality recommendations and preserving user privacy. However, the presence of statistical heterogeneity in FRS, commonly observed due to personalized decision-making patterns, can pose challenges. To address this issue and maximize the benefit of collaborative filtering (CF) in FRS, it is intuitive to consider clustering clients (users) as well as items into different groups and learning group-specific models. Existing methods either resort to client clustering via user representations-risking privacy leakage, or employ classical clustering strategies on item embeddings or gradients, which we found are plagued by the curse of dimensionality. In this paper, we delve into the inefficiencies of the K-Means method in client grouping, attributing failures due to the high dimensionality as well as data sparsity occurring in FRS, and propose CoFedRec, a novel Co-clustering Federated Recommendation mechanism, to address clients heterogeneity and enhance the collaborative filtering within the federated framework. Specifically, the server initially formulates an item membership from the client-provided item networks. Subsequently, clients are grouped regarding a specific item category picked from the item membership during each communication round, resulting in an intelligently aggregated group model. Meanwhile, to comprehensively capture the global inter-relationships among items, we incorporate an additional supervised contrastive learning term based on the server-side generated item membership into the local training phase for each client. Extensive experiments on four datasets are provided, which verify the effectiveness of the proposed CoFedRec.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3821–3832},
numpages = {12},
keywords = {co-clustering, federated recommendation, supervised contrastive learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3184558.3191586,
author = {Al-Ghossein, Marie and Abdessalem, Talel and Barr\'{e}, Anthony},
title = {Dynamic Local Models for Online Recommendation},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3191586},
doi = {10.1145/3184558.3191586},
abstract = {With the explosion of the volume of user-generated data, designing online recommender systems that learn from data streams has become essential. These systems rely on incremental learning that continuously update models as new observations arrive and they should be able to adapt to drifts in real-time. User preferences evolve over time and tracking their evolution is not an easy task. In addition to the low number of observations available per user, the preferences change at different moments and in different ways for each individual. In this paper, we propose a novel approach based on local models to address this problem. Local models are known for their ability to capture diverse preferences among user subsets. Our approach automatically detects the drift of preferences that leads a user to adopt a behavior closer to the users of another subset, and adjusts the models accordingly. Our experiments on real world datasets show promising results and prove the effectiveness of using local models to adapt to changes in user preferences.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1419–1423},
numpages = {5},
keywords = {concept drift, online recommendation, recommender systems},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3589334.3645369,
author = {Zhang, Zheng and Liu, Qi and Hu, Zirui and Zhan, Yi and Huang, Zhenya and Gao, Weibo and Mao, Qingyang},
title = {Enhancing Fairness in Meta-learned User Modeling via Adaptive Sampling},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645369},
doi = {10.1145/3589334.3645369},
abstract = {Meta-learning has been widely employed to tackle the cold-start problem in user modeling. Similar to a guidebook for a new traveler, meta-learning significantly affects decision-making for new users in crucial scenarios, such as career recommendations. Consequently, the issue of fairness in meta-learning has gained paramount importance. Several methods have been proposed to mitigate unfairness in meta-learning and have shown promising results. However, a fundamental question remains unexplored: What is the critical factor leading to unfairness in meta-learned user modeling? Through the theoretical analysis that integrates the meta-learning paradigm with group fairness metrics, we identify group proportion imbalance as a critical factor. Subsequently, in order to mitigate the impact of this factor, we introduce a novel Fairness-aware Adaptive Sampling framework for meTa-learning, abbreviated as FAST. Its core concept involves adaptively adjusting the sampling distribution for different user groups during the interleaved training process of meta-learning. Furthermore, we provide theoretical guarantees demonstrating the convergence of FAST. Finally, empirical experiments conducted on three datasets reveal that FAST effectively enhances fairness while maintaining high accuracy. The code for FAST is available at https://github.com/zhengz99/FAST.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3241–3252},
numpages = {12},
keywords = {adaptive sampling, fairness, meta-learning, user modeling},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3308558.3313733,
author = {Perera, Dilruk and Zimmermann, Roger},
title = {CnGAN: Generative Adversarial Networks for Cross-network user preference generation for non-overlapped users},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313733},
doi = {10.1145/3308558.3313733},
abstract = {A major drawback of cross-network recommender solutions is that they can only be applied to users that are overlapped across networks. Thus, the non-overlapped users, which form the majority of users are ignored. As a solution, we propose CnGAN, a novel multi-task learning based, encoder-GAN-recommender architecture. The proposed model synthetically generates source network user preferences for non-overlapped users by learning the mapping from target to source network preference manifolds. The resultant user preferences are used in a Siamese network based neural recommender architecture. Furthermore, we propose a novel user-based pairwise loss function for recommendations using implicit interactions to better guide the generation process in the multi-task learning environment. We illustrate our solution by generating user preferences on the Twitter source network for recommendations on the YouTube target network. Extensive experiments show that the generated preferences can be used to improve recommendations for non-overlapped users. The resultant recommendations achieve superior performance compared to the state-of-the-art cross-network recommender solutions in terms of accuracy, novelty and diversity.},
booktitle = {The World Wide Web Conference},
pages = {3144–3150},
numpages = {7},
keywords = {Implicit Feedback, Generative Adversarial Networks, Deep learning, Cross-network Recommendations, Collaborative Filtering},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3543507.3583359,
author = {Yuan, Wei and Yang, Chaoqun and Nguyen, Quoc Viet Hung and Cui, Lizhen and He, Tieke and Yin, Hongzhi},
title = {Interaction-level Membership Inference Attack Against Federated Recommender Systems},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583359},
doi = {10.1145/3543507.3583359},
abstract = {The marriage of federated learning and recommender system (FedRec) has been widely used to address the growing data privacy concerns in personalized recommendation services. In FedRecs, users’ attribute information and behavior data (i.e., user-item interaction data) are kept locally on their personal devices, therefore, it is considered a fairly secure approach to protect user privacy. As a result, the privacy issue of FedRecs is rarely explored. Unfortunately, several recent studies reveal that FedRecs are vulnerable to user attribute inference attacks, highlighting the privacy concerns of FedRecs. In this paper, we further investigate the privacy problem of user behavior data (i.e., user-item interactions) in FedRecs. Specifically, we perform the first systematic study on interaction-level membership inference attacks on FedRecs. An interaction-level membership inference attacker is first designed, and then the classical privacy protection mechanism, Local Differential Privacy (LDP), is adopted to defend against the membership inference attack. Unfortunately, the empirical analysis shows that LDP is not effective against such new attacks unless the recommendation performance is largely compromised. To mitigate the interaction-level membership attack threats, we design a simple yet effective defense method to significantly reduce the attacker’s inference accuracy without losing recommendation performance. Extensive experiments are conducted with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on three real-world recommendation datasets (MovieLens-100K, Steam-200K, and Amazon Cell Phone), and the experimental results show the effectiveness of our solutions.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1053–1062},
numpages = {10},
keywords = {Federated Learning, Membership Inference Attack and Defense, Recommender System},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583296,
author = {Xu, Chen and Chen, Sirui and Xu, Jun and Shen, Weiran and Zhang, Xiao and Wang, Gang and Dong, Zhenhua},
title = {P-MMF: Provider Max-min Fairness Re-ranking in Recommender System},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583296},
doi = {10.1145/3543507.3583296},
abstract = {In this paper, we address the issue of recommending fairly from the aspect of providers, which has become increasingly essential in multistakeholder recommender systems. Existing studies on provider fairness usually focused on designing proportion fairness (PF) metrics that first consider systematic fairness. However, sociological researches show that to make the market more stable, max-min fairness (MMF) is a better metric. The main reason is that MMF aims to improve the utility of the worst ones preferentially, guiding the system to support the providers in weak market positions. When applying MMF to recommender systems, how to balance user preferences and provider fairness in an online recommendation scenario is still a challenging problem. In this paper, we proposed an online re-ranking model named Provider Max-min Fairness Re-ranking (P-MMF) to tackle the problem. Specifically, P-MMF formulates provider fair recommendation as a resource allocation problem, where the exposure slots are considered the resources to be allocated to providers and the max-min fairness is used as the regularizer during the process. We show that the problem can be further represented as a regularized online optimizing problem and solved efficiently in its dual space. During the online re-ranking phase, a momentum gradient descent method is designed to conduct the dynamic re-ranking. Theoretical analysis showed that the regret of P-MMF can be bounded. Experimental results on four public recommender datasets demonstrated that P-MMF can outperformed the state-of-the-art baselines. Experimental results also show that P-MMF can retain small computationally costs on a corpus with the large number of items.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3701–3711},
numpages = {11},
keywords = {Max-min Fairness, Provider Fairness, Recommender System},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583321,
author = {Song, Wenzhuo and Wang, Shoujin and Wang, Yan and Liu, Kunpeng and Liu, Xueyan and Yin, Minghao},
title = {A Counterfactual Collaborative Session-based Recommender System},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583321},
doi = {10.1145/3543507.3583321},
abstract = {Most session-based recommender systems (SBRSs) focus on extracting information from the observed items in the current session of a user to predict a next item, ignoring the causes outside the session (called outer-session causes, OSCs) that influence the user’s selection of items. However, these causes widely exist in the real world, and few studies have investigated their role in SBRSs. In this work, we analyze the causalities and correlations of the OSCs in SBRSs from the perspective of causal inference. We find that the OSCs are essentially the confounders in SBRSs, which leads to spurious correlations in the data used to train SBRS models. To address this problem, we propose a novel SBRS framework named COCO-SBRS (COunterfactual COllaborative Session-Based Recommender Systems) to learn the causality between OSCs and user-item interactions in SBRSs. COCO-SBRS first adopts a self-supervised approach to pre-train a recommendation model by designing pseudo-labels of causes for each user’s selection of the item in data to guide the training process. Next, COCO-SBRS adopts counterfactual inference to recommend items based on the outputs of the pre-trained recommendation model considering the causalities to alleviate the data sparsity problem. As a result, COCO-SBRS can learn the causalities in data, preventing the model from learning spurious correlations. The experimental results of our extensive experiments conducted on three real-world datasets demonstrate the superiority of our proposed framework over ten representative SBRSs.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {971–982},
numpages = {12},
keywords = {counterfactuals, self-supervised learning, session-based recommendation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/2736277.2741087,
author = {Zhang, Yongfeng and Zhang, Min and Zhang, Yi and Lai, Guokun and Liu, Yiqun and Zhang, Honghui and Ma, Shaoping},
title = {Daily-Aware Personalized Recommendation based on Feature-Level Time Series Analysis},
year = {2015},
isbn = {9781450334693},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2736277.2741087},
doi = {10.1145/2736277.2741087},
abstract = {The frequently changing user preferences and/or item profiles have put essential importance on the dynamic modeling of users and items in personalized recommender systems. However, due to the insufficiency of per user/item records when splitting the already sparse data across time dimension, previous methods have to restrict the drifting purchasing patterns to pre-assumed distributions, and were hardly able to model them rather directly with, for example, time series analysis. Integrating content information helps to alleviate the problem in practical systems, but the domain-dependent content knowledge is expensive to obtain due to the large amount of manual efforts.In this paper, we make use of the large volume of textual reviews for the automatic extraction of domain knowledge, namely, the explicit features/aspects in a specific product domain. We thus degrade the product-level modeling of user preferences, which suffers from the lack of data, to the feature-level modeling, which not only grants us the ability to predict user preferences through direct time series analysis, but also allows us to know the essence under the surface of product-level changes in purchasing patterns. Besides, the expanded feature space also helps to make cold-start recommendations for users with few purchasing records.Technically, we develop the Fourier-assisted Auto-Regressive Integrated Moving Average (FARIMA) process to tackle with the year-long seasonal period of purchasing data to achieve daily-aware preference predictions, and we leverage the conditional opportunity models for daily-aware personalized recommendation. Extensive experimental results on real-world cosmetic purchasing data from a major e-commerce website (JD.com) in China verified both the effectiveness and efficiency of our approach.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {1373–1383},
numpages = {11},
keywords = {time series analysis, sentiment analysis, recommender systems, collaborative filtering},
location = {Florence, Italy},
series = {WWW '15}
}

@inproceedings{10.1145/3696410.3714668,
author = {Eberhard, Lukas and Ruprechter, Thorsten and Helic, Denis},
title = {Large Language Models as Narrative-Driven Recommenders},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714668},
doi = {10.1145/3696410.3714668},
abstract = {Narrative-driven recommenders aim to provide personalized suggestions for user requests expressed in free-form text such as ''I want to watch a thriller with a mind-bending story, like Shutter Island.'' Although large language models (LLMs) have been shown to excel in processing general natural language queries, their effectiveness for handling such recommendation requests remains relatively unexplored. To close this gap, we compare the performance of 38 open- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in a movie recommendation setting. For this, we utilize a gold-standard, crowdworker-annotated dataset of posts from reddit's movie suggestion community and employ various prompting strategies, including zero-shot, identity, and few-shot prompting. Our findings demonstrate the ability of LLMs to generate contextually relevant movie recommendations, significantly outperforming other state-of-the-art approaches, such as doc2vec. While we find that closed-source and large-parameterized models generally perform best, medium-sized open-source models remain competitive, being only slightly outperformed by their more computationally expensive counterparts. Furthermore, we observe no significant differences across prompting strategies for most models, underscoring the effectiveness of simple approaches such as zero-shot prompting for narrative-driven recommendations. Overall, this work offers valuable insights for recommender system researchers as well as practitioners aiming to integrate LLMs into real-world recommendation tools.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4543–4561},
numpages = {19},
keywords = {large language models, movie recommendations, narrative-driven recommendations, prompting strategies, recommender systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3543507.3583355,
author = {Chen, Xiao and Fan, Wenqi and Chen, Jingfan and Liu, Haochen and Liu, Zitao and Zhang, Zhaoxiang and Li, Qing},
title = {Fairly Adaptive Negative Sampling for Recommendations},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583355},
doi = {10.1145/3543507.3583355},
abstract = {Pairwise learning strategies are prevalent for optimizing recommendation models on implicit feedback data, which usually learns user preference by discriminating between positive (i.e., clicked by a user) and negative items (i.e., obtained by negative sampling). However, the size of different item groups (specified by item attribute) is usually unevenly distributed. We empirically find that the commonly used uniform negative sampling strategy for pairwise algorithms (e.g., BPR) can inherit such data bias and oversample the majority item group as negative instances, severely countering group fairness on the item side. In this paper, we propose a Fairly adaptive Negative sampling approach (FairNeg), which improves item group fairness via adaptively adjusting the group-level negative sampling distribution in the training process. In particular, it first perceives the model’s unfairness status at each step and then adjusts the group-wise sampling distribution with an adaptive momentum update strategy for better facilitating fairness optimization. Moreover, a negative sampling distribution Mixup mechanism is proposed, which gracefully incorporates existing importance-aware sampling techniques intended for mining informative negative samples, thus allowing for achieving multiple optimization purposes. Extensive experiments on four public datasets show our proposed method’s superiority in group fairness enhancement and fairness-utility tradeoff.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3723–3733},
numpages = {11},
keywords = {BPR, Fairness, Negative Sampling., Recommender Systems},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3442381.3450086,
author = {Zhang, Yin and Cheng, Derek Zhiyuan and Yao, Tiansheng and Yi, Xinyang and Hong, Lichan and Chi, Ed H.},
title = {A Model of Two Tales: Dual Transfer Learning Framework for Improved Long-tail Item Recommendation},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450086},
doi = {10.1145/3442381.3450086},
abstract = {Highly skewed long-tail item distribution is very common in recommendation systems. It significantly hurts model performance on tail items. To improve tail-item recommendation, we conduct research to transfer knowledge from head items to tail items, leveraging the rich user feedback in head items and the semantic connections between head and tail items. Specifically, we propose a novel dual transfer learning framework that jointly learns the knowledge transfer from both model-level and item-level: 1. The model-level knowledge transfer builds a generic meta-mapping of model parameters from few-shot to many-shot model. It captures the implicit data augmentation on the model-level to improve the representation learning of tail items. 2. The item-level transfer connects head and tail items through item-level features, to ensure a smooth transfer of meta-mapping from head items to tail items. The two types of transfers are incorporated to ensure the learned knowledge from head items can be well applied for tail item representation learning in the long-tail distribution settings. Through extensive experiments on two benchmark datasets, results show that our proposed dual transfer learning framework significantly outperforms other state-of-the-art methods for tail item recommendation in hit ratio and NDCG. It is also very encouraging that our framework further improves head items and overall performance on top of the gains on tail items.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {2220–2231},
numpages = {12},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3308558.3313543,
author = {Hu, Guangneng and Zhang, Yu and Yang, Qiang},
title = {Transfer Meets Hybrid: A Synthetic Approach for Cross-Domain Collaborative Filtering with Text},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313543},
doi = {10.1145/3308558.3313543},
abstract = {Collaborative Filtering (CF) is the key technique for recommender systems. CF exploits user-item behavior interactions (e.g., clicks) only and hence suffers from the data sparsity issue. One research thread is to integrate auxiliary information such as product reviews and news titles, leading to hybrid filtering methods. Another thread is to transfer knowledge from source domains such as improving the movie recommendation with the knowledge from the book domain, leading to transfer learning methods. In real-world applications, a user registers for multiple services across websites. Thus it motivates us to exploit both auxiliary and source information for recommendation in this paper. To achieve this, we propose a Transfer Meeting Hybrid (TMH) model for cross-domain recommendation with unstructured text. The proposed TMH model attentively extracts useful content from unstructured text via a memory network and selectively transfers knowledge from a source domain via a transfer network. On two real-world datasets, TMH shows better performance in terms of three ranking metrics by comparing with various baselines. We conduct thorough analyses to understand how the text content and transferred knowledge help the proposed model.},
booktitle = {The World Wide Web Conference},
pages = {2822–2829},
numpages = {8},
keywords = {Recommender Systems, Deep Learning, Collaborative Filtering},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3543507.3583374,
author = {Quan, Yuhan and Ding, Jingtao and Gao, Chen and Yi, Lingling and Jin, Depeng and Li, Yong},
title = {Robust Preference-Guided Denoising for Graph based Social Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583374},
doi = {10.1145/3543507.3583374},
abstract = {Graph Neural Network&nbsp;(GNN) based social recommendation models improve the prediction accuracy of user preference by leveraging GNN in exploiting preference similarity contained in social relations. However, in terms of both effectiveness and efficiency of recommendation, a large portion of social relations can be redundant or even noisy, e.g., it is quite normal that friends share no preference in a certain domain. Existing models do not fully solve this problem of relation redundancy and noise, as they directly characterize social influence over the full social network. In this paper, we instead propose to improve graph based social recommendation by only retaining the informative social relations to ensure an efficient and effective influence diffusion, i.e., graph denoising. Our designed denoising method is preference-guided to model social relation confidence and benefits user preference learning in return by providing a denoised but more informative social graph for recommendation models. Moreover, to avoid interference of noisy social relations, it designs a self-correcting curriculum learning module and an adaptive denoising strategy, both favoring highly-confident samples. Experimental results on three public datasets demonstrate its consistent capability of improving three state-of-the-art social recommendation models by robustly removing 10-40% of original relations. We release the source code at https://github.com/tsinghua-fib-lab/Graph-Denoising-SocialRec.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1097–1108},
numpages = {12},
keywords = {Graph Denoising, Preference Learning, Social Recommendation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3485447.3511956,
author = {Zhu, Qiannan and Zhang, Haobo and He, Qing and Dou, Zhicheng},
title = {A Gain-Tuning Dynamic Negative Sampler for Recommendation},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3511956},
doi = {10.1145/3485447.3511956},
abstract = {Selecting reliable negative training instances is the challenging task in the implicit feedback-based recommendation, which is optimized by pairwise learning on user feedback data. The existing methods usually exploit various negative samplers (i.e., heuristic-based or GAN-based sampling) on user feedback data to improve the quality of negative samples. However, these methods usually focused on maintaining the hard negative samples with a high gradient for training, causing the false negative samples to be selected preferentially. The limitation of the false negative noise amplification may lead to overfitting and further poor generalization of the model. To address this issue, we propose a Gain-Tuning Dynamic Negative Sampling GDNS to make the recommendation more robust and effective. Our proposed model designs an expectational gain sampler, concerning the expectation of user’ preference gap between the positive and negative samples in training, to guide the negative selection dynamically. This gain-tuning negative sampler can effectively identify the false negative samples and further diminish the risk of introducing false negative instances. Moreover, for improving the training efficiency, we construct positive and negative groups for each user in each iteration, and develop a group-wise optimizer to optimize them in a cross manner. Experiments on two real-world datasets show our approach significantly outperforms state-of-the-art negative sampling baselines.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {277–285},
numpages = {9},
keywords = {Collaborative filtering, Negative sampler, Recommendation system},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/2872518.2889400,
author = {Wu, Chao-Yuan and Beutel, Alex and Ahmed, Amr and Smola, Alexander J.},
title = {Explaining Reviews and Ratings with PACO: Poisson Additive Co-Clustering},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2889400},
doi = {10.1145/2872518.2889400},
abstract = {Understanding a user's motivations provides valuable information beyond the ability to recommend items. Quite often this can be accomplished by perusing both ratings and review texts. Unfortunately matrix factorization approaches to recommendation result in large, complex models that are difficult to interpret. In this paper, we attack this problem through succinct additive co-clustering on both ratings and reviews. Our model yields accurate and interpretable recommendations.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {127–128},
numpages = {2},
keywords = {recommendation systems, joint modeling, co-clustering},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3366424.3383540,
author = {Li, Lei and Chen, Li and Zhang, Yongfeng},
title = {Towards Controllable Explanation Generation for Recommender Systems via Neural Template},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3383540},
doi = {10.1145/3366424.3383540},
abstract = {It has been commonly agreed that the explanation associated with recommendation can be effective in increasing the recommender systems (RS)’s transparency and thus users’ satisfaction and acceptance. Among the various types of explanation in RS, the commonly used textual explanation can be roughly classified into two categories, i.e., template-based and generation-based. As for the former, the fixed template may lose flexibility, while, though the latter may enrich the explanation, it may produce less useful content due to the lack of controllability. In this work, we combine the advantages of the two types of method by developing a neural generation approach named Neural Template (NETE) whose explanations are not only flexible but also controllable and useful. Our human evaluation results confirm that the explanations from our model are perceived helpful by users. Furthermore, our case study illustrates that the explanation generation process is controllable. To demonstrate the controllability of our model, we present a demo that can be easily viewed on a Web browser.},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {198–202},
numpages = {5},
keywords = {neural networks, natural language generation, Explainable recommendation},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/2566486.2568006,
author = {Do, Loc and Lauw, Hady W.},
title = {Modeling contextual agreement in preferences},
year = {2014},
isbn = {9781450327442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2566486.2568006},
doi = {10.1145/2566486.2568006},
abstract = {Personalization, or customizing the experience of each individual user, is seen as a useful way to navigate the huge variety of choices on the Web today. A key tenet of personalization is the capacity to model user preferences. The paradigm has shifted from that of individual preferences, whereby we look at a user's past activities alone, to that of shared preferences, whereby we model the similarities in preferences between pairs of users (e.g., friends, people with similar interests). However, shared preferences are still too granular, because it assumes that a pair of users would share preferences across all items. We therefore postulate the need to pay attention to "context", which refers to the specific item on which the preferences between two users are to be estimated. In this paper, we propose a generative model for contextual agreement in preferences. For every triplet consisting of two users and an item, the model estimates both the prior probability of agreement between the two users, as well as the posterior probability of agreement with respect to the item at hand. The model parameters are estimated from ratings data. To extend the model to unseen ratings, we further propose several matrix factorization techniques focused on predicting agreement, rather than ratings. Experiments on real-life data show that our model yields context-specific similarity values that perform better on a prediction task than models relying on shared preferences.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {315–326},
numpages = {12},
keywords = {user preference, generative model, contextual agreement},
location = {Seoul, Korea},
series = {WWW '14}
}

@inproceedings{10.1145/2872427.2883090,
author = {Liang, Dawen and Charlin, Laurent and McInerney, James and Blei, David M.},
title = {Modeling User Exposure in Recommendation},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2883090},
doi = {10.1145/2872427.2883090},
abstract = {Collaborative filtering analyzes user preferences for items (e.g., books, movies, restaurants, academic papers) by exploiting the similarity patterns across users. In implicit feedback settings, all the items, including the ones that a user did not consume, are taken into consideration. But this assumption does not accord with the common sense understanding that users have a limited scope and awareness of items. For example, a user might not have heard of a certain paper, or might live too far away from a restaurant to experience it. In the language of causal analysis (Imbens &amp; Rubin, 2015), the assignment mechanism (i.e., the items that a user is exposed to) is a latent variable that may change for various user/item combinations. In this paper, we propose a new probabilistic approach that directly incorporates user exposure to items into collaborative filtering. The exposure is modeled as a latent variable and the model infers its value from data. In doing so, we recover one of the most successful state-of-the-art approaches as a special case of our model (Hu et al. 2008), and provide a plug-in method for conditioning exposure on various forms of exposure covariates (e.g., topics in text, venue locations). We show that our scalable inference algorithm outperforms existing benchmarks in four different domains both with and without exposure covariates.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {951–961},
numpages = {11},
keywords = {collaborative filtering, matrix factorization, recommender systems},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1145/3184558.3186956,
author = {Wu, Peizhi and Tu, Yi and Yang, Zhenglu and Jatowt, Adam and Odagaki, Masato},
title = {Deep Modeling of the Evolution of User Preferences and Item Attributes in Dynamic Social Networks},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3186956},
doi = {10.1145/3184558.3186956},
abstract = {Modeling the evolution of user preferences and item attributes in a dynamic social network is important because it is the basis for many applications, including recommendation systems and user behavior analysis. This study introduces a comprehensive general neural framework with several optimal strategies to jointly model the evolution of user preferences and item attributes in dynamic social networks. Preliminary experimental results conducted on real-world datasets demonstrate that our model performs better than the state-of-the-art methods.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {115–116},
numpages = {2},
keywords = {MLP, RNN, social networks, user modeling},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3366424.3383300,
author = {Cenikj, Gjorgjina and Gievska, Sonja},
title = {Boosting Recommender Systems with Advanced Embedding Models},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3383300},
doi = {10.1145/3366424.3383300},
abstract = {Recommender systems are paramount in providing personalized content and intelligent content filtering on any social media platform, web portal, and online application. In line with the current trends in the field directed towards mapping problem and data encoding representations from other fields, this research investigates the feasibility of augmenting a graph-based recommender system for Amazon products with two state-of-the-art representation models. In particular, the potential benefits of using the language representation model BERT and GraphSage based representations of nodes and edges for improving the quality of the recommendations were investigated. Link prediction and link attribute inference were used to identify the products that the users will buy and predict the rating they will give to a product, respectively. The initial results of our exploratory study are encouraging and point to potential directions for future research.},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {385–389},
numpages = {5},
keywords = {word embeddings, recommender systems, link prediction, graph embeddings},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/2736277.2741678,
author = {Christakopoulou, Konstantina and Banerjee, Arindam},
title = {Collaborative Ranking with a Push at the Top},
year = {2015},
isbn = {9781450334693},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2736277.2741678},
doi = {10.1145/2736277.2741678},
abstract = {The goal of collaborative filtering is to get accurate recommendations at the top of the list for a set of users. From such a perspective, collaborative ranking based formulations with suitable ranking loss functions are natural. While recent literature has explored the idea based on objective functions such as NDCG or Average Precision, such objectives are difficult to optimize directly. In this paper, building on recent advances from the learning to rank literature, we introduce a novel family of collaborative ranking algorithms which focus on accuracy at the top of the list for each user while learning the ranking functions collaboratively. We consider three specific formulations, based on collaborative p-norm push, infinite push, and reverse-height push, and propose efficient optimization methods for learning these models. Experimental results illustrate the value of collaborative ranking, and show that the proposed methods are competitive, usually better than existing popular approaches to personalized recommendation.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {205–215},
numpages = {11},
keywords = {recommender systems, infinite push, collaborative ranking},
location = {Florence, Italy},
series = {WWW '15}
}

@inproceedings{10.1145/3589334.3645485,
author = {Zhang, Xiaoying and Wang, Hongning and Liu, Yang},
title = {Retention Depolarization in Recommender System},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645485},
doi = {10.1145/3589334.3645485},
abstract = {Repeated risk minimization is a popular choice in real-world recommender systems driving their recommendation algorithms to adapt to user preferences and trends. However, numerous studies have shown that it exacerbates retention disparities among user groups, resulting in polarization within the user population. Given the primary objective of improving long-term user engagement in most industrial recommender systems and the significant commercial benefits from a diverse user population, enforcing retention fairness across user population is therefore crucial. Nonetheless, this goal is highly challenging due to the unknown dynamics of user retention (e.g., when a user would abandon the system) and the simultaneous aim to maximize the experience of every user. In this paper, we propose ReFair, the first computational framework that continuously improves recommendation algorithms while ensuring long-term retention fairness in the entire user population. ReFair alternates between environment learning (i.e., estimate the user retention dynamics) and fairness constrained policy improvement with respect to the estimated environment, while effectively handling uncertainties in the estimation. Our solution provides strong theoretical guarantees for long-term recommendation performance and retention fairness violation. Empirical experiments on two real-world recommendation datasets also demonstrate its effectiveness in realizing these two goals.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1126–1137},
numpages = {12},
keywords = {depolarization, fairness, recommender system},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/2736277.2741109,
author = {Anava, Oren and Golan, Shahar and Golbandi, Nadav and Karnin, Zohar and Lempel, Ronny and Rokhlenko, Oleg and Somekh, Oren},
title = {Budget-Constrained Item Cold-Start Handling in Collaborative Filtering Recommenders via Optimal Design},
year = {2015},
isbn = {9781450334693},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2736277.2741109},
doi = {10.1145/2736277.2741109},
abstract = {It is well known that collaborative filtering (CF) based recommender systems provide better modeling of users and items associated with considerable rating history. The lack of historical ratings results in the user and the item cold-start problems. The latter is the main focus of this work. Most of the current literature addresses this problem by integrating content-based recommendation techniques to model the new item. However, in many cases such content is not available, and the question arises is whether this problem can be mitigated using CF techniques only. We formalize this problem as an optimization problem: given a new item, a pool of available users, and a budget constraint, select which users to assign with the task of rating the new item in order to minimize the prediction error of our model. We show that the objective function is monotone-supermodular, and propose efficient optimal design based algorithms that attain an approximation to its optimum. Our findings are verified by an empirical study using the Netflix dataset, where the proposed algorithms outperform several baselines for the problem at hand.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {45–54},
numpages = {10},
keywords = {optimal design, item cold-start, collaborative filtering},
location = {Florence, Italy},
series = {WWW '15}
}

@inproceedings{10.1145/3442442.3451370,
author = {Bao, Peng and Hong, Weihui and Li, Xuanya},
title = {Predicting Paper Acceptance via Interpretable Decision Sets},
year = {2021},
isbn = {9781450383134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442442.3451370},
doi = {10.1145/3442442.3451370},
abstract = {Measuring the quality of research work is an essential component of the scientific process. With the ever-growing rates of articles being submitted to top-tier conferences, and the potential consistency and bias issues in the peer review process identified by scientific community, it is thus of great necessary and challenge to automatically evaluate submissions. Existing works mainly focus on exploring relevant factors and applying machine learning models to simply be accurate at predicting the acceptance of a given academic paper, while ignoring the interpretability power which is required by a wide range of applications. In this paper, we propose a framework to construct decision sets that consist of unordered if-then rules for predicting paper acceptance. We formalize decision set learning problem via a joint objective function that simultaneously optimize accuracy and interpretability of the rules, rather than organizing them in a hierarchy. We evaluate the effectiveness of the proposed framework by applying it on a public scientific peer reviews dataset. Experimental results demonstrate that the learned interpretable decision sets by our framework performs on par with state-of-the-art classification algorithms which optimize exclusively for predictive accuracy and much more interpretable than rule-based methods.},
booktitle = {Companion Proceedings of the Web Conference 2021},
pages = {461–467},
numpages = {7},
keywords = {peer reviews, interpretability, acceptance prediction},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/2740908.2742711,
author = {Qiu, Shuang and Cheng, Jian and Zhang, Xi and Lu, Hanqing},
title = {Exploring Heterogeneity for Multi-Domain Recommendation with Decisive Factors Selection},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2742711},
doi = {10.1145/2740908.2742711},
abstract = {To address the recommendation problems in the scenarios of multiple domains, in this paper, we propose a novel method, HMRec, which models both consistency and heterogeneity of users' multiple behaviors in a unified framework. Moreover, the decisive factors of each domain can also be captured by our approach successfully. Experiments on the real multi-domain dataset demonstrate the effectiveness of our model.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {95–96},
numpages = {2},
keywords = {recommendation, multiple domains, heterogeneity},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/3038912.3052705,
author = {Proskurnia, Julia and Grabowicz, Przemyslaw and Kobayashi, Ryota and Castillo, Carlos and Cudr\'{e}-Mauroux, Philippe and Aberer, Karl},
title = {Predicting the Success of Online Petitions Leveraging Multidimensional Time-Series},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052705},
doi = {10.1145/3038912.3052705},
abstract = {Applying classical time-series analysis techniques to online content is challenging, as web data tends to have data quality issues and is often incomplete, noisy, or poorly aligned. In this paper, we tackle the problem of predicting the evolution of a time series of user activity on the web in a manner that is both accurate and interpretable, using related time series to produce a more accurate prediction. We test our methods in the context of predicting signatures for online petitions using data from thousands of petitions posted on The Petition Site - one of the largest platforms of its kind. We observe that the success of these petitions is driven by a number of factors, including promotion through social media channels and on the front page of the petitions platform. We propose an interpretable model that incorporates seasonality, aging effects, self-excitation, and external effects. The interpretability of the model is important for understanding the elements that drives the activity of an online content. We show through an extensive empirical evaluation that our model is significantly better at predicting the outcome of a petition than state-of-the-art techniques.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {755–764},
numpages = {10},
keywords = {web applications, time series prediction, online petitions},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3308558.3313585,
author = {Kim, Seunghyeon and Lee, Jongwuk and Shim, Hyunjung},
title = {Dual Neural Personalized Ranking},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313585},
doi = {10.1145/3308558.3313585},
abstract = {Implicit user feedback is a fundamental dataset for personalized recommendation models. Because of its inherent characteristics of sparse one-class values, it is challenging to uncover meaningful user/item representations. In this paper, we propose dual neural personalized ranking (DualNPR), which fully exploits both user- and item-side pairwise rankings in a unified manner. The key novelties of the proposed model are three-fold: (1) DualNPR discovers mutual correlation among users and items by utilizing both user- and item-side pairwise rankings, alleviating the data sparsity problem. We stress that, unlike existing models that require extra information, DualNPR naturally augments both user- and item-side pairwise rankings from a user-item interaction matrix. (2) DualNPR is built upon deep matrix factorization to capture the variability of user/item representations. In particular, it chooses raw user/item vectors as an input and learns latent user/item representations effectively. (3) DualNPR employs a dynamic negative sampling method using an exponential function, further improving the accuracy of top-N recommendation. In experimental results over three benchmark datasets, DualNPR outperforms baseline models by 21.9-86.7% in hit rate, 14.5-105.8% in normalized discounted cumulative gain, and 5.1-23.3% in the area under the ROC curve.},
booktitle = {The World Wide Web Conference},
pages = {863–873},
numpages = {11},
keywords = {top-N recommendation, dual representation, Implicit feedback},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3184558.3186972,
author = {Kong, Quyu and Rizoiu, Marian-Andrei and Wu, Siqi and Xie, Lexing},
title = {Will This Video Go Viral: Explaining and Predicting the Popularity of Youtube Videos},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3186972},
doi = {10.1145/3184558.3186972},
abstract = {What makes content go viral Which videos become popular and why others don't Such questions have elicited significant attention from both researchers and industry, particularly in the context of online media. A range of models have been recently proposed to explain and predict popularity; however, there is a short supply of practical tools, accessible for regular users, that leverage these theoretical results. HIPie--an interactive visualization system--is created to fill this gap, by enabling users to reason about the virality and the popularity of online videos. It retrieves the metadata and the past popularity series of Youtube videos, it employs the Hawkes Intensity Process, a state-of-the-art online popularity model for explaining and predicting video popularity, and it presents videos comparatively in a series of interactive plots. This system will help both content consumers and content producers in a range of data-driven inquiries, such as to comparatively analyze videos and channels, to explain and to predict future popularity, to identify viral videos, and to estimate responses to online promotion.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {175–178},
numpages = {4},
keywords = {channel comparison, identifying future popular videos, interactive visualization, popularity modeling, promotion simulation, video comparison, youtube videos},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3543507.3583303,
author = {Du, Yuntao and Lian, Jianxun and Yao, Jing and Wang, Xiting and Wu, Mingqi and Chen, Lu and Gao, Yunjun and Xie, Xing},
title = {Towards Explainable Collaborative Filtering with Taste Clusters Learning},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583303},
doi = {10.1145/3543507.3583303},
abstract = {Collaborative Filtering (CF) is a widely used and effective technique for recommender systems. In recent decades, there have been significant advancements in latent embedding-based CF methods for improved accuracy, such as matrix factorization, neural collaborative filtering, and LightGCN. However, the explainability of these models has not been fully explored. Adding explainability to recommendation models can not only increase trust in the decision-making process, but also have multiple benefits such as providing persuasive explanations for item recommendations, creating explicit profiles for users and items, and assisting item producers in design improvements. In this paper, we propose a neat and effective Explainable Collaborative Filtering (ECF) model that leverages interpretable cluster learning to achieve the two most demanding objectives: (1) Precise - the model should not compromise accuracy in the pursuit of explainability; and (2) Self-explainable - the model’s explanations should truly reflect its decision-making process, not generated from post-hoc methods. The core of ECF is mining taste clusters from user-item interactions and item profiles. We map each user and item to a sparse set of taste clusters, and taste clusters are distinguished by a few representative tags. The user-item preference, users/items’ cluster affiliations, and the generation of taste clusters are jointly optimized in an end-to-end manner. Additionally, we introduce a forest mechanism to ensure the model’s accuracy, explainability, and diversity. To comprehensively evaluate the explainability quality of taste clusters, we design several quantitative metrics, including in-cluster item coverage, tag utilization, silhouette, and informativeness. Our model’s effectiveness is demonstrated through extensive experiments on three real-world datasets.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3712–3722},
numpages = {11},
keywords = {Clustering, Collaborative Filtering, Explanability, Recommendation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3485447.3512168,
author = {Wang, Peng and Cai, Renqin and Wang, Hongning},
title = {Graph-based Extractive Explainer for Recommendations},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512168},
doi = {10.1145/3485447.3512168},
abstract = {Explanations in a recommender system assist users make informed decisions among a set of recommended items. Extensive research attention has been devoted to generate natural language explanations to depict how the recommendations are generated and why the users should pay attention to them. However, due to different limitations of those solutions, e.g., template-based or generation-based, it is hard to make the explanations easily perceivable, reliable, and personalized at the same time. In this work, we develop a graph attentive neural network model that seamlessly integrates user, item, attributes and sentences for extraction-based explanation. The attributes of items are selected as the intermediary to facilitate message passing for user-item specific evaluation of sentence relevance. And to balance individual sentence relevance, overall attribute coverage and content redundancy, we solve an integer linear programming problem to make the final selection of sentences. Extensive empirical evaluations against a set of state-of-the-art baseline methods on two benchmark review datasets demonstrated the generation quality of proposed solution.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {2163–2171},
numpages = {9},
keywords = {Extraction-based explanation, graph neural networks},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3442381.3449866,
author = {Li, Yunqi and Chen, Hanxiong and Fu, Zuohui and Ge, Yingqiang and Zhang, Yongfeng},
title = {User-oriented Fairness in Recommendation},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449866},
doi = {10.1145/3442381.3449866},
abstract = {As a highly data-driven application, recommender systems could be affected by data bias, resulting in unfair results for different data groups, which could be a reason that affects the system performance. Therefore, it is important to identify and solve the unfairness issues in recommendation scenarios. In this paper, we address the unfairness problem in recommender systems from the user perspective. We group users into advantaged and disadvantaged groups according to their level of activity, and conduct experiments to show that current recommender systems will behave unfairly between two groups of users. Specifically, the advantaged users (active) who only account for a small proportion in data enjoy much higher recommendation quality than those disadvantaged users (inactive). Such bias can also affect the overall performance since the disadvantaged users are the majority. To solve this problem, we provide a re-ranking approach to mitigate this unfairness problem by adding constraints over evaluation metrics. The experiments we conducted on several real-world datasets with various recommendation algorithms show that our approach can not only improve group fairness of users in recommender systems, but also achieve better overall recommendation performance.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {624–632},
numpages = {9},
keywords = {Recommendation System, Re-ranking, Fairness, AI Ethics},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/2566486.2567970,
author = {Lee, Joonseok and Bengio, Samy and Kim, Seungyeon and Lebanon, Guy and Singer, Yoram},
title = {Local collaborative ranking},
year = {2014},
isbn = {9781450327442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2566486.2567970},
doi = {10.1145/2566486.2567970},
abstract = {Personalized recommendation systems are used in a wide variety of applications such as electronic commerce, social networks, web search, and more. Collaborative filtering approaches to recommendation systems typically assume that the rating matrix (e.g., movie ratings by viewers) is low-rank. In this paper, we examine an alternative approach in which the rating matrix is locally low-rank. Concretely, we assume that the rating matrix is low-rank within certain neighborhoods of the metric space defined by (user, item) pairs. We combine a recent approach for local low-rank approximation based on the Frobenius norm with a general empirical risk minimization for ranking losses. Our experiments indicate that the combination of a mixture of local low-rank matrices each of which was trained to minimize a ranking loss outperforms many of the currently used state-of-the-art recommendation systems. Moreover, our method is easy to parallelize, making it a viable approach for large scale real-world rank-based recommendation systems.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {85–96},
numpages = {12},
keywords = {recommender systems, ranking, collaborative filtering},
location = {Seoul, Korea},
series = {WWW '14}
}

@inproceedings{10.1145/3366423.3380076,
author = {Zhang, Zhen and Bu, Jiajun and Ester, Martin and Zhang, Jianfeng and Yao, Chengwei and Li, Zhao and Wang, Can},
title = {Learning Temporal Interaction Graph Embedding via Coupled Memory Networks},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380076},
doi = {10.1145/3366423.3380076},
abstract = {Graph embedding has become the research focus in both academic and industrial communities due to its powerful capabilities. The majority of existing work overwhelmingly learn node embeddings in the context of static, plain or attributed, homogeneous graphs. However, many real-world applications frequently involve bipartite graphs with temporal and attributed interaction edges, named temporal interaction graphs. The temporal interactions usually imply different facets of interest and might even evolve over time, thus putting forward huge challenges in learning effective node representations. In this paper, we propose a novel framework named TigeCMN to learn node representations from a sequence of temporal interactions. Specifically, we devise two coupled memory networks to store and update node embeddings in external matrices explicitly and dynamically, which forms deep matrix representations and could enhance the expressiveness of the node embeddings. We conduct experiments on two real-world datasets and the experimental results empirically demonstrate that TigeCMN can outperform the state-of-the-arts with different gains.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {3049–3055},
numpages = {7},
keywords = {Temporal Interaction Graphs, Graph Embedding},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3485447.3512078,
author = {Liu, Haochen and Tang, Da and Yang, Ji and Zhao, Xiangyu and Liu, Hui and Tang, Jiliang and Cheng, Youlong},
title = {Rating Distribution Calibration for Selection Bias Mitigation in Recommendations},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512078},
doi = {10.1145/3485447.3512078},
abstract = {Real-world recommendation datasets have been shown to be subject to selection bias, which can challenge recommendation models to learn real preferences of users, so as to make accurate recommendations. Existing approaches to mitigate selection bias, such as data imputation and inverse propensity score, are sensitive to the quality of the additional imputation or propensity estimation models. To break these limitations, in this work, we propose a novel self-supervised learning (SSL) framework, i.e., Rating Distribution Calibration (RDC), to tackle selection bias without introducing additional models. In addition to the original training objective, we introduce a rating distribution calibration loss. It aims to correct the predicted rating distribution of biased users by taking advantage of that of their similar unbiased users. We empirically evaluate RDC on two real-world datasets and one synthetic dataset. The experimental results show that RDC outperforms the original model as well as the state-of-the-art debiasing approaches by a significant margin.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {2048–2057},
numpages = {10},
keywords = {recommendation system, self-supervised learning, unbiased recommendation},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3485447.3511963,
author = {Pang, Haoyu and Giunchiglia, Fausto and Li, Ximing and Guan, Renchu and Feng, Xiaoyue},
title = {PNMTA: A Pretrained Network Modulation and Task Adaptation Approach for User Cold-Start Recommendation},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3511963},
doi = {10.1145/3485447.3511963},
abstract = {User cold-start recommendation is a serious problem that limits the performance of recommender systems (RSs). Recent studies have focused on treating this issue as a few-shot problem and seeking solutions with model-agnostic meta-learning (MAML). Such methods regard making recommendations for one user as a task and adapt to new users with a few steps of gradient updates on the meta-model. However, none of those methods consider the limitation of user representation learning imposed by the special task setting of MAML-based RSs. And they learn a common meta-model for all users while ignoring the implicit grouping distribution induced by the correlation differences among users. In response to the above problems, we propose a pretrained network modulation and task adaptation approach (PNMTA) for user cold-start recommendation. In the pretraining stage, a pretrained model is obtained with non-meta-learning methods to achieve better user representation and generalization, which can also transfer the learned knowledge to the meta-learning stage for modulation. During the meta-learning stage, an encoder modulator is utilized to realize the memorization and correction of prior parameters for the meta-learning task, and a predictor modulator is introduced to condition the model initialization on the task identity for adaptation steps. In addition, PNMTA can also make use of the existing non-cold-start users for pretraining. Comprehensive experiments on two benchmark datasets demonstrate that our model can achieve significant and consistent improvements against other state-of-the-art methods.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {348–359},
numpages = {12},
keywords = {Cold-start problem, Meta learning, Recommender systems, Transfer learning},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3041021.3051148,
author = {Zhang, Menghao and Hu, Binbin and Shi, Chuan and Wang, Bai},
title = {Local Low-Rank Matrix Approximation with Preference Selection of Anchor Points},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051148},
doi = {10.1145/3041021.3051148},
abstract = {Matrix factorization is widely used in personalized recommender systems, text mining, and computer vision. A general assumption to construct matrix approximation is that the original matrix is of global low rank, while Joonseok Lee et al. proposed that many real matrices may be not globally low rank, and thus a locally low-rank matrix approximation method has been proposed.[11] However, this kind of matrix approximation method still leaves some important issues unsolved, for example, the randomly selecting anchor nodes. In this paper, we study the problem of the selection of anchor nodes to enhance locally low-rank matrix approximation. We propose a new model for local low-rank matrix approximation which selects anchor-points using a heuristic method. Our experiments indicate that the proposed method outperforms many state-of-the-art recommendation methods. Moreover, the proposed method can significantly improve algorithm efficiency, and it is easy to parallelize. These traits make it potential for large scale real-world recommender systems.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1395–1403},
numpages = {9},
keywords = {recommender systems, matrix approximation, low-rank, clustering},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054139,
author = {Rodrigues, Phillipe and Silva, Ismael Santana and Barbosa, Gl\'{\i}via Ang\'{e}lica Rodigues and Coutinho, Fl\'{a}vio Roberto dos Santos and Mour\~{a}o, Fernando},
title = {Beyond the Stars: Towards a Novel Sentiment Rating to Evaluate Applications in Web Stores of Mobile Apps},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054139},
doi = {10.1145/3041021.3054139},
abstract = {This paper proposes an approach to evaluate mobile applications which complements the information provided by the number of stars and downloads in app stores. The goal is to provide novel information to assist users in the decision-making process regarding the choice of applications. In this sense, we conducted experiments to verify the relationship between the number of stars and the content of review comments. Results indicated that there is information in reviews not properly represented by stars. Thus, we present a sentiment rating generated automatically by aggregating opinions reported in the reviews related to each application. We evaluated this new rating using 26,996 reviews related to six applications present on the Google Play Store. The obtained results allow us to demonstrate that: (1) it is possible and feasible to generate a sentiment rating automatically and (2) the rating is useful for web stores of mobile applications to improve their mechanisms of ranking and recommendation as well as to assist users and developers to evaluate the quality and/or acceptance of the offered mobile applications.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {109–117},
numpages = {9},
keywords = {web stores, user review, sentiment analysis, mobile apps, machine learning, decision-making},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/2488388.2488475,
author = {Paquet, Ulrich and Koenigstein, Noam},
title = {One-class collaborative filtering with random graphs},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488475},
doi = {10.1145/2488388.2488475},
abstract = {The bane of one-class collaborative filtering is interpreting and modelling the latent signal from the missing class. In this paper we present a novel Bayesian generative model for implicit collaborative filtering. It forms a core component of the Xbox Live architecture, and unlike previous approaches, delineates the odds of a user disliking an item from simply being unaware of it. The latent signal is treated as an unobserved random graph connecting users with items they might have encountered. We demonstrate how large-scale distributed learning can be achieved through a combination of stochastic gradient descent and mean field variational inference over random graph samples. A fine-grained comparison is done against a state of the art baseline on real world data.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {999–1008},
numpages = {10},
keywords = {variational inference, random graph, one-class collaborative filtering},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/3696410.3714698,
author = {Cinus, Federico and Minici, Marco and Luceri, Luca and Ferrara, Emilio},
title = {Exposing Cross-Platform Coordinated Inauthentic Activity in the Run-Up to the 2024 U.S. Election},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714698},
doi = {10.1145/3696410.3714698},
abstract = {Coordinated information operations remain a persistent challenge on social media, despite platform efforts to curb them. While previous research has primarily focused on identifying these operations within individual platforms, this study shows that coordination frequently transcends platform boundaries. Leveraging newly collected data of online conversations related to the 2024 U.S. Election across 𝕏 (formerly, Twitter), Facebook, and Telegram, we construct similarity networks to detect coordinated communities exhibiting suspicious sharing behaviors within and across platforms. Proposing an advanced coordination detection model, we reveal evidence of potential foreign interference, with Russian-affiliated media being systematically promoted across Telegram and 𝕏. Our analysis also uncovers substantial intra- and cross-platform coordinated inauthentic activity, driving the spread of highly partisan, low-credibility, and conspiratorial content. These findings highlight the urgent need for regulatory measures that extend beyond individual platforms to effectively address the growing challenge of cross-platform coordinated influence campaigns.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {541–559},
numpages = {19},
keywords = {coordinated inauthentic behavior, information operations},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/2566486.2568018,
author = {Anderson, Ashton and Kumar, Ravi and Tomkins, Andrew and Vassilvitskii, Sergei},
title = {The dynamics of repeat consumption},
year = {2014},
isbn = {9781450327442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2566486.2568018},
doi = {10.1145/2566486.2568018},
abstract = {We study the patterns by which a user consumes the same item repeatedly over time, in a wide variety domains ranging from check-ins at the same business location to re-watches of the same video. We find that recency of consumption is the strongest predictor of repeat consumption. Based on this, we develop a model by which the item from $t$ timesteps ago is reconsumed with a probability proportional to a function of t. We study theoretical properties of this model, develop algorithms to learn reconsumption likelihood as a function of t, and show a strong fit of the resulting inferred function via a power law with exponential cutoff. We then introduce a notion of item quality, show that it alone underperforms our recency-based model, and develop a hybrid model that predicts user choice based on a combination of recency and quality. We show how the parameters of this model may be jointly estimated, and show that the resulting scheme outperforms other alternatives.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {419–430},
numpages = {12},
keywords = {repeat consumption, recency, quality, copying process},
location = {Seoul, Korea},
series = {WWW '14}
}

@inproceedings{10.1145/3184558.3186584,
author = {Chen, Xinpeng and Chen, Jingyuan and Ma, Lin and Yao, Jian and Liu, Wei and Luo, Jiebo and Zhang, Tong},
title = {Fine-grained Video Attractiveness Prediction Using Multimodal Deep Learning on a Large Real-world Dataset},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3186584},
doi = {10.1145/3184558.3186584},
abstract = {Nowadays, billions of videos are online ready to be viewed and shared. Among an enormous volume of videos, some popular ones are widely viewed by online users while the majority attract little attention. Furthermore, within each video, different segments may attract significantly different numbers of views. This phenomenon leads to a challenging yet important problem, namely fine-grained video attractiveness prediction, which only relies on video contents to forecast video attractiveness at fine-grained levels, specifically video segments of several second length in this paper. However, one major obstacle for such a challenging problem is that no suitable benchmark dataset currently exists. To this end, we construct the first fine-grained video attractiveness dataset (FVAD), which is collected from one of the most popular video websites in the world. In total, the constructed FVAD consists of 1,019 drama episodes with 780.6 hours covering different categories and a wide variety of video contents. Apart from the large amount of videos, hundreds of millions of user behaviors during watching videos are also included, such as view counts, "fast-forward, "fast-rewind, and so on, where "view counts" reflects the video attractiveness while other engagements capture the interactions between the viewers and videos. First, we demonstrate that video attractiveness and different engagements present different relationships. Second, FVAD provides us an opportunity to study the fine-grained video attractiveness prediction problem. We design different sequential models to perform video attractiveness prediction by relying solely on video contents. The sequential models exploit the multimodal relationships between visual and audio components of the video contents at different levels. Experimental results demonstrate the effectiveness of our proposed sequential models with different visual and audio representations, the necessity of incorporating the two modalities, and the complementary behaviors of the sequential prediction models at different levels.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {671–678},
numpages = {8},
keywords = {fine-grained, long short-term memory(lstm), multimodal fusion, video attractiveness},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3485447.3512216,
author = {Kuchhal, Dhruv and Li, Frank},
title = {A View into YouTube View Fraud},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512216},
doi = {10.1145/3485447.3512216},
abstract = {Social media platforms are driven by user engagement metrics. Unfortunately, such metrics are susceptible to manipulation and expose the platforms to abuse. Video view fraud is a unique class of fake engagement abuse on video-sharing platforms, such as YouTube, where the view count of videos is artificially inflated. There exists limited research on such abuse, and prior work focused on automated or bot-driven approaches. In this paper, we explore organic or human-driven approaches to view fraud, conducting a case study on a long-running YouTube view fraud campaign operated on a popular free video streaming service, 123Movies. Before 123Movies users are allowed to access a stream on the service, they must watch an unsolicited YouTube video displayed as a pre-roll advertisement. Due to 123Movies’ popularity, this activity drives large-scale YouTube view fraud. In this study, we reverse-engineer how 123Movies distributes these YouTube videos as pre-roll advertisements, and track the YouTube videos involved over a 9-month period. For a subset of these videos, we monitor their view counts and metrics for their respective YouTube channels over the same period. Our analysis reveals the characteristics of YouTube channels and videos participating in this view fraud, as well as the efficacy of such view fraud efforts. Ultimately, our study provides empirical grounding on organic YouTube view fraud.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {555–563},
numpages = {9},
keywords = {Fake Engagement, Online Abuse, View Fraud},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3308558.3313739,
author = {Yin, Ruiping and Li, Kan and Lu, Jie and Zhang, Guangquan},
title = {Enhancing Fashion Recommendation with Visual Compatibility Relationship},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313739},
doi = {10.1145/3308558.3313739},
abstract = {With the increasing of online shopping services, fashion recommendation plays an important role in daily online shopping scenes. A lot of recommender systems have been developed with visual information. However, few works take into account compatibility relationship when they are generating recommendations. The challenge is that fashion concept is often subtle and subjective for different customers. In this paper, we propose a fashion compatibility knowledge learning method that incorporates visual compatibility relationships as well as style information. We also propose a fashion recommendation method with domain adaptation strategy to alleviate the distribution gap between the items in target domain and the items of external compatible outfits. Our results indicate that the proposed method is capable of learning visual compatibility knowledge and outperforms all the baselines.},
booktitle = {The World Wide Web Conference},
pages = {3434–3440},
numpages = {7},
keywords = {Viusal Compatibility, Image Representation, Fashion Recommendation},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3308560.3317080,
author = {Lees, Alyssa and Welty, Chris},
title = {Discovering User Bias in Ordinal Voting Systems},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3317080},
doi = {10.1145/3308560.3317080},
abstract = {Crowdsourcing systems increasingly rely on users to provide more subjective ground truth for intelligent systems - e.g. ratings, aspect of quality and perspectives on how expensive or lively a place feels, etc. We focus on the ubiquitous implementation of online user ordinal voting (e.g 1-5, 1 star-4 stars) on some aspect of an entity, to extract a relative truth, measured by a selected metric such as vote plurality or mean. We argue that this methodology can aggregate results that yield little information to the end user. In particular, ordinal user rankings often converge to a indistinguishable rating. This is demonstrated by the trend in certain cities for the majority of restaurants to all have a 4 star rating. Similarly, the rating of an establishment can be significantly affected by a few users [10]. User bias in voting is not spam, but rather a preference that can be harnessed to provide more information to users. We explore notions of both global skew and user bias. Leveraging these bias and preference concepts, the paper suggests explicit models for better personalization and more informative ratings.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {1106–1110},
numpages = {5},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2872518.2889405,
author = {Abdollahi, Behnoush and Nasraoui, Olfa},
title = {Explainable Matrix Factorization for Collaborative Filtering},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2889405},
doi = {10.1145/2872518.2889405},
abstract = {Explanations have been shown to increase the user's trust in recommendations in addition to providing other benefits such as scrutability, which is the ability to verify the validity of recommendations. Most explanation methods are designed for classical neighborhood-based Collaborative Filtering (CF) or rule-based methods. For the state of the art Matrix Factorization (MF) recommender systems, recent explanation methods, require an additional data source, such as item content data, in addition to rating data. In this paper, we address the case where no such additional data is available and propose a new Explainable Matrix Factorization (EMF) technique that computes an accurate top-$n$ recommendation list of items that are explainable. We also introduce new explanation quality metrics, that we call Mean Explainability Precision (MEP) and Mean Explainability Recall (MER).},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {5–6},
numpages = {2},
keywords = {recommender systems, matrix factorization (mf), explanations, collaborative filtering (cf)},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3485447.3512031,
author = {Yang, Aobo and Wang, Nan and Cai, Renqin and Deng, Hongbo and Wang, Hongning},
title = {Comparative Explanations of Recommendations},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512031},
doi = {10.1145/3485447.3512031},
abstract = {As recommendation is essentially a comparative (or ranking) process, a good explanation should illustrate to users why an item is believed to be better than another, i.e., comparative explanations about the recommended items. Ideally, after reading the explanations, a user should reach the same ranking of items as the system’s. Unfortunately, little research attention has yet been paid on such comparative explanations. In this work, we develop an extract-and-refine architecture to explain the relative comparisons among a set of ranked items from a recommender system. For each recommended item, we first extract one sentence from its associated reviews that best suits the desired comparison against a set of reference items. Then this extracted sentence is further articulated with respect to the target user through a generative model to better explain why the item is recommended. We design a new explanation quality metric based on BLEU to guide the end-to-end training of the extraction and refinement components, which avoids generation of generic content. Extensive offline evaluations on two large recommendation benchmark datasets and serious user studies against an array of state-of-the-art explainable recommendation algorithms demonstrate the necessity of comparative explanations and the effectiveness of our solution.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {3113–3123},
numpages = {11},
keywords = {comparative explanation, explainable recommendation, extract-and-refine, text generation},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3308558.3313745,
author = {Gulati, Avni and Eirinaki, Magdalini},
title = {With a Little Help from My Friends (and Their Friends): Influence Neighborhoods for Social Recommendations},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313745},
doi = {10.1145/3308558.3313745},
abstract = {Social recommendations have been a very intriguing domain for researchers in the past decade. The main premise is that the social network of a user can be leveraged to enhance the rating-based recommendation process. This has been achieved in various ways, and under different assumptions about the network characteristics, structure, and availability of other information (such as trust, content, etc.) In this work, we create neighborhoods of influence leveraging only the social graph structure. These are in turn introduced in the recommendation process both as a pre-processing step and as a social regularization factor of the matrix factorization algorithm. Our experimental evaluation using real-life datasets demonstrates the effectiveness of the proposed technique.},
booktitle = {The World Wide Web Conference},
pages = {2778–2784},
numpages = {7},
keywords = {social recommender systems, recommendation systems, influence propagation},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2736277.2741122,
author = {Fan, Liyue and Jin, Hongxia},
title = {A Practical Framework for Privacy-Preserving Data Analytics},
year = {2015},
isbn = {9781450334693},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2736277.2741122},
doi = {10.1145/2736277.2741122},
abstract = {The availability of an increasing amount of user generated data is transformative to our society. We enjoy the benefits of analyzing big data for public interest, such as disease outbreak detection and traffic control, as well as for commercial interests, such as smart grid and product recommendation. However, the large collection of user generated data contains unique patterns and can be used to re-identify individuals, which has been exemplified by the AOL search log release incident. In this paper, we propose a practical framework for data analytics, while providing differential privacy guarantees to individual data contributors. Our framework generates differentially private aggregates which can be used to perform data mining and recommendation tasks. To alleviate the high perturbation errors introduced by the differential privacy mechanism, we present two methods with different sampling techniques to draw a subset of individual data for analysis. Empirical studies with real-world data sets show that our solutions enable accurate data analytics on a small fraction of the input data, reducing user privacy risk and data storage requirement without compromising the analysis results.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {311–321},
numpages = {11},
keywords = {sampling, differential privacy, data analytics},
location = {Florence, Italy},
series = {WWW '15}
}

@inproceedings{10.1145/3442381.3449869,
author = {Li, Xiucheng and Chin, Jin Yao and Chen, Yile and Cong, Gao},
title = {Sinkhorn Collaborative Filtering},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449869},
doi = {10.1145/3442381.3449869},
abstract = {Recommender systems play a vital role in modern web services. In a typical recommender system, we are given a set of observed user-item interaction records and seek to uncover the hidden behavioral patterns of users from these historical interactions. By exploiting these hidden patterns, we aim to discover users’ personalized tastes and recommend them new items. Among various types of recommendation methods, the latent factor collaborative filtering models have dominated the field. In this paper, we develop a unified view for the existing latent factor models from a probabilistic perspective. The unified framework enables us to discern the underlying connections of different latent factor models and deepen our understandings of their advantages and limitations. In particular, we observe that the loss functions adopted by the existing models are oblivious to the geometry induced by the item-similarity. To address this, we propose a novel model—SinkhornCF—based on Sinkhorn divergence. To address the challenge of the expensive computational cost of Sinkhorn divergence, we also propose new techniques to enable the resulting model to be able to scale to large datasets. Its effectiveness is verified on two real-world recommendation datasets.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {582–592},
numpages = {11},
keywords = {probabilistic generative models, Sinkhorn divergence, Latent factor models},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3442381.3449986,
author = {Liu, Fan and Cheng, Zhiyong and Zhu, Lei and Gao, Zan and Nie, Liqiang},
title = {Interest-aware Message-Passing GCN for Recommendation},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449986},
doi = {10.1145/3442381.3449986},
abstract = {Graph Convolution Networks (GCNs) manifest great potential in recommendation. This is attributed to their capability on learning good user and item embeddings by exploiting the collaborative signals from the high-order neighbors. Like other GCN models, the GCN based recommendation models also suffer from the notorious over-smoothing problem – when stacking more layers, node embeddings become more similar and eventually indistinguishable, resulted in performance degradation. The recently proposed LightGCN and LR-GCN alleviate this problem to some extent, however, we argue that they overlook an important factor for the over-smoothing problem in recommendation, that is, high-order neighboring users with no common interests of a user can be also involved in the user’s embedding learning in the graph convolution operation. As a result, the multi-layer graph convolution will make users with dissimilar interests have similar embeddings. In this paper, we propose a novel Interest-aware Message-Passing GCN (IMP-GCN) recommendation model, which performs high-order graph convolution inside subgraphs. The subgraph consists of users with similar interests and their interacted items. To form the subgraphs, we design an unsupervised subgraph generation module, which can effectively identify users with common interests by exploiting both user feature and graph structure. To this end, our model can avoid propagating negative information from high-order neighbors into embedding learning. Experimental results on three large-scale benchmark datasets show that our model can gain performance improvement by stacking more layers and outperform the state-of-the-art GCN-based recommendation models significantly.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {1296–1305},
numpages = {10},
keywords = {Subgraph, Recommendation, Message-Passing Strategy, Interest-aware, Graph Convolution Networks},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/2740908.2742726,
author = {Sedhain, Suvash and Menon, Aditya Krishna and Sanner, Scott and Xie, Lexing},
title = {AutoRec: Autoencoders Meet Collaborative Filtering},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2742726},
doi = {10.1145/2740908.2742726},
abstract = {This paper proposes AutoRec, a novel autoencoder framework for collaborative filtering (CF). Empirically, AutoRec's compact and efficiently trainable model outperforms state-of-the-art CF techniques (biased matrix factorization, RBM-CF and LLORMA) on the Movielens and Netflix datasets.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {111–112},
numpages = {2},
keywords = {recommender systems, collaborative filtering, autoencoders},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/3485447.3512021,
author = {Wang, Yuyan and Zhao, Zhe and Dai, Bo and Fifty, Christopher and Lin, Dong and Hong, Lichan and Wei, Li and Chi, Ed H.},
title = {Can Small Heads Help? Understanding and Improving Multi-Task Generalization},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512021},
doi = {10.1145/3485447.3512021},
abstract = {Multi-task learning aims to solve multiple machine learning tasks at the same time, with good solutions being both generalizable and Pareto optimal. A multi-task deep learning model consists of a shared representation learned to capture task commonalities, and task-specific sub-networks capturing the specificities of each task. In this work, we offer insights on the under-explored trade-off between minimizing task training conflicts in multi-task learning and improving multi-task generalization, i.e. the generalization capability of the shared presentation across all tasks. The trade-off can be viewed as the tension between multi-objective optimization and shared representation learning: As a multi-objective optimization problem, sufficient parameterization is needed for mitigating task conflicts in a constrained solution space; However, from a representation learning perspective, over-parameterizing the task-specific sub-networks may give the model too many ”degrees of freedom” and impedes the generalizability of the shared representation. Specifically, we first present insights on understanding the parameterization effect of multi-task deep learning models and empirically show that larger models are not necessarily better in terms of multi-task generalization. A delicate balance between mitigating task training conflicts vs. improving generalizability of the shared presentation learning is needed to achieve optimal performance across multiple tasks. Motivated by our findings, we then propose the use of a under-parameterized self-auxiliary head alongside each task-specific sub-network during training, which automatically balances the aforementioned trade-off. As the auxiliary heads are small in size and are discarded during inference time, the proposed method incurs minimal training cost and no additional serving cost. We conduct experiments with the proposed self-auxiliaries on two public datasets and live experiments on one of the largest industrial recommendation platforms serving billions of users. The results demonstrate the effectiveness of the proposed method in improving the predictive performance across multiple tasks in multi-task models.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {3009–3019},
numpages = {11},
keywords = {Pareto frontier, auxiliary tasks, multi-task learning, neural networks},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3308560.3317598,
author = {Matthews, Jeanna and Goerzen, Matt},
title = {Black Hat Trolling, White Hat Trolling, and Hacking the Attention Landscape},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3317598},
doi = {10.1145/3308560.3317598},
abstract = {In this paper, we analogize the practice of trolling to the practice of hacking. Just as hacking often involves the discovery and exploitation of vulnerabilities in a computer security landscape, trolling frequently involves the discovery and exploitation of vulnerabilities in a media or attention landscape to amplify messages and direct attention. Also like with hacking, we consider the possibility for a range of trolling personas: from black hat trolls who push an agenda that is clearly counter to the interests of the target, to gray hat trolls who exploit vulnerabilities to draw critical attention to unaddressed issues, and white hat trolls who could help proactively disclose vulnerabilities so that attack surface can be reduced. We discuss a variety of trolling techniques from dogpiling to sockpuppetry and also a range of possible interventions.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {523–528},
numpages = {6},
keywords = {social media, politics, memes, media governance, media, journalism, hacking, ethics, Trolling},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3543873.3587657,
author = {Sahijwani, Harshita and Dhole, Kaustubh and Purwar, Ankur and Vasudevan, Venugopal and Agichtein, Eugene},
title = {Contextual Response Interpretation for Automated Structured Interviews: A Case Study in Market Research},
year = {2023},
isbn = {9781450394192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543873.3587657},
doi = {10.1145/3543873.3587657},
abstract = {Structured interviews are used in many settings, importantly in market research on topics such as brand perception, customer habits, or preferences, which are critical to product development, marketing, and e-commerce at large. Such interviews generally consist of a series of questions that are asked to a participant. These interviews are typically conducted by skilled interviewers, who interpret the responses from the participants and can adapt the interview accordingly. Using automated conversational agents to conduct such interviews would enable reaching a much larger and potentially more diverse group of participants than currently possible. However, the technical challenges involved in building such a conversational system are relatively unexplored. To learn more about these challenges, we convert a market research multiple-choice questionnaire to a conversational format and conduct a user study. We address the key task of conducting structured interviews, namely interpreting the participant’s response, for example, by matching it to one or more predefined options. Our findings can be applied to improve response interpretation for the information elicitation phase of conversational recommender systems.},
booktitle = {Companion Proceedings of the ACM Web Conference 2023},
pages = {886–891},
numpages = {6},
keywords = {conversational preference elicitation, conversational recommender systems, intent prediction},
location = {Austin, TX, USA},
series = {WWW '23 Companion}
}

@inproceedings{10.1145/1526709.1526810,
author = {Matsuo, Yutaka and Yamamoto, Hikaru},
title = {Community gravity: measuring bidirectional effects by trust and rating on online social networks},
year = {2009},
isbn = {9781605584874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1526709.1526810},
doi = {10.1145/1526709.1526810},
abstract = {Several attempts have been made to analyze customer behavior on online E-commerce sites. Some studies particularly emphasize the social networks of customers. Users' reviews and ratings of a product exert effects on other consumers' purchasing behavior. Whether a user refers to other users' ratings depends on the trust accorded by a user to the reviewer. On the other hand, the trust that is felt by a user for another user correlates with the similarity of two users' ratings. This bidirectional interaction that involves trust and rating is an important aspect of understanding consumer behavior in online communities because it suggests clustering of similar users and the evolution of strong communities. This paper presents a theoretical model along with analyses of an actual online E-commerce site. We analyzed a large community site in Japan: @cosme. The noteworthy characteristics of @cosme are that users can bookmark their trusted users; in addition, they can post their own ratings of products, which facilitates our analyses of the ratings' bidirectional effects on trust and ratings. We describe an overview of the data in @cosme, analyses of effects from trust to rating and vice versa, and our proposition of a measure of community gravity, which measures how strongly a user might be attracted to a community. Our study is based on the @cosme dataset in addition to the Epinions dataset. It elucidates important insights and proposes a potentially important measure for mining online social networks.},
booktitle = {Proceedings of the 18th International Conference on World Wide Web},
pages = {751–760},
numpages = {10},
keywords = {trust, social networks, rating, online community},
location = {Madrid, Spain},
series = {WWW '09}
}

@inproceedings{10.1145/2872518.2889402,
author = {Ren, Jing and Shen, Jialie and Kauffman, Robert J.},
title = {What Makes a Music Track Popular in Online Social Networks?},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2889402},
doi = {10.1145/2872518.2889402},
abstract = {Tens of thousands of music tracks are uploaded to the Internet every day through social networks that focus on music and videos, as well as portal websites. While some of the content has been popular for decades, some tracks that have just been released have been completely ignored. So what makes a music track popular? Can we predict the popularity of a music track before it is released? In this research, we will focus on an online music social network, Last.fm, and investigate three key factors of a music track that may have impact on its popularity. They include: the music content, the artist reputation and the social context of the music. The results suggest that we can predict the future popularity of music with around 80% accuracy using just these three factors. We also found out that in the social networks scenario, the content of the music seems to be an surprisingly important factor that determines the popularity of a track online.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {95–96},
numpages = {2},
keywords = {ugc, topic, music online popularity, acoustic content},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3442381.3449846,
author = {Chen, Xu and Du, Yali and Xia, Long and Wang, Jun},
title = {Reinforcement Recommendation with User Multi-aspect Preference},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449846},
doi = {10.1145/3442381.3449846},
abstract = {Formulating recommender system with reinforcement learning (RL) frameworks has attracted increasing attention from both academic and industry communities. While many promising results have been achieved, existing models mostly simulate the environment reward with a unified value, which may hinder the understanding of users’ complex preferences and limit the model performance. In this paper, we consider how to model user multi-aspect preferences in the context of RL-based recommender system. More specifically, we base our model on the framework of deterministic policy gradient (DPG), which is effective in dealing with large action spaces. A major challenge for modeling user multi-aspect preferences lies in the fact that they may contradict with each other. To solve this problem, we introduce Pareto optimization into the DPG framework. We assign each aspect with a tailored critic, and all the critics share the same actor. The Pareto optimization is realized by a gradient-based method, which can be easily integrated into the actor and critic learning process. Based on the designed model, we theoretically analyze its gradient bias in the optimization process, and we design a weight-reuse mechanism to lower the upper bound of this bias, which is shown to be effective for improving the model performance. We conduct extensive experiments based on three real-world datasets to demonstrate our model’s superiorities.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {425–435},
numpages = {11},
keywords = {Reinforcement learning, Recommender system, Multi-objective optimization},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3308558.3313406,
author = {Suresh, Amoghavarsha and Gandhi, Anshul},
title = {Using Variability as a Guiding Principle to Reduce Latency in Web Applications via OS Profiling},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313406},
doi = {10.1145/3308558.3313406},
abstract = {Request latency is a critical metric in determining the usability of web services. The latency of a request includes service time - the time when the request is being actively serviced - and waiting time - the time when the request is waiting to be served. Most existing works aim to reduce request latency by focusing on reducing the mean service time (that is, shortening the critical path). In this paper, we explore an alternative approach to reducing latency - using variability as a guiding principle when designing web services. By tracking the service time variability of the request as it traverses across software layers within the user and kernel space of the web server, we identify the most critical stages of request processing. We then determine control knobs in the OS and application, such as thread scheduling and request batching, that regulate the variability in these stages, and demonstrate that tuning these specific knobs can significantly improve end-to-end request latency. Our experimental results with Memcached and Apache web server under different request rates, including real-world traces, show that this alternative approach can reduce mean and tail latency by 30-50%.},
booktitle = {The World Wide Web Conference},
pages = {1759–1770},
numpages = {12},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2740908.2742825,
author = {Wang, Liang and Tasoulis, Sotiris and Roos, Teemu and Kangasharju, Jussi},
title = {Kvasir: Seamless Integration of Latent Semantic Analysis-Based Content Provision into Web Browsing},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2742825},
doi = {10.1145/2740908.2742825},
abstract = {The Internet is overloading its users with excessive information flows, so that effective content-based filtering becomes crucial in improving user experience and work efficiency. We build Kvasir, a semantic recommendation system, atop latent semantic analysis and other state-of-art technologies to seamlessly integrate an automated and proactive content provision service into web browsing. We utilize the power of Apache Spark to scale up Kvasir to a practical Internet service. Herein we present the architecture of Kvasir, along with our solutions to the technical challenges in the actual system implementation.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {251–254},
numpages = {4},
keywords = {web browsing, random projection, latent semantic analysis, information retrieval, content-based filter, big data},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/2567948.2577270,
author = {Lee, Kyumin and Caverlee, James and Pu, Calton},
title = {Social spam, campaigns, misinformation and crowdturfing},
year = {2014},
isbn = {9781450327459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567948.2577270},
doi = {10.1145/2567948.2577270},
abstract = {This tutorial will introduce peer-reviewed research work on information quality on social systems. Specifically, we will address new threats such as social spam, campaigns, misinformation and crowdturfing, and overview modern techniques to improve information quality by revealing and detecting malicious participants (e.g., social spammers, content polluters and crowdturfers) and low quality contents.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {199–200},
numpages = {2},
keywords = {social spam, social media, misinformation, crowdturfing, campaign},
location = {Seoul, Korea},
series = {WWW '14 Companion}
}

@inproceedings{10.1145/3308558.3313672,
author = {Ozcaglar, Cagri and Geyik, Sahin and Schmitz, Brian and Sharma, Prakhar and Shelkovnykov, Alex and Ma, Yiming and Buchanan, Erik},
title = {Entity Personalized Talent Search Models with Tree Interaction Features},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313672},
doi = {10.1145/3308558.3313672},
abstract = {Talent Search systems aim to recommend potential candidates who are a good match to the hiring needs of a recruiter expressed in terms of the recruiter's search query or job posting. Past work in this domain has focused on linear and nonlinear models which lack preference personalization in the user-level due to being trained only with globally collected recruiter activity data. In this paper, we propose an entity-personalized Talent Search model which utilizes a combination of generalized linear mixed (GLMix) models and gradient boosted decision tree (GBDT) models, and provides personalized talent recommendations using nonlinear tree interaction features generated by the GBDT. We also present the offline and online system architecture for the productionization of this hybrid model approach in our Talent Search systems. Finally, we provide offline and online experiment results benchmarking our entity-personalized model with tree interaction features, which demonstrate significant improvements in our precision metrics compared to globally trained non-personalized models.},
booktitle = {The World Wide Web Conference},
pages = {3116–3122},
numpages = {7},
keywords = {XGBoost, Search ranking, Personalization, Nonlinear personalized models, GLMix models},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3442381.3449973,
author = {Chen, Hanxiong and Shi, Shaoyun and Li, Yunqi and Zhang, Yongfeng},
title = {Neural Collaborative Reasoning},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449973},
doi = {10.1145/3442381.3449973},
abstract = {Existing Collaborative Filtering (CF) methods are mostly designed based on the idea of matching, i.e., by learning user and item embeddings from data using shallow or deep models, they try to capture the associative relevance patterns in data, so that a user embedding can be matched with relevant item embeddings using designed or learned similarity functions. However, as a cognition rather than a perception intelligent task, recommendation requires not only the ability of pattern recognition and matching from data, but also the ability of cognitive reasoning in data. In this paper, we propose to advance Collaborative Filtering (CF) to Collaborative Reasoning (CR), which means that each user knows part of the reasoning space, and they collaborate for reasoning in the space to estimate preferences for each other. Technically, we propose a Neural Collaborative Reasoning (NCR) framework to bridge learning and reasoning. Specifically, we integrate the power of representation learning and logical reasoning, where representations capture similarity patterns in data from perceptual perspectives, and logic facilitates cognitive reasoning for informed decision making. An important challenge, however, is to bridge differentiable neural networks and symbolic reasoning in a shared architecture for optimization and inference. To solve the problem, we propose a modularized reasoning architecture, which learns logical operations such as AND (∧), OR (∨) and NOT (¬) as neural modules for implication reasoning (→). In this way, logical expressions can be equivalently organized as neural networks, so that logical reasoning and prediction can be conducted in a continuous space. Experiments on real-world datasets verified the advantages of our framework compared with both shallow, deep and reasoning models.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {1516–1527},
numpages = {12},
keywords = {Recommender Systems, Collaborative Reasoning, Collaborative Filtering, Cognitive Reasoning, Cognitive Intelligence},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/2567948.2577363,
author = {Hwang, Won-Seok and Li, Shaoyu and Kim, Sang-Wook and Lee, Kichun},
title = {Data imputation using a trust network for recommendation},
year = {2014},
isbn = {9781450327459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567948.2577363},
doi = {10.1145/2567948.2577363},
abstract = {Recommendation methods suffer from the data sparsity and cold-start user problems, often resulting in low accuracy. To address these problems, we propose a novel imputation method, which effectively densifies a rating matrix by filling unevaluated ratings with probable values. In our method, we use a trust network to estimate the unevaluated ratings accurately. We conduct experiments on the Epinions dataset and demonstrate that our method helps provide better recommendation accuracy than previous methods, especially for cold-start users.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {299–300},
numpages = {2},
keywords = {trust network, recommendation system, matrix factorization, data imputation},
location = {Seoul, Korea},
series = {WWW '14 Companion}
}

@inproceedings{10.1145/3308558.3313453,
author = {Xia, Tong and Yu, Yue and Xu, Fengli and Sun, Funing and Guo, Diansheng and Jin, Depeng and Li, Yong},
title = {Understanding Urban Dynamics via State-sharing Hidden Markov Model},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313453},
doi = {10.1145/3308558.3313453},
abstract = {Modeling people's activities in the urban space is a crucial socio-economic task but extremely challenging due to the deficiency of suitable methods. To model the temporal dynamics of human activities concisely and specifically, we present State-sharing Hidden Markov Model (SSHMM). First, it extracts the urban states from the whole city, which captures the volume of population flows as well as the frequency of each type of Point of Interests (PoIs) visited. Second, it characterizes the urban dynamics of each urban region as the state transition on the shared-states, which reveals distinct daily rhythms of urban activities. We evaluate our method via a large-scale real-life mobility dataset and results demonstrate that SSHMM learns semantics-rich urban dynamics, which are highly correlated with the functions of the region. Besides, it recovers the urban dynamics in different time slots with an error of 0.0793, which outperforms the general HMM by 54.2%.},
booktitle = {The World Wide Web Conference},
pages = {3363–3369},
numpages = {7},
keywords = {Urban Dynamics, Mobility, Hidden Markov Model},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3041021.3053064,
author = {Effendy, Suhendry and Yap, Roland H.C.},
title = {Analysing Trends in Computer Science Research: A Preliminary Study Using The Microsoft Academic Graph},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053064},
doi = {10.1145/3041021.3053064},
abstract = {Research in Computer Science (CS) evolves rapidly in a dynamic fashion. New research area may emerge and attract researchers, while older areas may have lesser interest from researchers. Studying how trends evolve in CS can be interesting from several dimensions. Furthermore, it can be used to craft research agendas. In this paper, we present trend analysis on research area in CS. We also look at citation trend analysis. Our analysis is performed using the Microsoft Academic Graph dataset. We propose the FoS score to measure the level of interest in any particular research area or topic. We apply the FoS score to investigate general publication trends, citation trends, evolution of research areas, and relation between research areas in CS.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1245–1250},
numpages = {6},
keywords = {trend analysis, computer science, bibliographic databases},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3442381.3450107,
author = {Jiang, Song and Koch, Bernard and Sun, Yizhou},
title = {HINTS: Citation Time Series Prediction for New Publications via Dynamic Heterogeneous Information Network Embedding},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450107},
doi = {10.1145/3442381.3450107},
abstract = {Accurate prediction of scientific impact is important for scientists, academic recommender systems, and granting organizations alike. Existing approaches rely on many years of leading citation values to predict a scientific paper’s citations (a proxy for impact), even though most papers make their largest contributions in the first few years after they are published. In this paper, we tackle a new problem: predicting a new paper’s citation time series from the date of publication (i.e., without leading values). We propose HINTS, a novel end-to-end deep learning framework that converts citation signals from dynamic heterogeneous information networks (DHIN) into citation time series. HINTS imputes pseudo-leading values for a paper in the years before it is published from DHIN embeddings, and then transforms these embeddings into the parameters of a formal model that can predict citation counts immediately after publication. Empirical analysis on two real-world datasets from Computer Science and Physics show that HINTS is competitive with baseline citation prediction models. While we focus on citations, our approach generalizes to other “cold start” time series prediction tasks where relational data is available and accurate prediction in early timestamps is crucial.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {3158–3167},
numpages = {10},
keywords = {time series, science of science, dynamic heterogeneous information network, Citation prediction},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/2872518.2889360,
author = {Gilani, Zafar and Wang, Liang and Crowcroft, Jon and Almeida, Mario and Farahbakhsh, Reza},
title = {Stweeler: A Framework for Twitter Bot Analysis},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2889360},
doi = {10.1145/2872518.2889360},
abstract = {The WWW has seen a massive growth in variety and usage of OSNs. The rising population of users on Twitter and its open nature has made it an ideal platform for various kinds of opportunistic pursuits, such as news and emergency communication, business promotion, political campaigning, spamming and spreading malicious content. Most of these opportunistic pursuits are exploited through automated programs, known as bots. In this study we propose a framework (Stweeler) to study bot impact and influence on Twitter from systems and social media perspectives.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {37–38},
numpages = {2},
keywords = {information dissemination, content analysis, bot analyser},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/2187980.2188215,
author = {Ricci, Francesco},
title = {Context-aware music recommender systems: workshop keynote abstract},
year = {2012},
isbn = {9781450312301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187980.2188215},
doi = {10.1145/2187980.2188215},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {865–866},
numpages = {2},
keywords = {tags, music recommender systems, mobile services, context awareness},
location = {Lyon, France},
series = {WWW '12 Companion}
}

@inproceedings{10.1145/3366423.3380135,
author = {Khawar, Farhan and Poon, Leonard and Zhang, Nevin L.},
title = {Learning the Structure of Auto-Encoding Recommenders},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380135},
doi = {10.1145/3366423.3380135},
abstract = {Autoencoder recommenders have recently shown state-of-the-art performance in the recommendation task due to their ability to model non-linear item relationships effectively. However, existing autoencoder recommenders use fully-connected neural network layers and do not employ structure learning. This can lead to inefficient training, especially when the data is sparse as commonly found in collaborative filtering. The aforementioned results in lower generalization ability and reduced performance. In this paper, we introduce structure learning for autoencoder recommenders by taking advantage of the inherent item groups present in the collaborative filtering domain. Due to the nature of items in general, we know that certain items are more related to each other than to other items. Based on this, we propose a method that first learns groups of related items and then uses this information to determine the connectivity structure of an auto-encoding neural network. This results in a network that is sparsely connected. This sparse structure can be viewed as a prior that guides the network training. Empirically we demonstrate that the proposed structure learning enables the autoencoder to converge to a local optimum with a much smaller spectral norm and generalization error bound than the fully-connected network. The resultant sparse network considerably outperforms the state-of-the-art methods like Mult-vae/Mult-dae on multiple benchmarked datasets even when the same number of parameters and flops are used. It also has a better cold-start performance.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {519–529},
numpages = {11},
keywords = {Collaborative Filtering, Wide Autoencoder, Structure Learning, Sparse Autoencoder, Shallow Networks.},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3178876.3186158,
author = {Lu, Yichao and Dong, Ruihai and Smyth, Barry},
title = {Coevolutionary Recommendation Model: Mutual Learning between Ratings and Reviews},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186158},
doi = {10.1145/3178876.3186158},
abstract = {Collaborative filtering (CF) is a common recommendation approach that relies on user-item ratings. However, the natural sparsity of user-item rating data can be problematic in many domains and settings, limiting the ability to generate accurate predictions and effective recommendations. Moreover, in some CF approaches latent features are often used to represent users and items, which can lead to a lack of recommendation transparency and explainability. User-generated, customer reviews are now commonplace on many websites, providing users with an opportunity to convey their experiences and opinions of products and services. As such, these reviews have the potential to serve as a useful source of recommendation data, through capturing valuable sentiment information about particular product features. In this paper, we present a novel deep learning recommendation model, which co-learns user and item information from ratings and customer reviews, by optimizing matrix factorization and an attention-based GRU network. Using real-world datasets we show a significant improvement in recommendation performance, compared to a variety of alternatives. Furthermore, the approach is useful when it comes to assigning intuitive meanings to latent features to improve the transparency and explainability of recommender systems.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {773–782},
numpages = {10},
keywords = {user modeling, recommender systems, natural language processing, deep learning, collaborative filtering},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3308558.3313473,
author = {Li, Pengfei and Lu, Hua and Zheng, Gang and Zheng, Qian and Yang, Long and Pan, Gang},
title = {Exploiting Ratings, Reviews and Relationships for Item Recommendations in Topic Based Social Networks},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313473},
doi = {10.1145/3308558.3313473},
abstract = {Many e-commerce platforms today allow users to give their rating scores and reviews on items as well as to establish social relationships with other users. As a result, such platforms accumulate heterogeneous data including numeric scores, short textual reviews, and social relationships. However, many recommender systems only consider historical user feedbacks in modeling user preferences. More specifically, most existing recommendation approaches only use rating scores but ignore reviews and social relationships in the user-generated data. In this paper, we propose TSNPF-a latent factor model to effectively capture user preferences and item features. Employing Poisson factorization, TSNPF fully exploits the wealth of information in rating scores, review text and social relationships altogether. It extracts topics of items and users from the review text and makes use of similarities between user pairs with social relationships, which results in a comprehensive understanding of user preferences. Experimental results on real-world datasets demonstrate that our TSNPF approach is highly effective at recommending items to users.},
booktitle = {The World Wide Web Conference},
pages = {995–1005},
numpages = {11},
keywords = {Variational Inference, Recommender System, Graphical Model},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2872518.2890562,
author = {Zhang, Qian and Goncalves, Bruno},
title = {Topical differences between Chinese language Twitter and Sina Weibo},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2890562},
doi = {10.1145/2872518.2890562},
abstract = {Sina Weibo, China's most popular microblogging platform, is considered to be a proxy of Chinese social life. In this study, we contrast the discussions occurring on Sina Weibo and on Chinese language Twitter in order to observe two different strands of Chinese culture: people within China who use Sina Weibo with its government imposed restrictions and those outside that are free to speak completely anonymously. We first propose a simple ad-hoc algorithm to identify topics of Tweets and Weibos. Different from previous works on micro-message topic detection, our algorithm considers topics of the same contents but with different #tags. Our algorithm can also detect topics for Tweets and Weibos without any #tags. Using a large corpus of Weibo and Chinese language tweets, covering the entire year of 2012, we obtain a list of topics using clustered #tags and compare them on two platforms. Surprisingly, we find that there are no common entries among the Top 100 most popular topics. Only 9.2% of tweets correspond to the Top 1000 topics of Weibo, and conversely only 4.4% of weibos were found to discuss the most popular Twitter topics. Our results reveal significant differences in social attention on the two platforms, with most popular topics on Weibo relating to entertainment while most tweets corresponded to cultural or political contents that is practically non existent in Weibo.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {625–628},
numpages = {4},
keywords = {weibo, twitter, topic detection on short-message, social media, social attention, online behavior},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@proceedings{10.1145/3487553,
title = {WWW '22: Companion Proceedings of the Web Conference 2022},
year = {2022},
isbn = {9781450391306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Lyon, France}
}

@inproceedings{10.1145/3041021.3051149,
author = {Zhang, Limeng and Zhou, Rui and Jiang, Haixin and Wang, Hua and Zhang, Yanchun},
title = {Item Group Recommendation: A Method Based on Game Theory},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051149},
doi = {10.1145/3041021.3051149},
abstract = {In this paper, we focus on recommending an item set to multiple users. Group recommender systems are designed to deal with the issue of recommending items for a user group. However, in some scenarios such as gift set promotion (different items are packed together as a gift set), album promotion, we need to focus on consumers' preference to multiple items rather than to some specific item. To deal with this issue, we pioneer a Nash equilibrium based Item Group Recommendation approach (NIGR). Specifically, we evaluate each consumer's preference to an item group in two perspectives, interest part from the customer herself and social affection from her friends. Then, we model the recommending process as a game to achieve Nash equilibrium. Finally, we demonstrate the effectiveness of our approach with extensive experiments.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1405–1411},
numpages = {7},
keywords = {nash equilibrium, item group recommendation, group recommender system, game theory},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3442381.3450075,
author = {Tu, Ye and Basu, Kinjal and DiCiccio, Cyrus and Bansal, Romil and Nandy, Preetam and Jaikumar, Padmini and Chatterjee, Shaunak},
title = {Personalized Treatment Selection using Causal Heterogeneity},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450075},
doi = {10.1145/3442381.3450075},
abstract = {Randomized experimentation (also known as A/B testing or bucket testing) is widely used in the internet industry to measure the metric impact obtained by different treatment variants. A/B tests identify the treatment variant showing the best performance, which then becomes the chosen or selected treatment for the entire population. However, the effect of a given treatment can differ across experimental units and a personalized approach for treatment selection can greatly improve upon the usual global selection strategy. In this work, we develop a framework for personalization through (i) estimation of heterogeneous treatment effect at either a cohort or member-level, followed by (ii) selection of optimal treatment variants for cohorts (or members) obtained through (deterministic or stochastic) constrained optimization. We perform a two-fold evaluation of our proposed methods. First, a simulation analysis is conducted to study the effect of personalized treatment selection under carefully controlled settings. This simulation illustrates the differences between the proposed methods and the suitability of each with increasing uncertainty. We also demonstrate the effectiveness of the method through a real-life example related to serving notifications at Linkedin. The solution significantly outperformed both heuristic solutions and the global treatment selection baseline leading to a sizable win on top-line metrics like member visits.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {1574–1585},
numpages = {12},
keywords = {Treatment Selection, Personalization, Heterogeneous causal effects, Constraint optimization},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3038912.3052680,
author = {Abeliuk, Andr\'{e}s and Berbeglia, Gerardo and Van Hentenryck, Pascal and Hogg, Tad and Lerman, Kristina},
title = {Taming the Unpredictability of Cultural Markets with Social Influence},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052680},
doi = {10.1145/3038912.3052680},
abstract = {Unpredictability is often portrayed as an undesirable outcome of social influence in cultural markets. Unpredictability stems from the "rich get richer" effect, whereby small fluctuations in the market share or popularity of products are amplified over time by social influence. In this paper, we report results of an experimental study that shows that unpredictability is not an inherent property of social influence. We investigate strategies for creating markets in which the popularity of products is better-and more predictably-aligned with their underlying quality. For our study, we created a cultural market of science stories and conducted randomized experiments on different policies for presenting the stories to study participants. Specifically, we varied how the stories were ranked, and whether or not participants were shown the ratings these stories received from others. We present a policy that leverages social influence and product positioning to help distinguish the product's market share (popularity) from underlying quality. Highlighting products with the highest estimated quality reduces the "rich get richer" effect highlighting popular products. We show that this policy allows us to more robustly and predictably identify high quality products and promote blockbusters. The policy can be used to create more efficient online cultural markets with a better allocation of resources to products.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {745–754},
numpages = {10},
keywords = {unpredictability, social influence, ranking policies, position bias, mathew effect, experimental study, cultural markets, "rich get richer" effect},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/2872518.2890525,
author = {Effendy, Suhendry and Yap, Roland H.C.},
title = {Investigations on Rating Computer Sciences Conferences: An Experiment with the Microsoft Academic Graph Dataset},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2890525},
doi = {10.1145/2872518.2890525},
abstract = {The rating of Computer Science (CS) conferences are important as it influences how papers published at the conferences and may also be used to evaluate research. In this paper, we proposed a method, rsit{}, based on a small given set of top conference ({em pivots}) and a relatedness measure based this set as well as basic baseline methods using citation count and field rating. We experimented with a snapshot dataset from Microsoft Academic Graph together with conference data from Microsoft Academic Search. We evaluated the conference ratings from our methods with the CCF conference rating list. We showed that rsit{} correlates well with CCF rating and correlates better than ratings from using a baseline ranking with citation count or field rating.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {425–430},
numpages = {6},
keywords = {relatedness measure, conference rating, classification},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3308558.3313478,
author = {Yu, Wenhui and Qin, Zheng},
title = {Spectrum-enhanced Pairwise Learning to Rank},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313478},
doi = {10.1145/3308558.3313478},
abstract = {To enhance the performance of the recommender system, side information is extensively explored with various features (e.g., visual features and textual features). However, there are some demerits of side information: (1) the extra data is not always available in all recommendation tasks; (2) it is only for items, there is seldom high-level feature describing users. To address these gaps, we introduce the spectral features extracted from two hypergraph structures of the purchase records. Spectral features describe the similarity of users/items in the graph space, which is critical for recommendation. We leverage spectral features to model the users' preference and items' properties by incorporating them into a Matrix Factorization (MF) model. In addition to modeling, we also use spectral features to optimize. Bayesian Personalized Ranking (BPR) is extensively leveraged to optimize models in implicit feedback data. However, in BPR, all missing values are regarded as negative samples equally while many of them are indeed unseen positive ones. We enrich the positive samples by calculating the similarity among users/items by the spectral features. The key ideas are: (1) similar users shall have similar preference on the same item; (2) a user shall have similar perception on similar items. Extensive experiments on two real-world datasets demonstrate the usefulness of the spectral features and the effectiveness of our spectrum-enhanced pairwise optimization. Our models outperform several state-of-the-art models significantly.},
booktitle = {The World Wide Web Conference},
pages = {2247–2257},
numpages = {11},
keywords = {spectral feature, pairwise learning to rank, latent community, latent category., Collaborative filtering},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3366423.3380164,
author = {Sun, Peijie and Wu, Le and Zhang, Kun and Fu, Yanjie and Hong, Richang and Wang, Meng},
title = {Dual Learning for Explainable Recommendation: Towards Unifying User Preference Prediction and Review Generation},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380164},
doi = {10.1145/3366423.3380164},
abstract = {In many recommender systems, users express item opinions through two kinds of behaviors: giving preferences and writing detailed reviews. As both kinds of behaviors reflect users’ assessment of items, review enhanced recommender systems leverage these two kinds of user behaviors to boost recommendation performance. On the one hand, researchers proposed to better model the user and item embeddings with additional review information for enhancing preference prediction accuracy. On the other hand, some recent works focused on automatically generating item reviews for recommendation explanations with related user and item embeddings. We argue that, while the task of preference prediction with the accuracy goal is well recognized in the community, the task of generating reviews for explainable recommendation is also important to gain user trust and increase conversion rate. Some preliminary attempts have considered jointly modeling these two tasks, with the user and item embeddings are shared. These studies empirically showed that these two tasks are correlated, and jointly modeling them would benefit the performance of both tasks. In this paper, we make a further study of unifying these two tasks for explainable recommendation. Instead of simply correlating these two tasks with shared user and item embeddings, we argue that these two tasks are presented in dual forms. In other words, the input of the primal preference prediction task is exactly the output of the dual review generation task , with and denote the preference value space and review space. Therefore, we could explicitly model the probabilistic correlation between these two dual tasks with . We design a unified dual framework of how to inject the probabilistic duality of the two tasks in the training stage. Furthermore, as the detailed preference and review information are not available for each user-item pair in the test stage, we propose a transfer learning based model for preference prediction and review generation. Finally, extensive experimental results on two real-world datasets clearly show the effectiveness of our proposed model for both user preference prediction and review generation.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {837–847},
numpages = {11},
keywords = {review generation, recommender system, dual learning},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3178876.3186165,
author = {Feng, Jun and Li, Heng and Huang, Minlie and Liu, Shichen and Ou, Wenwu and Wang, Zhirong and Zhu, Xiaoyan},
title = {Learning to Collaborate: Multi-Scenario Ranking via Multi-Agent Reinforcement Learning},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186165},
doi = {10.1145/3178876.3186165},
abstract = {Ranking is a fundamental and widely studied problem in scenarios such as search, advertising, and recommendation. However, joint optimization for multi-scenario ranking, which aims to improve the overall performance of several ranking strategies in different scenarios, is rather untouched. Separately optimizing each individual strategy has two limitations. The first one is lack of collaboration between scenarios meaning that each strategy maximizes its own objective but ignores the goals of other strategies, leading to a sub-optimal overall performance. The second limitation is the inability of modeling the correlation between scenarios meaning that independent optimization in one scenario only uses its own user data but ignores the context in other scenarios. In this paper, we formulate multi-scenario ranking as a fully cooperative, partially observable, multi-agent sequential decision problem. We propose a novel model named Multi-Agent Recurrent Deterministic Policy Gradient (MA-RDPG) which has a communication component for passing messages, several private actors (agents) for making actions for ranking, and a centralized critic for evaluating the overall performance of the co-working actors. Each scenario is treated as an agent (actor). Agents collaborate with each other by sharing a global action-value function (the critic) and passing messages that encodes historical information across scenarios. The model is evaluated with online settings on a large E-commerce platform. Results show that the proposed model exhibits significant improvements against baselines in terms of the overall performance.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {1939–1948},
numpages = {10},
keywords = {reinforcement learning, multi-agent learning, learning to rank, joint optimization},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3178876.3185994,
author = {Zheng, Guanjie and Zhang, Fuzheng and Zheng, Zihan and Xiang, Yang and Yuan, Nicholas Jing and Xie, Xing and Li, Zhenhui},
title = {DRN: A Deep Reinforcement Learning Framework for News Recommendation},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3185994},
doi = {10.1145/3178876.3185994},
abstract = {In this paper, we propose a novel Deep Reinforcement Learning framework for news recommendation. Online personalized news recommendation is a highly challenging problem due to the dynamic nature of news features and user preferences. Although some online recommendation models have been proposed to address the dynamic nature of news recommendation, these methods have three major issues. First, they only try to model current reward (e.g., Click Through Rate). Second, very few studies consider to use user feedback other than click / no click labels (e.g., how frequent user returns) to help improve recommendation. Third, these methods tend to keep recommending similar news to users, which may cause users to get bored. Therefore, to address the aforementioned challenges, we propose a Deep Q-Learning based recommendation framework, which can model future reward explicitly. We further consider user return pattern as a supplement to click / no click label in order to capture more user feedback information. In addition, an effective exploration strategy is incorporated to find new attractive news for users. Extensive experiments are conducted on the offline dataset and online production environment of a commercial news recommendation application and have shown the superior performance of our methods.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {167–176},
numpages = {10},
keywords = {reinforcement learning, news recommendation, deep Q-Learning},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3178876.3186146,
author = {Yu, Wenhui and Zhang, Huidi and He, Xiangnan and Chen, Xu and Xiong, Li and Qin, Zheng},
title = {Aesthetic-based Clothing Recommendation},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186146},
doi = {10.1145/3178876.3186146},
abstract = {Recently, product images have gained increasing attention in clothing recommendation since the visual appearance of clothing products has a significant impact on consumers» decision. Most existing methods rely on conventional features to represent an image, such as the visual features extracted by convolutional neural networks (CNN features) and the scale-invariant feature transform algorithm (SIFT features), color histograms, and so on. Nevertheless, one important type of features, the aesthetic features, is seldom considered. It plays a vital role in clothing recommendation since a users» decision depends largely on whether the clothing is in line with her aesthetics, however the conventional image features cannot portray this directly. To bridge this gap, we propose to introduce the aesthetic information, which is highly relevant with user preference, into clothing recommender systems. To achieve this, we first present the aesthetic features extracted by a pre-trained neural network, which is a brain-inspired deep structure trained for the aesthetic assessment task. Considering that the aesthetic preference varies significantly from user to user and by time, we then propose a new tensor factorization model to incorporate the aesthetic features in a personalized manner. We conduct extensive experiments on real-world datasets, which demonstrate that our approach can capture the aesthetic preference of users and significantly outperform several state-of-the-art recommendation methods.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {649–658},
numpages = {10},
keywords = {tensor factorization, side information, dynamic collaborative filtering, clothing recommendation, aesthetic features},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/2488388.2488519,
author = {Zhang, Xi and Cheng, Jian and Yuan, Ting and Niu, Biao and Lu, Hanqing},
title = {TopRec: domain-specific recommendation through community topic mining in social network},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488519},
doi = {10.1145/2488388.2488519},
abstract = {Traditionally, Collaborative Filtering assumes that similar users have similar responses to similar items. However, human activities exhibit heterogenous features across multiple domains such that users own similar tastes in one domain may behave quite differently in other domains. Moreover, highly sparse data presents crucial challenge in preference prediction. Intuitively, if users' interested domains are captured first, the recommender system is more likely to provide the enjoyed items while filter out those uninterested ones. Therefore, it is necessary to learn preference profiles from the correlated domains instead of the entire user-item matrix. In this paper, we propose a unified framework, TopRec, which detects topical communities to construct interpretable domains for domain-specific collaborative filtering. In order to mine communities as well as the corresponding topics, a semi-supervised probabilistic topic model is utilized by integrating user guidance with social network. Experimental results on real-world data from Epinions and Ciao demonstrate the effectiveness of the proposed framework.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {1501–1510},
numpages = {10},
keywords = {social network, recommender systems, probabilistic topic modeling, collaborative filtering},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/3041021.3054762,
author = {Lim, Hongjun and Chung, Choongho and Kim, Jihee and Kim, Juho and Moon, Sue and Cha, Meeyoung},
title = {Changing News Media Landscape in South Korea},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054762},
doi = {10.1145/3041021.3054762},
abstract = {A recent disclosure of a presidential scandal and the following development of subsequent events have been a major news topic in South Korea. We conducted a data-driven study to examine public reactions to the scandal and their effect on the Korean media landscape. Our analysis is based on 59,224 news articles published by five popular newsrooms that received a total of 47,906,770 Likes on Facebook. The data reveal notable changes in media ranks throughout the scandal, where a relatively young TV news network outgrew its audience over other half-a-century old established newspapers in less than a month. Topical similarity of news headlines also remained high over an extended period of time, despite the varying political stance of each newsroom. The topical similarity further shows a gradual divergence, indicating re-positioning of media stance takes place over time. Implications of these findings and suggestions for future directions are discussed based on data analysis of this extraordinary event.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1521–1526},
numpages = {6},
keywords = {social media, media bias, data-driven journalism},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3038912.3052694,
author = {Bayer, Immanuel and He, Xiangnan and Kanagal, Bhargav and Rendle, Steffen},
title = {A Generic Coordinate Descent Framework for Learning from Implicit Feedback},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052694},
doi = {10.1145/3038912.3052694},
abstract = {In recent years, interest in recommender research has shifted from explicit feedback towards implicit feedback data. A diversity of complex models has been proposed for a wide variety of applications. Despite this, learning from implicit feedback is still computationally challenging. So far, most work relies on stochastic gradient descent (SGD) solvers which are easy to derive, but in practice challenging to apply, especially for tasks with many items. For the simple matrix factorization model, an efficient coordinate descent (CD) solver has been previously proposed. However, efficient CD approaches have not been derived for more complex models.In this paper, we provide a new framework for deriving efficient CD algorithms for complex recommender models. We identify and introduce the property of k-separable models. We show that k-separability is a sufficient property to allow efficient optimization of implicit recommender problems with CD. We illustrate this framework on a variety of state-of-the-art models including factorization machines and Tucker decomposition. To summarize, our work provides the theory and building blocks to derive efficient implicit CD algorithms for complex recommender models.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {1341–1350},
numpages = {10},
keywords = {recommender systems, matrix factorization, implicit feedback, factorization machine, coordinate descent},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3038912.3052585,
author = {Cheng, Peizhe and Wang, Shuaiqiang and Ma, Jun and Sun, Jiankai and Xiong, Hui},
title = {Learning to Recommend Accurate and Diverse Items},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052585},
doi = {10.1145/3038912.3052585},
abstract = {In this study, we investigate diversified recommendation problem by supervised learning, seeking significant improvement in diversity while maintaining accuracy. In particular, we regard each user as a training instance, and heuristically choose a subset of accurate and diverse items as ground-truth for each user. We then represent each user or item as a vector resulted from the factorization of the user-item rating matrix. In our paper, we try to discover a factorization for matching the following supervised learning task. In doing this, we define two coupled optimization problems, parameterized matrix factorization and structural learning, to formulate our task. And we propose a diversified collaborative filtering algorithm (DCF) to solve the coupled problems. We also introduce a new pairwise accuracy metric and a normalized topic coverage diversity metric to measure the performance of accuracy and diversity respectively. Extensive experiments on benchmark datasets show the performance gains of DCF in comparison with the state-of-the-art algorithms.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {183–192},
numpages = {10},
keywords = {structural svm, recommender systems, diversity, collaborative filtering},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/2187980.2188077,
author = {Beauvisage, Thomas and Beuscart, Jean-Samuel},
title = {Audience dynamics of online catch up TV},
year = {2012},
isbn = {9781450312301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187980.2188077},
doi = {10.1145/2187980.2188077},
abstract = {This paper studies the demand for TV contents on online catch up platforms, in order to assess how catch up TV offers transform TV consumption. We build upon empirical data on French TV consumption in June 2011: a daily monitoring of online audience on web catch up platforms, and live audience ratings of traditional broadcast TV. We provide three main results: 1) online consumption is more concentrated than off-line audience, contradicting the hypothesis of a long tail effect of catch up TV; 2) the temporality of replay TV consumption on the web is very close to the live broadcasting of the programs, thus softening rather than breaking the synchrony of traditional TV; 3) detailed data on online consumption of news reveals two patterns of consumption ("alternative TV ritual" vs. "\`{a} la carte").},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {461–462},
numpages = {2},
keywords = {temporal dynamics, online audience, long tail, catch up TV},
location = {Lyon, France},
series = {WWW '12 Companion}
}

@inproceedings{10.1145/3178876.3186075,
author = {Lin, Xiao and Zhang, Wenpeng and Zhang, Min and Zhu, Wenwu and Pei, Jian and Zhao, Peilin and Huang, Junzhou},
title = {Online Compact Convexified Factorization Machine},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186075},
doi = {10.1145/3178876.3186075},
abstract = {Factorization Machine (FM) is a supervised learning approach with a powerful capability of feature engineering. It yields state-of-the-art performances in various batch learning tasks where all the training data is made available prior to the training. However, in real-world applications where the data arrives sequentially in a streaming manner, the high cost of re-training with batch learning algorithms has posed formidable challenges in the online learning scenario. The initial challenge is that no prior formulations of FM could directly fulfill the requirements in Online Convex Optimization (OCO) -- the paramount framework for online learning algorithm design. To address this aforementioned challenge, we invent a new convexification scheme leading to a Compact Convexified FM (CCFM) that seamlessly meets the requirements in OCO. However for learning Compact Convexified FM (CCFM) in the online learning settings, most existing algorithms suffer from expensive projection operations. To address this subsequent challenge, we follow the general projection-free algorithmic framework of Online Conditional Gradient and propose an Online Compact Convex Factorization Machine (OCCFM) algorithm that eschews the projection operation with efficient linear optimization steps. In support of the proposed OCCFM in terms of its theoretical foundation, we prove that the developed algorithm achieves a sub-linear regret bound. To evaluate the empirical performance of OCCFM, we conduct extensive experiments on 6 real-world datasets for online regression and online classification tasks. The experimental results show that OCCFM outperforms the state-of-art online learning methods for FM.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {1633–1642},
numpages = {10},
keywords = {online learning, online convex optimization, online conditional gradient, factorization machine},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3038912.3052627,
author = {Chang, Shiyu and Zhang, Yang and Tang, Jiliang and Yin, Dawei and Chang, Yi and Hasegawa-Johnson, Mark A. and Huang, Thomas S.},
title = {Streaming Recommender Systems},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052627},
doi = {10.1145/3038912.3052627},
abstract = {The increasing popularity of real-world recommender systems produces data continuously and rapidly, and it becomes more realistic to study recommender systems under streaming scenarios. Data streams present distinct properties such as temporally ordered, continuous and high-velocity, which poses tremendous challenges to traditional recommender systems. In this paper, we investigate the problem of recommendation with stream inputs. In particular, we provide a principled framework termed sRec, which provides explicit continuous-time random process models of the creation of users and topics, and of the evolution of their interests. A variational Bayesian approach called recursive meanfield approximation is proposed, which permits computationally efficient instantaneous on-line inference. Experimental results on several real-world datasets demonstrate the advantages of our sRec over other state-of-the-arts.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {381–389},
numpages = {9},
keywords = {streaming, recommender system, online learning, data stream., continuous time},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/2872518.2890097,
author = {Bhattacharya, Devipsita and Ram, Sudha},
title = {Understanding the Competitive Landscape of News Providers on Social Media},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2890097},
doi = {10.1145/2872518.2890097},
abstract = {Social media has emerged as a mechanism for online news propagation. This in turn has changed the competitive landscape of news providers, a landscape that was previously partitioned based on the traditional channels of news dispersion. The channels of news distribution refer to - television, newspaper, magazine, radio, news agency and online only. In this paper, we examine similarities and differences in news propagation patterns on social media based on the primary channel of a news provider. We collected news article propagation activity data from Twitter for 32 news providers over a three-week period and analyzed their propagation networks. Our analysis shows that the structural properties of the propagation networks are statistically different based on the type of primary channel. Our study has useful implications for understanding the competition between news providers in an online environment.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {719–724},
numpages = {6},
keywords = {twitter, news propagation, micro-blogging, article propagation},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3184558.3191531,
author = {Zannettou, Savvas and Bradlyn, Barry and De Cristofaro, Emiliano and Kwak, Haewoon and Sirivianos, Michael and Stringini, Gianluca and Blackburn, Jeremy},
title = {What is Gab: A Bastion of Free Speech or an Alt-Right Echo Chamber},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3191531},
doi = {10.1145/3184558.3191531},
abstract = {Over the past few years, a number of new "fringe" communities, like 4chan or certain subreddits, have gained traction on the Web at a rapid pace. However, more often than not, little is known about how they evolve or what kind of activities they attract, despite recent research has shown that they influence how false information reaches mainstream communities. This motivates the need to monitor these communities and analyze their impact on the Web's information ecosystem. In August 2016, a new social network called Gab was created as an alternative to Twitter. It positions itself as putting "people and free speech first", welcoming users banned or suspended from other social networks. In this paper, we provide, to the best of our knowledge, the first characterization of Gab. We collect and analyze 22M posts produced by 336K users between August 2016 and January 2018, finding that Gab is predominantly used for the dissemination and discussion of news and world events, and that it attracts alt-right users, conspiracy theorists, and other trolls. We also measure the prevalence of hate speech on the platform, finding it to be much higher than Twitter, but lower than 4chan's Politically Incorrect board.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1007–1014},
numpages = {8},
keywords = {alt-right, changepoint analysis, hate speech, social networks},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3366423.3380217,
author = {Papadopoulos, Panagiotis and Snyder, Peter and Athanasakis, Dimitrios and Livshits, Benjamin},
title = {Keeping out the Masses: Understanding the Popularity and Implications of Internet Paywalls},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380217},
doi = {10.1145/3366423.3380217},
abstract = {Funding the production of quality online content is a pressing problem for content producers. The most common funding method, online advertising, is rife with well-known performance and privacy harms, and an intractable subject-agent conflict: many users do not want to see advertisements, depriving the site of needed funding. Because of these negative aspects of advertisement-based funding, paywalls are an increasingly popular alternative for websites. This shift to a “pay-for-access” web is one that has potentially huge implications for the web and society. Instead of a system where information (nominally) flows freely, paywalls create a web where high quality information is available to fewer and fewer people, leaving the rest of the web users with less information, that might be also less accurate and of lower quality. Despite the potential significance of a move from an “advertising-but-open” web to a “paywalled” web, we find this issue understudied. This work addresses this gap in our understanding by measuring how widely paywalls have been adopted, what kinds of sites use paywalls, and the distribution of policies enforced by paywalls. A partial list of our findings include that (i) paywall use has increased, and at an increasing rate (2 \texttimes{} more paywalls every 6 months), (ii) paywall adoption differs by country (e.g., 18.75% in US, 12.69% in Australia), (iii) paywall deployment significantly changes how users interact with the site (e.g., higher bounce rates, less incoming links), (iv) the median cost of an annual paywall access is 108 USD per site, and (v) paywalls are in general trivial to circumvent. Finally, we present the design of a novel, automated system for detecting whether a site uses a paywall, through the combination of runtime browser instrumentation and repeated programmatic interactions with the site. We intend this classifier to augment future, longitudinal measurements of paywall use and behavior.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {1433–1444},
numpages = {12},
keywords = {Web Monetization, User privacy, User Subscription, Paywalls},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/2872518.2890094,
author = {Meshulam, Ram and Sasson, Roy},
title = {For Your Eyes Only: Consuming vs. Sharing Content},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2890094},
doi = {10.1145/2872518.2890094},
abstract = {This paper analyzes two types of user interactions with online content: (1) private engagement with content, measured by page-views and click-through rate; and (2) social engagement, measured by the number of shares on Facebook as well as share-rate. Based on more than a billion data points across hundreds of publishers worldwide and two time periods, it is shown that the correlation between these signals is generally low. Potential reasons for the low correlation are discussed, and the notion of private-social dissonance is defined. A more in-depth analysis shows that the dissonance between private engagement and social engagement consistently depends on content category. Categories such as Sex, Crime and Celebrities have higher private engagement than social engagement. On the other hand, categories such as Books, Careers and Music have higher social engagement than private engagement. In addition to the offline analysis, a model which utilizes the different signals was trained and deployed on a live recommendation system. The resulting weights ranked the social signal lower than click-through rate. The results are relevant for publishers, content marketers, architects of recommendation systems and researchers who wish to use social signals in order to measure and predict user engagement.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {725–730},
numpages = {6},
keywords = {social network, recommender system, bfacebook, behavioral modeling},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1145/3041021.3053901,
author = {Jia, Adele Lu and Shen, Siqi and Chen, Shengling and Li, Dongsheng and Iosup, Alexandru},
title = {An Analysis on a YouTube-like UGC site with Enhanced Social Features},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053901},
doi = {10.1145/3041021.3053901},
abstract = {YouTube-like User Generated Content (UGC) sites are nowadays entertaining over a billion people. Resource provision is essential for these giant UGC sites as they allow users to request videos from a potentially unlimited selection in an asynchronous fashion. Still, the UGC sites are seeking to create new viewing patterns and social interactions that would engage and attract more users and complicate the already rigorous resource provision problem. In this paper, we seek to combine these two tasks by leveraging social features to provide the reference for resource provision.To this end, we conduct an extensive measurement and analysis of BiliBili, a YouTube-like UGC site with enhanced social features including user following, chat replay, and virtual money donation. Based on datasets that capture the complete view of BiliBili---containing over 2 million videos and over 28 million users---we characterize its video repository and user activities, we demonstrate the positive reinforcement between on-line social behavior and upload behavior, we propose graph models that reveal user relationships and high-level social structures, and we successfully apply our findings to build machine-learnt classifiers to identify videos that will need priority in resource provision.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1477–1483},
numpages = {7},
keywords = {user generated content sites, social features, prediction, graph model},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/2487788.2487947,
author = {Kiseleva, Julia},
title = {Context mining and integration into predictive web analytics},
year = {2013},
isbn = {9781450320382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487788.2487947},
doi = {10.1145/2487788.2487947},
abstract = {Predictive Web Analytics is aimed at understanding behavioural patterns of users of various web-based applications: e-commerce, ubiquitous and mobile computing, and computational advertising. Within these applications business decisions often rely on two types of predictions: an overall or particular user segment demand predictions and individualised recommendations for visitors. Visitor behaviour is inherently sensitive to the context, which can be defined as a collection of external factors. Context-awareness allows integrating external explanatory information into the learning process and adapting user behaviour accordingly. The importance of context-awareness has been recognised by researchers and practitioners in many disciplines, including recommendation systems, information retrieval, personalisation, data mining, and marketing. We focus on studying ways of context discovery and its integration into predictive analytics.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {383–388},
numpages = {6},
keywords = {user modeling, context, advertising},
location = {Rio de Janeiro, Brazil},
series = {WWW '13 Companion}
}

@inproceedings{10.1145/3366423.3380300,
author = {Piccardi, Tiziano and Redi, Miriam and Colavizza, Giovanni and West, Robert},
title = {Quantifying Engagement with Citations on Wikipedia},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380300},
doi = {10.1145/3366423.3380300},
abstract = {Wikipedia is one of the most visited sites on the Web and a common source of information for many users. As an encyclopedia, Wikipedia was not conceived as a source of original information, but as a gateway to secondary sources: according to Wikipedia’s guidelines, facts must be backed up by reliable sources that reflect the full spectrum of views on the topic. Although citations lie at the heart of Wikipedia, little is known about how users interact with them. To close this gap, we built client-side instrumentation for logging all interactions with links leading from English Wikipedia articles to cited references during one month, and conducted the first analysis of readers’ interactions with citations. We find that overall engagement with citations is low: about one in 300 page views results in a reference click (0.29% overall; 0.56% on desktop; 0.13% on mobile). Matched observational studies of the factors associated with reference clicking reveal that clicks occur more frequently on shorter pages and on pages of lower quality, suggesting that references are consulted more commonly when Wikipedia itself does not contain the information sought by the user. Moreover, we observe that recent content, open access sources, and references about life events (births, deaths, marriages, etc.) are particularly popular. Taken together, our findings deepen our understanding of Wikipedia’s role in a global information economy where reliability is ever less certain, and source attribution ever more vital.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2365–2376},
numpages = {12},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/2487788.2488090,
author = {Carvalho, Lucas Augusto Montalv\~{a}o Costa and Macedo, Hendrik Teixeira},
title = {Users' satisfaction in recommendation systems for groups: an approach based on noncooperative games},
year = {2013},
isbn = {9781450320382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487788.2488090},
doi = {10.1145/2487788.2488090},
abstract = {A major difficulty in a recommendation system for groups is to use a group aggregation strategy to ensure, among other things, the maximization of the average satisfaction of group members. This paper presents an approach based on the theory of noncooperative games to solve this problem. While group members can be seen as game players, the items for potential recommendation for the group comprise the set of possible actions. Achieving group satisfaction as a whole becomes, then, a problem of finding the Nash equilibrium. Experiments with a MovieLens dataset and a function of arithmetic mean to compute the prediction of group satisfaction for the generated recommendation have shown statistically significant results when compared to state-of-the-art aggregation strategies, in particular, when evaluation among group members are more heterogeneous. The feasibility of this unique approach is shown by the development of an application for Facebook, which recommends movies to groups of friends.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {951–958},
numpages = {8},
keywords = {nash equilibrium, group recommendation, game theory},
location = {Rio de Janeiro, Brazil},
series = {WWW '13 Companion}
}

@inproceedings{10.1145/2567948.2579208,
author = {Oka, Mizuki and Hashimoto, Yasuhiro and Ikegami, Takashi},
title = {Fluctuation and burst response in social media},
year = {2014},
isbn = {9781450327459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567948.2579208},
doi = {10.1145/2567948.2579208},
abstract = {A salient dynamic property of social media is bursting be- havior. In this paper, we study bursting behavior in relation to the structure of fluctuation, known as fluctuation-response relation, to reveal the origin of bursts. More specifically, we study the temporal relation between a preceding baseline fluctuation and the successive burst response using a frequency time series of 3,000 keywords on Twitter. We find three types of keyword time series in terms of the fluctuation-response relation. For the first type of keyword, the baseline fluctuation has a positive correlation with the burst size; as the preceding fluctuation increases, the burst size increases. These bursts are caused endogenously as a result of word-of-mouth interactions in a social network; the keyword is sensitive only to the internal context of the system. For the second type, there is a critical threshold in the fluctuation value up to which a positive correlation is observed. Beyond this value, the size of the bursts becomes independent from the fluctuation size. Our analysis shows that this critical threshold emerges because the bursts in the time series are endogenous and exogenous. This type of keyword is sensitive to internal and external stimuli. The third type is mainly bursts caused by exogenous bursts. This type of keyword is mostly sensitive only to external stimuli. These results are useful for characterizing how excitable a keyword is on Twitter and could be used, for example, for marketing purposes.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {1037–1042},
numpages = {6},
keywords = {social media, fluctuation-response relation, exogenous, endogenous, burst},
location = {Seoul, Korea},
series = {WWW '14 Companion}
}

@inproceedings{10.1145/1963405.1963505,
author = {Antoniades, Demetris and Polakis, Iasonas and Kontaxis, Georgios and Athanasopoulos, Elias and Ioannidis, Sotiris and Markatos, Evangelos P. and Karagiannis, Thomas},
title = {we.b: the web of short urls},
year = {2011},
isbn = {9781450306324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963405.1963505},
doi = {10.1145/1963405.1963505},
abstract = {Short URLs have become ubiquitous. Especially popular within social networking services, short URLs have seen a significant increase in their usage over the past years, mostly due to Twitter's restriction of message length to 140 characters. In this paper, we provide a first characterization on the usage of short URLs. Specifically, our goal is to examine the content short URLs point to, how they are published, their popularity and activity over time, as well as their potential impact on the performance of the web.Our study is based on traces of short URLs as seen from two different perspectives: i) collected through a large-scale crawl of URL shortening services, and ii) collected by crawling Twitter messages. The former provides a general characterization on the usage of short URLs, while the latter provides a more focused view on how certain communities use shortening services. Our analysis highlights that domain and website popularity, as seen from short URLs, significantly differs from the distributions provided by well publicised services such as Alexa. The set of most popular websites pointed to by short URLs appears stable over time, despite the fact that short URLs have a limited high popularity lifetime. Surprisingly short URLs are not ephemeral, as a significant fraction, roughly 50%, appears active for more than three months. Overall, our study emphasizes the fact that short URLs reflect an "alternative" web and, hence, provide an additional view on web usage and content consumption complementing traditional measurement sources. Furthermore, our study reveals the need for alternative shortening architectures that will eliminate the non-negligible performance penalty imposed by today's shortening services.},
booktitle = {Proceedings of the 20th International Conference on World Wide Web},
pages = {715–724},
numpages = {10},
keywords = {twitter, short urls, online social networks},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{10.1145/2740908.2741698,
author = {Kanhabua, Nattiya and Ngoc Nguyen, Tu and Nejdl, Wolfgang},
title = {Learning to Detect Event-Related Queries for Web Search},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2741698},
doi = {10.1145/2740908.2741698},
abstract = {In many cases, a user turns to search engines to find information about real-world situations, namely, political elections, sport competitions, or natural disasters. Such temporal querying behavior can be observed through a significant number of event-related queries generated in web search. In this paper, we study the task of detecting event-related queries, which is the first step for understanding temporal query intent and enabling different temporal search applications, e.g., time-aware query auto-completion, temporal ranking, and result diversification. We propose a two-step approach to detecting events from query logs. We first identify a set of event candidates by considering both implicit and explicit temporal information needs. The next step further classifies the candidates into two main categories, namely, event or non-event. In more detail, we leverage different machine learning techniques for query classification, which are trained using the feature set composed of time series features from signal processing, along with features derived from click-through information, and standard statistical features. In order to evaluate our proposed approach, we conduct an experiment using two real-world query logs with manually annotated relevance assessments for 837 events. To this end, we provide a large set of event-related queries made available for fostering research on this challenging task.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {1339–1344},
numpages = {6},
keywords = {temporal query classification, query intent, events},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/3038912.3052556,
author = {Wang, Xin and Hoi, Steven C.H. and Ester, Martin and Bu, Jiajun and Chen, Chun},
title = {Learning Personalized Preference of Strong and Weak Ties for Social Recommendation},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052556},
doi = {10.1145/3038912.3052556},
abstract = {Recent years have seen a surge of research on social recommendation techniques for improving recommender systems due to the growing influence of social networks to our daily life. The intuition of social recommendation is that users tend to show affinities with items favored by their social ties due to social influence. Despite the extensive studies, no existing work has attempted to distinguish and learn the personalized preferences between strong and weak ties, two important terms widely used in social sciences, for each individual in social recommendation. In this paper, we first highlight the importance of different types of ties in social relations originated from social sciences, and then propose anovel social recommendation method based on a new Probabilistic Matrix Factorization model that incorporates the distinction of strong and weak ties for improving recommendation performance. The proposed method is capable of simultaneously classifying different types of social ties in a social network w.r.t. optimal recommendation accuracy, and learning a personalized tie type preference for each user in addition to other parameters. We conduct extensive experiments on four real-world datasets by comparing our method with state-of-the-art approaches, and find encouraging results that validate the efficacy of the proposed method in exploiting the personalized preferences of strong and weak ties for social recommendation.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {1601–1610},
numpages = {10},
keywords = {user behavior modeling, strong and weak ties, social recommendation, personalization},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3178876.3186108,
author = {Rizoiu, Marian-Andrei and Mishra, Swapnil and Kong, Quyu and Carman, Mark and Xie, Lexing},
title = {SIR-Hawkes: Linking Epidemic Models and Hawkes Processes to Model Diffusions in Finite Populations},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186108},
doi = {10.1145/3178876.3186108},
abstract = {Among the statistical tools for online information diffusion modeling, both epidemic models and Hawkes point processes are popular choices. The former originate from epidemiology, and consider information as a viral contagion which spreads into a population of online users. The latter have roots in geophysics and finance, view individual actions as discrete events in continuous time, and modulate the rate of events according to the self-exciting nature of event sequences. Here, we establish a novel connection between these two frameworks. Namely, the rate of events in an extended Hawkes model is identical to the rate of new infections in the Susceptible-Infected-Recovered (SIR) model after marginalizing out recovery events -- which are unobserved in a Hawkes process. This result paves the way to apply tools developed for SIR to Hawkes, and vice versa. It also leads to HawkesN, a generalization of the Hawkes model which accounts for a finite population size. Finally, we derive the distribution of cascade sizes for HawkesN, inspired by methods in stochastic SIR. Such distributions provide nuanced explanations to the general unpredictability of popularity: the distribution for diffusion cascade sizes tends to have two modes, one corresponding to large cascade sizes and another one around zero.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {419–428},
numpages = {10},
keywords = {temporal point processes, epidemic models, diffusions in finite population, diffusion size prediction},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/1772690.1772773,
author = {Rendle, Steffen and Freudenthaler, Christoph and Schmidt-Thieme, Lars},
title = {Factorizing personalized Markov chains for next-basket recommendation},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1772690.1772773},
doi = {10.1145/1772690.1772773},
abstract = {Recommender systems are an important component of many websites. Two of the most popular approaches are based on matrix factorization (MF) and Markov chains (MC). MF methods learn the general taste of a user by factorizing the matrix over observed user-item preferences. On the other hand, MC methods model sequential behavior by learning a transition graph over items that is used to predict the next action based on the recent actions of a user. In this paper, we present a method bringing both approaches together. Our method is based on personalized transition graphs over underlying Markov chains. That means for each user an own transition matrix is learned - thus in total the method uses a transition cube. As the observations for estimating the transitions are usually very limited, our method factorizes the transition cube with a pairwise interaction model which is a special case of the Tucker Decomposition. We show that our factorized personalized MC (FPMC) model subsumes both a common Markov chain and the normal matrix factorization model. For learning the model parameters, we introduce an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data. Empirically, we show that our FPMC model outperforms both the common matrix factorization and the unpersonalized MC model both learned with and without factorization.},
booktitle = {Proceedings of the 19th International Conference on World Wide Web},
pages = {811–820},
numpages = {10},
keywords = {matrix factorization, markov chain, basket recommendation},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}

@inproceedings{10.1145/3308558.3313727,
author = {Wu, Qingyun and Wang, Huazheng and Li, Yanen and Wang, Hongning},
title = {Dynamic Ensemble of Contextual Bandits to Satisfy Users' Changing Interests},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313727},
doi = {10.1145/3308558.3313727},
abstract = {Recommender systems have to handle a highly non-stationary environment, due to users' fast changing interests over time. Traditional solutions have to periodically rebuild their models, despite high computational cost. But this still cannot empower them to automatically adjust to abrupt changes in trends caused by timely information. It is important to note that the changes of reward distributions caused by a non-stationary environment can also be context dependent. When the change is orthogonal to the given context, previously maintained models should be reused for better recommendation prediction. In this work, we focus on contextual bandit algorithms for making adaptive recommendations. We capitalize on the unique context-dependent property of reward changes to conquer the challenging non-stationary environment for model update. In particular, we maintain a dynamic ensemble of contextual bandit models, where each bandit model's reward estimation quality is monitored regarding given context and possible environment changes. Only the admissible models to the current environment will be used for recommendation. We provide a rigorous upper regret bound analysis of our proposed algorithm. Extensive empirical evaluations on both synthetic and three real-world datasets confirmed the algorithm's advantage against existing non-stationary solutions that simply create new models whenever an environment change is detected.},
booktitle = {The World Wide Web Conference},
pages = {2080–2090},
numpages = {11},
keywords = {regret analysis, recommender systems, Non-stationary bandits},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3308558.3313440,
author = {Santos, Tiago and Walk, Simon and Kern, Roman and Strohmaier, Markus and Helic, Denis},
title = {Self- and Cross-Excitation in Stack Exchange Question &amp; Answer Communities},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313440},
doi = {10.1145/3308558.3313440},
abstract = {In this paper, we quantify the impact of self- and cross-excitation on the temporal development of user activity in Stack Exchange Question &amp; Answer (Q&amp;A) communities. We study differences in user excitation between growing and declining Stack Exchange communities, and between those dedicated to STEM and humanities topics by leveraging Hawkes processes. We find that growing communities exhibit early stage, high cross-excitation by a small core of power users reacting to the community as a whole, and strong long-term self-excitation in general and cross-excitation by casual users in particular, suggesting community openness towards less active users. Further, we observe that communities in the humanities exhibit long-term power user cross-excitation, whereas in STEM communities activity is more evenly distributed towards casual user self-excitation. We validate our findings via permutation tests and quantify the impact of these excitation effects with a range of prediction experiments. Our work enables researchers to quantitatively assess the evolution and activity potential of Q&amp;A communities.},
booktitle = {The World Wide Web Conference},
pages = {1634–1645},
numpages = {12},
keywords = {Q&amp;A communities, Hawkes processes, Excitation effects},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2872427.2882973,
author = {Zhang, Yongfeng and Zhao, Qi and Zhang, Yi and Friedman, Daniel and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
title = {Economic Recommendation with Surplus Maximization},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2882973},
doi = {10.1145/2872427.2882973},
abstract = {A prime function of many major World Wide Web applications is Online Service Allocation (OSA), the function of matching individual consumers with particular services/goods (which may include loans or jobs as well as products) each with its own producer. In the applications of interest, consumers are free to choose, so OSA usually takes the form of personalized recommendation or search in practice. The performance metrics of recommender and search systems currently tend to focus on just one side of the match, in some cases the consumers (e.g. satisfaction) and in other cases the producers (e.g., profit). However, a sustainable OSA platform needs benefit both consumers and producers; otherwise the neglected party eventually may stop using it. In this paper, we show how to adapt economists' traditional idea of maximizing total surplus (the sum of consumer net benefit and producer profit) to the heterogeneous world of online service allocation, in an effort to promote the web intelligence for social good in online eco-systems. Modifications of traditional personalized recommendation algorithms enable us to apply Total Surplus Maximization (TSM) to three very different types of real-world tasks -- e-commerce, P2P lending and freelancing. The results for all three tasks suggest that TSM compares very favorably to currently popular approaches, to the benefit of both producers and consumers.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {73–83},
numpages = {11},
keywords = {web-based services, total surplus maximization, recommendation systems, online service allocation, computational economics},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1145/2740908.2741694,
author = {Gamzu, Iftah and Karnin, Zohar and Maarek, Yoelle and Wajc, David},
title = {You Will Get Mail!Predicting the Arrival of Future Email},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2741694},
doi = {10.1145/2740908.2741694},
abstract = {The majority of Web email is known to be generated by machines even when one excludes spam. Many machine-generated email messages such as invoices or travel itineraries are critical to users. Recent research studies establish that causality relations between certain types of machine-generated email messages exist and can be mined. These relations exhibit a link between a given message to a past message that gave rise to its creation. For example, a shipment notification message can often be linked to a past online purchase message. Instead of studying how an incoming message can be linked to the past, we propose here to focus on predicting future email arrival as implied by causality relations. Such a prediction method has several potential applications, ranging from improved ad targeting in up sell scenarios to reducing false positives in spam detection.We introduce a novel approach for predicting which types of machine-generated email messages, represented by so-called "email templates", a user should receive in future time windows. Our prediction approach relies on (1) statistically inferring causality relations between email templates, (2) building a generative model that explains the inbox of each user using those causality relations, and (3) combining those results to predict which email templates are likely to appear in future time frames. We present preliminary experimental results and some data insights obtained by analyzing several million inboxes of Yahoo Mail users, who voluntarily opted-in for such research.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {1327–1332},
numpages = {6},
keywords = {machine-generated email, email arrival prediction, causal relations},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/3308558.3313721,
author = {Budak, Ceren},
title = {What happened? The Spread of Fake News Publisher Content During the 2016 U.S. Presidential Election},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313721},
doi = {10.1145/3308558.3313721},
abstract = {The spread of content produced by fake news publishers was one of the most discussed characteristics of the 2016 U.S. Presidential Election. Yet, little is known about the prevalence and focus of such content, how its prevalence changed over time, and how this prevalence related to important election dynamics. In this paper, we address these questions using tweets that mention the two presidential candidates sampled at the daily level, the news content mentioned in such tweets, and open-ended responses from nationally representative telephone interviews. The results of our analysis highlight various important lessons for news consumers and journalists. We find that (i.) traditional news producers outperformed fake news producers in aggregate, (ii.) the prevalence of content produced by fake news publishers increased over the course of the campaign-particularly among tweets that mentioned Clinton, and (iii.) changes in such prevalence were closely following changes in net Clinton favorability. Turning to content, we (iv.) identify similarities and differences in agenda setting by fake and traditional news media and show that (v.) information individuals most commonly reported to having read, seen or heard about the candidates was more closely aligned with content produced by fake news outlets than traditional news outlets, in particular for information Republican voters retained about Clinton. We also model fake-ness of retained information as a function of demographics characteristics. Implications for platform owners, news consumers, and journalists are discussed.},
booktitle = {The World Wide Web Conference},
pages = {139–150},
numpages = {12},
keywords = {topic modeling, news media, multi-level regression, fake news},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2872427.2883049,
author = {Wang, Beidou and Ester, Martin and Bu, Jiajun and Zhu, Yu and Guan, Ziyu and Cai, Deng},
title = {Which to View: Personalized Prioritization for Broadcast Emails},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2883049},
doi = {10.1145/2872427.2883049},
abstract = {Email is one of the most important communication tools today, but email overload resulting from the large number of unimportant or irrelevant emails is causing trillion-level economy loss every year. Thus personalized email prioritization algorithms are of urgent need. Despite lots of previous effort on this topic, broadcast email, an important type of email, is overlooked in previous literature. Broadcast emails are significantly different from normal emails, introducing both new challenges and opportunities. On one hand, lack of real senders and limited user interactions invalidate the key features exploited by traditional email prioritization algorithms; on the other hand, thousands of receivers for one broadcast email bring us the opportunity to predict importance through collaborative filtering. However, broadcast emails face a severe cold-start problem which hinders the direct application of collaborative filtering. In this paper, we propose the first framework for broadcast email prioritization by designing a novel active learning model that considers the collaborative filtering, implicit feedback and time sensitive responsiveness features of broadcast emails. Our method is thoroughly evaluated on a large scale real world industrial dataset from Samsung Electronics. Our method is proved highly effective and outperforms state-of-the-art personalized email prioritization methods.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {1181–1190},
numpages = {10},
keywords = {recommendation system, email prioritization, active learning},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1145/3038912.3052605,
author = {Kowald, Dominik and Pujari, Subhash Chandra and Lex, Elisabeth},
title = {Temporal Effects on Hashtag Reuse in Twitter: A Cognitive-Inspired Hashtag Recommendation Approach},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052605},
doi = {10.1145/3038912.3052605},
abstract = {Hashtags have become a powerful tool in social platforms such as Twitter to categorize and search for content, and to spread short messages across members of the social network. In this paper, we study temporal hashtag usage practices in Twitter with the aim of designing a cognitive-inspired hashtag recommendation algorithm we call BLLi,s. Our main idea is to incorporate the effect of time on (i) individual hashtag reuse (i.e., reusing own hashtags), and (ii) social hashtag reuse (i.e., reusing hashtags, which has been previously used by a followee) into a predictive model. For this, we turn to the Base-Level Learning (BLL) equation from the cognitive architecture ACT-R, which accounts for the time-dependent decay of item exposure in human memory. We validate BLLI,S using two crawled Twitter datasets in two evaluation scenarios. Firstly, only temporal usage patterns of past hashtag assignments are utilized and secondly, these patterns are combined with a content-based analysis of the current tweet. In both evaluation scenarios, we find not only that temporal effects play an important role for both individual and social hashtag reuse but also that our BLLI,S approach provides significantly better prediction accuracy and ranking results than current state-of-the-art hashtag recommendation methods.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {1401–1410},
numpages = {10},
keywords = {twitter, tf-idf, temporal dynamics, recommender systems, hashtags, hashtag usage recency, hashtag reuse prediction, hashtag recommendation, bll equation, act-r},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3038912.3052650,
author = {Rizoiu, Marian-Andrei and Xie, Lexing and Sanner, Scott and Cebrian, Manuel and Yu, Honglin and Van Hentenryck, Pascal},
title = {Expecting to be HIP: Hawkes Intensity Processes for Social Media Popularity},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052650},
doi = {10.1145/3038912.3052650},
abstract = {Modeling and predicting the popularity of online content is a significant problem for the practice of information dissemination, advertising, and consumption. Recent work analyzing massive datasets advances our understanding of popularity, but one major gap remains: To precisely quantify the relationship between the popularity of an online item and the external promotions it receives. This work supplies the missing link between exogenous inputs from public social media platforms, such as Twitter, and endogenous responses within the content platform, such as YouTube. We develop a novel mathematical model, the Hawkes intensity process, which can explain the complex popularity history of each video according to its type of content, network of diffusion, and sensitivity to promotion. Our model supplies a prototypical description of videos, called an endo-exo map. This map explains popularity as the result of an extrinsic factor -- the amount of promotions from the outside world that the video receives, acting upon two intrinsic factors -- sensitivity to promotion, and inherent virality. We use this model to forecast future popularity given promotions on a large 5-months feed of the most-tweeted videos, and found it to lower the average error by 28.6% from approaches based on popularity history. Finally, we can identify videos that have a high potential to become viral, as well as those for which promotions will have hardly any effect.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {735–744},
numpages = {10},
keywords = {self-exciting processes, popularity modeling, popularity forecasting, item virality, hawkes intensity process},
location = {Perth, Australia},
series = {WWW '17}
}

@proceedings{10.1145/3308558,
title = {WWW '19: The World Wide Web Conference},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to The Web Conference 2019. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, CA, USA}
}

@inproceedings{10.1145/1242572.1242806,
author = {Cheng, Yun-Maw and Chou, Tzu-Chuan and Yu, Wai and Chen, Li-Chieh and Yeh, Ching-Long and Chen, Meng-Chang},
title = {Life is sharable: mechanisms to support and sustain blogging life experience},
year = {2007},
isbn = {9781595936547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1242572.1242806},
doi = {10.1145/1242572.1242806},
abstract = {Recent trend in the development of mobile devices, wireless communications, sensor technologies, weblogs, and peer-to-peer communications have prompted a new design opportunity for enhancing social interactions. This paper introduces our preliminary experiences in designing a prototype utilizing the aforementioned technologies to share life experience. Users equipped with camera phones coupled with short-range communication technology, such as RFID, can capture life experience and share it as weblogs to other people. However, in reality, this is easier said than done. The success of weblogs relies on the active participation and willingness of people to contribute. To encourage active participations, a ranking system, AgreeRank, is specifically developed to get them motivated.},
booktitle = {Proceedings of the 16th International Conference on World Wide Web},
pages = {1277–1278},
numpages = {2},
keywords = {wireless networking, weblog, peer-to-peer communication, mobile phone, collaborative system, RFID},
location = {Banff, Alberta, Canada},
series = {WWW '07}
}

@inproceedings{10.1145/2488388.2488396,
author = {Aly, Mohamed and Pandey, Sandeep and Josifovski, Vanja and Punera, Kunal},
title = {Towards a robust modeling of temporal interest change patterns for behavioral targeting},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488396},
doi = {10.1145/2488388.2488396},
abstract = {Modern web-scale behavioral targeting platforms leverage historical activity of billions of users to predict user interests and inclinations, and consequently future activities. Future activities of particular interest involve purchases or transactions, and are referred to as conversions. Unlike ad-clicks, conversions directly translate to advertiser's revenue, and thus provide a very concrete metric for return on advertising investment. A typical behavioral targeting system faces two main challenges: the web-scale amounts of user histories to process on a daily basis, and the relative sparsity of conversions (compared to clicks in a traditional setting). These challenges call for generation of effective and efficient user profiles. Most existing works use the historical intensity of a user's interest in various topics to model future interest. In this paper we explore how the change in user behavior can be used to predict future actions and show how it complements the traditional models of decaying interest and action recency to build a complete picture about the user interests and better predict conversions. Our evaluation over a real-world set of campaigns indicates that the combination of change of interest, decaying intensity, and action recency helps in: 1) scoring significant improvements in optimizing for conversions over traditional baselines, 2) substantially improving the targeting efficiency for campaigns with highly sparse conversions, and 3) highly reducing the overall history sizes used in targeting. Furthermore, our techniques have been deployed to production and scored a substantial improvement in targeting performance while imposing a negligible overhead in terms of overall platform running time.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {71–82},
numpages = {12},
keywords = {user modeling, time-based features, display advertising, behavioral targeting},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/2488388.2488432,
author = {Gorla, Jagadeesh and Lathia, Neal and Robertson, Stephen and Wang, Jun},
title = {Probabilistic group recommendation via information matching},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488432},
doi = {10.1145/2488388.2488432},
abstract = {Increasingly, web recommender systems face scenarios where they need to serve suggestions to groups of users; for example, when families share e-commerce or movie rental web accounts. Research to date in this domain has proposed two approaches: computing recommendations for the group by merging any members' ratings into a single profile, or computing ranked recommendations for each individual that are then merged via a range of heuristics. In doing so, none of the past approaches reason on the preferences that arise in individuals when they are members of a group. In this work, we present a probabilistic framework, based on the notion of information matching, for group recommendation. This model defines group relevance as a combination of the item's relevance to each user as an individual and as a member of the group; it can then seamlessly incorporate any group recommendation strategy in order to rank items for a set of individuals. We evaluate the model's efficacy at generating recommendations for both single individuals and groups using the MovieLens and MoviePilot data sets. In both cases, we compare our results with baselines and state-of-the-art collaborative filtering algorithms, and show that the model outperforms all others over a variety of ranking metrics.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {495–504},
numpages = {10},
keywords = {relevance ranking, probabilistic modelling, information matching, group recommendation},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/2566486.2567968,
author = {Zhang, Jun and Wang, Chaokun and Wang, Jianmin},
title = {Who proposed the relationship? recovering the hidden directions of undirected social networks},
year = {2014},
isbn = {9781450327442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2566486.2567968},
doi = {10.1145/2566486.2567968},
abstract = {Together with the sign (positive or negative) and strength (strong or weak), the directionality is also an important property of social ties, though usually ignored in undirected social networks for its invisibility. However, we believe most social ties are natively directed, and the awareness of directionality can improve our understanding about the network structures and further benefit social network analysis and mining tasks. Thus it's appealing to study whether there exist interesting patterns about directionality in social networks and whether we can learn the directions for undirected networks based on these patterns. In this study, we engage in the investigation of directionality patterns on real-world directed social networks and summarize our findings using four consistency hypotheses. Based on these hypotheses, we propose ReDirect, an optimization framework which makes it possible to infer the hidden directions of undirected social ties based on the network topology only. This general framework can incorporate various predictive models under specific scenarios. Furthermore, we show how to improve ReDirect by introducing semi/self-supervision in the framework and how to construct the self-labeled training data using simple but effective heuristics. Experimental results show that even without external information, our approach can recover the directions of networks effectively.Moreover, we're quite surprising to find that ReDirect can benefit predictive tasks remarkably, with a case study of link prediction. In experiments the redirected networks inferred using ReDirect are proven much more informative than original undirected ones and can improve the prediction performance significantly. It convinces us that ReDirect can be a beneficial general data preprocess tool for various network analysis and mining tasks by uncovering the hidden directions of undirected social networks.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {807–818},
numpages = {12},
keywords = {tie direction inference, social networks, redirect, directionality},
location = {Seoul, Korea},
series = {WWW '14}
}

@inproceedings{10.1145/1526709.1526802,
author = {Chu, Wei and Park, Seung-Taek},
title = {Personalized recommendation on dynamic content using predictive bilinear models},
year = {2009},
isbn = {9781605584874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1526709.1526802},
doi = {10.1145/1526709.1526802},
abstract = {In Web-based services of dynamic content (such as news articles), recommender systems face the difficulty of timely identifying new items of high-quality and providing recommendations for new users. We propose a feature-based machine learning approach to personalized recommendation that is capable of handling the cold-start issue effectively. We maintain profiles of content of interest, in which temporal characteristics of the content, e.g. popularity and freshness, are updated in real-time manner. We also maintain profiles of users including demographic information and a summary of user activities within Yahoo! properties. Based on all features in user and content profiles, we develop predictive bilinear regression models to provide accurate personalized recommendations of new items for both existing and new users. This approach results in an offline model with light computational overhead compared with other recommender systems that require online re-training. The proposed framework is general and flexible for other personalized tasks. The superior performance of our approach is verified on a large-scale data set collected from the Today-Module on Yahoo! Front Page, with comparison against six competitive approaches.},
booktitle = {Proceedings of the 18th International Conference on World Wide Web},
pages = {691–700},
numpages = {10},
keywords = {user and content profile, regression, recommender systems, ranking, personalization, dynamic features, bilinear models},
location = {Madrid, Spain},
series = {WWW '09}
}

@inproceedings{10.1145/2187836.2187870,
author = {Brodersen, Anders and Scellato, Salvatore and Wattenhofer, Mirjam},
title = {YouTube around the world: geographic popularity of videos},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187870},
doi = {10.1145/2187836.2187870},
abstract = {One of the most popular user activities on the Web is watching videos. Services like YouTube, Vimeo, and Hulu host and stream millions of videos, providing content that is on par with TV. While some of this content is popular all over the globe, some videos might be only watched in a confined, local region.In this work we study the relationship between popularity and locality of online YouTube videos. We investigate whether YouTube videos exhibit geographic locality of interest, with views arising from a confined spatial area rather than from a global one. Our analysis is done on a corpus of more than 20 millions YouTube videos, uploaded over one year from different regions. We find that about 50% of the videos have more than 70% of their views in a single region. By relating locality to viralness we show that social sharing generally widens the geographic reach of a video. If, however, a video cannot carry its social impulse over to other means of discovery, it gets stuck in a more confined geographic region. Finally, we analyze how the geographic properties of a video's views evolve on a daily basis during its lifetime, providing new insights on how the geographic reach of a video changes as its popularity peaks and then fades away.Our results demonstrate how, despite the global nature of the Web, online video consumption appears constrained by geographic locality of interest: this has a potential impact on a wide range of systems and applications, spanning from delivery networks to recommendation and discovery engines, providing new directions for future research.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {241–250},
numpages = {10},
keywords = {social content diffusion, online video sharing, geographic popularity analysis},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/1963192.1963346,
author = {Mahanti, Aniket},
title = {Measurement and analysis of cyberlocker services},
year = {2011},
isbn = {9781450306379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963192.1963346},
doi = {10.1145/1963192.1963346},
abstract = {Cyberlocker Services (CLS) such as RapidShare and Megaupload have recently become popular. The decline of Peer-to-Peer (P2P) file sharing has prompted various services including CLS to replace it. We propose a comprehensive multi-level characterization of the CLS ecosystem. We answer three research questions: (a) what is a suitable measurement infrastructure for gathering CLS workloads; (b) what are the characteristics of the CLS ecosystem; and (c) what are the implications of CLS on Web 2.0 (and the Internet). To the best of our knowledge, this work is the first to characterize the CLS ecosystem. The work will highlight the content, usage, performance, infrastructure, quality of service, and evolution characteristics of CLS.},
booktitle = {Proceedings of the 20th International Conference Companion on World Wide Web},
pages = {373–378},
numpages = {6},
keywords = {web 2.0, rapidshare, performance, measurement, file hosting services, cyberlockers},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{10.1145/2488388.2488445,
author = {Jamali, Mohsen and Lakshmanan, Laks},
title = {HeteroMF: recommendation in heterogeneous information networks using context dependent factor models},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488445},
doi = {10.1145/2488388.2488445},
abstract = {With the growing amount of information available online, recommender systems are starting to provide a viable alternative and complement to search engines, in helping users to find objects of interest. Methods based on Matrix Factorization (MF) models are the state-of-the-art in recommender systems. The input to MF is user feedback, in the form of a rating matrix. However, users can be engaged in interactions with multiple types of entities across different contexts, leading to multiple rating matrices. In other words, users can have interactions in a heterogeneous information network. Generally, in a heterogeneous network, entities from any two entity types can have interactions with a weight (rating) indicating the level of endorsement. Collective Matrix Factorization (CMF) has been proposed to address the recommendation problem in heterogeneous networks. However, a main issue with CMF is that entities share the same latent factor across different contexts. This is particularly problematic in two cases: Latent factors for entities that are cold-start in a context will be learnt mainly based on the data from other contexts where these entities are not cold-start, and therefore the factors are not properly learned for the cold-start context. Also, if a context has more data compared to another context, then the dominant context will dominate the learning process for the latent factors for entities shared in these two contexts. In this paper, we propose a context-dependent matrix factorization model, HeteroMF, that considers a general latent factor for entities of every entity type and context-dependent latent factors for every context in which the entities are involved. We learn a general latent factor for every entity and transfer matrices for every context to convert the general latent factors into a context-dependent latent factor. Experiments on two real life datasets from Epinions and Flixster demonstrate that HeteroMF substantially outperforms CMF, particularly for cold-start entities and for contexts where interactions in one contexts are dominated by other contexts.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {643–654},
numpages = {12},
keywords = {recommendation, multi-context, matrix factorization, cold start},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/2872427.2883010,
author = {Matsubara, Yasuko and Sakurai, Yasushi and Faloutsos, Christos},
title = {Non-Linear Mining of Competing Local Activities},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2883010},
doi = {10.1145/2872427.2883010},
abstract = {Given a large collection of time-evolving activities, such as Google search queries, which consist of d keywords/activities for m locations of duration n, how can we analyze temporal patterns and relationships among all these activities and find location-specific trends? How do we go about capturing non-linear evolutions of local activities and forecasting future patterns? For example, assume that we have the online search volume for multiple keywords, e.g., "Nokia/Nexus/Kindle" or "CNN/BBC" for 236 countries/territories, from 2004 to 2015. Our goal is to analyze a large collection of multi-evolving activities, and specifically, to answer the following questions: (a) Is there any sign of interaction/competition between two different keywords? If so, who competes with whom? (b) In which country is the competition strong? (c) Are there any seasonal/annual activities? (d) How can we automatically detect important world-wide (or local) events? We present COMPCUBE, a unifying non-linear model, which provides a compact and powerful representation of co-evolving activities; and also a novel fitting algorithm, COMPCUBE-FIT, which is parameter-free and scalable. Our method captures the following important patterns: (B)asic trends, i.e., non-linear dynamics of co-evolving activities, signs of (C)ompetition and latent interaction, e.g., Nokia vs. Nexus, (S)easonality, e.g., a Christmas spike for iPod in the U.S. and Europe, and (D)eltas, e.g., unrepeated local events such as the U.S. election in 2008. Thanks to its concise but effective summarization, COMPCUBE can also forecast long-range future activities. Extensive experiments on real datasets demonstrate that COMPCUBE consistently outperforms the best state-of- the-art methods in terms of both accuracy and execution speed.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {737–747},
numpages = {11},
keywords = {forecasting, non-linear, parameter-free, time-series},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1145/2488388.2488520,
author = {Zhang, Yongfeng and Zhang, Min and Liu, Yiqun and Ma, Shaoping and Feng, Shi},
title = {Localized matrix factorization for recommendation based on matrix block diagonal forms},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488520},
doi = {10.1145/2488388.2488520},
abstract = {Matrix factorization on user-item rating matrices has achieved significant success in collaborative filtering based recommendation tasks. However, it also encounters the problems of data sparsity and scalability when applied in real-world recommender systems. In this paper, we present the Localized Matrix Factorization (LMF) framework, which attempts to meet the challenges of sparsity and scalability by factorizing Block Diagonal Form (BDF) matrices. In the LMF framework, a large sparse matrix is first transformed into Recursive Bordered Block Diagonal Form (RBBDF), which is an intuitionally interpretable structure for user-item rating matrices. Smaller and denser submatrices are then extracted from this RBBDF matrix to construct a BDF matrix for more effective collaborative prediction. We show formally that the LMF framework is suitable for matrix factorization and that any decomposable matrix factorization algorithm can be integrated into this framework. It has the potential to improve prediction accuracy by factorizing smaller and denser submatrices independently, which is also suitable for parallelization and contributes to system scalability at the same time. Experimental results based on a number of real-world public-access benchmarks show the effectiveness and efficiency of the proposed LMF framework.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {1511–1520},
numpages = {10},
keywords = {matrix factorization, graph partitioning, collaborative filtering, block diagonal form},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/2488388.2488441,
author = {Hu, Liang and Cao, Jian and Xu, Guandong and Cao, Longbing and Gu, Zhiping and Zhu, Can},
title = {Personalized recommendation via cross-domain triadic factorization},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488441},
doi = {10.1145/2488388.2488441},
abstract = {Collaborative filtering (CF) is a major technique in recommender systems to help users find their potentially desired items. Since the data sparsity problem is quite commonly encountered in real-world scenarios, Cross-Domain Collaborative Filtering (CDCF) hence is becoming an emerging research topic in recent years. However, due to the lack of sufficient dense explicit feedbacks and even no feedback available in users' uninvolved domains, current CDCF approaches may not perform satisfactorily in user preference prediction. In this paper, we propose a generalized Cross Domain Triadic Factorization (CDTF) model over the triadic relation user-item-domain, which can better capture the interactions between domain-specific user factors and item factors. In particular, we devise two CDTF algorithms to leverage user explicit and implicit feedbacks respectively, along with a genetic algorithm based weight parameters tuning algorithm to trade off influence among domains optimally. Finally, we conduct experiments to evaluate our models and compare with other state-of-the-art models by using two real world datasets. The results show the superiority of our models against other comparative models.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {595–606},
numpages = {12},
keywords = {triadic factorization, recommender system, cross-domain collaborative filtering},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/2488388.2488407,
author = {Chen, Ying and Xu, Heng and Zhou, Yilu and Zhu, Sencun},
title = {Is this app safe for children? a comparison study of maturity ratings on Android and iOS applications},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488407},
doi = {10.1145/2488388.2488407},
abstract = {There is a rising concern among parents who have experienced unreliable content maturity ratings for mobile applications (apps) that result in inappropriate risk exposure for their children and adolescents. In reality, there is no consistent maturity rating policy for mobile applications. The maturity ratings of Android apps are provided purely by developers' self-disclosure and are rarely verified. While Apple's iOS app ratings are considered to be more accurate, they can also be inconsistent with Apple's published policies. To address these issues, this research aims to systematically uncover the extent and severity of unreliable maturity ratings for mobile apps. Specifically, we develop mechanisms to verify the maturity ratings of mobile apps and investigate possible reasons behind the incorrect ratings. We believe that our findings have important implications for platform providers (e.g., Google or Apple) as well as for regulatory bodies and application developers.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {201–212},
numpages = {12},
keywords = {privacy, mobile app, maturity rating, ios apps, children safety, application permissions, android apps},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/3366423.3380154,
author = {Pan, Feiyang and Ao, Xiang and Tang, Pingzhong and Lu, Min and Liu, Dapeng and Xiao, Lei and He, Qing},
title = {Field-aware Calibration: A Simple and Empirically Strong Method for Reliable Probabilistic Predictions},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380154},
doi = {10.1145/3366423.3380154},
abstract = {It is often observed that the probabilistic predictions given by a machine learning model can disagree with averaged actual outcomes on specific subsets of data, which is also known as the issue of miscalibration. It is responsible for the unreliability of practical machine learning systems. For example, in online advertising, an ad can receive a click-through rate prediction of 0.1 over some population of users where its actual click rate is 0.15. In such cases, the probabilistic predictions have to be fixed before the system can be deployed. In this paper, we first introduce a new evaluation metric named field-level calibration error that measures the bias in predictions over the sensitive input field that the decision-maker concerns. We show that existing post-hoc calibration methods have limited improvements in the new field-level metric and other non-calibration metrics such as the AUC score. To this end, we propose Neural Calibration, a simple yet powerful post-hoc calibration method that learns to calibrate by making full use of the field-aware information over the validation set. We present extensive experiments on five large-scale datasets. The results showed that Neural Calibration significantly improves against uncalibrated predictions in common metrics such as the negative log-likelihood, Brier score and AUC, as well as the proposed field-level calibration error.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {729–739},
numpages = {11},
keywords = {Probabilistic prediction, Neural Calibration, Field-level Calibration Error, Field-aware Calibration},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/2488388.2488442,
author = {Hu, Xia and Tang, Jiliang and Gao, Huiji and Liu, Huan},
title = {Unsupervised sentiment analysis with emotional signals},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488442},
doi = {10.1145/2488388.2488442},
abstract = {The explosion of social media services presents a great opportunity to understand the sentiment of the public via analyzing its large-scale and opinion-rich data. In social media, it is easy to amass vast quantities of unlabeled data, but very costly to obtain sentiment labels, which makes unsupervised sentiment analysis essential for various applications. It is challenging for traditional lexicon-based unsupervised methods due to the fact that expressions in social media are unstructured, informal, and fast-evolving. Emoticons and product ratings are examples of emotional signals that are associated with sentiments expressed in posts or words. Inspired by the wide availability of emotional signals in social media, we propose to study the problem of unsupervised sentiment analysis with emotional signals. In particular, we investigate whether the signals can potentially help sentiment analysis by providing a unified way to model two main categories of emotional signals, i.e., emotion indication and emotion correlation. We further incorporate the signals into an unsupervised learning framework for sentiment analysis. In the experiment, we compare the proposed framework with the state-of-the-art methods on two Twitter datasets and empirically evaluate our proposed framework to gain a deep understanding of the effects of emotional signals.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {607–618},
numpages = {12},
keywords = {social media, social correlation, sentiment classification, sentiment analysis, emotional signals, emoticon, Twitter},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@proceedings{10.5555/3041021,
title = {WWW '17 Companion: Proceedings of the 26th International Conference on World Wide Web Companion},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {We welcome you to the WWW2017 conference, the 26th of the series, and only the second one to be held in Australia.The annual World Wide Web Conference is the premier international forum to present and discuss progress in research, development, standards, and applications related to the Web. This conference is organised under the aegis of the International World Wide Web Conference Committee (IW3C2) in collaboration with local conference organisers in the host city, in this case, the four public universities in Western Australia: Curtin University, Murdoch University, the University of Western Australia and Edith Cowan University. This year, WWW 2017 is offered as the centerpiece of the inaugural Festival of the Web in Perth, a week-long celebration.WWW 2017 provides an opportunity to hear from the leaders of the web including three distinguished keynote speeches by world-class experts: Mark Pesce, Yoelle Maarek, and Melanie Johnston-Hollitt. There is a rich environment of technical activities, including 164 high quality papers in the Research Tracks, 54 papers in the four alternate tracks, over 100 papers in 15 workshops, 13 tutorial sessions, a Ph.D. Symposium track comprising presentations by seven doctoral students, an Industry track consisting of 20 papers focused on applied research, 20 demonstrations, a W3C track examining the latest Web standards and emerging technologies and 64 posters with, for the first time, a number of these offered as e-posters to augment the static poster panels. Overall, WWW2017 provides more than 400 high quality presentations on the key research and development issues of the World Wide Web.Co-located events in the Festival of the Web 2017 include the 4th Big Data Innovators Gathering (BIG 2017), the Web for All conference (W4A2017), and the 5th Serious Games and Applications for Health conference (SeGaH'17). In addition, several new events include Collaboration-Innovation, a one day conference focusing on building smart business innovation through collaboration; the Trust Factory, a curated forum exploring issues of trust and privacy on the web; and Bytes and Rights, a conference focused on issues of web governance, copyright, digital rights, privacy and security on the web. Finally, the Big Day In is a one-day IT careers conference designed by students for students, including tips and advice for secondary school students interested in IT and the web.Given Perth's location in one of the world's richest areas of natural resources, DeepSensor, a world class gathering of industry professionals, is being conducted as part of the Festival as an opportunity for professionals to share their real-world insights into the continuing development of the internet of things in the mining, oil and gas industries.},
location = {Perth, Australia}
}

@inproceedings{10.1145/2187836.2187896,
author = {San Pedro, Jose and Yeh, Tom and Oliver, Nuria},
title = {Leveraging user comments for aesthetic aware image search reranking},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187896},
doi = {10.1145/2187836.2187896},
abstract = {The increasing number of images available online has created a growing need for efficient ways to search for relevant content. Text-based query search is the most common approach to retrieve images from the Web. In this approach, the similarity between the input query and the metadata of images is used to find relevant information. However, as the amount of available images grows, the number of relevant images also increases, all of them sharing very similar metadata but differing in other visual characteristics. This paper studies the influence of visual aesthetic quality in search results as a complementary attribute to relevance. By considering aesthetics, a new ranking parameter is introduced aimed at improving the quality at the top ranks when large amounts of relevant results exist. Two strategies for aesthetic rating inference are proposed: one based on visual content, another based on the analysis of user comments to detect opinions about the quality of images. The results of a user study with $58$ participants show that the comment-based aesthetic predictor outperforms the visual content-based strategy, and reveals that aesthetic-aware rankings are preferred by users searching for photographs on the Web.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {439–448},
numpages = {10},
keywords = {visual aesthetics modeling, user comments, sentiment analysis, opinion mining, image search reranking},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/2736277.2741092,
author = {Matsubara, Yasuko and Sakurai, Yasushi and Faloutsos, Christos},
title = {The Web as a Jungle: Non-Linear Dynamical Systems for Co-evolving Online Activities},
year = {2015},
isbn = {9781450334693},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2736277.2741092},
doi = {10.1145/2736277.2741092},
abstract = {Given a large collection of co-evolving online activities, such as searches for the keywords "Xbox", "PlayStation" and "Wii", how can we find patterns and rules? Are these keywords related? If so, are they competing against each other? Can we forecast the volume of user activity for the coming month? We conjecture that online activities compete for user attention in the same way that species in an ecosystem compete for food. We present ECOWEB, (i.e., Ecosystem on the Web), which is an intuitive model designed as a non-linear dynamical system for mining large-scale co-evolving online activities. Our second contribution is a novel, parameter-free, and scalable fitting algorithm, ECOWEB-FIT, that estimates the parameters of ECOWEB. Extensive experiments on real data show that ECOWEB is effective, in that it can capture long-range dynamics and meaningful patterns such as seasonalities, and practical, in that it can provide accurate long-range forecasts. ECOWEB consistently outperforms existing methods in terms of both accuracy and execution speed.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {721–731},
numpages = {11},
keywords = {time-series, parameter-free, non-linear, ecosystem},
location = {Florence, Italy},
series = {WWW '15}
}

@inproceedings{10.1145/2187836.2187894,
author = {Dalal, Onkar and Sengemedu, Srinivasan H. and Sanyal, Subhajit},
title = {Multi-objective ranking of comments on web},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187894},
doi = {10.1145/2187836.2187894},
abstract = {With the explosion of information on any topic, the need for ranking is becoming very critical. Ranking typically depends on several aspects. Products, for example, have several aspects like price, recency, rating, etc. Product ranking has to bring the "best" product which is recent and highly rated. Hence ranking has to satisfy multiple objectives. In this paper, we explore multi-objective ranking of comments using Hodge decomposition. While Hodge decomposition produces a globally consistent ranking, a globally inconsistent component is also present. We propose an active learning strategy for the reduction of this component. Finally, we develop techniques for online Hodge decomposition. We experimentally validate the ideas presented in this paper.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {419–428},
numpages = {10},
keywords = {multi-objective ranking, hodge decomposition, active learning},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/1963405.1963471,
author = {Scellato, Salvatore and Mascolo, Cecilia and Musolesi, Mirco and Crowcroft, Jon},
title = {Track globally, deliver locally: improving content delivery networks by tracking geographic social cascades},
year = {2011},
isbn = {9781450306324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963405.1963471},
doi = {10.1145/1963405.1963471},
abstract = {Providers such as YouTube offer easy access to multimedia content to millions, generating high bandwidth and storage demand on the Content Delivery Networks they rely upon. More and more, the diffusion of this content happens on online social networks such as Facebook and Twitter, where social cascades can be observed when users increasingly repost links they have received from others.In this paper we describe how geographic information extracted from social cascades can be exploited to improve caching of multimedia files in a Content Delivery Network. We take advantage of the fact that social cascades can propagate in a geographically limited area to discern whether an item is spreading locally or globally. This informs cache replacement policies, which utilize this information to ensure that content relevant to a cascade is kept close to the users who may be interested in it.We validate our approach by using a novel dataset which combines social interaction data with geographic information: we track social cascades of YouTube links over Twitter and build a proof-of-concept geographic model of a realistic distributed Content Delivery Network. Our performance evaluation shows that we are able to improve cache hits with respect to cache policies without geographic and social information.},
booktitle = {Proceedings of the 20th International Conference on World Wide Web},
pages = {457–466},
numpages = {10},
keywords = {online social networks, information propagation, content delivery networks},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{10.1145/2187836.2187838,
author = {Aizenberg, Natalie and Koren, Yehuda and Somekh, Oren},
title = {Build your own music recommender by modeling internet radio streams},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187838},
doi = {10.1145/2187836.2187838},
abstract = {In the Internet music scene, where recommendation technology is key for navigating huge collections, large market players enjoy a considerable advantage. Accessing a wider pool of user feedback leads to an increasingly more accurate analysis of user tastes, effectively creating a "rich get richer" effect. This work aims at significantly lowering the entry barrier for creating music recommenders, through a paradigm coupling a public data source and a new collaborative filtering (CF) model. We claim that Internet radio stations form a readily available resource of abundant fresh human signals on music through their playlists, which are essentially cohesive sets of related tracks. In a way, our models rely on the knowledge of a diverse group of experts in lieu of the commonly used wisdom of crowds. Over several weeks, we aggregated publicly available playlists of thousands of Internet radio stations, resulting in a dataset encompassing millions of plays, and hundreds of thousands of tracks and artists. This provides the large scale ground data necessary to mitigate the cold start problem of new items at both mature and emerging services.Furthermore, we developed a new probabilistic CF model, tailored to the Internet radio resource. The success of the model was empirically validated on the collected dataset. Moreover, we tested the model at a cross-source transfer learning manner -- the same model trained on the Internet radio data was used to predict behavior of Yahoo! Music users. This demonstrates the ability to tap the Internet radio signals in other music recommendation setups. Based on encouraging empirical results, our hope is that the proposed paradigm will make quality music recommendation accessible to all interested parties in the community.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {1–10},
numpages = {10},
keywords = {music recommendation, internet radio, collaborative filtering},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/1772690.1772794,
author = {Zheleva, Elena and Guiver, John and Mendes Rodrigues, Eduarda and Mili\'{c}-Frayling, Nata\v{s}a},
title = {Statistical models of music-listening sessions in social media},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1772690.1772794},
doi = {10.1145/1772690.1772794},
abstract = {User experience in social media involves rich interactions with the media content and other participants in the community. In order to support such communities, it is important to understand the factors that drive the users' engagement. In this paper we show how to define statistical models of different complexity to describe patterns of song listening in an online music community. First, we adapt the LDA model to capture music taste from listening activities across users and identify both the groups of songs associated with the specific taste and the groups of listeners who share the same taste. Second, we define a graphical model that takes into account listening sessions and captures the listening moods of users in the community. Our session model leads to groups of songs and groups of listeners with similar behavior across listening sessions and enables faster inference when compared to the LDA model. Our experiments with the data from an online media site demonstrate that the session model is better in terms of the perplexity compared to two other models: the LDA-based taste model that does not incorporate cross-session information and a baseline model that does not use latent groupings of songs.},
booktitle = {Proceedings of the 19th International Conference on World Wide Web},
pages = {1019–1028},
numpages = {10},
keywords = {taste, social media, sessions, recommendations, music, mood, graphical models, collaborative filtering},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}

@inproceedings{10.1145/2187836.2187895,
author = {Shmueli, Erez and Kagian, Amit and Koren, Yehuda and Lempel, Ronny},
title = {Care to comment? recommendations for commenting on news stories},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187895},
doi = {10.1145/2187836.2187895},
abstract = {Many websites provide commenting facilities for users to express their opinions or sentiments with regards to content items, such as, videos, news stories, blog posts, etc. Previous studies have shown that user comments contain valuable information that can provide insight on Web documents and may be utilized for various tasks. This work presents a model that predicts, for a given user, suitable news stories for commenting. The model achieves encouraging results regarding the ability to connect users with stories they are likely to comment on. This provides grounds for personalized recommendations of stories to users who may want to take part in their discussion. We combine a content-based approach with a collaborative-filtering approach (utilizing users' co-commenting patterns) in a latent factor modeling framework. We experiment with several variations of the model's loss function in order to adjust it to the problem domain. We evaluate the results on two datasets and show that employing co-commenting patterns improves upon using content features alone, even with as few as two available comments per story. Finally, we try to incorporate available social network data into the model. Interestingly, the social data does not lead to substantial performance gains, suggesting that the value of social data for this task is quite negligible.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {429–438},
numpages = {10},
keywords = {user generated content, recommendation system, personalization, latent factor models, comment recommendation, collaborative filtering},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/2872427.2882993,
author = {Cheng, Justin and Adamic, Lada A. and Kleinberg, Jon M. and Leskovec, Jure},
title = {Do Cascades Recur?},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2882993},
doi = {10.1145/2872427.2882993},
abstract = {Cascades of information-sharing are a primary mechanism by which content reaches its audience on social media, and an active line of research has studied how such cascades, which form as content is reshared from person to person, develop and subside. In this paper, we perform a large-scale analysis of cascades on Facebook over significantly longer time scales, and find that a more complex picture emerges, in which many large cascades recur, exhibiting multiple bursts of popularity with periods of quiescence in between. We characterize recurrence by measuring the time elapsed between bursts, their overlap and proximity in the social network, and the diversity in the demographics of individuals participating in each peak. We discover that content virality, as revealed by its initial popularity, is a main driver of recurrence, with the availability of multiple copies of that content helping to spark new bursts. Still, beyond a certain popularity of content, the rate of recurrence drops as cascades start exhausting the population of interested individuals. We reproduce these observed patterns in a simple model of content recurrence simulated on a real social network. Using only characteristics of a cascade's initial burst, we demonstrate strong performance in predicting whether it will recur in the future.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {671–681},
numpages = {11},
keywords = {cascade prediction, content recurrence, information diffusion, memes, virality},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1145/2488388.2488503,
author = {Vaz de Melo, Pedro Olmo S. and Faloutsos, Christos and Assun\c{c}\~{a}o, Renato and Loureiro, Antonio},
title = {The self-feeding process: a unifying model for communication dynamics in the web},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488503},
doi = {10.1145/2488388.2488503},
abstract = {How often do individuals perform a given communication activity in the Web, such as posting comments on blogs or news? Could we have a generative model to create communication events with realistic inter-event time distributions (IEDs)? Which properties should we strive to match? Current literature has seemingly contradictory results for IED: some studies claim good fits with power laws; others with non-homogeneous Poisson processes. Given these two approaches, we ask: which is the correct one? Can we reconcile them all? We show here that, surprisingly, both approaches are correct, being corner cases of the proposed Self-Feeding Process (SFP). We show that the SFP (a) exhibits a unifying power, which generates power law tails (including the so-called "top-concavity" that real data exhibits), as well as short-term Poisson behavior; (b) avoids the "i.i.d. fallacy", which none of the prevailing models have studied before; and (c) is extremely parsimonious, requiring usually only one, and in general, at most two parameters. Experiments conducted on eight large, diverse real datasets (e.g., Youtube and blog comments, e-mails, SMSs, etc) reveal that the SFP mimics their properties very well.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {1319–1330},
numpages = {12},
keywords = {inter-event times, generative model, communication dynamics},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/2566486.2567997,
author = {Cheng, Justin and Adamic, Lada and Dow, P. Alex and Kleinberg, Jon Michael and Leskovec, Jure},
title = {Can cascades be predicted?},
year = {2014},
isbn = {9781450327442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2566486.2567997},
doi = {10.1145/2566486.2567997},
abstract = {On many social networking web sites such as Facebook and Twitter, resharing or reposting functionality allows users to share others' content with their own friends or followers. As content is reshared from user to user, large cascades of reshares can form. While a growing body of research has focused on analyzing and characterizing such cascades, a recent, parallel line of work has argued that the future trajectory of a cascade may be inherently unpredictable. In this work, we develop a framework for addressing cascade prediction problems. On a large sample of photo reshare cascades on Facebook, we find strong performance in predicting whether a cascade will continue to grow in the future. We find that the relative growth of a cascade becomes more predictable as we observe more of its reshares, that temporal and structural features are key predictors of cascade size, and that initially, breadth, rather than depth in a cascade is a better indicator of larger cascades. This prediction performance is robust in the sense that multiple distinct classes of features all achieve similar performance. We also discover that temporal features are predictive of a cascade's eventual shape. Observing independent cascades of the same content, we find that while these cascades differ greatly in size, we are still able to predict which ends up the largest.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {925–936},
numpages = {12},
keywords = {information diffusion, contagion, cascade prediction},
location = {Seoul, Korea},
series = {WWW '14}
}

@inproceedings{10.1145/2187836.2187839,
author = {Jambor, Tamas and Wang, Jun and Lathia, Neal},
title = {Using control theory for stable and efficient recommender systems},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187839},
doi = {10.1145/2187836.2187839},
abstract = {The aim of a web-based recommender system is to provide highly accurate and up-to-date recommendations to its users; in practice, it will hope to retain its users over time. However, this raises unique challenges. To achieve complex goals such as keeping the recommender model up-to-date over time, we need to consider a number of external requirements. Generally, these requirements arise from the physical nature of the system, for instance the available computational resources. Ideally, we would like to design a system that does not deviate from the required outcome. Modeling such a system over time requires to describe the internal dynamics as a combination of the underlying recommender model and the its users' behavior. We propose to solve this problem by applying the principles of modern control theory - a powerful set of tools to deal with dynamical systems - to construct and maintain a stable and robust recommender system for dynamically evolving environments. In particular, we introduce a design principle by focusing on the dynamic relationship between the recommender system's performance and the number of new training samples the system requires. This enables us to automate the control other external factors such as the system's update frequency. We show that, by using a Proportional-Integral-Derivative controller, a recommender system is able to automatically and accurately estimate the required input to keep the output close to a pre-defined requirements. Our experiments on a standard rating dataset show that, by using a feedback loop between system performance and training, the trade-off between the effectiveness and efficiency of the system can be well maintained. We close by discussing the widespread applicability of our approach to a variety of scenarios that recommender systems face.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {11–20},
numpages = {10},
keywords = {temporal analysis, recommender systems, control theory},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/3041021.3055166,
author = {Zhang, Aston and Garcia-Pueyo, Lluis and Wendt, James B. and Najork, Marc and Broder, Andrei},
title = {Email Category Prediction},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055166},
doi = {10.1145/3041021.3055166},
abstract = {According to recent estimates, about 90% of consumer received emails are machine-generated. Such messages include shopping receipts, promotional campaigns, newsletters, booking confirmations, etc. Most such messages are created by populating a fixed template with a small amount of personalized information, such as name, salutation, reservation numbers, dates, etc. Web mail providers (Gmail, Hotmail, Yahoo) are leveraging the structured nature of such emails to extract salient information and use it to improve the user experience: e.g. by automatically entering reservation data into a user calendar, or by sending alerts about upcoming shipments. To facilitate these extraction tasks it is helpful to classify templates according to their category, e.g. restaurant reservations or bill reminders, since each category triggers a particular user experience.Recent research has focused on discovering the causal thread of templates, e.g. inferring that a shopping order is usually followed by a shipping confirmation, an airline booking is followed by a confirmation and then by a "ready to check in" message, etc. Gamzu et al. took this idea one step further by implementing a method to predict the template category of future emails for a given user based on previously received templates. The motivation is that predicting future emails has a wide range of potential applications, including better user experiences (e.g. warning users of items ordered but not shipped), targeted advertising (e.g. users that recently made a flight reservation may be interested in hotel reservations), and spam classification (a message that is part of a legitimate causal thread is unlikely to be spam).The gist of the Gamzu et al. approach is modeling the problem as a Markov chain, where the nodes are templates or temporal events (e.g. the first day of the month). This paper expands on their work by investigating the use of neural networks for predicting the category of emails that will arrive during a fixed-sized time window in the future. We consider two types of neural networks: multi-layer perceptrons (MLP), a type of feedforward neural network; and long short-term memory (LSTM), a type of recurrent neural network. For each type of neural network, we explore the effects of varying their configuration (e.g. number of layers or number of neurons) and hyper-parameters (e.g. drop-out ratio). We find that the prediction accuracy of neural networks vastly outperforms the Markov chain approach, and that LSTMs perform slightly better than MLPs. We offer some qualitative interpretation of our findings and identify some promising future directions.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {495–503},
numpages = {9},
keywords = {time series analysis, prediction, email},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3178876.3186013,
author = {Jiao, Yunhao and Li, Cheng and Wu, Fei and Mei, Qiaozhu},
title = {Find the Conversation Killers: A Predictive Study of Thread-ending Posts},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186013},
doi = {10.1145/3178876.3186013},
abstract = {How to improve the quality of conversations in online communities has attracted considerable attention recently. Having engaged, civil, and reactive online conversations has a critical effect on the social life of Internet users. In this study, we are particularly interested in identifying a post in a multi-party conversation that is unlikely to be further replied to, which therefore kills that thread of the conversation. For this purpose, we propose a deep learning model called the ConverNet. ConverNet is attractive due to its capability of modeling the internal structure of a long conversation and its appropriate encoding of the contextual information of the conversation, through effective integration of attention mechanisms. Empirical experiments on real-world datasets demonstrate the effectiveness of the proposed model. For the widely concerned topic, our analysis also offers implications for how to improve the quality and user experience of online conversations, or how to engage users in a conversation with a chatbot.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {1145–1154},
numpages = {10},
keywords = {online conversations, deep learning, conversation prediction},
location = {Lyon, France},
series = {WWW '18}
}

@proceedings{10.1145/3696410,
title = {WWW '25: Proceedings of the ACM on Web Conference 2025},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 2025 ACM Web Conference (WWW '25) took place from April 28 to May 2, 2025, in the Sydney Convention &amp; Exhibition Centre, Australia. Its logo, featuring the Sydney Harbour Bridge, symbolizes the core "connecting" function of the Web. Formerly known as the International World Wide Web Conference (WWW), this event originated at CERN in 1994 and has long served as the premier venue for presenting and discussing research, development, standards, and applications related to the Web.The 2025 ACM Web Conference (WWW'25) took place from April 28 to May 2, 2025, in the Sydney Convention &amp; Exhibition Centre, Australia. Its logo, featuring the Sydney Harbour Bridge, symbolizes the core "connecting" function of the Web. Formerly known as the International World Wide Web Conference (WWW), this event originated at CERN in 1994 and has long served as the premier venue for presenting and discussing research, development, standards, and applications related to the Web.Between 2024 and 2025, large language models (LLMs) significantly impacted nearly every industry and many aspects of daily life, prompting transformations in the Web's ecosystem. Acknowledging the importance of LLMs in advancing Web technologies, the call for papers (CFP) across ten research tracks was slightly modified. Three program chairs - Liane Lewin-Eytan, Helen Huang, and Elad Yom-Tov - led the program committee, which used OpenReview to evaluate and accept the research track papers.},
location = {Sydney NSW, Australia}
}

@inproceedings{10.1145/2488388.2488463,
author = {Maggi, Federico and Frossi, Alessandro and Zanero, Stefano and Stringhini, Gianluca and Stone-Gross, Brett and Kruegel, Christopher and Vigna, Giovanni},
title = {Two years of short URLs internet measurement: security threats and countermeasures},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488463},
doi = {10.1145/2488388.2488463},
abstract = {URL shortening services have become extremely popular. However, it is still unclear whether they are an effective and reliable tool that can be leveraged to hide malicious URLs, and to what extent these abuses can impact the end users. With these questions in mind, we first analyzed existing countermeasures adopted by popular shortening services. Surprisingly, we found such countermeasures to be ineffective and trivial to bypass. This first measurement motivated us to proceed further with a large-scale collection of the HTTP interactions that originate when web users access live pages that contain short URLs. To this end, we monitored 622 distinct URL shortening services between March 2010 and April 2012, and collected 24,953,881 distinct short URLs. With this large dataset, we studied the abuse of short URLs. Despite short URLs are a significant, new security risk, in accordance with the reports resulting from the observation of the overall phishing and spamming activity, we found that only a relatively small fraction of users ever encountered malicious short URLs. Interestingly, during the second year of measurement, we noticed an increased percentage of short URLs being abused for drive-by download campaigns and a decreased percentage of short URLs being abused for spam campaigns. In addition to these security-related findings, our unique monitoring infrastructure and large dataset allowed us to complement previous research on short URLs and analyze these web services from the user's perspective.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {861–872},
numpages = {12},
keywords = {short urls, security, measurement, crowdsourcing},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/1772690.1772754,
author = {Lerman, Kristina and Hogg, Tad},
title = {Using a model of social dynamics to predict popularity of news},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1772690.1772754},
doi = {10.1145/1772690.1772754},
abstract = {Popularity of content in social media is unequally distributed, with some items receiving a disproportionate share of attention from users. Predicting which newly-submitted items will become popular is critically important for both companies that host social media sites and their users. Accurate and timely prediction would enable the companies to maximize revenue through differential pricing for access to content or ad placement. Prediction would also give consumers an important tool for filtering the ever-growing amount of content. Predicting popularity of content in social media, however, is challenging due to the complex interactions among content quality, how the social media site chooses to highlight content, and influence among users. While these factors make it difficult to predict popularity a priori, we show that stochastic models of user behavior on these sites allows predicting popularity based on early user reactions to new content. By incorporating aspects of the web site design, such models improve on predictions based on simply extrapolating from the early votes. We validate this claim on the social news portal Digg using a previously-developed model of social voting based on the Digg user interface.},
booktitle = {Proceedings of the 19th International Conference on World Wide Web},
pages = {621–630},
numpages = {10},
keywords = {social voting, social media, social dynamics, prediction, popularity},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}

@inproceedings{10.1145/1060745.1060754,
author = {Ziegler, Cai-Nicolas and McNee, Sean M. and Konstan, Joseph A. and Lausen, Georg},
title = {Improving recommendation lists through topic diversification},
year = {2005},
isbn = {1595930469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1060745.1060754},
doi = {10.1145/1060745.1060754},
abstract = {In this work we present topic diversification, a novel method designed to balance and diversify personalized recommendation lists in order to reflect the user's complete spectrum of interests. Though being detrimental to average accuracy, we show that our method improves user satisfaction with recommendation lists, in particular for lists generated using the common item-based collaborative filtering algorithm.Our work builds upon prior research on recommender systems, looking at properties of recommendation lists as entities in their own right rather than specifically focusing on the accuracy of individual recommendations. We introduce the intra-list similarity metric to assess the topical diversity of recommendation lists and the topic diversification approach for decreasing the intra-list similarity. We evaluate our method using book recommendation data, including offline analysis on 361, !, 349 ratings and an online study involving more than 2, !, 100 subjects.},
booktitle = {Proceedings of the 14th International Conference on World Wide Web},
pages = {22–32},
numpages = {11},
keywords = {recommender systems, metrics, diversification, collaborative filtering, accuracy},
location = {Chiba, Japan},
series = {WWW '05}
}

@inproceedings{10.1145/2872427.2883024,
author = {Benson, Austin R. and Kumar, Ravi and Tomkins, Andrew},
title = {Modeling User Consumption Sequences},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2883024},
doi = {10.1145/2872427.2883024},
abstract = {We study sequences of consumption in which the same item may be consumed multiple times. We identify two macroscopic behavior patterns of repeated consumptions. First, in a given user's lifetime, very few items live for a long time. Second, the last consumptions of an item exhibit growing inter-arrival gaps consistent with the notion of increasing boredom leading up to eventual abandonment.We then present what is to our knowledge the first holistic model of sequential repeated consumption, covering all observed aspects of this behavior. Our simple and purely combinatorial model includes no planted notion of lifetime distributions or user boredom; nonetheless, the model correctly predicts both of these phenomena. Further, we provide theoretical analysis of the behavior of the model confirming these phenomena. Additionally, the model quantitatively matches a number of microscopic phenomena across a broad range of datasets.Intriguingly, these findings suggest that the observation in a variety of domains of increasing user boredom leading to abandonment may be explained simply by probabilistic conditioning on an extinction event in a simple model, without resort to explanations based on complex human dynamics.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {519–529},
numpages = {11},
keywords = {sequence mining, repeat consumption, boredom},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1145/1526709.1526806,
author = {Cha, Meeyoung and Mislove, Alan and Gummadi, Krishna P.},
title = {A measurement-driven analysis of information propagation in the flickr social network},
year = {2009},
isbn = {9781605584874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1526709.1526806},
doi = {10.1145/1526709.1526806},
abstract = {Online social networking sites like MySpace, Facebook, and Flickr have become a popular way to share and disseminate content. Their massive popularity has led to viral marketing techniques that attempt to spread content, products, and ideas on these sites. However, there is little data publicly available on viral propagation in the real world and few studies have characterized how information spreads over current online social networks.In this paper, we collect and analyze large-scale traces of information dissemination in the Flickr social network. Our analysis, based on crawls of the favorite markings of 2.5 million users on 11 million photos, aims at answering three key questions: (a) how widely does information propagate in the social network? (b) how quickly does information propagate? and (c) what is the role of word-of-mouth exchanges between friends in the overall propagation of information in the network? Contrary to viral marketing ``intuition,'' we find that (a) even popular photos do not spread widely throughout the network, (b) even popular photos spread slowly through the network, and (c) information exchanged between friends is likely to account for over 50 of all favorite-markings, but with a significant delay at each hop.},
booktitle = {Proceedings of the 18th International Conference on World Wide Web},
pages = {721–730},
numpages = {10},
keywords = {viral marketing, social networks, information dissemination, flickr, cascades},
location = {Madrid, Spain},
series = {WWW '09}
}

@inproceedings{10.1145/1772690.1772758,
author = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E.},
title = {A contextual-bandit approach to personalized news article recommendation},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1772690.1772758},
doi = {10.1145/1772690.1772758},
abstract = {Personalized web services strive to adapt their services (advertisements, news articles, etc.) to individual users by making use of both content and user information. Despite a few recent advances, this problem remains challenging for at least two reasons. First, web service is featured with dynamically changing pools of content, rendering traditional collaborative filtering methods inapplicable. Second, the scale of most web services of practical interest calls for solutions that are both fast in learning and computation.In this work, we model personalized recommendation of news articles as a contextual bandit problem, a principled approach in which a learning algorithm sequentially selects articles to serve users based on contextual information about the users and articles, while simultaneously adapting its article-selection strategy based on user-click feedback to maximize total user clicks.The contributions of this work are three-fold. First, we propose a new, general contextual bandit algorithm that is computationally efficient and well motivated from learning theory. Second, we argue that any bandit algorithm can be reliably evaluated offline using previously recorded random traffic. Finally, using this offline evaluation method, we successfully applied our new algorithm to a Yahoo! Front Page Today Module dataset containing over 33 million events. Results showed a 12.5% click lift compared to a standard context-free bandit algorithm, and the advantage becomes even greater when data gets more scarce.},
booktitle = {Proceedings of the 19th International Conference on World Wide Web},
pages = {661–670},
numpages = {10},
keywords = {web service, recommender systems, personalization, exploration/exploitation dilemma, contextual bandit},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}

@inproceedings{10.1145/1526709.1526749,
author = {Erman, Jeffrey and Gerber, Alexandre and Hajiaghayi, Mohammad T. and Pei, Dan and Spatscheck, Oliver},
title = {Network-aware forward caching},
year = {2009},
isbn = {9781605584874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1526709.1526749},
doi = {10.1145/1526709.1526749},
abstract = {This paper proposes and evaluates a Network Aware Forward Caching approach for determining the optimal deployment strategy of forward caches to a network. A key advantage of this approach is that we can reduce the network costs associated with forward caching to maximize the benefit obtained from their deployment. We show in our simulation that a 37% increase to net benefits could be achieved over the standard method of full cache deployment to cache all POPs traffic. In addition, we show that this maximal point occurs when only 68% of the total traffic is cached.Another contribution of this paper is the analysis we use to motivate and evaluate this problem. We characterize the Internet traffic of 100K subscribers of a US residential broadband provider. We use both layer 4 and layer 7 analysis to investigate the traffic volumes of the flows as well as study the general characteristics of the applications used. We show that HTTP is a dominant protocol and account for 68% of the total downstream traffic and that 34% of that traffic is multimedia. In addition, we show that multimedia content using HTTP exhibits a 83% annualized growth rate and other HTTP traffic has a 53% growth rate versus the 26% over all annual growth rate of broadband traffic. This shows that HTTP traffic will become ever more dominent and increase the potential caching opportunities. Furthermore, we characterize the core backbone traffic of this broadband provider to measure the distance travelled by content and traffic. We find that CDN traffic is much more efficient than P2P content and that there is large skew in the Air Miles between POP in a typical network. Our findings show that there are many opportunties in broadband provider networks to optimize how traffic is delivered and cached.},
booktitle = {Proceedings of the 18th International Conference on World Wide Web},
pages = {291–300},
numpages = {10},
keywords = {web caching},
location = {Madrid, Spain},
series = {WWW '09}
}

@proceedings{10.1145/3701716,
title = {WWW '25: Companion Proceedings of the ACM on Web Conference 2025},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to The ACM Web Conference 2025 (WWW'25), held from April 28 to May 2, 2025, at the Sydney Convention &amp; Exhibition Centre in Australia. Recognizing the breadth of this year's program, we are publishing two sets of proceedings: one dedicated to research track papers, the Web4Good track, and keynotes; and a companion proceedings featuring the Demo Paper Track, Short Paper Track, PhD Symposium, Special Day, Resource Track, and History of Web sessions. Through this rich assortment of activities, we aim to foster a vibrant community where delegates can share ideas, forge collaborations, and cultivate a sustainable, inclusive environment.Marking its 34th edition, WWW'25 welcomes more than 1,000 industry and academic experts eager to shape the future of Web technologies and applications. The conference logo, depicting the Sydney Harbour Bridge, symbolizes the Web's key function of "connecting" people and information. Originally founded at CERN in 1994 as the International World Wide Web Conference (WWW), this event has long been the leading venue for research, development, standards, and applications related to the Web.Over the years, WWW has introduced important breakthroughs, from The Anatomy of a Large-Scale Web Search Engine in 1998-which heralded Google-to the EigenTrust algorithm in 2003 and the YAGO knowledge base in 2007. In the period between 2024 and 2025, large language models (LLMs) have significantly influenced countless industries and everyday life, prompting fundamental shifts in the Web ecosystem. We anticipate that the research and discussions at this year's conference will spark further breakthroughs in this rapidly evolving field.Continuing the tradition of depth and diversity, WWW'25 accepted 26 workshops and 20 tutorials as pre-conference events. In addition, consistent with previous editions, we feature a Demo Paper Track, Short Paper Track, PhD Symposium, Special Day, Resource Track, History of Web sessions, and Artifact Badging. Some of these are incorporated into the main conference schedule to encourage communication and collaboration among attendees.A commitment to diversity is pivotal to fostering robust, sustainable Web technologies. Our Web4Good track highlights how Web-based tools can address societal challenges, while the Industry Track showcases novel and impactful results from the industrial sector. This year, we have also launched an Emerging World Track to broaden participation from developing countries, as well as a competition track to enhance industry engagement..Organizing WWW'25 has been a true team effort. We sincerely thank the authors who contributed their work, and we extend our gratitude to the program and senior program committees for their dedication to reviewing submissions and offering feedback. We also appreciate the many additional chairs whose efforts ensured that each element of the program ran smoothly. Together, they have helped this conference continue to grow into a premier event for the Web research community.Finally, we would like to thank ACM SIGWEB and our industry sponsors-Meta, Huawei, Google, Baidu, Taobao, JD, and Infinigence-for their generous support, as well as our local government sponsors, Business Event Sydney and the NSW Government. We are equally grateful to our academic partner, the University of Technology Sydney, and the PCO company, ICMSA, for their indispensable help with registration, venue logistics, and social events. Their collective contributions have made the 2025 edition of this conference a resounding success.},
location = {Sydney NSW, Australia}
}

@inproceedings{10.1145/511446.511530,
author = {Yoshimura, Takeshi and Yonemoto, Yoshifumi and Ohya, Tomoyuki and Etoh, Minoru and Wee, Susie},
title = {Mobile streaming media CDN enabled by dynamic SMIL},
year = {2002},
isbn = {1581134495},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511446.511530},
doi = {10.1145/511446.511530},
abstract = {In this paper, we present a mobile streaming media CDN (Content Delivery Network) architecture in which content segmentation, request routing, pre-fetch scheduling, and session handoff are controlled by SMIL (Synchronized Multimedia Integrated Language) modification. In this architecture, mobile clients simply follow modified SMIL files downloaded from a streaming portal server; these modifications enable multimedia content to be delivered to the mobile clients from the best surrogates in the CDN. The key components of this architecture are 1) content segmentation with SMIL modification, 2) on-demand rewriting of URLs in SMIL, 3) pre-fetch scheduling based on timing information derived from SMIL, 4) SMIL updates by SOAP (Simple Object Access Protocol) messaging for session handoffs due to clients mobility. We also introduce QoS control with a network agent called an "RTP monitoring agent" to enable appropriate control of media quality based on both network congestion and radio link conditions. The current status of our prototyping on a mobile QoS testbed "MOBIQ" is reported in this paper. We are currently designing the SOAP-based APIs (Application Programmable Interfaces) needed for the mobile streaming media CDN and building the CDN over the current testbed.},
booktitle = {Proceedings of the 11th International Conference on World Wide Web},
pages = {651–661},
numpages = {11},
keywords = {streaming media, mobile network, SMIL, CDN},
location = {Honolulu, Hawaii, USA},
series = {WWW '02}
}

@proceedings{10.1145/3308560,
title = {WWW '19: Companion Proceedings of The 2019 World Wide Web Conference},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to &lt;I&gt;The Web Conference 2019&lt;/I&gt;. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, USA}
}

