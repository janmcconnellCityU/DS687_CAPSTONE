_doi_norm,_doi_raw,_source_file,_source_file_count,_source_files_all,_quality_score,series,location,keywords,numpages,pages,booktitle,abstract,doi,url,address,publisher,isbn,year,title,author,ENTRYTYPE,ID,articleno
10.1109/asonam49781.2020.9381314,10.1109/ASONAM49781.2020.9381314,KDD.bib,1,['KDD.bib'],8,ASONAM '20,"Virtual Event, Netherlands","business, collaborative filtering, concept drift, personalization, prediction accuracy, recommender systems, social networks",7,877–883,Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Businesses benefit by recommender systems since the latter analyse reviews and ratings of products and services, providing useful insight of the buyer perception of them. One of the most popular, successful and easy-to-build recommender system techniques is collaborative filtering. Recommender systems take into account social network information, to achieve more accurate predictions. Unfortunately, however, many applications do not have full access to such ""rich"" information, so they have to properly manage the limited information, which, in the worst case, is comprised of just the user relationships in the social network. A social network collaborative filtering system combines the two sources of information, in order to formulate rating predictions which will lead to recommendations. However, the vast majority of users change their tastes, as time goes by, a phenomenon termed as concept drift, and in order for a recommender system to be successful, it must effectively face this problem. In this paper, we present a social network collaborative filtering rating prediction algorithm that tunes the weight-importance of each source of information based on the age of the information. The proposed algorithm considerably improves rating prediction accuracy, while it can be easily integrated in social network collaborative filtering recommender systems.",10.1109/ASONAM49781.2020.9381314,https://doi.org/10.1109/ASONAM49781.2020.9381314,,IEEE Press,9781728110561,2021,Neighbourhood aging factors for limited information social network collaborative filtering,"Margaris, Dionisis and Spiliotopoulos, Dimitris and Vassilakis, Costas",inproceedings,10.1109/ASONAM49781.2020.9381314,
10.1109/asonam55673.2022.10068628,10.1109/ASONAM55673.2022.10068628,KDD.bib,1,['KDD.bib'],8,ASONAM '22,"Istanbul, Turkey","coordinated behavior, Twitter, backbone extraction, community detection",8,80–87,Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"A large volume of content related to claims of election fraud, often associated with hate speech and extremism, was reported on Twitter during the 2020 US election, with evidence that coordinated efforts took place to promote such content on the platform. In response, Twitter announced the suspension of thousands of user accounts allegedly involved in such actions. Motivated by these events, we here propose a novel network-based approach to uncover evidence of coordination in a set of user interactions. Our approach is designed to address the challenges incurred by the often sheer volume of noisy edges in the network (i.e., edges that are unrelated to coordination) and the effects of data sampling. To that end, it exploits the joint use of two network backbone extraction techniques, namely Disparity Filter and Neighborhood Overlap, to reveal strongly tied groups of users (here referred to as communities) exhibiting repeatedly common behavior, consistent with coordination. We employ our strategy to a large dataset of tweets related to the aforementioned fraud claims, in which users were labeled as suspended, deleted or active, according to their accounts status after the election. Our findings reveal well-structured communities, with strong evidence of coordination to promote (i.e., retweet) the aforementioned fraud claims. Moreover, many of those communities are formed not only by suspended and deleted users, but also by users who, despite exhibiting very similar sharing patterns, remained active in the platform. This observation suggests that a significant number of users who were potentially involved in the coordination efforts went unnoticed by the platform, and possibly remained actively spreading this content on the system.",10.1109/ASONAM55673.2022.10068628,https://doi.org/10.1109/ASONAM55673.2022.10068628,,IEEE Press,9781665456616,2023,Uncovering Coordinated Communities on Twitter during the 2020 U.S. Election,"Linhares, Renan S. and Rosa, Jos\'{e} M. and Ferreira, Carlos H. G. and Murai, Fabricio and Nobre, Gabriel and Almeida, Jussara",inproceedings,10.1109/ASONAM55673.2022.10068628,
10.1109/asonam55673.2022.10068664,10.1109/ASONAM55673.2022.10068664,KDD.bib,1,['KDD.bib'],8,ASONAM '22,"Istanbul, Turkey","online review helpfulness, cultural background, review recommendations",8,308–315,Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Online reviews have become essential for users to make informed decisions in everyday tasks ranging from planning summer vacations to purchasing groceries and making financial investments. A key problem in using online reviews is the overabundance of online that overwhelms the users. As a result, recommendation systems for providing helpfulness of reviews are being developed. This paper argues that cultural background is an important feature that impacts the nature of a review written by the user, and must be considered as a feature in assessing the helpfulness of online reviews. The paper provides an in-depth study of differences in online reviews written by users from different cultural backgrounds and how incorporating culture as a feature can lead to better review helpfulness recommendations. In particular, we analyze online reviews originating from two distinct cultural spheres, namely Arabic and Western cultures, for two different products, hotels and books. Our analysis demonstrates that the nature of reviews written by users differs based on their cultural backgrounds and that this difference varies based on the specific product being reviewed. Finally, we have developed six different review helpfulness recommendation models that demonstrate that taking culture into account leads to better recommendations.",10.1109/ASONAM55673.2022.10068664,https://doi.org/10.1109/ASONAM55673.2022.10068664,,IEEE Press,9781665456616,2023,Understanding the Impact of Culture in Assessing Helpfulness of Online Reviews,"Alanezi, Khaled and Albadi, Nuha and Hammad, Omar and Kurdi, Maram and Mishra, Shivakant",inproceedings,10.1109/ASONAM55673.2022.10068664,
10.1145/1031171.1031201,10.1145/1031171.1031201,CIKM.bib,1,['CIKM.bib'],8,CIKM '04,"Washington, D.C., USA",unified filtering,2,156–157,Proceedings of the Thirteenth ACM International Conference on Information and Knowledge Management,"Collaborative filtering and content-based filtering are two types of information filtering techniques. Combining these two techniques can improve the recommendation effectiveness. The main problem with previous research is that the content information and the rating information are not combined in an integrated way. This paper presents a unified probabilistic framework that allows the mutual interaction between these two types of information. Experiments have shown that the new unified filtering algorithm outperforms a pure collaborative filtering approach, a pure content-based filtering approach and another unified filtering algorithm.",10.1145/1031171.1031201,https://doi.org/10.1145/1031171.1031201,"New York, NY, USA",Association for Computing Machinery,1581138741,2004,Unified filtering by combining collaborative filtering and content-based filtering via mixture model and exponential model,"Si, Luo and Jin, Rong",inproceedings,10.1145/1031171.1031201,
10.1145/1060745.1060754,10.1145/1060745.1060754,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '05,"Chiba, Japan","recommender systems, metrics, diversification, collaborative filtering, accuracy",11,22–32,Proceedings of the 14th International Conference on World Wide Web,"In this work we present topic diversification, a novel method designed to balance and diversify personalized recommendation lists in order to reflect the user's complete spectrum of interests. Though being detrimental to average accuracy, we show that our method improves user satisfaction with recommendation lists, in particular for lists generated using the common item-based collaborative filtering algorithm.Our work builds upon prior research on recommender systems, looking at properties of recommendation lists as entities in their own right rather than specifically focusing on the accuracy of individual recommendations. We introduce the intra-list similarity metric to assess the topical diversity of recommendation lists and the topic diversification approach for decreasing the intra-list similarity. We evaluate our method using book recommendation data, including offline analysis on 361, !, 349 ratings and an online study involving more than 2, !, 100 subjects.",10.1145/1060745.1060754,https://doi.org/10.1145/1060745.1060754,"New York, NY, USA",Association for Computing Machinery,1595930469,2005,Improving recommendation lists through topic diversification,"Ziegler, Cai-Nicolas and McNee, Sean M. and Konstan, Joseph A. and Lausen, Georg",inproceedings,10.1145/1060745.1060754,
10.1145/1081870.1081945,10.1145/1081870.1081945,KDD.bib,1,['KDD.bib'],8,KDD '05,"Chicago, Illinois, USA","maximum entropy, recommendation, user profiling, web usage mining",6,612–617,Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining,"Web users display their preferences implicitly by navigating through a sequence of pages or by providing numeric ratings to some items. Web usage mining techniques are used to extract useful knowledge about user interests from such data. The discovered user models are then used for a variety of applications such as personalized recommendations. Web site content or semantic features of objects provide another source of knowledge for deciphering users' needs or interests. We propose a novel Web recommendation system in which collaborative features such as navigation or rating data as well as the content features accessed by the users are seamlessly integrated under the maximum entropy principle. Both the discovered user patterns and the semantic relationships among Web objects are represented as sets of constraints that are integrated to fit the model. In the case of content features, we use a new approach based on Latent Dirichlet Allocation (LDA) to discover the hidden semantic relationships among items and derive constraints used in the model. Experiments on real Web site usage data sets show that this approach can achieve better recommendation accuracy, when compared to systems using only usage information. The integration of semantic information also allows for better interpretation of the generated recommendations.",10.1145/1081870.1081945,https://doi.org/10.1145/1081870.1081945,"New York, NY, USA",Association for Computing Machinery,159593135X,2005,A maximum entropy web recommendation system: combining collaborative and content features,"Jin, Xin and Zhou, Yanzan and Mobasher, Bamshad",inproceedings,10.1145/1081870.1081945,
10.1145/1150402.1150508,10.1145/1150402.1150508,KDD.bib,1,['KDD.bib'],8,KDD '06,"Philadelphia, PA, USA","anomaly detection, recommender systems, shilling attacks, time series",6,809–814,Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Recent research has identified significant vulnerabilities in recommender systems. Shilling attacks, in which attackers introduce biased ratings in order to influence future recommendations, have been shown to be effective against collaborative filtering algorithms. We postulate that the distribution of item ratings in time can reveal the presence of a wide range of shilling attacks given reasonable assumptions about their duration. To construct a time series of ratings for an item, we use a window size of k to group consecutive ratings for the item into disjoint windows and compute the sample average and sample entropy in each window. We derive a theoretically optimal window size to best detect an attack event if the number of attack profiles is known. For practical applications where this number is unknown, we propose a heuristic algorithm that adaptively changes the window size. Our experimental results demonstrate that monitoring rating distributions in time series is an effective approach for detecting shilling attacks.",10.1145/1150402.1150508,https://doi.org/10.1145/1150402.1150508,"New York, NY, USA",Association for Computing Machinery,1595933395,2006,Attack detection in time series for recommender systems,"Zhang, Sheng and Chakrabarti, Amit and Ford, James and Makedon, Fillia",inproceedings,10.1145/1150402.1150508,
10.1145/1242572.1242806,10.1145/1242572.1242806,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '07,"Banff, Alberta, Canada","wireless networking, weblog, peer-to-peer communication, mobile phone, collaborative system, RFID",2,1277–1278,Proceedings of the 16th International Conference on World Wide Web,"Recent trend in the development of mobile devices, wireless communications, sensor technologies, weblogs, and peer-to-peer communications have prompted a new design opportunity for enhancing social interactions. This paper introduces our preliminary experiences in designing a prototype utilizing the aforementioned technologies to share life experience. Users equipped with camera phones coupled with short-range communication technology, such as RFID, can capture life experience and share it as weblogs to other people. However, in reality, this is easier said than done. The success of weblogs relies on the active participation and willingness of people to contribute. To encourage active participations, a ranking system, AgreeRank, is specifically developed to get them motivated.",10.1145/1242572.1242806,https://doi.org/10.1145/1242572.1242806,"New York, NY, USA",Association for Computing Machinery,9781595936547,2007,Life is sharable: mechanisms to support and sustain blogging life experience,"Cheng, Yun-Maw and Chou, Tzu-Chuan and Yu, Wai and Chen, Li-Chieh and Yeh, Ching-Long and Chen, Meng-Chang",inproceedings,10.1145/1242572.1242806,
10.1145/1281192.1281206,10.1145/1281192.1281206,KDD.bib,1,['KDD.bib'],8,KDD '07,"San Jose, California, USA","collaborative filtering, netflix prize, recommender systems",10,95–104,Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"The collaborative filtering approach to recommender systems predicts user preferences for products or services by learning past user-item relationships. In this work, we propose novel algorithms for predicting user ratings of items by integrating complementary models that focus on patterns at different scales. At a local scale, we use a neighborhood-based technique that infers ratings from observed ratings by similar users or of similar items. Unlike previous local approaches, our method is based on a formal model that accounts for interactions within the neighborhood, leading to improved estimation quality. At a higher, regional, scale, we use SVD-like matrix factorization for recovering the major structural patterns in the user-item rating matrix. Unlike previous approaches that require imputations in order to fill in the unknown matrix entries, our new iterative algorithm avoids imputation. Because the models involve estimation of millions, or even billions, of parameters, shrinkage of estimated values to account for sampling variability proves crucial to prevent overfitting. Both the local and the regional approaches, and in particular their combination through a unifying model, compare favorably with other approaches and deliver substantially better results than the commercial Netflix Cinematch recommender system on a large publicly available data set.",10.1145/1281192.1281206,https://doi.org/10.1145/1281192.1281206,"New York, NY, USA",Association for Computing Machinery,9781595936097,2007,Modeling relationships at multiple scales to improve accuracy of large recommender systems,"Bell, Robert and Koren, Yehuda and Volinsky, Chris",inproceedings,10.1145/1281192.1281206,
10.1145/1297231.1297235,10.1145/1297231.1297235,RecSys.bib,1,['RecSys.bib'],7,RecSys '07,"Minneapolis, MN, USA",,8,17–24,Proceedings of the 2007 ACM Conference on Recommender Systems,"Recommender Systems based on Collaborative Filtering suggest to users items they might like. However due to data sparsity of the input ratings matrix, the step of finding similar users often fails. We propose to replace this step with the use of a trust metric, an algorithm able to propagate trust over the trust network and to estimate a trust weight that can be used in place of the similarity weight. An empirical evaluation on Epinions.com dataset shows that Recommender Systems that make use of trust information are the most effective in term of accuracy while preserving a good coverage. This is especially evident on users who provided few ratings.",10.1145/1297231.1297235,https://doi.org/10.1145/1297231.1297235,"New York, NY, USA",Association for Computing Machinery,9781595937308,2007,Trust-aware recommender systems,"Massa, Paolo and Avesani, Paolo",inproceedings,10.1145/1297231.1297235,
10.1145/1297231.1297238,10.1145/1297231.1297238,RecSys.bib,1,['RecSys.bib'],8,RecSys '07,"Minneapolis, MN, USA","distributed collaborative filtering, mediation of user modeling data, recommender systems",8,33–40,Proceedings of the 2007 ACM Conference on Recommender Systems,"User data scarcity has always been indicated among the major problems of collaborative filtering recommender systems. That is, if two users do not share sufficiently large set of items for whom their ratings are known, then the user-to-user similarity computation is not reliable and a rating prediction for one user can not be based on the ratings of the other. This paper shows that this problem can be solved, and that the accuracy of collaborative recommendations can be improved by: a) partitioning the collaborative user data into specialized and distributed repositories, and b) aggregating information coming from these repositories. This paper explores a content-dependent partitioning of collaborative movie ratings, where the ratings are partitioned according to the genre of the movie and presents an evaluation of four aggregation approaches. The evaluation demonstrates that the aggregation improves the accuracy of a centralized system containing the same ratings and proves the feasibility and advantages of a distributed collaborative filtering scenario.",10.1145/1297231.1297238,https://doi.org/10.1145/1297231.1297238,"New York, NY, USA",Association for Computing Machinery,9781595937308,2007,Distributed collaborative filtering with domain specialization,"Berkovsky, Shlomo and Kuflik, Tsvi and Ricci, Francesco",inproceedings,10.1145/1297231.1297238,
10.1145/1297231.1297249,10.1145/1297231.1297249,RecSys.bib,1,['RecSys.bib'],8,RecSys '07,"Minneapolis, MN, USA","security, recommender systems, data mining, collaborative filtering, association rule mining",8,105–112,Proceedings of the 2007 ACM Conference on Recommender Systems,"Standard memory-based collaborative filtering algorithms, such as k-nearest neighbor, are quite vulnerable to profile injection attacks. Previous work has shown that some model-based techniques are more robust than k-nn. Model abstraction can inhibit certain aspects of an attack, providing an algorithmic approach to minimizing attack effectiveness. In this paper, we examine the robustness of a recommendation algorithm based on the data mining technique of association rule mining. Our results show that the Apriori algorithm offers large improvement in stability and robustness compared to k-nearest neighbor and other model-based techniques we have studied. Furthermore, our results show that Apriori can achieve comparable recommendation accuracy to k-nn.",10.1145/1297231.1297249,https://doi.org/10.1145/1297231.1297249,"New York, NY, USA",Association for Computing Machinery,9781595937308,2007,Robustness of collaborative recommendation based on association rule mining,"Sandvig, J. J. and Mobasher, Bamshad and Burke, Robin",inproceedings,10.1145/1297231.1297249,
10.1145/1297231.1297255,10.1145/1297231.1297255,RecSys.bib,1,['RecSys.bib'],8,RecSys '07,"Minneapolis, MN, USA","reviews, recommender systems, rating systems, amazon",4,137–140,Proceedings of the 2007 ACM Conference on Recommender Systems,"We studied user behavior in a recommender-rich environment, Amazon online store, to see what role the algorithm-based and user-generated recommendations play in finding items of interest. We used applied ethnography, on-location interviewing and observation, to get an accurate picture of user activity. We were especially interested in the role of customer ratings and reviews and what kind of strategies users had developed for such an environment. Our results underline the need to develop recommender systems as a whole. The way the recommendations are shown affects which items get picked, and for improving the interface, it is necessary to study the whole in addition to studying the parts in isolation.",10.1145/1297231.1297255,https://doi.org/10.1145/1297231.1297255,"New York, NY, USA",Association for Computing Machinery,9781595937308,2007,Case amazon: ratings and reviews as part of recommendations,"Leino, Juha and R\""{a}ih\""{a}, Kari-Jouko",inproceedings,10.1145/1297231.1297255,
10.1145/1321440.1321533,10.1145/1321440.1321533,CIKM.bib,1,['CIKM.bib'],8,CIKM '07,"Lisbon, Portugal","web caching, placement strategy, peer-to-peer",10,663–672,Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management,"As a promising new technology with the unique properties like high efficiency, scalability and fault tolerance, Peer-to-Peer (P2P) technology is used as the underlying network to build new Internet-scale applications. However, one of the well known issues in such an application (for example WWW) is that the distribution of data popularities is heavily tailed with a Zipf-like distribution. With consideration of the skewed popularity we adopt a proactive caching approach to handle the challenge, and focus on two key problems: where (i.e. the placement strategy: where to place the replicas) and how (i.e. the degree problem: how many replicas are assigned to one specific content)? For the where problem, we propose a novel approach which can be generally applied to structured P2P networks. Next, we solve two optimization objectives related to the how problem: MAX_PERF and MIN_COST. Our solution is called &lt;B&gt;PoPCache&lt;/B&gt;, and we discover two interesting properties: (1) the number of replicas assigned to each content is proportional to its popularity; (2) the derived optimal solutions are related to the entropy of popularity. To our knowledge, none of the previous works has mentioned such results. Finally, we apply the results of PoPCache to propose a P2P base web caching, called as Web-PoPCache. By means of web cache trace driven simulation, our extensive evaluation results demonstrate the advantages of PoPCache and Web-PoPCache.",10.1145/1321440.1321533,https://doi.org/10.1145/1321440.1321533,"New York, NY, USA",Association for Computing Machinery,9781595938039,2007,Optimal proactive caching in peer-to-peer network: analysis and application,"Rao, Weixiong and Chen, Lei and Fu, Ada Wai-Chee and Bu, YingYi",inproceedings,10.1145/1321440.1321533,
10.1145/1348549.1348555,10.1145/1348549.1348555,KDD.bib,1,['KDD.bib'],8,WebKDD/SNA-KDD '07,"San Jose, California","collaborative rating, mathematical analysis, news aggregation, social networks",10,46–55,Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 Workshop on Web Mining and Social Network Analysis,"The rise of social media sites, such as blogs, wikis, Digg and Flickr among others, underscores a transformation of the Web to a participatory medium in which users are actively creating, evaluating and distributing information. The social news aggregator Digg allows users to submit links to and vote on news stories. Like other social media sites, Digg also allows users to designate others as ""friends"" and easily track friends' activities: what new stories they submitted, commented on or liked. Each day Digg selects a handful of stories to feature on its front page. Rather than rely on the opinion of a few editors, Digg aggregates opinions of thousands of its users to decide which stories to promote to the front page. We construct a mathematical model to study how collaborative rating and promotion of news stories emerges from independent decisions made by many users. The model takes into account user behavior: e.g., whether they read stories on the front page or through the Friends interface. Solutions of the model qualitatively reproduce the observed dynamics of votes received by actual stories on Digg.Digg also ranks users according to how successful they are in getting their stories promoted to the front page. We create a model that describes how a user's rank changes in time as he gets more stories to the front page and becomes more influential in the community. We find qualitative agreement between predictions of the model and the evolution of rank for Digg users.The Digg model of allowing users to collectively evaluate how interesting the news stories are can be generalized to collaborative evaluation of the quality of information. Mathematical analysis can be used as a tool to explore different voting methods to select the most effective one before the method is ever implemented in a real system.",10.1145/1348549.1348555,https://doi.org/10.1145/1348549.1348555,"New York, NY, USA",Association for Computing Machinery,9781595938480,2007,Dynamics of collaborative document rating systems,"Lerman, Kristina",inproceedings,10.1145/1348549.1348555,
10.1145/1401890.1401969,10.1145/1401890.1401969,KDD.bib,1,['KDD.bib'],8,KDD '08,"Las Vegas, Nevada, USA","matrix factorization, relational learning, stochastic approximation",9,650–658,Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Relational learning is concerned with predicting unknown values of a relation, given a database of entities and observed relations among entities. An example of relational learning is movie rating prediction, where entities could include users, movies, genres, and actors. Relations encode users' ratings of movies, movies' genres, and actors' roles in movies. A common prediction technique given one pairwise relation, for example a #users x #movies ratings matrix, is low-rank matrix factorization. In domains with multiple relations, represented as multiple matrices, we may improve predictive accuracy by exploiting information from one relation while predicting another. To this end, we propose a collective matrix factorization model: we simultaneously factor several matrices, sharing parameters among factors when an entity participates in multiple relations. Each relation can have a different value type and error distribution; so, we allow nonlinear relationships between the parameters and outputs, using Bregman divergences to measure error. We extend standard alternating projection algorithms to our model, and derive an efficient Newton update for the projection. Furthermore, we propose stochastic optimization methods to deal with large, sparse matrices. Our model generalizes several existing matrix factorization methods, and therefore yields new large-scale optimization algorithms for these problems. Our model can handle any pairwise relational schema and a wide variety of error models. We demonstrate its efficiency, as well as the benefit of sharing parameters among relations.",10.1145/1401890.1401969,https://doi.org/10.1145/1401890.1401969,"New York, NY, USA",Association for Computing Machinery,9781605581934,2008,Relational learning via collective matrix factorization,"Singh, Ajit P. and Gordon, Geoffrey J.",inproceedings,10.1145/1401890.1401969,
10.1145/1454008.1454011,10.1145/1454008.1454011,RecSys.bib,1,['RecSys.bib'],8,RecSys '08,"Lausanne, Switzerland","similarity, recommender systems, prediction errors, collaborative filtering",8,3–10,Proceedings of the 2008 ACM Conference on Recommender Systems,"User-based collaborative filtering methods typically predict a user's item ratings as a weighted average of the ratings given by similar users, where the weight is proportional to the user similarity. Therefore, the accuracy of user similarity is the key to the success of the recommendation, both for selecting neighborhoods and computing predictions. However, the computed similarities between users are somewhat inaccurate due to data sparsity.For a given user, the set of neighbors selected for predicting ratings on different items typically exhibit overlap. Thus, error terms contributing to rating predictions will tend to be shared, leading to correlation of the prediction errors.Through a set of case studies, we discovered that for a given user, the prediction errors on different items are correlated to the similarities of the corresponding items, and to the degree to which they share common neighbors.We propose a framework to improve prediction accuracy based on these statistical prediction errors. Two different strategies to estimate the prediction error on a desired item are proposed. Our experiments show that these approaches improve the prediction accuracy of standard user based methods significantly, and they outperform other state-of-the-art methods.",10.1145/1454008.1454011,https://doi.org/10.1145/1454008.1454011,"New York, NY, USA",Association for Computing Machinery,9781605580937,2008,Boosting collaborative filtering based on statistical prediction errors,"Ding, Shengchao and Zhao, Shiwan and Yuan, Quan and Zhang, Xiatian and Fu, Rongyao and Bergman, Lawrence",inproceedings,10.1145/1454008.1454011,
10.1145/1454008.1454012,10.1145/1454008.1454012,RecSys.bib,1,['RecSys.bib'],8,RecSys '08,"Lausanne, Switzerland","recommendation, long tail, data mining, clustering",8,11–18,Proceedings of the 2008 ACM Conference on Recommender Systems,"The paper studies the Long Tail problem of recommender systems when many items in the Long Tail have only few ratings, thus making it hard to use them in recommender systems. The approach presented in the paper splits the whole itemset into the head and the tail parts and clusters only the tail items. Then recommendations for the tail items are based on the ratings in these clusters and for the head items on the ratings of individual items. If such partition and clustering are done properly, we show that this reduces the recommendation error rates for the tail items, while maintaining reasonable computational performance.",10.1145/1454008.1454012,https://doi.org/10.1145/1454008.1454012,"New York, NY, USA",Association for Computing Machinery,9781605580937,2008,The long tail of recommender systems and how to leverage it,"Park, Yoon-Joo and Tuzhilin, Alexander",inproceedings,10.1145/1454008.1454012,
10.1145/1454008.1454013,10.1145/1454008.1454013,RecSys.bib,1,['RecSys.bib'],8,RecSys '08,"Lausanne, Switzerland","recommender systems, content-based filtering, collaborative filtering, cold start, boltzmann machines",8,19–26,Proceedings of the 2008 ACM Conference on Recommender Systems,"We describe a novel statistical model, the tied Boltzmann machine, for combining collaborative and content information for recommendations. In our model, pairwise interactions between items are captured through a Boltzmann machine, whose parameters are constrained according to the content associated with the items. This allows the model to use content information to recommend items that are not seen during training. We describe a tractable algorithm for training the model, and give experimental results evaluating the model in two cold start recommendation tasks on the MovieLens data set.",10.1145/1454008.1454013,https://doi.org/10.1145/1454008.1454013,"New York, NY, USA",Association for Computing Machinery,9781605580937,2008,Tied boltzmann machines for cold start recommendations,"Gunawardana, Asela and Meek, Christopher",inproceedings,10.1145/1454008.1454013,
10.1145/1454008.1454015,10.1145/1454008.1454015,RecSys.bib,1,['RecSys.bib'],8,RecSys '08,"Lausanne, Switzerland","web mining, recommender systems, evaluation metrics",8,35–42,Proceedings of the 2008 ACM Conference on Recommender Systems,"In this paper we study the challenges and evaluate the effectiveness of data collected from the web for recommendations. We provide experimental results, including a user study, showing that our methods produce good recommendations in realistic applications. We propose a new evaluation metric, that takes into account the difficulty of prediction. We show that the new metric aligns well with the results from a user study.",10.1145/1454008.1454015,https://doi.org/10.1145/1454008.1454015,"New York, NY, USA",Association for Computing Machinery,9781605580937,2008,Mining recommendations from the web,"Shani, Guy and Chickering, Max and Meek, Christopher",inproceedings,10.1145/1454008.1454015,
10.1145/1454008.1454038,10.1145/1454008.1454038,RecSys.bib,1,['RecSys.bib'],8,RecSys '08,"Lausanne, Switzerland","recommender systems, popularity, novelty, long tail, evaluation, complex network analysis",8,179–186,Proceedings of the 2008 ACM Conference on Recommender Systems,"This paper presents two methods, named Item- and User-centric, to evaluate the quality of novel recommendations. The former method focuses on analyzing the item-based recommendation network. The aim is to detect whether the network topology has any pathology that hinders novel recommendations. The latter, user-centric evaluation, aims at measuring users' perceived quality of novel, previously unknown, recommendations.The results of the experiments, done in the music recommendation context, show that last.fm social recommender, based on collaborative filtering, is prone to popularity bias. This has direct consequences on the topology of the item-based recommendation network. Pure audio content-based methods (CB) are not affected by popularity. However, a user-centric experiment done with 288 subjects shows that even though a social-based approach recommends less novel items than our CB, users' perceived quality is better than those recommended by a pure CB method.",10.1145/1454008.1454038,https://doi.org/10.1145/1454008.1454038,"New York, NY, USA",Association for Computing Machinery,9781605580937,2008,A new approach to evaluating novel recommendations,"Celma, \`{O}scar and Herrera, Perfecto",inproceedings,10.1145/1454008.1454038,
10.1145/1454008.1454047,10.1145/1454008.1454047,RecSys.bib,1,['RecSys.bib'],8,RecSys '08,"Lausanne, Switzerland","recommender system, online-update, matrix factorization",8,251–258,Proceedings of the 2008 ACM Conference on Recommender Systems,"Regularized matrix factorization models are known to generate high quality rating predictions for recommender systems. One of the major drawbacks of matrix factorization is that once computed, the model is static. For real-world applications dynamic updating a model is one of the most important tasks. Especially when ratings on new users or new items come in, updating the feature matrices is crucial.In this paper, we generalize regularized matrix factorization (RMF) to regularized kernel matrix factorization (RKMF). Kernels provide a flexible method for deriving new matrix factorization methods. Furthermore with kernels nonlinear interactions between feature vectors are possible. We propose a generic method for learning RKMF models. From this method we derive an online-update algorithm for RKMF models that allows to solve the new-user/new-item problem. Our evaluation indicates that our proposed online-update methods are accurate in approximating a full retrain of a RKMF model while the runtime of online-updating is in the range of milliseconds even for huge datasets like Netflix.",10.1145/1454008.1454047,https://doi.org/10.1145/1454008.1454047,"New York, NY, USA",Association for Computing Machinery,9781605580937,2008,Online-updating regularized kernel matrix factorization models for large-scale recommender systems,"Rendle, Steffen and Schmidt-Thieme, Lars",inproceedings,10.1145/1454008.1454047,
10.1145/1454008.1454056,10.1145/1454008.1454056,RecSys.bib,1,['RecSys.bib'],8,RecSys '08,"Lausanne, Switzerland","recommender systems, context",4,295–298,Proceedings of the 2008 ACM Conference on Recommender Systems,"Recommender Systems help an on-line user to tame information overload and are being used now in complex domains where it could be beneficial to exploit context-awareness, e.g., in travel recommendation. Technically, in Recommender Systems we can interpret context as a set of constraints or preferences over the usage of items determined by the contextual conditions (e.g., today it is raining or the user is in a particular location). In fact, there is a lack of approaches to deal effectively with contextual data. This thesis investigates some approaches to exploit context in Recommender Systems. It provides a general architecture of context-aware Recommender Systems and analyzes separate components of this model. The main focus is to investigate new approaches that can bring a real added value to users. In this paper I also describe my initial results on item selection and item weighting for context-dependent Collaborative Filtering (CF). Moreover, I shall present my ongoing research on CF hybridization using context.",10.1145/1454008.1454056,https://doi.org/10.1145/1454008.1454056,"New York, NY, USA",Association for Computing Machinery,9781605580937,2008,Exploiting contextual information in recommender systems,"Baltrunas, Linas",inproceedings,10.1145/1454008.1454056,
10.1145/1454008.1454059,10.1145/1454008.1454059,RecSys.bib,1,['RecSys.bib'],8,RecSys '08,"Lausanne, Switzerland","recommendation ranking, recommendation filtering, rating variance, diversity, accuracy",4,307–310,Proceedings of the 2008 ACM Conference on Recommender Systems,"One of the goals in recommender systems is to recommend those items to each user that maximize the user's utility. In this study, we propose new approaches which, in conjunction with any existing recommendation technique, can improve the top-N item selection by taking into account rating variance. We empirically demonstrate how these approaches work with several recommendation techniques, increasing the accuracy of recommendations. We also show how these approaches can generate more personalized recommendations, as measured by the diversity metric. As a result, users can be given a better control to choose whether to receive recommendations with higher accuracy or higher diversity.",10.1145/1454008.1454059,https://doi.org/10.1145/1454008.1454059,"New York, NY, USA",Association for Computing Machinery,9781605580937,2008,Improving top-n recommendation techniques using rating variance,"Kwon, YoungOk",inproceedings,10.1145/1454008.1454059,
10.1145/1458469.1458479,10.1145/1458469.1458479,CIKM.bib,1,['CIKM.bib'],8,LSDS-IR '08,"Napa Valley, California, USA","p2p, distributed retrieval, collaborative search",8,27–34,Proceedings of the 2008 ACM Workshop on Large-Scale Distributed Systems for Information Retrieval,"Despite the many research efforts invested recently in peer-to-peer search engines, none of the proposed system has reached the level of quality and efficiency of their centralized counterpart. One of the main reasons for this inferior performance is the difficulty to attract a critical mass of users that would make the peer-to-peer system truly competitive. We argue that decentralized search mechanisms should not aim at replacing existing engines, but instead complement them by adding novel functionalities that would be difficult to provide in a centralized manner. This paper introduces an example of such a complementary search mechanism and presents the design of a distributed collaborative system for leveraging user feedback and document/user profiling information.",10.1145/1458469.1458479,https://doi.org/10.1145/1458469.1458479,"New York, NY, USA",Association for Computing Machinery,9781605582542,2008,Managing collaborative feedback information for distributed retrieval,"Felber, Pascal and Luu, Toan and Rajman, Martin and Riviere, Etienne",inproceedings,10.1145/1458469.1458479,
10.1145/1526709.1526725,10.1145/1526709.1526725,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '09,"Madrid, Spain","recommender system, online services, machine learning, collaborative filtering, bayesian inference, advertising",10,111–120,Proceedings of the 18th International Conference on World Wide Web,"We present a probabilistic model for generating personalised recommendations of items to users of a web service. The Matchbox system makes use of content information in the form of user and item meta data in combination with collaborative filtering information from previous user behavior in order to predict the value of an item for a user. Users and items are represented by feature vectors which are mapped into a low-dimensional `trait space' in which similarity is measured in terms of inner products. The model can be trained from different types of feedback in order to learn user-item preferences. Here we present three alternatives: direct observation of an absolute rating each user gives to some items, observation of a binary preference (like/ don't like) and observation of a set of ordinal ratings on a user-specific scale. Efficient inference is achieved by approximate message passing involving a combination of Expectation Propagation (EP) and Variational Message Passing. We also include a dynamics model which allows an item's popularity, a user's taste or a user's personal rating scale to drift over time. By using Assumed-Density Filtering (ADF) for training, the model requires only a single pass through the training data. This is an on-line learning algorithm capable of incrementally taking account of new data so the system can immediately reflect the latest user preferences. We evaluate the performance of the algorithm on the MovieLens and Netflix data sets consisting of approximately 1,000,000 and 100,000,000 ratings respectively. This demonstrates that training the model using the on-line ADF approach yields state-of-the-art performance with the option of improving performance further if computational resources are available by performing multiple EP passes over the training data.",10.1145/1526709.1526725,https://doi.org/10.1145/1526709.1526725,"New York, NY, USA",Association for Computing Machinery,9781605584874,2009,Matchbox: large scale online bayesian recommendations,"Stern, David H. and Herbrich, Ralf and Graepel, Thore",inproceedings,10.1145/1526709.1526725,
10.1145/1526709.1526728,10.1145/1526709.1526728,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '09,"Madrid, Spain","short comments, rating prediction, rated aspect summarization",10,131–140,Proceedings of the 18th International Conference on World Wide Web,"Web 2.0 technologies have enabled more and more people to freely comment on different kinds of entities (e.g. sellers, products, services). The large scale of information poses the need and challenge of automatic summarization. In many cases, each of the user-generated short comments comes with an overall rating. In this paper, we study the problem of generating a ``rated aspect summary'' of short comments, which is a decomposed view of the overall ratings for the major aspects so that a user could gain different perspectives towards the target entity. We formally define the problem and decompose the solution into three steps. We demonstrate the effectiveness of our methods by using eBay sellers' feedback comments. We also quantitatively evaluate each step of our methods and study how well human agree on such a summarization task. The proposed methods are quite general and can be used to generate rated aspect summary automatically given any collection of short comments each associated with an overall rating.",10.1145/1526709.1526728,https://doi.org/10.1145/1526709.1526728,"New York, NY, USA",Association for Computing Machinery,9781605584874,2009,Rated aspect summarization of short comments,"Lu, Yue and Zhai, ChengXiang and Sundaresan, Neel",inproceedings,10.1145/1526709.1526728,
10.1145/1526709.1526749,10.1145/1526709.1526749,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '09,"Madrid, Spain",web caching,10,291–300,Proceedings of the 18th International Conference on World Wide Web,"This paper proposes and evaluates a Network Aware Forward Caching approach for determining the optimal deployment strategy of forward caches to a network. A key advantage of this approach is that we can reduce the network costs associated with forward caching to maximize the benefit obtained from their deployment. We show in our simulation that a 37% increase to net benefits could be achieved over the standard method of full cache deployment to cache all POPs traffic. In addition, we show that this maximal point occurs when only 68% of the total traffic is cached.Another contribution of this paper is the analysis we use to motivate and evaluate this problem. We characterize the Internet traffic of 100K subscribers of a US residential broadband provider. We use both layer 4 and layer 7 analysis to investigate the traffic volumes of the flows as well as study the general characteristics of the applications used. We show that HTTP is a dominant protocol and account for 68% of the total downstream traffic and that 34% of that traffic is multimedia. In addition, we show that multimedia content using HTTP exhibits a 83% annualized growth rate and other HTTP traffic has a 53% growth rate versus the 26% over all annual growth rate of broadband traffic. This shows that HTTP traffic will become ever more dominent and increase the potential caching opportunities. Furthermore, we characterize the core backbone traffic of this broadband provider to measure the distance travelled by content and traffic. We find that CDN traffic is much more efficient than P2P content and that there is large skew in the Air Miles between POP in a typical network. Our findings show that there are many opportunties in broadband provider networks to optimize how traffic is delivered and cached.",10.1145/1526709.1526749,https://doi.org/10.1145/1526709.1526749,"New York, NY, USA",Association for Computing Machinery,9781605584874,2009,Network-aware forward caching,"Erman, Jeffrey and Gerber, Alexandre and Hajiaghayi, Mohammad T. and Pei, Dan and Spatscheck, Oliver",inproceedings,10.1145/1526709.1526749,
10.1145/1526709.1526802,10.1145/1526709.1526802,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '09,"Madrid, Spain","user and content profile, regression, recommender systems, ranking, personalization, dynamic features, bilinear models",10,691–700,Proceedings of the 18th International Conference on World Wide Web,"In Web-based services of dynamic content (such as news articles), recommender systems face the difficulty of timely identifying new items of high-quality and providing recommendations for new users. We propose a feature-based machine learning approach to personalized recommendation that is capable of handling the cold-start issue effectively. We maintain profiles of content of interest, in which temporal characteristics of the content, e.g. popularity and freshness, are updated in real-time manner. We also maintain profiles of users including demographic information and a summary of user activities within Yahoo! properties. Based on all features in user and content profiles, we develop predictive bilinear regression models to provide accurate personalized recommendations of new items for both existing and new users. This approach results in an offline model with light computational overhead compared with other recommender systems that require online re-training. The proposed framework is general and flexible for other personalized tasks. The superior performance of our approach is verified on a large-scale data set collected from the Today-Module on Yahoo! Front Page, with comparison against six competitive approaches.",10.1145/1526709.1526802,https://doi.org/10.1145/1526709.1526802,"New York, NY, USA",Association for Computing Machinery,9781605584874,2009,Personalized recommendation on dynamic content using predictive bilinear models,"Chu, Wei and Park, Seung-Taek",inproceedings,10.1145/1526709.1526802,
10.1145/1526709.1526806,10.1145/1526709.1526806,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '09,"Madrid, Spain","viral marketing, social networks, information dissemination, flickr, cascades",10,721–730,Proceedings of the 18th International Conference on World Wide Web,"Online social networking sites like MySpace, Facebook, and Flickr have become a popular way to share and disseminate content. Their massive popularity has led to viral marketing techniques that attempt to spread content, products, and ideas on these sites. However, there is little data publicly available on viral propagation in the real world and few studies have characterized how information spreads over current online social networks.In this paper, we collect and analyze large-scale traces of information dissemination in the Flickr social network. Our analysis, based on crawls of the favorite markings of 2.5 million users on 11 million photos, aims at answering three key questions: (a) how widely does information propagate in the social network? (b) how quickly does information propagate? and (c) what is the role of word-of-mouth exchanges between friends in the overall propagation of information in the network? Contrary to viral marketing ``intuition,'' we find that (a) even popular photos do not spread widely throughout the network, (b) even popular photos spread slowly through the network, and (c) information exchanged between friends is likely to account for over 50 of all favorite-markings, but with a significant delay at each hop.",10.1145/1526709.1526806,https://doi.org/10.1145/1526709.1526806,"New York, NY, USA",Association for Computing Machinery,9781605584874,2009,A measurement-driven analysis of information propagation in the flickr social network,"Cha, Meeyoung and Mislove, Alan and Gummadi, Krishna P.",inproceedings,10.1145/1526709.1526806,
10.1145/1526709.1526810,10.1145/1526709.1526810,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '09,"Madrid, Spain","trust, social networks, rating, online community",10,751–760,Proceedings of the 18th International Conference on World Wide Web,"Several attempts have been made to analyze customer behavior on online E-commerce sites. Some studies particularly emphasize the social networks of customers. Users' reviews and ratings of a product exert effects on other consumers' purchasing behavior. Whether a user refers to other users' ratings depends on the trust accorded by a user to the reviewer. On the other hand, the trust that is felt by a user for another user correlates with the similarity of two users' ratings. This bidirectional interaction that involves trust and rating is an important aspect of understanding consumer behavior in online communities because it suggests clustering of similar users and the evolution of strong communities. This paper presents a theoretical model along with analyses of an actual online E-commerce site. We analyzed a large community site in Japan: @cosme. The noteworthy characteristics of @cosme are that users can bookmark their trusted users; in addition, they can post their own ratings of products, which facilitates our analyses of the ratings' bidirectional effects on trust and ratings. We describe an overview of the data in @cosme, analyses of effects from trust to rating and vice versa, and our proposition of a measure of community gravity, which measures how strongly a user might be attracted to a community. Our study is based on the @cosme dataset in addition to the Epinions dataset. It elucidates important insights and proposes a potentially important measure for mining online social networks.",10.1145/1526709.1526810,https://doi.org/10.1145/1526709.1526810,"New York, NY, USA",Association for Computing Machinery,9781605584874,2009,Community gravity: measuring bidirectional effects by trust and rating on online social networks,"Matsuo, Yutaka and Yamamoto, Hikaru",inproceedings,10.1145/1526709.1526810,
10.1145/1557019.1557029,10.1145/1557019.1557029,KDD.bib,1,['KDD.bib'],8,KDD '09,"Paris, France","dyadic data, interaction, latent factor, predictive, recommender systems, sparse",10,19–28,Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"We propose a novel latent factor model to accurately predict response for large scale dyadic data in the presence of features. Our approach is based on a model that predicts response as a multiplicative function of row and column latent factors that are estimated through separate regressions on known row and column features. In fact, our model provides a single unified framework to address both cold and warm start scenarios that are commonplace in practical applications like recommender systems, online advertising, web search, etc. We provide scalable and accurate model fitting methods based on Iterated Conditional Mode and Monte Carlo EM algorithms. We show our model induces a stochastic process on the dyadic space with kernel (covariance) given by a polynomial function of features. Methods that generalize our procedure to estimate factors in an online fashion for dynamic applications are also considered. Our method is illustrated on benchmark datasets and a novel content recommendation application that arises in the context of Yahoo! Front Page. We report significant improvements over several commonly used methods on all datasets.",10.1145/1557019.1557029,https://doi.org/10.1145/1557019.1557029,"New York, NY, USA",Association for Computing Machinery,9781605584959,2009,Regression-based latent factor models,"Agarwal, Deepak and Chen, Bee-Chung",inproceedings,10.1145/1557019.1557029,
10.1145/1557019.1557036,10.1145/1557019.1557036,KDD.bib,1,['KDD.bib'],8,KDD '09,"Paris, France","human response, media scheduling, user interaction",10,89–98,Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Website traffic varies through time in consistent and predictable ways, with highest traffic in the middle of the day. When providing media content to visitors, it is important to present repeat visitors with new content so that they keep coming back. In this paper we present an algorithm to balance the need to keep a website fresh with new content with the desire to present the best content to the most visitors at times of peak traffic. We formulate this as the media scheduling problem, where we attempt to maximize total clicks, given the overall traffic pattern and the time varying clickthrough rates of available media content. We present an efficient algorithm to perform this scheduling under certain conditions and apply this algorithm to real data obtained from server logs, showing evidence of significant improvements in traffic from our algorithmic schedules. Finally, we analyze the click data, presenting models for why and how the clickthrough rate for new content declines as it ages.",10.1145/1557019.1557036,https://doi.org/10.1145/1557019.1557036,"New York, NY, USA",Association for Computing Machinery,9781605584959,2009,Optimizing web traffic via the media scheduling problem,"Backstrom, Lars and Kleinberg, Jon and Kumar, Ravi",inproceedings,10.1145/1557019.1557036,
10.1145/1557019.1557072,10.1145/1557019.1557072,KDD.bib,1,['KDD.bib'],8,KDD '09,"Paris, France","collaborative filtering, concept drift, recommender systems",10,447–456,Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance-decay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset.",10.1145/1557019.1557072,https://doi.org/10.1145/1557019.1557072,"New York, NY, USA",Association for Computing Machinery,9781605584959,2009,Collaborative filtering with temporal dynamics,"Koren, Yehuda",inproceedings,10.1145/1557019.1557072,
10.1145/1557019.1557100,10.1145/1557019.1557100,KDD.bib,1,['KDD.bib'],8,KDD '09,"Paris, France","ranking, tag recommendation, tensor factorization",10,727–736,Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Tag recommendation is the task of predicting a personalized list of tags for a user given an item. This is important for many websites with tagging capabilities like last.fm or delicious. In this paper, we propose a method for tag recommendation based on tensor factorization (TF). In contrast to other TF methods like higher order singular value decomposition (HOSVD), our method RTF ('ranking with tensor factorization') directly optimizes the factorization model for the best personalized ranking. RTF handles missing values and learns from pairwise ranking constraints. Our optimization criterion for TF is motivated by a detailed analysis of the problem and of interpretation schemes for the observed data in tagging systems. In all, RTF directly optimizes for the actual problem using a correct interpretation of the data. We provide a gradient descent algorithm to solve our optimization problem. We also provide an improved learning and prediction method with runtime complexity analysis for RTF. The prediction runtime of RTF is independent of the number of observations and only depends on the factorization dimensions. Besides the theoretical analysis, we empirically show that our method outperforms other state-of-the-art tag recommendation methods like FolkRank, PageRank and HOSVD both in quality and prediction runtime.",10.1145/1557019.1557100,https://doi.org/10.1145/1557019.1557100,"New York, NY, USA",Association for Computing Machinery,9781605584959,2009,Learning optimal ranking with tensor factorization for tag recommendation,"Rendle, Steffen and Balby Marinho, Leandro and Nanopoulos, Alexandros and Schmidt-Thieme, Lars",inproceedings,10.1145/1557019.1557100,
10.1145/1557019.1557140,10.1145/1557019.1557140,KDD.bib,1,['KDD.bib'],8,KDD '09,"Paris, France","co-clustering, dataflow, predictive modeling, scalability",10,1115–1124,Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"All Netflix Prize algorithms proposed so far are prohibitively costly for large-scale production systems. In this paper, we describe an efficient dataflow implementation of a collaborative filtering (CF) solution to the Netflix Prize problem [1] based on weighted coclustering [5]. The dataflow library we use facilitates the development of sophisticated parallel programs designed to fully utilize commodity multicore hardware, while hiding traditional difficulties such as queuing, threading, memory management, and deadlocks.The dataflow CF implementation first compresses the large, sparse training dataset into co-clusters. Then it generates recommendations by combining the average ratings of the co-clusters with the biases of the users and movies. When configured to identify 20x20 co-clusters in the Netflix training dataset, the implementation predicted over 100 million ratings in 16.31 minutes and achieved an RMSE of 0.88846 without any fine-tuning or domain knowledge. This is an effective real-time prediction runtime of 9.7 us per rating which is far superior to previously reported results. Moreover, the implemented co-clustering framework supports a wide variety of other large-scale data mining applications and forms the basis for predictive modeling on large, dyadic datasets [4, 7].",10.1145/1557019.1557140,https://doi.org/10.1145/1557019.1557140,"New York, NY, USA",Association for Computing Machinery,9781605584959,2009,Pervasive parallelism in data mining: dataflow solution to co-clustering large and sparse Netflix data,"Daruru, Srivatsava and Marin, Nena M. and Walker, Matt and Ghosh, Joydeep",inproceedings,10.1145/1557019.1557140,
10.1145/1639714.1639717,10.1145/1639714.1639717,RecSys.bib,1,['RecSys.bib'],8,RecSys '09,"New York, New York, USA","recommender systems, ranking, probabilistic models, non-random missing data, collaborative filtering",8,5–12,Proceedings of the Third ACM Conference on Recommender Systems,"A fundamental aspect of rating-based recommender systems is the observation process, the process by which users choose the items they rate. Nearly all research on collaborative filtering and recommender systems is founded on the assumption that missing ratings are missing at random. The statistical theory of missing data shows that incorrect assumptions about missing data can lead to biased parameter estimation and prediction. In a recent study, we demonstrated strong evidence for violations of the missing at random condition in a real recommender system. In this paper we present the first study of the effect of non-random missing data on collaborative ranking, and extend our previous results regarding the impact of non-random missing data on collaborative prediction.",10.1145/1639714.1639717,https://doi.org/10.1145/1639714.1639717,"New York, NY, USA",Association for Computing Machinery,9781605584355,2009,Collaborative prediction and ranking with non-random missing data,"Marlin, Benjamin M. and Zemel, Richard S.",inproceedings,10.1145/1639714.1639717,
10.1145/1639714.1639719,10.1145/1639714.1639719,RecSys.bib,1,['RecSys.bib'],8,RecSys '09,"New York, New York, USA","spatial modeling, matrix factorization, kalman filtering, graphical model, collaborative filtering",8,13–20,Proceedings of the Third ACM Conference on Recommender Systems,"In this paper, we propose a novel spatio-temporal model for collaborative filtering applications. Our model is based on low-rank matrix factorization that uses a spatio-temporal filtering approach to estimate user and item factors. The spatial component regularizes the factors by exploiting correlation across users and/or items, modeled as a function of some implicit feedback (e.g., who rated what) and/or some side information (e.g., user demographics, browsing history). In particular, we incorporate correlation in factors through a Markov random field prior in a probabilistic framework, whereby the neighborhood weights are functions of user and item covariates. The temporal component ensures that the user/item factors adapt to process changes that occur through time and is implemented in a state space framework with fast estimation through Kalman filtering. Our spatio-temporal filtering (ST-KF hereafter) approach provides a single joint model to simultaneously incorporate both spatial and temporal structure in ratings and therefore provides an accurate method to predict future ratings. To ensure scalability of ST-KF, we employ a mean-field approximation for inference. Incorporating user/item covariates in estimating neighborhood weights also helps in dealing with both cold-start and warm-start problems seamlessly in a single unified modeling framework; covariates predict factors for new users and items through the neighborhood. We illustrate our method on simulated data, benchmark data and data obtained from a relatively new recommender system application arising in the context of Yahoo! Front Page.",10.1145/1639714.1639719,https://doi.org/10.1145/1639714.1639719,"New York, NY, USA",Association for Computing Machinery,9781605584355,2009,A spatio-temporal approach to collaborative filtering,"Lu, Zhengdong and Agarwal, Deepak and Dhillon, Inderjit S.",inproceedings,10.1145/1639714.1639719,
10.1145/1639714.1639722,10.1145/1639714.1639722,RecSys.bib,1,['RecSys.bib'],8,RecSys '09,"New York, New York, USA","predictive models, hierarchical models, aggregate variance, aggregate ratings",8,37–44,Proceedings of the Third ACM Conference on Recommender Systems,"Previous work on using external aggregate rating information showed that this information can be incorporated in several different types of recommender systems and improves their performance. In this paper, we propose a more general class of methods that combine external aggregate information with individual ratings in a novel way. Unlike the previously proposed methods, one of the defining features of this approach is that it takes into the consideration not only the aggregate average ratings but also the variance of the aggregate distribution of ratings. The methods proposed in this paper estimate unknown ratings by finding an optimal linear combination of individual-level and aggregate-level rating estimators in a form of a hierarchical regression (HR) model that is grounded in the theory of statistics and machine learning.The proposed HR model is general enough so that the standard individual-level recommender systems and naive aggregate methods constitute special cases of this model.We show that for the general HR model, the presence of the aggregate variance, surprisingly, does not significantly improve estimation of unknown ratings vis-a-vis the case when only aggregate average ratings are considered.In the paper, we experimentally show that the optimal linear combination approach significantly dominates all other special cases, including the classical non-aggregated case and our previously studied aggregate methods, and therefore is the method of choice.",10.1145/1639714.1639722,https://doi.org/10.1145/1639714.1639722,"New York, NY, USA",Association for Computing Machinery,9781605584355,2009,Improving rating estimation in recommender systems using aggregation- and variance-based hierarchical models,"Umyarov, Akhmed and Tuzhilin, Alexander",inproceedings,10.1145/1639714.1639722,
10.1145/1639714.1639736,10.1145/1639714.1639736,RecSys.bib,1,['RecSys.bib'],8,RecSys '09,"New York, New York, USA","collaborative filtering, community-based multimedia content management, recommendation, recommender systems, user-item matrix",8,125–132,Proceedings of the Third ACM Conference on Recommender Systems,"An approach to user-based collaborative filtering is proposed that refines prediction of item ratings that is based on global user similarity by incorporating information derived from a more detailed user comparison made on the basis of Rated Item Pools (RIPs). The preference spectrum defined by items that a user has rated, and ranging from best-liked to most disliked items, is divided into item sets, or RIPs, which supply the basis for a fine-grained calculation of similarity between users. The RIP-based approach makes it possible for the model to take advantage of user tastes that are matched at one end of the spectrum, e.g., two users agree on favorites, without requiring complete correspondence of item ratings between user profiles. The approach improves rating prediction, as compared to a baseline that uses the global user similarity alone. It does not unduly inflate computational complexity or rely on external resources, common shortcomings of competing rating prediction methods. Cases in which the nearest neighbors are relatively dissimilar, known to be challenging for user-based collaborative filtering, demonstrate particularly substantial improvement. Performance is shown to be stable across the choice of neighborhood size, number of pools and relative pool size.",10.1145/1639714.1639736,https://doi.org/10.1145/1639714.1639736,"New York, NY, USA",Association for Computing Machinery,9781605584355,2009,Exploiting user similarity based on rated-item pools for improved user-based collaborative filtering,"Shi, Yue and Larson, Martha and Hanjalic, Alan",inproceedings,10.1145/1639714.1639736,
10.1145/1639714.1639747,10.1145/1639714.1639747,RecSys.bib,1,['RecSys.bib'],8,RecSys '09,"New York, New York, USA","trust, social networks, recommender systems, personalisation, information overload",8,197–204,Proceedings of the Third ACM Conference on Recommender Systems,"We propose a novel trust metric for social networks which is suitable for application to recommender systems. It is personalised and dynamic, and allows to compute the indirect trust between two agents which are not neighbours based on the direct trust between agents that are neighbours. In analogy to some personalised versions of PageRank, this metric makes use of the concept of feedback centrality and overcomes some of the limitations of other trust metrics. In particular, it does not neglect cycles and other patterns characterising social networks, as some other algorithms do. In order to apply the metric to recommender systems, we propose a way to make trust dynamic over time. We show by means of analytical approximations and computer simulations that the metric has the desired properties. Finally, we carry out an empirical validation on a dataset crawled from an Internet community and compare the performance of a recommender system using our metric to one using collaborative filtering.",10.1145/1639714.1639747,https://doi.org/10.1145/1639714.1639747,"New York, NY, USA",Association for Computing Machinery,9781605584355,2009,Personalised and dynamic trust in social networks,"Walter, Frank E. and Battiston, Stefano and Schweitzer, Frank",inproceedings,10.1145/1639714.1639747,
10.1145/1639714.1639759,10.1145/1639714.1639759,RecSys.bib,1,['RecSys.bib'],8,RecSys '09,"New York, New York, USA","recommender systems, item split, context-based reasoning, collaborative filtering",4,245–248,Proceedings of the Third ACM Conference on Recommender Systems,"Collaborative Filtering (CF) recommendations are computed by leveraging a historical data set of users' ratings for items. It assumes that the users' previously recorded ratings can help in predicting future ratings. This has been validated extensively, but in some domains item ratings can be influenced by contextual conditions, such as the time or the goal of the item consumption. This type of information is not exploited by standard CF models. This paper introduces and analyzes a novel pre-filtering technique for context-aware CF called item splitting. In this approach, the ratings of certain items are split, according to the value of an item-dependent contextual condition. Each split item generates two fictitious items that are used in the prediction algorithm instead of the original one. We evaluated this approach on real world and semi-synthetic data sets using matrix-factorization and nearest neighbor CF algorithms. We show that item splitting can be beneficial and its performance depends on the item selection method and on the influence of the contextual variables on the item ratings.",10.1145/1639714.1639759,https://doi.org/10.1145/1639714.1639759,"New York, NY, USA",Association for Computing Machinery,9781605584355,2009,Context-based splitting of item ratings in collaborative filtering,"Baltrunas, Linas and Ricci, Francesco",inproceedings,10.1145/1639714.1639759,
10.1145/1639714.1639763,10.1145/1639714.1639763,RecSys.bib,1,['RecSys.bib'],8,RecSys '09,"New York, New York, USA","neighborhood based collaborative filtering, ensemble methods, collaborative filtering",4,261–264,Proceedings of the Third ACM Conference on Recommender Systems,"Recommender systems provide consumers with ratings of items. These ratings are based on a set of ratings that were obtained from a wide scope of users. Predicting the ratings can be formulated as a regression problem. Ensemble regression methods are effective tools that improve the results of simple regression algorithms by iteratively applying the simple algorithm to a diverse set of inputs. The present paper describes a simple and effective ensemble regressor for the prediction of missing ratings in recommender systems. The ensemble method is an adaptation of the AdaBoost regression algorithm for recommendation tasks. In all iterations, interpolation weights for all nearest neighbors are simultaneously derived by minimizing the root mean squared error. From iteration to iteration instances that are hard to predict are reinforced by manipulating their weights in the goal function that needs to be minimized. The experimental evaluation demonstrates that the ensemble methodology significantly improves the predictive performance of single neighborhood-based collaborative filtering.",10.1145/1639714.1639763,https://doi.org/10.1145/1639714.1639763,"New York, NY, USA",Association for Computing Machinery,9781605584355,2009,Ensemble methods for improving the performance of neighborhood-based collaborative filtering,"Schclar, Alon and Tsikinovsky, Alexander and Rokach, Lior and Meisels, Amnon and Antwarg, Liat",inproceedings,10.1145/1639714.1639763,
10.1145/1639714.1639795,10.1145/1639714.1639795,RecSys.bib,1,['RecSys.bib'],8,RecSys '09,"New York, New York, USA","user modeling, recommender systems, item views, collaborative filtering",4,389–392,Proceedings of the Third ACM Conference on Recommender Systems,"Different recommender systems based on collaborative technology have been proposed that recommend new relevant products to users by exploring past user preference patterns. The most common approach generates recommendations based on user consumption patterns and on rating information gathered during each user-item interaction. In this paper we introduce a novel approach based on views of items, which are basically more complex models of the user-item interactions aimed at capturing the aspects on which users base their ratings. The resulting view-based approach recommends views to users instead of the traditional items. The proposed algorithms are tested on an artificial database, and the results show that modeling further interaction information improves the accuracy of predictions, provides a robust background to explain recommendations, exposes users to more specific recommendations and leads to better models of user preferences.",10.1145/1639714.1639795,https://doi.org/10.1145/1639714.1639795,"New York, NY, USA",Association for Computing Machinery,9781605584355,2009,View-based recommender systems,"Lousame, Fabi\'{a}n P. P. and S\'{a}nchez, Eduardo",inproceedings,10.1145/1639714.1639795,
10.1145/1645953.1646050,10.1145/1645953.1646050,CIKM.bib,1,['CIKM.bib'],8,CIKM '09,"Hong Kong, China","ranking, latent class model, collaborative filtering",8,759–766,Proceedings of the 18th ACM Conference on Information and Knowledge Management,"A central goal of collaborative filtering (CF) is to rank items by their utilities with respect to individual users in order to make personalized recommendations. Traditionally, this is often formulated as a rating prediction problem. However, it is more desirable for CF algorithms to address the ranking problem directly without going through an extra rating prediction step. In this paper, we propose the probabilistic latent preference analysis (pLPA) model for ranking predictions by directly modeling user preferences with respect to a set of items rather than the rating scores on individual items. From a user's observed ratings, we extract his preferences in the form of pairwise comparisons of items which are modeled by a mixture distribution based on Bradley-Terry model. An EM algorithm for fitting the corresponding latent class model as well as a method for predicting the optimal ranking are described. Experimental results on real world data sets demonstrated the superiority of the proposed method over several existing CF algorithms based on rating predictions in terms of ranking performance measure NDCG.",10.1145/1645953.1646050,https://doi.org/10.1145/1645953.1646050,"New York, NY, USA",Association for Computing Machinery,9781605585123,2009,Probabilistic latent preference analysis for collaborative filtering,"Liu, Nathan N. and Zhao, Min and Yang, Qiang",inproceedings,10.1145/1645953.1646050,
10.1145/1645953.1646267,10.1145/1645953.1646267,CIKM.bib,1,['CIKM.bib'],8,CIKM '09,"Hong Kong, China","sponsored search, online advertising, collaborative filtering, click-through rate, click data",4,1927–1930,Proceedings of the 18th ACM Conference on Information and Knowledge Management,Search engine logs contain a large amount of click-through data that can be leveraged as soft indicators of relevance. In this paper we address the sponsored search retrieval problem which is to find and rank relevant ads to a search query. We propose a new technique to determine the relevance of an ad document for a search query using click-through data. The method builds on a collaborative filtering approach to discover new ads related to a query using a click graph. It is implemented on a graph with several million edges and scales to larger sizes easily. The proposed method is compared to three different baselines that are state-of-the-art for a commercial search engine. Evaluations on editorial data indicate that the model discovers many new ads not retrieved by the baseline methods. The ads from the new approach are on average of better quality than the baselines.,10.1145/1645953.1646267,https://doi.org/10.1145/1645953.1646267,"New York, NY, USA",Association for Computing Machinery,9781605585123,2009,A collaborative filtering approach to ad recommendation using the query-ad click graph,"Anastasakos, Tasos and Hillard, Dustin and Kshetramade, Sanjay and Raghavan, Hema",inproceedings,10.1145/1645953.1646267,
10.1145/1651274.1651289,10.1145/1651274.1651289,CIKM.bib,1,['CIKM.bib'],8,CNIKM '09,"Hong Kong, China","matrix factorization, hybrid recommender, cross-linked data",6,75–80,Proceedings of the 1st ACM International Workshop on Complex Networks Meet Information &amp; Knowledge Management,"This paper discusses the combination of collaborative and content-based filtering in the context of web-based recommender systems. In particular, we link the well-known MovieLens rating data with supplementary IMDB content information. The resulting network of user-item relations and associated content features is converted into a unified mathematical model, which is applicable to our underlying neighbor-based prediction algorithm. By means of various experiments, we demonstrate the influence of supplementary user as well as item features on the prediction accuracy of Hydra, our proposed hybrid recommender. In order to decrease system runtime and to reveal latent user and item relations, we factorize our hybrid model via singular value decomposition (SVD).",10.1145/1651274.1651289,https://doi.org/10.1145/1651274.1651289,"New York, NY, USA",Association for Computing Machinery,9781605588070,2009,Hydra: a hybrid recommender system [cross-linked rating and content information],"Spiegel, Stephan and Kunegis, J\'{e}r\^{o}me and Li, Fang",inproceedings,10.1145/1651274.1651289,
10.1145/1718487.1718498,10.1145/1718487.1718498,WSDM.bib,1,['WSDM.bib'],8,WSDM '10,"New York, New York, USA","personalization, recommender systems, tag recommendation, tensor factorization",10,81–90,Proceedings of the Third ACM International Conference on Web Search and Data Mining,"Tagging plays an important role in many recent websites. Recommender systems can help to suggest a user the tags he might want to use for tagging a specific item. Factorization models based on the Tucker Decomposition (TD) model have been shown to provide high quality tag recommendations outperforming other approaches like PageRank, FolkRank, collaborative filtering, etc. The problem with TD models is the cubic core tensor resulting in a cubic runtime in the factorization dimension for prediction and learning.In this paper, we present the factorization model PITF (Pairwise Interaction Tensor Factorization) which is a special case of the TD model with linear runtime both for learning and prediction. PITF explicitly models the pairwise interactions between users, items and tags. The model is learned with an adaption of the Bayesian personalized ranking (BPR) criterion which originally has been introduced for item recommendation. Empirically, we show on real world datasets that this model outperforms TD largely in runtime and even can achieve better prediction quality. Besides our lab experiments, PITF has also won the ECML/PKDD Discovery Challenge 2009 for graph-based tag recommendation.",10.1145/1718487.1718498,https://doi.org/10.1145/1718487.1718498,"New York, NY, USA",Association for Computing Machinery,9781605588896,2010,Pairwise interaction tensor factorization for personalized tag recommendation,"Rendle, Steffen and Schmidt-Thieme, Lars",inproceedings,10.1145/1718487.1718498,
10.1145/1718487.1718499,10.1145/1718487.1718499,WSDM.bib,1,['WSDM.bib'],8,WSDM '10,"New York, New York, USA","bayesian hierarchical model, collaborative filtering, graphical model, latent factor model, recommender systems, supervised topic model",10,91–100,Proceedings of the Third ACM International Conference on Web Search and Data Mining,"We propose fLDA, a novel matrix factorization method to predict ratings in recommender system applications where a ""bag-of-words"" representation for item meta-data is natural. Such scenarios are commonplace in web applications like content recommendation, ad targeting and web search where items are articles, ads and web pages respectively. Because of data sparseness, regularization is key to good predictive accuracy. Our method works by regularizing both user and item factors simultaneously through user features and the bag of words associated with each item. Specifically, each word in an item is associated with a discrete latent factor often referred to as the topic of the word; item topics are obtained by averaging topics across all words in an item. Then, user rating on an item is modeled as user's affinity to the item's topics where user affinity to topics (user factors) and topic assignments to words in items (item factors) are learned jointly in a supervised fashion. To avoid overfitting, user and item factors are regularized through Gaussian linear regression and Latent Dirichlet Allocation (LDA) priors respectively. We show our model is accurate, interpretable and handles both cold-start and warm-start scenarios seamlessly through a single model. The efficacy of our method is illustrated on benchmark datasets and a new dataset from Yahoo! Buzz where fLDA provides superior predictive accuracy in cold-start scenarios and is comparable to state-of-the-art methods in warm-start scenarios. As a by-product, fLDA also identifies interesting topics that explains user-item interactions. Our method also generalizes a recently proposed technique called supervised LDA (sLDA) to collaborative filtering applications. While sLDA estimates item topic vectors in a supervised fashion for a single regression, fLDA incorporates multiple regressions (one for each user) in estimating the item factors.",10.1145/1718487.1718499,https://doi.org/10.1145/1718487.1718499,"New York, NY, USA",Association for Computing Machinery,9781605588896,2010,fLDA: matrix factorization through latent dirichlet allocation,"Agarwal, Deepak and Chen, Bee-Chung",inproceedings,10.1145/1718487.1718499,
10.1145/1718487.1718513,10.1145/1718487.1718513,WSDM.bib,1,['WSDM.bib'],8,WSDM '10,"New York, New York, USA","infinite inventory, long tail",10,201–210,Proceedings of the Third ACM International Conference on Web Search and Data Mining,"The success of ""infinite-inventory"" retailers such as Amazon.com and Netflix has been ascribed to a ""long tail"" phenomenon. To wit, while the majority of their inventory is not in high demand, in aggregate these ""worst sellers,"" unavailable at limited-inventory competitors, generate a significant fraction of total revenue. The long tail phenomenon, however, is in principle consistent with two fundamentally different theories. The first, and more popular hypothesis, is that a majority of consumers consistently follow the crowds and only a minority have any interest in niche content; the second hypothesis is that everyone is a bit eccentric, consuming both popular and specialty products. Based on examining extensive data on user preferences for movies, music, Web search, and Web browsing, we find overwhelming support for the latter theory. However, the observed eccentricity is much less than what is predicted by a fully random model whereby every consumer makes his product choices independently and proportional to product popularity; so consumers do indeed exhibit at least some a priori propensity toward either the popular or the exotic.Our findings thus suggest an additional factor in the success of infinite-inventory retailers, namely, that tail availability may boost head sales by offering consumers the convenience of ""one-stop shopping"" for both their mainstream and niche interests. This hypothesis is further supported by our theoretical analysis that presents a simple model in which shared inventory stores, such as Amazon Marketplace, gain a clear advantage by satisfying tail demand, helping to explain the emergence and increasing popularity of such retail arrangements. Hence, we believe that the return-on-investment (ROI) of niche products goes beyond direct revenue, extending to second-order gains associated with increased consumer satisfaction and repeat patronage. More generally, our findings call into question the conventional wisdom that specialty products only appeal to a minority of consumers.",10.1145/1718487.1718513,https://doi.org/10.1145/1718487.1718513,"New York, NY, USA",Association for Computing Machinery,9781605588896,2010,Anatomy of the long tail: ordinary people with extraordinary tastes,"Goel, Sharad and Broder, Andrei and Gabrilovich, Evgeniy and Pang, Bo",inproceedings,10.1145/1718487.1718513,
10.1145/1722149.1722153,10.1145/1722149.1722153,KDD.bib,1,['KDD.bib'],7,NETFLIX '08,"Las Vegas, Nevada","KNN, Netflix, collaborative filtering, ensemble performance, latent factor model, matrix factorization, recommender systems, similarity matrix",6,,Proceedings of the 2nd KDD Workshop on Large-Scale Recommender Systems and the Netflix Prize Competition,"Neighborhood-based algorithms are frequently used modules of recommender systems. Usually, the choice of the similarity measure used for evaluation of neighborhood relationships is crucial for the success of such approaches. In this article we propose a way to calculate similarities by formulating a regression problem which enables us to extract the similarities from the data in a problem-specific way. Another popular approach for recommender systems is regularized matrix factorization (RMF). We present an algorithm -- neighborhood-aware matrix factorization -- which efficiently includes neighborhood information in a RMF model. This leads to increased prediction accuracy. The proposed methods are tested on the Netflix dataset.",10.1145/1722149.1722153,https://doi.org/10.1145/1722149.1722153,"New York, NY, USA",Association for Computing Machinery,9781605582658,2008,Improved neighborhood-based algorithms for large-scale recommender systems,"T\""{o}scher, Andreas and Jahrer, Michael and Legenstein, Robert",inproceedings,10.1145/1722149.1722153,4
10.1145/1722149.1722154,10.1145/1722149.1722154,KDD.bib,1,['KDD.bib'],7,NETFLIX '08,"Las Vegas, Nevada","complex network analysis, evaluation, long tail, popularity, recommender systems",8,,Proceedings of the 2nd KDD Workshop on Large-Scale Recommender Systems and the Netflix Prize Competition,"This paper presents some experiments to analyse the popularity effect in music recommendation. Popularity is measured in terms of total playcounts, and the Long Tail model is used in order to rank music artists. Furthermore, metrics derived from complex network analysis are used to detect the influence of the most popular artists in the network of similar artists.The results from the experiments reveal that---as expected by its inherent social component---the collaborative filtering approach is prone to popularity bias. This has some consequences on the discovery ratio as well as in the navigation through the Long Tail. On the other hand, in both audio content--based and human expert--based approaches artists are linked independently of their popularity. This allows one to navigate from a mainstream artist to a Long Tail artist in just two or three clicks.",10.1145/1722149.1722154,https://doi.org/10.1145/1722149.1722154,"New York, NY, USA",Association for Computing Machinery,9781605582658,2008,From hits to niches? or how popular artists can bias music recommendation and discovery,"Celma, \`{O}scar and Cano, Pedro",inproceedings,10.1145/1722149.1722154,5
10.1145/1772690.1772754,10.1145/1772690.1772754,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '10,"Raleigh, North Carolina, USA","social voting, social media, social dynamics, prediction, popularity",10,621–630,Proceedings of the 19th International Conference on World Wide Web,"Popularity of content in social media is unequally distributed, with some items receiving a disproportionate share of attention from users. Predicting which newly-submitted items will become popular is critically important for both companies that host social media sites and their users. Accurate and timely prediction would enable the companies to maximize revenue through differential pricing for access to content or ad placement. Prediction would also give consumers an important tool for filtering the ever-growing amount of content. Predicting popularity of content in social media, however, is challenging due to the complex interactions among content quality, how the social media site chooses to highlight content, and influence among users. While these factors make it difficult to predict popularity a priori, we show that stochastic models of user behavior on these sites allows predicting popularity based on early user reactions to new content. By incorporating aspects of the web site design, such models improve on predictions based on simply extrapolating from the early votes. We validate this claim on the social news portal Digg using a previously-developed model of social voting based on the Digg user interface.",10.1145/1772690.1772754,https://doi.org/10.1145/1772690.1772754,"New York, NY, USA",Association for Computing Machinery,9781605587998,2010,Using a model of social dynamics to predict popularity of news,"Lerman, Kristina and Hogg, Tad",inproceedings,10.1145/1772690.1772754,
10.1145/1772690.1772758,10.1145/1772690.1772758,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '10,"Raleigh, North Carolina, USA","web service, recommender systems, personalization, exploration/exploitation dilemma, contextual bandit",10,661–670,Proceedings of the 19th International Conference on World Wide Web,"Personalized web services strive to adapt their services (advertisements, news articles, etc.) to individual users by making use of both content and user information. Despite a few recent advances, this problem remains challenging for at least two reasons. First, web service is featured with dynamically changing pools of content, rendering traditional collaborative filtering methods inapplicable. Second, the scale of most web services of practical interest calls for solutions that are both fast in learning and computation.In this work, we model personalized recommendation of news articles as a contextual bandit problem, a principled approach in which a learning algorithm sequentially selects articles to serve users based on contextual information about the users and articles, while simultaneously adapting its article-selection strategy based on user-click feedback to maximize total user clicks.The contributions of this work are three-fold. First, we propose a new, general contextual bandit algorithm that is computationally efficient and well motivated from learning theory. Second, we argue that any bandit algorithm can be reliably evaluated offline using previously recorded random traffic. Finally, using this offline evaluation method, we successfully applied our new algorithm to a Yahoo! Front Page Today Module dataset containing over 33 million events. Results showed a 12.5% click lift compared to a standard context-free bandit algorithm, and the advantage becomes even greater when data gets more scarce.",10.1145/1772690.1772758,https://doi.org/10.1145/1772690.1772758,"New York, NY, USA",Association for Computing Machinery,9781605587998,2010,A contextual-bandit approach to personalized news article recommendation,"Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E.",inproceedings,10.1145/1772690.1772758,
10.1145/1772690.1772773,10.1145/1772690.1772773,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '10,"Raleigh, North Carolina, USA","matrix factorization, markov chain, basket recommendation",10,811–820,Proceedings of the 19th International Conference on World Wide Web,"Recommender systems are an important component of many websites. Two of the most popular approaches are based on matrix factorization (MF) and Markov chains (MC). MF methods learn the general taste of a user by factorizing the matrix over observed user-item preferences. On the other hand, MC methods model sequential behavior by learning a transition graph over items that is used to predict the next action based on the recent actions of a user. In this paper, we present a method bringing both approaches together. Our method is based on personalized transition graphs over underlying Markov chains. That means for each user an own transition matrix is learned - thus in total the method uses a transition cube. As the observations for estimating the transitions are usually very limited, our method factorizes the transition cube with a pairwise interaction model which is a special case of the Tucker Decomposition. We show that our factorized personalized MC (FPMC) model subsumes both a common Markov chain and the normal matrix factorization model. For learning the model parameters, we introduce an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data. Empirically, we show that our FPMC model outperforms both the common matrix factorization and the unpersonalized MC model both learned with and without factorization.",10.1145/1772690.1772773,https://doi.org/10.1145/1772690.1772773,"New York, NY, USA",Association for Computing Machinery,9781605587998,2010,Factorizing personalized Markov chains for next-basket recommendation,"Rendle, Steffen and Freudenthaler, Christoph and Schmidt-Thieme, Lars",inproceedings,10.1145/1772690.1772773,
10.1145/1772690.1772794,10.1145/1772690.1772794,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '10,"Raleigh, North Carolina, USA","taste, social media, sessions, recommendations, music, mood, graphical models, collaborative filtering",10,1019–1028,Proceedings of the 19th International Conference on World Wide Web,"User experience in social media involves rich interactions with the media content and other participants in the community. In order to support such communities, it is important to understand the factors that drive the users' engagement. In this paper we show how to define statistical models of different complexity to describe patterns of song listening in an online music community. First, we adapt the LDA model to capture music taste from listening activities across users and identify both the groups of songs associated with the specific taste and the groups of listeners who share the same taste. Second, we define a graphical model that takes into account listening sessions and captures the listening moods of users in the community. Our session model leads to groups of songs and groups of listeners with similar behavior across listening sessions and enables faster inference when compared to the LDA model. Our experiments with the data from an online media site demonstrate that the session model is better in terms of the perplexity compared to two other models: the LDA-based taste model that does not incorporate cross-session information and a baseline model that does not use latent groupings of songs.",10.1145/1772690.1772794,https://doi.org/10.1145/1772690.1772794,"New York, NY, USA",Association for Computing Machinery,9781605587998,2010,Statistical models of music-listening sessions in social media,"Zheleva, Elena and Guiver, John and Mendes Rodrigues, Eduarda and Mili\'{c}-Frayling, Nata\v{s}a",inproceedings,10.1145/1772690.1772794,
10.1145/1830252.1830256,10.1145/1830252.1830256,KDD.bib,1,['KDD.bib'],8,MLG '10,"Washington, D.C.","SimRank, item recommendation, link-based similarity, networks",8,26–33,Proceedings of the Eighth Workshop on Mining and Learning with Graphs,"Several key applications like recommender systems require to compute similarities between the nodes (objects or entities) of a bipartite network. These similarities serve many important purposes, such as finding users sharing common interests or items with similar characteristics, as well as the automated recommendation and categorization of items. While a broad range of methods have been proposed to compute similarities in networks, such methods have two limitations: (1) they require the link values to be in the form of numerical weights representing the strength of the corresponding relation, and (2) they do not take into account prior information on the similarities. This paper presents a novel approach, based on the SimRank algorithm, to compute similarities between the nodes of a bipartite network. Unlike current methods, this approach allows one to model the agreement between link values using any desired function, and provides a simple way to integrate prior information on the similarity values directly in the computations. To evaluate its usefulness, we test this approach on the problem of predicting the ratings of users for movies and jokes.",10.1145/1830252.1830256,https://doi.org/10.1145/1830252.1830256,"New York, NY, USA",Association for Computing Machinery,9781450302142,2010,Enhancing link-based similarity through the use of non-numerical labels and prior information,"Desrosiers, Christian and Karypis, George",inproceedings,10.1145/1830252.1830256,
10.1145/1835804.1835834,10.1145/1835804.1835834,KDD.bib,1,['KDD.bib'],8,KDD '10,"Washington, DC, USA","computational advertising, count data, display advertising, gamma-poisson, spars contingency tables, spike and slab prior",10,213–222,Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"We consider the problem of estimating rates of rare events for high dimensional, multivariate categorical data where several dimensions are hierarchical. Such problems are routine in several data mining applications including computational advertising, our main focus in this paper. We propose LMMH, a novel log-linear modeling method that scales to massive data applications with billions of training records and several million potential predictors in a map-reduce framework. Our method exploits correlations in aggregates observed at multiple resolutions when working with multiple hierarchies; stable estimates at coarser resolution provide informative prior information to improve estimates at finer resolutions. Other than prediction accuracy and scalability, our method has an inbuilt variable screening procedure based on a ""spike and slab prior"" that provides parsimony by removing non-informative predictors without hurting predictive accuracy. We perform large scale experiments on data from real computational advertising applications and illustrate our approach on datasets with several billion records and hundreds of millions of predictors. Extensive comparisons with other benchmark methods show significant improvements in prediction accuracy.",10.1145/1835804.1835834,https://doi.org/10.1145/1835804.1835834,"New York, NY, USA",Association for Computing Machinery,9781450300551,2010,Estimating rates of rare events with multiple hierarchies through scalable log-linear models,"Agarwal, Deepak and Agrawal, Rahul and Khanna, Rajiv and Kota, Nagaraj",inproceedings,10.1145/1835804.1835834,
10.1145/1835804.1835893,10.1145/1835804.1835893,KDD.bib,1,['KDD.bib'],8,KDD '10,"Washington, DC, USA","Netflix, ensemble learning, recommender systems, supervised learning",10,693–702,Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"We analyze the application of ensemble learning to recommender systems on the Netflix Prize dataset. For our analysis we use a set of diverse state-of-the-art collaborative filtering (CF) algorithms, which include: SVD, Neighborhood Based Approaches, Restricted Boltzmann Machine, Asymmetric Factor Model and Global Effects. We show that linearly combining (blending) a set of CF algorithms increases the accuracy and outperforms any single CF algorithm. Furthermore, we show how to use ensemble methods for blending predictors in order to outperform a single blending algorithm. The dataset and the source code for the ensemble blending are available online.",10.1145/1835804.1835893,https://doi.org/10.1145/1835804.1835893,"New York, NY, USA",Association for Computing Machinery,9781450300551,2010,Combining predictions for accurate recommender systems,"Jahrer, Michael and T\""{o}scher, Andreas and Legenstein, Robert",inproceedings,10.1145/1835804.1835893,
10.1145/1835804.1835896,10.1145/1835804.1835896,KDD.bib,1,['KDD.bib'],8,KDD '10,"Washington, DC, USA","graph, temporal recommendation, user preference",10,723–732,Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Accurately capturing user preferences over time is a great practical challenge in recommender systems. Simple correlation over time is typically not meaningful, since users change their preferences due to different external events. User behavior can often be determined by individual's long-term and short-term preferences. How to represent users' long-term and short-term preferences? How to leverage them for temporal recommendation? To address these challenges, we propose Session-based Temporal Graph (STG) which simultaneously models users' long-term and short-term preferences over time. Based on the STG model framework, we propose a novel recommendation algorithm Injected Preference Fusion (IPF) and extend the personalized Random Walk for temporal recommendation. Finally, we evaluate the effectiveness of our method using two real datasets on citations and social bookmarking, in which our proposed method IPF gives 15%-34% improvement over the previous state-of-the-art.",10.1145/1835804.1835896,https://doi.org/10.1145/1835804.1835896,"New York, NY, USA",Association for Computing Machinery,9781450300551,2010,Temporal recommendation on graphs via long- and short-term preference fusion,"Xiang, Liang and Yuan, Quan and Zhao, Shiwan and Chen, Li and Zhang, Xiatian and Yang, Qing and Sun, Jimeng",inproceedings,10.1145/1835804.1835896,
10.1145/1835804.1835917,10.1145/1835804.1835917,KDD.bib,1,['KDD.bib'],8,KDD '10,"Washington, DC, USA","probability, social network, statistics, trust prediction",10,889–898,Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"In an online rating system, raters assign ratings to objects contributed by other users. In addition, raters can develop trust and distrust on object contributors depending on a few rating and trust related factors. Previous study has shown that ratings and trust links can influence each other but there has been a lack of a formal model to relate these factors together. In this paper, we therefore propose Trust Antecedent Factor (TAF) Model, a novel probabilistic model that generate ratings based on a number of rater's and contributor's factors. We demonstrate that parameters of the model can be learnt by Collapsed Gibbs Sampling. We then apply the model to predict trust and distrust between raters and review contributors using a real data-set. Our experiments have shown that the proposed model is capable of predicting both trust and distrust in a unified way. The model can also determine user factors which otherwise cannot be observed from the rating and trust data.",10.1145/1835804.1835917,https://doi.org/10.1145/1835804.1835917,"New York, NY, USA",Association for Computing Machinery,9781450300551,2010,Trust network inference for online rating data using generative models,"Chua, Freddy Chong Tat and Lim, Ee-Peng",inproceedings,10.1145/1835804.1835917,
10.1145/1864708.1864715,10.1145/1864708.1864715,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","crowdsourcing, geotagging, incentive design, mechanical turk, recommender system",8,13–20,Proceedings of the Fourth ACM Conference on Recommender Systems,"We present the design, implementation and evaluation of a new geotagging service, Gloe, that makes it easy to find, rate and recommend arbitrary on-line content in a mobile setting. The service automates the content search process by taking advantage of geographic and social context, while using crowdsourced expertise to present a personalized feed of targeted information ranked by a novel geo-aware rating and incentive mechanism.Users rate the relevance of recommendations for particular locations using a limited, global voting budget. This budget is, in turn, increased by accurately predicting local content popularity. One of the key goals of our mechanism is to encourage ratings, and in an evaluation of the live system we found that the rating to click ratio was 107 times higher than the ratio for videos on YouTube, 34 times higher than the ratio for applications on the Android Market, and 3 times higher than the ratio for Web pages on Digg.To investigate whether our mechanism also had qualitative effects on the ratings we conducted a number of experiments on Amazon Mechanical Turk, with 500 users, comparing our mechanism to the de-facto 5-star ratings commonly in use on the Web. Our results show that budgets improved the ranking and incentives improved the aggregate rating of a series of location-dependent Web pages.",10.1145/1864708.1864715,https://doi.org/10.1145/1864708.1864715,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Global budgets for local recommendations,"Sandholm, Thomas and Ung, Hang and Aperjis, Christina and Huberman, Bernardo A.",inproceedings,10.1145/1864708.1864715,
10.1145/1864708.1864716,10.1145/1864708.1864716,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","collaborative filtering, information retrieval, online learning, recommender systems",8,21–28,Proceedings of the Fourth ACM Conference on Recommender Systems,"Collaborative filtering is a widely used technique for rating prediction in recommender systems. Memory based collaborative filtering algorithms assign weights to the users to capture similarities between them. The weighted average of similar users' ratings for the test item is output as prediction. We propose a memory based algorithm that is markedly different from the existing approaches. We use preference relations instead of absolute ratings for similarity calculations, as preference relations between items are generally more consistent than ratings across like-minded users. Each user's ratings are viewed as a preference graph. Similarity weights are learned using an iterative method motivated by online learning. These weights are used to create an aggregate preference graph. Ratings are inferred to maximally agree with this aggregate graph. The use of preference relations allows the rating of an item to be influenced by other items, which is not the case in the weighted-average approaches of the existing techniques. This is very effective when the data is sparse, specially for the items rated by few users. Our experiments show that the our method outperforms other methods in the sparse regions. However, for dense regions, sometimes our results are comparable to the competing approaches, and sometimes worse.",10.1145/1864708.1864716,https://doi.org/10.1145/1864708.1864716,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Aggregating preference graphs for collaborative rating prediction,"Desarkar, Maunendra Sankar and Sarkar, Sudeshna and Mitra, Pabitra",inproceedings,10.1145/1864708.1864716,
10.1145/1864708.1864721,10.1145/1864708.1864721,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","evaluation, precision, recall, top-n recommendations",8,39–46,Proceedings of the Fourth ACM Conference on Recommender Systems,"In many commercial systems, the 'best bet' recommendations are shown, but the predicted rating values are not. This is usually referred to as a top-N recommendation task, where the goal of the recommender system is to find a few specific items which are supposed to be most appealing to the user. Common methodologies based on error metrics (such as RMSE) are not a natural fit for evaluating the top-N recommendation task. Rather, top-N performance can be directly measured by alternative methodologies based on accuracy metrics (such as precision/recall).An extensive evaluation of several state-of-the art recommender algorithms suggests that algorithms optimized for minimizing RMSE do not necessarily perform as expected in terms of top-N recommendation task. Results show that improvements in RMSE often do not translate into accuracy improvements. In particular, a naive non-personalized algorithm can outperform some common recommendation approaches and almost match the accuracy of sophisticated algorithms. Another finding is that the very few top popular items can skew the top-N performance. The analysis points out that when evaluating a recommender algorithm on the top-N recommendation task, the test set should be chosen carefully in order to not bias accuracy metrics towards non-personalized solutions. Finally, we offer practitioners new variants of two collaborative filtering algorithms that, regardless of their RMSE, significantly outperform other recommender algorithms in pursuing the top-N recommendation task, with offering additional practical advantages. This comes at surprise given the simplicity of these two methods.",10.1145/1864708.1864721,https://doi.org/10.1145/1864708.1864721,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Performance of recommender algorithms on top-n recommendation tasks,"Cremonesi, Paolo and Koren, Yehuda and Turrin, Roberto",inproceedings,10.1145/1864708.1864721,
10.1145/1864708.1864723,10.1145/1864708.1864723,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","collaborative filtering, long tail, multiple objectives, personalization, popularity, recommender systems, stock management",8,55–62,Proceedings of the Fourth ACM Conference on Recommender Systems,"This paper is about the utility of making personalized recommendations. While it is important to accurately predict the target user's preference, in practice the accuracy should not be the only concern; a useful recommender system needs to consider the user's utility or satisfaction of fulfilling a certain information seeking task. For example, recommending popular items (products) is unlikely to result in more gain than discovering insignificant (""long tail"") yet liked items because the popular ones might be already known to the user. Equally, recommending items that are out of stock would be frustrating for both the user and system if the system is employed to discover items to purchase. Thus, it is important to have a flexible recommendation framework that takes into account additional recommendation goals meanwhile minimizing the performance loss in order to provide greater adjustability and a better user experience.To achieve this, in this paper, we propose a general recommendation optimization framework that not only considers the predicted preference scores (e.g. ratings) but also deals with additional operational or resource related recommendation goals. Using this framework we demonstrate through realistic examples how to expand existing rating prediction algorithms by biasing the recommendation depending on other external factors such as the availability, profitability or usefulness of an item. Our experiments on real data sets demonstrate that this framework is indeed able to cope with multiple objectives with minor performance loss.",10.1145/1864708.1864723,https://doi.org/10.1145/1864708.1864723,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Optimizing multiple objectives in collaborative filtering,"Jambor, Tamas and Wang, Jun",inproceedings,10.1145/1864708.1864723,
10.1145/1864708.1864728,10.1145/1864708.1864728,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","multidimensional scaling, fast recommendation generation, euclidean embedding, collaborative filtering",8,87–94,Proceedings of the Fourth ACM Conference on Recommender Systems,"Recommendation systems suggest items based on user preferences. Collaborative filtering is a popular approach in which recommending is based on the rating history of the system. One of the most accurate and scalable collaborative filtering algorithms is matrix factorization, which is based on a latent factor model. We propose a novel Euclidean embedding method as an alternative latent factor model to implement collaborative filtering. In this method, users and items are embedded in a unified Euclidean space where the distance between a user and an item is inversely proportional to the rating. This model is comparable to matrix factorization in terms of both scalability and accuracy while providing several advantages. First, the result of Euclidean embedding is more intuitively understandable for humans, allowing useful visualizations. Second, the neighborhood structure of the unified Euclidean space allows very efficient recommendation queries. Finally, the method facilitates online implementation requirements such as mapping new users or items in an existing model. Our experimental results confirm these advantages and show that collaborative filtering via Euclidean embedding is a promising approach for online recommender systems.",10.1145/1864708.1864728,https://doi.org/10.1145/1864708.1864728,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Collaborative filtering via euclidean embedding,"Khoshneshin, Mohammad and Street, W. Nick",inproceedings,10.1145/1864708.1864728,
10.1145/1864708.1864729,10.1145/1864708.1864729,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","collaborative filtering, latent class model, ranking",8,95–102,Proceedings of the Fourth ACM Conference on Recommender Systems,"Collaborative filtering algorithms attempt to predict a user's interests based on his past feedback. In real world applications, a user's feedback is often continuously collected over a long period of time. It is very common for a user's interests or an item's popularity to change over a long period of time. Therefore, the underlying recommendation algorithm should be able to adapt to such changes accordingly. However, most existing algorithms do not distinguish current and historical data when predicting the users' current interests. In this paper, we consider a new problem - online evolutionary collaborative filtering, which tracks user interests over time in order to make timely recommendations. We extended the widely used neighborhood based algorithms by incorporating temporal information and developed an incremental algorithm for updating neighborhood similarities with new data. Experiments on two real world datasets demonstrated both improved effectiveness and efficiency of the proposed approach.",10.1145/1864708.1864729,https://doi.org/10.1145/1864708.1864729,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Online evolutionary collaborative filtering,"Liu, Nathan N. and Zhao, Min and Xiang, Evan and Yang, Qiang",inproceedings,10.1145/1864708.1864729,
10.1145/1864708.1864733,10.1145/1864708.1864733,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","rank aggregation, group recommender system, collaborative filtering",8,119–126,Proceedings of the Fourth ACM Conference on Recommender Systems,"The majority of recommender systems are designed to make recommendations for individual users. However, in some circumstances the items to be selected are not intended for personal usage but for a group; e.g., a DVD could be watched by a group of friends. In order to generate effective recommendations for a group the system must satisfy, as much as possible, the individual preferences of the group's members.This paper analyzes the effectiveness of group recommendations obtained aggregating the individual lists of recommendations produced by a collaborative filtering system. We compare the effectiveness of individual and group recommendation lists using normalized discounted cumulative gain. It is observed that the effectiveness of a group recommendation does not necessarily decrease when the group size grows. Moreover, when individual recommendations are not effective a user could obtain better suggestions looking at the group recommendations. Finally, it is shown that the more alike the users in the group are, the more effective the group recommendations are.",10.1145/1864708.1864733,https://doi.org/10.1145/1864708.1864733,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Group recommendations with rank aggregation and collaborative filtering,"Baltrunas, Linas and Makcinskas, Tadas and Ricci, Francesco",inproceedings,10.1145/1864708.1864733,
10.1145/1864708.1864737,10.1145/1864708.1864737,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","visual explanation, trust, recommender systems, interaction, cold start",8,143–150,Proceedings of the Fourth ACM Conference on Recommender Systems,"Content-centric social websites, such as discussion forums and blog sites, have flourished during the past several years. These sites often contain overwhelming amounts of information that are also being updated rapidly. To help users locate their interests at such sites (e.g., interesting blogs to read or discussion forums to join), researchers have developed a number of recommendation technologies. However, it is difficult to make effective recommendations for new users (a.k.a. the cold start problem) due to a lack of user information (e.g., preferences and interests). Furthermore, the complexity of recommendation algorithms often prevents users from comprehending let alone trusting the recommended results. To tackle the above two challenges, we are building a social map-based recommender system called Pharos. A social map summarizes users' content-related social behavior over time (e.g., reading, writing, and commenting behavior during the past week) as a set of latent communities. Each community is characterized by the theme of the content being discussed and the key people involved. By discovering, ranking, and displaying the most ""popular"" latent communities, Pharos creates a visual social map of a website. This enables new users to obtain a quick overview of the site, alleviating the cold start problem. Furthermore, we use the social map as a context to help explain Pharos-recommended content and people. Users can also interactively explore the social map to locate their interested content or people that are not being explicitly recommended, compensating for the imperfection in the recommendation algorithms. We have deployed Pharos within our company and our preliminary evaluation shows the usefulness of Pharos.",10.1145/1864708.1864737,https://doi.org/10.1145/1864708.1864737,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Who is talking about what: social map-based recommendation for content-centric social websites,"Zhao, Shiwan and Zhou, Michelle X. and Yuan, Quan and Zhang, Xiatian and Zheng, Wentao and Fu, Rongyao",inproceedings,10.1145/1864708.1864737,
10.1145/1864708.1864755,10.1145/1864708.1864755,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","accuracy, collaborative filtering, computational efficiency, evaluation, sparse data sets",4,233–236,Proceedings of the Fourth ACM Conference on Recommender Systems,"Since the development of the comparably simple neighborhood-based methods in the 1990s, a plethora of techniques has been developed to improve various aspects of collaborative filtering recommender systems like predictive accuracy, scalability to large problem instances or the capability to deal with sparse data sets. Many of the recent algorithms rely on sophisticated methods which are based, for instance, on matrix factorization techniques or advanced probabilistic models and/or require a computationally intensive model-building phase. In this work, we evaluate the accuracy of a new and extremely simple prediction method (RF-Rec) that uses the user's and the item's most frequent rating value to make a rating prediction. The evaluation on three standard test data sets shows that the accuracy of the algorithm is on a par with the standard collaborative filtering algorithms on dense data sets and outperforms them on sparse rating databases. At the same time, the algorithm's implementation is trivial, has a high prediction coverage, requires no complex offline pre-processing or model-building phase and can generate predictions in constant time.",10.1145/1864708.1864755,https://doi.org/10.1145/1864708.1864755,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Recommending based on rating frequencies,"Gedikli, Fatih and Jannach, Dietmar",inproceedings,10.1145/1864708.1864755,
10.1145/1864708.1864759,10.1145/1864708.1864759,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","click through rate, collaborative filtering, evaluation, relevance",4,249–252,Proceedings of the Fourth ACM Conference on Recommender Systems,"Evaluation have been an important subject since the early days of recommender systems. In online test, the click-through rate (CTR) is often adopted as the metric. However, recommended items with higher CTR does not imply higher relevance of two items since factors like item popularity or item serendipity may influence user's click behavior. We argue that the relevance of recommendation system is also desirable in many real applications. Here relevant means relevance in a human perceptible way. Relevant recommendations not only increase the users' trust to the system but are extremely useful for the vast number of anonymous user as their recommendations may only be made based on the current item. In this paper, we empirically examine the relation between the relevance of recommendations and the corresponding CTR with a few representative ItemCF algorithms through online data from a TV show/movie website, Hulu. Experiments show that algorithms with higher overall CTR may not correspond to higher relevance. Thus CTR may not be the optimal metric for online evaluation of recommender systems if producing relevant recommendations is of importance.",10.1145/1864708.1864759,https://doi.org/10.1145/1864708.1864759,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Do clicks measure recommendation relevancy? an empirical user study,"Zheng, Hua and Wang, Dong and Zhang, Qi and Li, Hang and Yang, Tinghao",inproceedings,10.1145/1864708.1864759,
10.1145/1864708.1864764,10.1145/1864708.1864764,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","collaborative filtering, learning to rank, matrix factorization, recommendation, recommender systems",4,269–272,Proceedings of the Fourth ACM Conference on Recommender Systems,"A ranking approach, ListRank-MF, is proposed for collaborative filtering that combines a list-wise learning-to-rank algorithm with matrix factorization (MF). A ranked list of items is obtained by minimizing a loss function that represents the uncertainty between training lists and output lists produced by a MF ranking model. ListRank-MF enjoys the advantage of low complexity and is analytically shown to be linear with the number of observed ratings for a given user-item matrix. We also experimentally demonstrate the effectiveness of ListRank-MF by comparing its performance with that of item-based collaborative recommendation and a related state-of-the-art collaborative ranking approach (CoFiRank).",10.1145/1864708.1864764,https://doi.org/10.1145/1864708.1864764,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,List-wise learning to rank with matrix factorization for collaborative filtering,"Shi, Yue and Larson, Martha and Hanjalic, Alan",inproceedings,10.1145/1864708.1864764,
10.1145/1864708.1864778,10.1145/1864708.1864778,RecSys.bib,1,['RecSys.bib'],8,RecSys '10,"Barcelona, Spain","incremental collaborative filtering, evolutionary algorithm, ensembles, co-clustering",4,325–328,Proceedings of the Fourth ACM Conference on Recommender Systems,"Collaborative filtering is a popular approach for building recommender systems. Current collaborative filtering algorithms are accurate but also computationally expensive, and so are best in static off-line settings. It is desirable to include the new data in a collaborative filtering model in an online manner, requiring a model that can be incrementally updated efficiently. Incremental collaborative filtering via co-clustering has been shown to be a very scalable approach for this purpose. However, locally optimized co-clustering solutions via current fast iterative algorithms give poor accuracy. We propose an evolutionary co-clustering method that improves predictive performance while maintaining the scalability of co-clustering in the online phase.",10.1145/1864708.1864778,https://doi.org/10.1145/1864708.1864778,"New York, NY, USA",Association for Computing Machinery,9781605589060,2010,Incremental collaborative filtering via evolutionary co-clustering,"Khoshneshin, Mohammad and Street, W. Nick",inproceedings,10.1145/1864708.1864778,
10.1145/1871437.1871664,10.1145/1871437.1871664,CIKM.bib,1,['CIKM.bib'],8,CIKM '10,"Toronto, ON, Canada","recommendation system, object typicality",4,1529–1532,Proceedings of the 19th ACM International Conference on Information and Knowledge Management,"Current recommendation methods are mainly classified into content-based, collaborative filtering and hybrid methods. These methods are based on similarity measurements among items or users. In this paper, we investigate recommendation systems from a new perspective based on object typicality and propose a novel typicality-based recommendation approach. Experiments show that our method outperforms compared methods on recommendation quality.",10.1145/1871437.1871664,https://doi.org/10.1145/1871437.1871664,"New York, NY, USA",Association for Computing Machinery,9781450300995,2010,Recommendation based on object typicality,"Cai, Yi and Leung, Ho-fung and Li, Qing and Tang, Jie and Li, Juanzi",inproceedings,10.1145/1871437.1871664,
10.1145/1871437.1871707,10.1145/1871437.1871707,CIKM.bib,1,['CIKM.bib'],8,CIKM '10,"Toronto, ON, Canada","personalized ranking, interests expansion, collaborative filtering",4,1697–1700,Proceedings of the 19th ACM International Conference on Information and Knowledge Management,"In real applications, a given user buys or rates an item based on his/her interests. Learning to leverage this interest information is often critical for recommender systems. However, in existing recommender systems, the information about latent user interests are largely under-explored. To that end, in this paper, we propose an interest expansion strategy via personalized ranking based on the topic model, named iExpand, for building an interest-oriented collaborative filtering framework. The iExpand method introduces a three-layer, user-interest-item, representation scheme, which leads to more interpretable recommendation results and helps the understanding of the interactions among users, items, and user interests. Moreover, iExpand strategically deals with many issues, such as the overspecialization and the cold-start problems. Finally, we evaluate iExpand on benchmark data sets, and experimental results show that iExpand outperforms state-of-the-art methods.",10.1145/1871437.1871707,https://doi.org/10.1145/1871437.1871707,"New York, NY, USA",Association for Computing Machinery,9781450300995,2010,Exploiting user interests for collaborative filtering: interests expansion via personalized ranking,"Liu, Qi and Chen, Enhong and Xiong, Hui and Ding, Chris H.Q.",inproceedings,10.1145/1871437.1871707,
10.1145/1871437.1871734,10.1145/1871437.1871734,CIKM.bib,1,['CIKM.bib'],8,CIKM '10,"Toronto, ON, Canada","user cold start, recommender systems, new user, collaborative filtering",4,1805–1808,Proceedings of the 19th ACM International Conference on Information and Knowledge Management,"Recommender systems perform much better on users for which they have more information. This gives rise to a problem of satisfying users new to a system. The problem is even more acute considering that some of these hard to profile new users judge the unfamiliar system by its ability to immediately provide them with satisfying recommendations, and may be the quickest to abandon the system when disappointed. Rapid profiling of new users is often achieved through a bootstrapping process - a kind of an initial interview - that elicits users to provide their opinions on certain carefully chosen items or categories. This work offers a new bootstrapping method, which is based on a concrete optimization goal, thereby handily outperforming known approaches in our tests.",10.1145/1871437.1871734,https://doi.org/10.1145/1871437.1871734,"New York, NY, USA",Association for Computing Machinery,9781450300995,2010,On bootstrapping recommender systems,"Golbandi, Nadav and Koren, Yehuda and Lempel, Ronny",inproceedings,10.1145/1871437.1871734,
10.1145/1871437.1871739,10.1145/1871437.1871739,CIKM.bib,1,['CIKM.bib'],8,CIKM '10,"Toronto, ON, Canada","text mining, sentiment analysis, rating prediction, opinion mining, aspect extraction",4,1825–1828,Proceedings of the 19th ACM International Conference on Information and Knowledge Management,"Mining customer reviews (opinion mining) has emerged as an interesting new research direction. Most of the reviewing websites such as Epinions.com provide some additional information on top of the review text and overall rating, including a set of predefined aspects and their ratings, and a rating guideline which shows the intended interpretation of the numerical ratings. However, the existing methods have ignored this additional information. We claim that using this information, which is freely available, along with the review text can effectively improve the accuracy of opinion mining. We propose an unsupervised method, called Opinion Digger, which extracts important aspects of a product and determines the overall consumer's satisfaction for each, by estimating a rating in the range from 1 to 5. We demonstrate the improved effectiveness of our methods on a real life dataset that we crawled from Epinions.com.",10.1145/1871437.1871739,https://doi.org/10.1145/1871437.1871739,"New York, NY, USA",Association for Computing Machinery,9781450300995,2010,Opinion digger: an unsupervised opinion miner from unstructured product reviews,"Moghaddam, Samaneh and Ester, Martin",inproceedings,10.1145/1871437.1871739,
10.1145/1871940.1871959,10.1145/1871940.1871959,CIKM.bib,1,['CIKM.bib'],8,DOLAP '10,"Toronto, ON, Canada","recommender systems, recommendation, performance analysis, olap, multidimensional, integration, exploratory data analysis, data warehouse",8,85–92,Proceedings of the ACM 13th International Workshop on Data Warehousing and OLAP,"The integration of OLAP with web-search technologies is a promising research topic. Recommender systems are popular web-search mechanisms, because they can address information overload and provide personalization of results. Nevertheless, the evaluation of recommender systems is a challenging task. In this paper, we propose a novel framework for evaluating recommender systems, which is multidimensional and takes into account for the multiple facets of the recommendation algorithms, data sets and performance measures. Emphasis is placed on supporting business applications of recommender systems, notably e-commerce, by allowing analysts to perform ad-hoc analysis and use popular online analytical processing (OLAP) operations. Combined with support for visual analysis, action such as drill-down or slice/dice allow assessment of the performance of recommendations in terms of business objectives. We describe a detailed methodology for designing and developing the proposed multidimensional framework, and provide insights about its applications. Our experimental results, using a research prototype, demonstrate the ability of the proposed framework to comprise an effective way for evaluating recommender systems.",10.1145/1871940.1871959,https://doi.org/10.1145/1871940.1871959,"New York, NY, USA",Association for Computing Machinery,9781450303835,2010,Integrating OLAP and recommender systems: an evaluation perspective,"Krohn-Grimberghe, Artus and Nanopoulos, Alexandros and Schmidt-Thieme, Lars",inproceedings,10.1145/1871940.1871959,
10.1145/1935826.1935863,10.1145/1935826.1935863,WSDM.bib,1,['WSDM.bib'],8,WSDM '11,"Hong Kong, China","social media, time series clustering",10,177–186,Proceedings of the Fourth ACM International Conference on Web Search and Data Mining,"Online content exhibits rich temporal dynamics, and diverse realtime user generated content further intensifies this process. However, temporal patterns by which online content grows and fades over time, and by which different pieces of content compete for attention remain largely unexplored.We study temporal patterns associated with online content and how the content's popularity grows and fades over time. The attention that content receives on the Web varies depending on many factors and occurs on very different time scales and at different resolutions. In order to uncover the temporal dynamics of online content we formulate a time series clustering problem using a similarity metric that is invariant to scaling and shifting. We develop the K-Spectral Centroid (K-SC) clustering algorithm that effectively finds cluster centroids with our similarity measure. By applying an adaptive wavelet-based incremental approach to clustering, we scale K-SC to large data sets.We demonstrate our approach on two massive datasets: a set of 580 million Tweets, and a set of 170 million blog posts and news media articles. We find that K-SC outperforms the K-means clustering algorithm in finding distinct shapes of time series. Our analysis shows that there are six main temporal shapes of attention of online content. We also present a simple model that reliably predicts the shape of attention by using information about only a small number of participants. Our analyses offer insight into common temporal patterns of the content on theWeb and broaden the understanding of the dynamics of human attention.",10.1145/1935826.1935863,https://doi.org/10.1145/1935826.1935863,"New York, NY, USA",Association for Computing Machinery,9781450304931,2011,Patterns of temporal variation in online media,"Yang, Jaewon and Leskovec, Jure",inproceedings,10.1145/1935826.1935863,
10.1145/1935826.1935895,10.1145/1935826.1935895,WSDM.bib,1,['WSDM.bib'],8,WSDM '11,"Hong Kong, China","collaborative filtering, continuous-time markov process, recommender system",10,455–464,Proceedings of the Fourth ACM International Conference on Web Search and Data Mining,"The research issue of recommender systems has been treated as a classical regression problem over the decades and has obtained a great success. In the next generation of recommender systems, multi-criteria recommendation has been predicted as an important direction. Different from traditional recommender systems that aim particularly at recommending high-quality items evaluated by users' ratings, inmulti-criteria recommendation, quality only serves as one criterion, and many other criteria such as relevance, coverage, and diversity should be simultaneously optimized. Although recently there is work investigating each single criterion, there is rarely any literature that reports how each single criterion impacts each other and how to combine them in real applications. Thus in this paper, we study the relationship of two criteria, quality and relevance, as a preliminary work in multi-criteria recommendation. We first give qualitative and quantitative analysis of competitive quality-based and relevance-based algorithms in these two criteria to show that both algorithms cannot work well in the opposite criteria. Then we propose an integrated metric and finally investigate how to combine previous work together into an unified model. In the combination, we introduce a Continuous-time MArkov Process (CMAP) algorithm for ranking, which enables principled and natural integration with features derived from both quality-based and relevance-based algorithms. Through experimental verification, the combined methods can significantly outperform either single quality-based or relevance-based algorithms in the integrated metric and the CMAP model outperforms traditional combination methods by around 3%. Its linear complexity with respect to the number of users and items leads to satisfactory performance, as demonstrated by the around 7-hour computational time for over 480k users and almost 20k items.",10.1145/1935826.1935895,https://doi.org/10.1145/1935826.1935895,"New York, NY, USA",Association for Computing Machinery,9781450304931,2011,CMAP: effective fusion of quality and relevance for multi-criteria recommendation,"Xin, Xin and Lyu, Michael R. and King, Irwin",inproceedings,10.1145/1935826.1935895,
10.1145/1935826.1935899,10.1145/1935826.1935899,WSDM.bib,1,['WSDM.bib'],8,WSDM '11,"Hong Kong, China","collaborative filtering, matrix factorization, recommender systems, social influence, trust network",10,495–504,Proceedings of the Fourth ACM International Conference on Web Search and Data Mining,"Some popular product review sites such as Epinions allow users to establish a trust network among themselves, indicating who they trust in providing product reviews and ratings. While trust relations have been found to be useful in generating personalised recommendations, the relations between trust and product ratings has so far been overlooked. In this paper, we examine large datasets collected from Epinions and Ciao, two popular product review sites. We discover that in general users who trust each other tend to have smaller differences in their ratings as time passes, giving support to the theories of homophily and social influence. However, we also discover that this does not hold true across all trusted users. A trust relation does not guarantee that two users have similar preferences, implying that personalised recommendations based on trust relations do not necessarily produce more accurate predictions. We propose a method to estimate the strengths of trust relations so as to estimate the true influence among the trusted users. Our method extends the popular matrix factorisation technique for collaborative filtering, which allow us to generate more accurate rating predictions at the same time. We also show that the estimated strengths of trust relations correlate with the similarity among the users. Our work contributes to the understanding of the interplay between trust relations and product ratings, and suggests that trust networks may serve as a more general socialising venue than only an indication of similarity in user preferences.",10.1145/1935826.1935899,https://doi.org/10.1145/1935826.1935899,"New York, NY, USA",Association for Computing Machinery,9781450304931,2011,Strength of social influence in trust networks in product review sites,"Au Yeung, Ching-man and Iwata, Tomoharu",inproceedings,10.1145/1935826.1935899,
10.1145/1935826.1935910,10.1145/1935826.1935910,WSDM.bib,1,['WSDM.bib'],8,WSDM '11,"Hong Kong, China","collaborative filtering, decision tree, new user, recommender systems, user cold start",10,595–604,Proceedings of the Fourth ACM International Conference on Web Search and Data Mining,"Recommender systems perform much better on users for which they have more information. This gives rise to a problem of satisfying users new to a system. The problem is even more acute considering that some of these hard to profile new users judge the unfamiliar system by its ability to immediately provide them with satisfying recommendations, and may quickly abandon the system when disappointed. Rapid profiling of new users by a recommender system is often achieved through a bootstrapping process - a kind of an initial interview - that elicits users to provide their opinions on certain carefully chosen items or categories. The elicitation process becomes particularly effective when adapted to users' responses, making best use of users' time by dynamically modifying the questions to improve the evolving profile. In particular, we advocate a specialized version of decision trees as the most appropriate tool for this task. We detail an efficient tree learning algorithm, specifically tailored to the unique properties of the problem. Several extensions to the tree construction are also introduced, which enhance the efficiency and utility of the method. We implemented our methods within a movie recommendation service. The experimental study delivered encouraging results, with the tree-based bootstrapping process significantly outperforming previous approaches.",10.1145/1935826.1935910,https://doi.org/10.1145/1935826.1935910,"New York, NY, USA",Association for Computing Machinery,9781450304931,2011,Adaptive bootstrapping of recommender systems using decision trees,"Golbandi, Nadav and Koren, Yehuda and Lempel, Ronny",inproceedings,10.1145/1935826.1935910,
10.1145/1935826.1935925,10.1145/1935826.1935925,WSDM.bib,1,['WSDM.bib'],8,WSDM '11,"Hong Kong, China","keywords youtube, popularity growth, referrer, video popularity",10,745–754,Proceedings of the Fourth ACM International Conference on Web Search and Data Mining,"Understanding content popularity growth is of great importance to Internet service providers, content creators and online marketers. In this work, we characterize the growth patterns of video popularity on the currently most popular video sharing application, namely YouTube. Using newly provided data by the application, we analyze how the popularity of individual videos evolves since the video's upload time. Moreover, addressing a key aspect that has been mostly overlooked by previous work, we characterize the types of the referrers that most often attracted users to each video, aiming at shedding some light into the mechanisms (e.g., searching or external linking) that often drive users towards a video, and thus contribute to popularity growth. Our analyses are performed separately for three video datasets, namely, videos that appear in the YouTube top lists, videos removed from the system due to copyright violation, and videos selected according to random queries submitted to YouTube's search engine. Our results show that popularity growth patterns depend on the video dataset. In particular, copyright protected videos tend to get most of their views much earlier in their lifetimes, often exhibiting a popularity growth characterized by a viral epidemic-like propagation process. In contrast, videos in the top lists tend to experience sudden significant bursts of popularity. We also show that not only search but also other YouTube internal mechanisms play important roles to attract users to videos in all three datasets.",10.1145/1935826.1935925,https://doi.org/10.1145/1935826.1935925,"New York, NY, USA",Association for Computing Machinery,9781450304931,2011,The tube over time: characterizing popularity growth of youtube videos,"Figueiredo, Flavio and Benevenuto, Fabr\'{\i}cio and Almeida, Jussara M.",inproceedings,10.1145/1935826.1935925,
10.1145/1963192.1963346,10.1145/1963192.1963346,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '11,"Hyderabad, India","web 2.0, rapidshare, performance, measurement, file hosting services, cyberlockers",6,373–378,Proceedings of the 20th International Conference Companion on World Wide Web,"Cyberlocker Services (CLS) such as RapidShare and Megaupload have recently become popular. The decline of Peer-to-Peer (P2P) file sharing has prompted various services including CLS to replace it. We propose a comprehensive multi-level characterization of the CLS ecosystem. We answer three research questions: (a) what is a suitable measurement infrastructure for gathering CLS workloads; (b) what are the characteristics of the CLS ecosystem; and (c) what are the implications of CLS on Web 2.0 (and the Internet). To the best of our knowledge, this work is the first to characterize the CLS ecosystem. The work will highlight the content, usage, performance, infrastructure, quality of service, and evolution characteristics of CLS.",10.1145/1963192.1963346,https://doi.org/10.1145/1963192.1963346,"New York, NY, USA",Association for Computing Machinery,9781450306379,2011,Measurement and analysis of cyberlocker services,"Mahanti, Aniket",inproceedings,10.1145/1963192.1963346,
10.1145/1963405.1963471,10.1145/1963405.1963471,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '11,"Hyderabad, India","online social networks, information propagation, content delivery networks",10,457–466,Proceedings of the 20th International Conference on World Wide Web,"Providers such as YouTube offer easy access to multimedia content to millions, generating high bandwidth and storage demand on the Content Delivery Networks they rely upon. More and more, the diffusion of this content happens on online social networks such as Facebook and Twitter, where social cascades can be observed when users increasingly repost links they have received from others.In this paper we describe how geographic information extracted from social cascades can be exploited to improve caching of multimedia files in a Content Delivery Network. We take advantage of the fact that social cascades can propagate in a geographically limited area to discern whether an item is spreading locally or globally. This informs cache replacement policies, which utilize this information to ensure that content relevant to a cascade is kept close to the users who may be interested in it.We validate our approach by using a novel dataset which combines social interaction data with geographic information: we track social cascades of YouTube links over Twitter and build a proof-of-concept geographic model of a realistic distributed Content Delivery Network. Our performance evaluation shows that we are able to improve cache hits with respect to cache policies without geographic and social information.",10.1145/1963405.1963471,https://doi.org/10.1145/1963405.1963471,"New York, NY, USA",Association for Computing Machinery,9781450306324,2011,"Track globally, deliver locally: improving content delivery networks by tracking geographic social cascades","Scellato, Salvatore and Mascolo, Cecilia and Musolesi, Mirco and Crowcroft, Jon",inproceedings,10.1145/1963405.1963471,
10.1145/1963405.1963505,10.1145/1963405.1963505,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '11,"Hyderabad, India","twitter, short urls, online social networks",10,715–724,Proceedings of the 20th International Conference on World Wide Web,"Short URLs have become ubiquitous. Especially popular within social networking services, short URLs have seen a significant increase in their usage over the past years, mostly due to Twitter's restriction of message length to 140 characters. In this paper, we provide a first characterization on the usage of short URLs. Specifically, our goal is to examine the content short URLs point to, how they are published, their popularity and activity over time, as well as their potential impact on the performance of the web.Our study is based on traces of short URLs as seen from two different perspectives: i) collected through a large-scale crawl of URL shortening services, and ii) collected by crawling Twitter messages. The former provides a general characterization on the usage of short URLs, while the latter provides a more focused view on how certain communities use shortening services. Our analysis highlights that domain and website popularity, as seen from short URLs, significantly differs from the distributions provided by well publicised services such as Alexa. The set of most popular websites pointed to by short URLs appears stable over time, despite the fact that short URLs have a limited high popularity lifetime. Surprisingly short URLs are not ephemeral, as a significant fraction, roughly 50%, appears active for more than three months. Overall, our study emphasizes the fact that short URLs reflect an ""alternative"" web and, hence, provide an additional view on web usage and content consumption complementing traditional measurement sources. Furthermore, our study reveals the need for alternative shortening architectures that will eliminate the non-negligible performance penalty imposed by today's shortening services.",10.1145/1963405.1963505,https://doi.org/10.1145/1963405.1963505,"New York, NY, USA",Association for Computing Machinery,9781450306324,2011,we.b: the web of short urls,"Antoniades, Demetris and Polakis, Iasonas and Kontaxis, Georgios and Athanasopoulos, Elias and Ioannidis, Sotiris and Markatos, Evangelos P. and Karagiannis, Thomas",inproceedings,10.1145/1963405.1963505,
10.1145/2020408.2020435,10.1145/2020408.2020435,KDD.bib,1,['KDD.bib'],8,KDD '11,"San Diego, California, USA","click shaping, constrained optimization, multi-objective",9,132–140,Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Recommending interesting content to engage users is important for web portals (e.g. AOL, MSN, Yahoo!, and many others). Existing approaches typically recommend articles to optimize for a single objective, i.e., number of clicks. However a click is only the starting point of a user's journey and subsequent downstream utilities such as time-spent and revenue are important. In this paper, we call the problem of recommending links to jointly optimize for clicks and post-click downstream utilities click shaping. We propose a multi-objective programming approach in which multiple objectives are modeled in a constrained optimization framework. Such a formulation can naturally incorporate various application-driven requirements. We study several variants that model different requirements as constraints and discuss some of the subtleties involved. We conduct our experiments on a large dataset from a real system by using a newly proposed unbiased evaluation methodology [17]. Through extensive experiments we quantify the tradeoff between different objectives under various constraints. Our experimental results show interesting characteristics of different formulations and our findings may provide valuable guidance to the design of recommendation engines for web portals.",10.1145/2020408.2020435,https://doi.org/10.1145/2020408.2020435,"New York, NY, USA",Association for Computing Machinery,9781450308137,2011,Click shaping to optimize multiple objectives,"Agarwal, Deepak and Chen, Bee-Chung and Elango, Pradheep and Wang, Xuanhui",inproceedings,10.1145/2020408.2020435,
10.1145/2020408.2020436,10.1145/2020408.2020436,KDD.bib,1,['KDD.bib'],8,KDD '11,"San Diego, California, USA","collaborative filtering, hierarchies, response prediction",9,141–149,Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"In online advertising, response prediction is the problem of estimating the probability that an advertisement is clicked when displayed on a content publisher's webpage. In this paper, we show how response prediction can be viewed as a problem of matrix completion, and propose to solve it using matrix factorization techniques from collaborative filtering (CF). We point out the two crucial differences between standard CF problems and response prediction, namely the requirement of predicting probabilities rather than scores, and the issue of confidence in matrix entries. We address these issues using a matrix factorization analogue of logistic regression, and by applying a principled confidence-weighting scheme to its objective. We show how this factorization can be seamlessly combined with explicit features or side-information for pages and ads, which let us combine the benefits of both approaches. Finally, we combat the extreme sparsity of response prediction data by incorporating hierarchical information about the pages and ads into our factorization model. Experiments on three very large real-world datasets show that our model outperforms current state-of-the-art methods for response prediction.",10.1145/2020408.2020436,https://doi.org/10.1145/2020408.2020436,"New York, NY, USA",Association for Computing Machinery,9781450308137,2011,Response prediction using collaborative filtering with hierarchies and side-information,"Menon, Aditya Krishna and Chitrapura, Krishna-Prasad and Garg, Sachin and Agarwal, Deepak and Kota, Nagaraj",inproceedings,10.1145/2020408.2020436,
10.1145/2020408.2020439,10.1145/2020408.2020439,KDD.bib,1,['KDD.bib'],8,KDD '11,"San Diego, California, USA","bias removal, hierarchical smoothing, latent factor model, tensor factorization, text quality",9,159–167,Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Reputable users are valuable assets of a web site. We focus on user reputation in a comment rating environment, where users make comments about content items and rate the comments of one another. Intuitively, a reputable user posts high quality comments and is highly rated by the user community. To our surprise, we find that the quality of a comment judged editorially is almost uncorrelated with the ratings that it receives, but can be predicted using standard text features, achieving accuracy as high as the agreement between two editors! However, extracting a pure reputation signal from ratings is difficult because of data sparseness and several confounding factors in users' voting behavior. To address these issues, we propose a novel bias-smoothed tensor model and empirically show that our model significantly outperforms a number of alternatives based on Yahoo! News, Yahoo! Buzz and Epinions datasets.",10.1145/2020408.2020439,https://doi.org/10.1145/2020408.2020439,"New York, NY, USA",Association for Computing Machinery,9781450308137,2011,User reputation in a comment rating environment,"Chen, Bee-Chung and Guo, Jian and Tseng, Belle and Yang, Jie",inproceedings,10.1145/2020408.2020439,
10.1145/2020408.2020504,10.1145/2020408.2020504,KDD.bib,1,['KDD.bib'],8,KDD '11,"San Diego, California, USA","data fusion, epinions, kalman filter, meta-analysis, recommender systems",9,609–617,Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Combining correlated information from multiple contexts can significantly improve predictive accuracy in recommender problems. Such information from multiple contexts is often available in the form of several incomplete matrices spanning a set of entities like users, items, features, and so on. Existing methods simultaneously factorize these matrices by sharing a single set of factors for entities across all contexts. We show that such a strategy may introduce significant bias in estimates and propose a new model that ameliorates this issue by positing local, context-specific factors for entities. To avoid over-fitting in contexts with sparse data, the local factors are connected through a shared global model. This sharing of parameters allows information to flow across contexts through multivariate regressions among local factors, instead of enforcing exactly the same factors for an entity, everywhere. Model fitting is done in an EM framework, we show that the E-step can be fitted through a fast multi-resolution Kalman filter algorithm that ensures scalability. Experiments on benchmark and real-world Yahoo! datasets clearly illustrate the usefulness of our approach. Our model significantly improves predictive accuracy, especially in cold-start scenarios.",10.1145/2020408.2020504,https://doi.org/10.1145/2020408.2020504,"New York, NY, USA",Association for Computing Machinery,9781450308137,2011,Localized factor models for multi-context recommendation,"Agarwal, Deepak and Chen, Bee-Chung and Long, Bo",inproceedings,10.1145/2020408.2020504,
10.1145/2020408.2020505,10.1145/2020408.2020505,KDD.bib,1,['KDD.bib'],8,KDD '11,"San Diego, California, USA","aspect identification, latent rating analysis, review mining",9,618–626,Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Mining detailed opinions buried in the vast amount of review text data is an important, yet quite challenging task with widespread applications in multiple domains. Latent Aspect Rating Analysis (LARA) refers to the task of inferring both opinion ratings on topical aspects (e.g., location, service of a hotel) and the relative weights reviewers have placed on each aspect based on review content and the associated overall ratings. A major limitation of previous work on LARA is the assumption of pre-specified aspects by keywords. However, the aspect information is not always available, and it may be difficult to pre-define appropriate aspects without a good knowledge about what aspects are actually commented on in the reviews.In this paper, we propose a unified generative model for LARA, which does not need pre-specified aspect keywords and simultaneously mines 1) latent topical aspects, 2) ratings on each identified aspect, and 3) weights placed on different aspects by a reviewer. Experiment results on two different review data sets demonstrate that the proposed model can effectively perform the Latent Aspect Rating Analysis task without the supervision of aspect keywords. Because of its generality, the proposed model can be applied to explore all kinds of opinionated text data containing overall sentiment judgments and support a wide range of interesting application tasks, such as aspect-based opinion summarization, personalized entity ranking and recommendation, and reviewer behavior analysis.",10.1145/2020408.2020505,https://doi.org/10.1145/2020408.2020505,"New York, NY, USA",Association for Computing Machinery,9781450308137,2011,Latent aspect rating analysis without aspect keyword supervision,"Wang, Hongning and Lu, Yue and Zhai, ChengXiang",inproceedings,10.1145/2020408.2020505,
10.1145/2020408.2020568,10.1145/2020408.2020568,KDD.bib,1,['KDD.bib'],8,KDD '11,"San Diego, California, USA","cost-aware recommendation, matrix factorization",9,983–991,Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Advances in tourism economics have enabled us to collect massive amounts of travel tour data. If properly analyzed, this data can be a source of rich intelligence for providing real-time decision making and for the provision of travel tour recommendations. However, tour recommendation is quite different from traditional recommendations, because the tourist's choice is directly affected by the travel cost, which includes the financial cost and the time. To that end, in this paper, we provide a focused study of cost-aware tour recommendation. Along this line, we develop two cost-aware latent factor models to recommend travel packages by considering both the travel cost and the tourist's interests. Specifically, we first design a cPMF model, which models the tourist's cost with a 2-dimensional vector. Also, in this cPMF model, the tourist's interests and the travel cost are learnt by exploring travel tour data. Furthermore, in order to model the uncertainty in the travel cost, we further introduce a Gaussian prior into the cPMF model and develop the GcPMF model, where the Gaussian prior is used to express the uncertainty of the travel cost. Finally, experiments on real-world travel tour data show that the cost-aware recommendation models outperform state-of-the-art latent factor models with a significant margin. Also, the GcPMF model with the Gaussian prior can better capture the impact of the uncertainty of the travel cost, and thus performs better than the cPMF model.",10.1145/2020408.2020568,https://doi.org/10.1145/2020408.2020568,"New York, NY, USA",Association for Computing Machinery,9781450308137,2011,Cost-aware travel tour recommendation,"Ge, Yong and Liu, Qi and Xiong, Hui and Tuzhilin, Alexander and Chen, Jian",inproceedings,10.1145/2020408.2020568,
10.1145/2043932.2043941,10.1145/2043932.2043941,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","collaborative filtering, recommender systems, topic models",8,21–28,Proceedings of the Fifth ACM Conference on Recommender Systems,"We propose a bayesian probabilistic model for explicit preference data. The model introduces a generative process, which takes into account both item selection and rating emission to gather into communities those users who experience the same items and tend to adopt the same rating pattern. Each user is modeled as a random mixture of topics, where each topic is characterized by a distribution modeling the popularity of items within the respective user-community and by a distribution over preference values for those items. The proposed model can be associated with a novel item-relevance ranking criterion, which is based both on item popularity and user's preferences. We show that the proposed model, equipped with the new ranking criterion, outperforms state-of-art approaches in terms of accuracy of the recommendation list provided to users on standard benchmark datasets.",10.1145/2043932.2043941,https://doi.org/10.1145/2043932.2043941,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Modeling item selection and relevance for accurate recommendations: a bayesian approach,"Barbieri, Nicola and Costa, Gianni and Manco, Giuseppe and Ortale, Riccardo",inproceedings,10.1145/2043932.2043941,
10.1145/2043932.2043942,10.1145/2043932.2043942,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","recommender, neighborhood boosting, differential privacy, collaborative filtering",8,29–36,Proceedings of the Fifth ACM Conference on Recommender Systems,"Traditional collaborative filtering (CF) methods suffer from sparse or even cold-start problems, especially for new established recommenders. However, since there are now quite a few recommender systems already existing in good working order, their data should be valuable to the new-start recommenders. This paper proposes shared collaborative filtering approach to leverage the data from other parties (contributor party) to improve own (beneficiary party's) CF performance, and at the same time the privacy of other parties cannot be compromised. Item neighborhood list is chosen as the shared data from the contributor party with considering differential privacy. And an innovative algorithm called neighborhood boosting is proposed to make the beneficiary party leverage the shared data. MovieLens and Netflix data sets are considered as two parties to simulate and evaluate the proposed shared CF approach. The experiment results validate the positive effects of shared CF for increasing the recommendation accuracy of the beneficiary party. Especially when the beneficiary party's data is quite sparse, the performance can be increased by around 10%. The experiments also show that shared CF even outperforms the methods that incorporate the detailed original rating scores of the contributor party without considering the privacy issues. The proposed shared CF approach obtains a win-win situation for both performance and privacy.",10.1145/2043932.2043942,https://doi.org/10.1145/2043932.2043942,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Shared collaborative filtering,"Zhao, Yu and Feng, Xinping and Li, Jianqiang and Liu, Bo",inproceedings,10.1145/2043932.2043942,
10.1145/2043932.2043946,10.1145/2043932.2043946,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","clustering, link prediction, social recommendation, stochastic block model",8,53–60,Proceedings of the Fifth ACM Conference on Recommender Systems,"The rapidly increasing availability of online social networks and the well-known effect of social influence have motivated research on social-network based recommenders. Social influence and selection together lead to the formation of communities of like-minded and well connected users. Exploiting the clustering of users and items is one of the most important approaches for model-based recommendation. Users may belong to multiple communities or groups, but only a few clustering algorithms allow clusters to overlap. One of these algorithms is the probabilistic EM clustering method, which assumes that data is generated from a mixture of Gaussian models. The mixed membership stochastic block model (MMB) transfers the idea of EM clustering from conventional, non-relational data to social network data. In this paper, we introduce a generalized stochastic blockmodel (GSBM) that models not only the social relations but also the rating behavior. This model learns the mixed group membership assignments for both users and items in an SRN. GSBM can predict the future behavior of users, both the rating of items and creation of links to other users. We performed experiments on two real life datasets from Epinions.com and Flixster.com, demonstrating the accuracy of the proposed GSBM for rating prediction as well as link prediction.",10.1145/2043932.2043946,https://doi.org/10.1145/2043932.2043946,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,A generalized stochastic block model for recommendation in social rating networks,"Jamali, Mohsen and Huang, Tianle and Ester, Martin",inproceedings,10.1145/2043932.2043946,
10.1145/2043932.2043947,10.1145/2043932.2043947,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","recommender systems, social networks",8,61–68,Proceedings of the Fifth ACM Conference on Recommender Systems,"Online Social Rating Networks (SRNs) such as Epinions and Flixter, allow users to form several implicit social networks, through their daily interactions like co-commenting on the same products, or similarly co-rating products. The majority of earlier work in Rating Prediction and Recommendation of products (e.g. Collaborative Filtering) mainly takes into account ratings of users on products. However, in SRNs users can also built their explicit social network by adding each other as friends. In this paper, we propose Social-Union, a method which combines similarity matrices derived from heterogeneous (unipartite and bipartite) explicit or implicit SRNs. Moreover, we propose an effective weighting strategy of SRNs influence based on their structured density. We also generalize our model for combining multiple social networks. We perform an extensive experimental comparison of the proposed method against existing rating prediction and product recommendation algorithms, using synthetic and two real data sets (Epinions and Flixter). Our experimental results show that our Social-Union algorithm is more effective in predicting rating and recommending products in SRNs.",10.1145/2043932.2043947,https://doi.org/10.1145/2043932.2043947,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Product recommendation and rating prediction based on multi-modal social networks,"Symeonidis, Panagiotis and Tiakas, Eleftherios and Manolopoulos, Yannis",inproceedings,10.1145/2043932.2043947,
10.1145/2043932.2043948,10.1145/2043932.2043948,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","distributed system, recommendation system",8,69–76,Proceedings of the Fifth ACM Conference on Recommender Systems,"Recommender systems predict user preferences based on a range of available information. For systems in which users generate streams of content (e.g., blogs, periodically-updated newsfeeds), users may rate the produced content that they read, and be given accurate predictions about future content they are most likely to prefer. We design a distributed mechanism for predicting user ratings that avoids the disclosure of information to a centralized authority or an untrusted third party: users disclose the rating they give to certain content only to the user that produced this content.We demonstrate how rating prediction in this context can be formulated as a matrix factorization problem. Using this intuition, we propose a distributed gradient descent algorithm for its solution that abides with the above restriction on how information is exchanged between users. We formally analyse the convergence properties of this algorithm, showing that it reduces a weighted root mean square error of the accuracy of predictions. Although our algorithm may be used many different ways, we evaluate it on the Neflix data set and prediction problem as a benchmark. In addition to the improved privacy properties that stem from its distributed nature, our algorithm is competitive with current centralized solutions. Finally, we demonstrate the algorithm's fast convergence in practice by conducting an online experiment with a prototype user-generated content exchange system implemented as a Facebook application.",10.1145/2043932.2043948,https://doi.org/10.1145/2043932.2043948,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Distributed rating prediction in user generated content streams,"Isaacman, Sibren and Ioannidis, Stratis and Chaintreau, Augustin and Martonosi, Margaret",inproceedings,10.1145/2043932.2043948,
10.1145/2043932.2043951,10.1145/2043932.2043951,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","trust, purchasing behavior, diversity, context, accuracy",8,85–92,Proceedings of the Fifth ACM Conference on Recommender Systems,"Despite the growing popularity of Context-Aware Recommender Systems (CARSs), only limited work has been done on how contextual recommendations affect the behavior of customers in real-life settings. In this paper, we study the effects of contextual recommendations on the purchasing behavior of customers and their trust in the provided recommendations. In particular, we did live controlled experiments with real customers of a major commercial Italian retailer in which we compared the customers' purchasing behavior and measured their trust in the provided recommendations across the contextual, content-based and random recommendations. As a part of this study, we have investigated the role of accuracy and diversity of recommendations on customers' behavior and their trust in the provided recommendations for the three types of RSes. We have demonstrated that the context-aware RS outperformed the other two RSes in terms of accuracy, trust and other economics-based performance metrics across most of our experimental settings.",10.1145/2043932.2043951,https://doi.org/10.1145/2043932.2043951,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,The effect of context-aware recommendations on customer purchasing behavior and trust,"Gorgoglione, Michele and Panniello, Umberto and Tuzhilin, Alexander",inproceedings,10.1145/2043932.2043951,
10.1145/2043932.2043952,10.1145/2043932.2043952,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","usage log, recommender systems, random walks, multidimensional, implicit feedback, context-awareness, context-aware recommender systems",8,93–100,Proceedings of the Fifth ACM Conference on Recommender Systems,"In many applications, flexibility of recommendation, which is the capability of handling multiple dimensions and various recommendation types, is very important. In this paper, we focus on the flexibility of recommendation and propose a graph-based multidimensional recommendation method. We consider the problem as an entity ranking problem on the graph which is constructed using an implicit feedback dataset (e.g. music listening log), and we adapt Personalized PageRank algorithm to rank entities according to a given query that is represented as a set of entities in the graph. Our model has advantages in that not only can it support the flexibility, but also it can take advantage of exploiting indirect relationships in the graph so that it can perform competitively with the other existing recommendation methods without suffering from the sparsity problem.",10.1145/2043932.2043952,https://doi.org/10.1145/2043932.2043952,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Random walk based entity ranking on graph for multidimensional recommendation,"Lee, Sangkeun and Song, Sang-il and Kahng, Minsuk and Lee, Dongjoo and Lee, Sang-goo",inproceedings,10.1145/2043932.2043952,
10.1145/2043932.2043955,10.1145/2043932.2043955,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","recommender systems, novelty, metrics, evaluation, diversity",8,109–116,Proceedings of the Fifth ACM Conference on Recommender Systems,"The Recommender Systems community is paying increasing attention to novelty and diversity as key qualities beyond accuracy in real recommendation scenarios. Despite the raise of interest and work on the topic in recent years, we find that a clear common methodological and conceptual ground for the evaluation of these dimensions is still to be consolidated. Different evaluation metrics have been reported in the literature but the precise relation, distinction or equivalence between them has not been explicitly studied. Furthermore, the metrics reported so far miss important properties such as taking into consideration the ranking of recommended items, or whether items are relevant or not, when assessing the novelty and diversity of recommendations.We present a formal framework for the definition of novelty and diversity metrics that unifies and generalizes several state of the art metrics. We identify three essential ground concepts at the roots of novelty and diversity: choice, discovery and relevance, upon which the framework is built. Item rank and relevance are introduced through a probabilistic recommendation browsing model, building upon the same three basic concepts. Based on the combination of ground elements, and the assumptions of the browsing model, different metrics and variants unfold. We report experimental observations which validate and illustrate the properties of the proposed metrics.",10.1145/2043932.2043955,https://doi.org/10.1145/2043932.2043955,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Rank and relevance in novelty and diversity metrics for recommender systems,"Vargas, Sa\'{u}l and Castells, Pablo",inproceedings,10.1145/2043932.2043955,
10.1145/2043932.2043957,10.1145/2043932.2043957,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA",recommender systems,8,125–132,Proceedings of the Fifth ACM Conference on Recommender Systems,"Recommendations from the long tail of the popularity distribution of items are generally considered to be particularly valuable. On the other hand, recommendation accuracy tends to decrease towards the long tail. In this paper, we quantitatively examine this trade-off between item popularity and recommendation accuracy. To this end, we assume that there is a selection bias towards popular items in the available data. This allows us to define a new accuracy measure that can be gradually tuned towards the long tail. We show that, under this assumption, this measure has the desirable property of providing nearly unbiased estimates concerning recommendation accuracy. In turn, this also motivates a refinement for training collaborative-filtering approaches. In various experiments with real-world data, including a user study, empirical evidence suggests that only a small, if any, bias of the recommendations towards less popular items is appreciated by users.",10.1145/2043932.2043957,https://doi.org/10.1145/2043932.2043957,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Item popularity and recommendation accuracy,"Steck, Harald",inproceedings,10.1145/2043932.2043957,
10.1145/2043932.2043964,10.1145/2043932.2043964,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","recommender systems, matrix factorization, collaborative filtering, Yahoo! music",8,165–172,Proceedings of the Fifth ACM Conference on Recommender Systems,"In the past decade large scale recommendation datasets were published and extensively studied. In this work we describe a detailed analysis of a sparse, large scale dataset, specifically designed to push the envelope of recommender system models. The Yahoo! Music dataset consists of more than a million users, 600 thousand musical items and more than 250 million ratings, collected over a decade. It is characterized by three unique features: First, rated items are multi-typed, including tracks, albums, artists and genres; Second, items are arranged within a four level taxonomy, proving itself effective in coping with a severe sparsity problem that originates from the unusually large number of items (compared to, e.g., movie ratings datasets). Finally, fine resolution timestamps associated with the ratings enable a comprehensive temporal and session analysis. We further present a matrix factorization model exploiting the special characteristics of this dataset. In particular, the model incorporates a rich bias model with terms that capture information from the taxonomy of items and different temporal dynamics of music ratings. To gain additional insights of its properties, we organized the KddCup-2011 competition about this dataset. As the competition drew thousands of participants, we expect the dataset to attract considerable research activity in the future.",10.1145/2043932.2043964,https://doi.org/10.1145/2043932.2043964,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Yahoo! music recommendations: modeling music ratings with temporal dynamics and item taxonomy,"Koenigstein, Noam and Dror, Gideon and Koren, Yehuda",inproceedings,10.1145/2043932.2043964,
10.1145/2043932.2043969,10.1145/2043932.2043969,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","user similarity, recommender system, personality, collaborative filtering, cold start",8,197–204,Proceedings of the Fifth ACM Conference on Recommender Systems,"Collaborative filtering (CF), one of the most successful recommendation approaches, continues to attract interest in both academia and industry. However, one key issue limiting the success of collaborative filtering in certain application domains is the cold-start problem, a situation where historical data is too sparse (known as the sparsity problem), new users have not rated enough items (known as the new user problem), or both. In this paper, we aim at addressing the cold-start problem by incorporating human personality into the collaborative filtering framework. We propose three approaches: the first is a recommendation method based on users' personality information alone; the second is based on a linear combination of both personality and rating information; and the third uses a cascade mechanism to leverage both resources. To evaluate their effectiveness, we have conducted an experimental study comparing the proposed approaches with the traditional rating-based CF in two cold-start scenarios: sparse data sets and new users. Our results show that the proposed CF variations, which consider personality characteristics, can significantly improve the performance of the traditional rating-based CF in terms of the evaluation metrics MAE and ROC sensitivity.",10.1145/2043932.2043969,https://doi.org/10.1145/2043932.2043969,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Enhancing collaborative filtering systems with personality information,"Hu, Rong and Pu, Pearl",inproceedings,10.1145/2043932.2043969,
10.1145/2043932.2043970,10.1145/2043932.2043970,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","social networks, new item problem, influence spread",8,205–212,Proceedings of the Fifth ACM Conference on Recommender Systems,"In this paper we propose a market-based approach for seeding recommendations for new items in which publishers bid to have items presented to the most influential users for each item. Users are able to select (or not) items for rating on an earn-per-rating basis, with payment given for providing a rating regardless of whether the rating is positive or negative. This approach reduces the time taken to obtain ratings for new items, while encouraging users to give honest ratings (to increase their influence) which in turn supports the quality of recommendations. To support this approach we propose techniques for inferring the social influence network from users' rating vectors and recommendation lists. Using this influence network we apply existing heuristics for estimating a user's influence, adapting them to account for the new items already presented to a user. We also propose an extension to Chen et al.'s Degree Discount heuristic [Chen et al. 2009], to enable it to be used in this context. We evaluate our approach on the MovieLens dataset and show that we are able to reduce the time taken to achieve coverage, while supporting the quality of recommendations.",10.1145/2043932.2043970,https://doi.org/10.1145/2043932.2043970,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,A market-based approach to address the new item problem,"Anand, Sarabjot Singh and Griffiths, Nathan",inproceedings,10.1145/2043932.2043970,
10.1145/2043932.2043973,10.1145/2043932.2043973,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","usage-based recommendations, similarity computation, recommender systems",8,229–236,Proceedings of the Fifth ACM Conference on Recommender Systems,"In item-based collaborative filtering, a critical intermediate step to personalized recommendations is the definition of an item-similarity metric. Existing algorithms compute the item-similarity using the user-to-item ratings (cosine, Pearson, Jaccard, etc.). When computing the similarity between two items A and B many of these algorithms divide the actual number of co-occurring users by some ""difficulty"" of co-occurrence. We refine this approach by defining item similarity as the ratio of the actual number of co-occurrences to the number of co-occurrences that would be expected if user choices were random. In the final step of our method to compute personalized recommendations we apply the usage history of a user to the item similarity matrix. The well defined probabilistic meaning of our similarities allows us to further improve this final step. We measured the quality of our algorithm on a large real-world data-set. As part of Comcast's efforts to improve its personalized recommendations of movies and TV shows, several top recommender companies were invited to apply their algorithms to one year of Video-on-Demand usage data. Our algorithm tied for first place. This paper includes a MapReduce pseudo code implementation of our algorithm.",10.1145/2043932.2043973,https://doi.org/10.1145/2043932.2043973,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,A probabilistic definition of item similarity,"Jojic, Oliver and Shukla, Manu and Bhosarekar, Niranjan",inproceedings,10.1145/2043932.2043973,
10.1145/2043932.2043975,10.1145/2043932.2043975,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","social relationships, regularization, membership, friendship, factorization",8,245–252,Proceedings of the Fifth ACM Conference on Recommender Systems,"Collaborative Filtering (CF) based recommender systems often suffer from the sparsity problem, particularly for new and inactive users when they use the system. The emerging trend of social networking sites and their accommodation in other sites like e-commerce can potentially help alleviate the sparsity problem with their provided social relation data. In this paper, we have particularly explored a new kind of social relation, the membership, and its combined effect with friendship. The two type of heterogeneous social relations are fused into the CF recommender via a factorization process. Due to the two relations' respective properties, we adopt different fusion strategies: regularization was leveraged for friendship and collective matrix factorization (CMF) was proposed for incorporating membership. We further developed a unified model to combine the two relations together and tested it with real large-scale datasets at five sparsity levels. The experiment has not only revealed the significant effect of the two relations, especially the membership, in augmenting recommendation accuracy in the sparse data condition, but also identified the ability of our fusing model in achieving the desired fusion performance.",10.1145/2043932.2043975,https://doi.org/10.1145/2043932.2043975,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Factorization vs. regularization: fusing heterogeneous social relationships in top-n recommendation,"Yuan, Quan and Chen, Li and Zhao, Shiwan",inproceedings,10.1145/2043932.2043975,
10.1145/2043932.2043978,10.1145/2043932.2043978,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","social network, recommender system, collaborative filtering",4,257–260,Proceedings of the Fifth ACM Conference on Recommender Systems,"Collaborative filtering (CF) is an effective recommendation technique, which selects items for an individual user based on similar users' preferences. However, CF may not fully reflect the procedure how people choose an item in real life, for users are more likely to ask friends for opinions instead of asking similar strangers. Recently, some recommendation methods based on social network have been raised. These approaches incorporate social network into the CF algorithms and users' preferences can be influenced by the favors of their friends. These social approaches require the knowledge of similarities among friends. There are two popular similarity functions: Vector Space Similarity (VSS) and Pearson Correlation Coefficient (PCC). However, both friends similarity functions are based on the item-sets they rated in common. In most cases, these functions are impractical, i.e. if two friends do not share the same items in common, the similarity between them will be zeros. To solve this problem, we propose an Adaptive Social Similarity (ASS) function based on the matrix factorization technique. We conduct our experiment on a large dataset: Epinions, which is a widely-used dataset with social information. The experiment results illustrate that our approach outperforms the baseline models and achieves a better performance than social-based method in [4].",10.1145/2043932.2043978,https://doi.org/10.1145/2043932.2043978,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Adaptive social similarities for recommender systems,"Yu, Le and Pan, Rong and Li, Zhangfeng",inproceedings,10.1145/2043932.2043978,
10.1145/2043932.2043983,10.1145/2043932.2043983,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","collaborative filtering, collective training",4,281–284,Proceedings of the Fifth ACM Conference on Recommender Systems,"Rating sparsity is a critical issue for collaborative filtering. For example, the well-known Netflix Movie rating data contain ratings of only about 1% user-item pairs. One way to address this rating sparsity problem is to develop more effective methods for training rating prediction models. To this end, in this paper, we introduce a collective training paradigm to automatically and effectively augment the training ratings. Essentially, the collective training paradigm builds multiple different Collaborative Filtering (CF) models separately, and augments the training ratings of each CF model by using the partial predictions of other CF models for unknown ratings. Along this line, we develop two algorithms, Bi-CF and Tri-CF, based on collective training. For Bi-CF and Tri-CF, we collectively and iteratively train two and three different CF models via iteratively augmenting training ratings for individual CF model. We also design different criteria to guide the selection of augmented training ratings for Bi-CF and Tri-CF. Finally, the experimental results show that Bi-CF and Tri-CF algorithms can significantly outperform baseline methods, such as neighborhood-based and SVD-based models.",10.1145/2043932.2043983,https://doi.org/10.1145/2043932.2043983,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Collaborative filtering with collective training,"Ge, Yong and Xiong, Hui and Tuzhilin, Alexander and Liu, Qi",inproceedings,10.1145/2043932.2043983,
10.1145/2043932.2043984,10.1145/2043932.2043984,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","recommender systems, collaborative filtering, cold start problem, Wikipedia",4,285–288,Proceedings of the Fifth ACM Conference on Recommender Systems,One important challenge in the field of recommender systems is the sparsity of available data. This problem limits the ability of recommender systems to provide accurate predictions of user ratings. We overcome this problem by using the publicly available user generated information contained in Wikipedia. We identify similarities between items by mapping them to Wikipedia pages and finding similarities in the text and commonalities in the links and categories of each page. These similarities can be used in the recommendation process and improve ranking predictions. We find that this method is most effective in cases where ratings are extremely sparse or nonexistent. Preliminary experimental results on the MovieLens dataset are encouraging.,10.1145/2043932.2043984,https://doi.org/10.1145/2043932.2043984,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Using Wikipedia to boost collaborative filtering techniques,"Katz, Gilad and Ofek, Nir and Shapira, Bracha and Rokach, Lior and Shani, Guy",inproceedings,10.1145/2043932.2043984,
10.1145/2043932.2043988,10.1145/2043932.2043988,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","collaborative filtering, context-based reasoning, matrix factorization, recommender systems",4,301–304,Proceedings of the Fifth ACM Conference on Recommender Systems,"Context aware recommender systems (CARS) adapt the recommendations to the specific situation in which the items will be consumed. In this paper we present a novel context-aware recommendation algorithm that extends Matrix Factorization. We model the interaction of the contextual factors with item ratings introducing additional model parameters. The performed experiments show that the proposed solution provides comparable results to the best, state of the art, and more complex approaches. The proposed solution has the advantage of smaller computational cost and provides the possibility to represent at different granularities the interaction between context and items. We have exploited the proposed model in two recommendation applications: places of interest and music.",10.1145/2043932.2043988,https://doi.org/10.1145/2043932.2043988,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Matrix factorization techniques for context aware recommendation,"Baltrunas, Linas and Ludwig, Bernd and Ricci, Francesco",inproceedings,10.1145/2043932.2043988,
10.1145/2043932.2043989,10.1145/2043932.2043989,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","e-commerce, open source, personalization",4,305–308,Proceedings of the Fifth ACM Conference on Recommender Systems,"MyMediaLite is a fast and scalable, multi-purpose library of recommender system algorithms, aimed both at recommender system researchers and practitioners. It addresses two common scenarios in collaborative filtering: rating prediction (e.g. on a scale of 1 to 5 stars) and item prediction from positive-only implicit feedback (e.g. from clicks or purchase actions). The library offers state-of-the-art algorithms for those two tasks. Programs that expose most of the library's functionality, plus a GUI demo, are included in the package. Efficient data structures and a common API are used by the implemented algorithms, and may be used to implement further algorithms. The API also contains methods for real-time updates and loading/storing of already trained recommender models.MyMediaLite is free/open source software, distributed under the terms of the GNU General Public License (GPL). Its methods have been used in four different industrial field trials of the MyMedia project, including one trial involving over 50,000 households.",10.1145/2043932.2043989,https://doi.org/10.1145/2043932.2043989,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,MyMediaLite: a free recommender system library,"Gantner, Zeno and Rendle, Steffen and Freudenthaler, Christoph and Schmidt-Thieme, Lars",inproceedings,10.1145/2043932.2043989,
10.1145/2043932.2043990,10.1145/2043932.2043990,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","matrix factorization, time-aware evaluation, time-aware recommender systems",4,309–312,Proceedings of the Fifth ACM Conference on Recommender Systems,"The use of temporal dynamic terms in Matrix Factorization (MF) models of recommendation have been proposed as a means to obtain better accuracy in rating prediction task. However, the way such models have been tested may not be a realistic setting for recommendation. In this paper, we evaluated rating prediction and top-N recommendation tasks using a MF model with and without temporal dynamic terms under two evaluation settings. Our experiments show that the addition of dynamic parameters do not necessarily yield to better results on these tasks when a more strict time-aware separation of train/test data is performed, and moreover, results may vary notably when different evaluation schemes are used.",10.1145/2043932.2043990,https://doi.org/10.1145/2043932.2043990,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Towards a more realistic evaluation: testing the ability to predict future tastes of matrix factorization-based recommenders,"Campos, Pedro G. and D\'{\i}ez, Fernando and S\'{a}nchez-Monta\~{n}\'{e}s, Manuel",inproceedings,10.1145/2043932.2043990,
10.1145/2043932.2044009,10.1145/2043932.2044009,RecSys.bib,1,['RecSys.bib'],8,RecSys '11,"Chicago, Illinois, USA","hybrid recommender system, performance prediction, query clarity, recommender systems",4,371–374,Proceedings of the Fifth ACM Conference on Recommender Systems,"Performance prediction has gained growing attention in the Information Retrieval field since the late nineties and has become an established research topic in the field. Our work restates the problem in the area of Recommender Systems, where it has barely been researched so far, despite being an appealing problem, as it enables an array of strategies for deciding when to deliver or hold back recommendations based on their foreseen accuracy. We investigate the adaptation and definition of different performance predictors based on the available user and item features. The properties of the predictor are empirically studied by checking the correlation of the predictor output with a performance measure. Then, we propose to introduce the performance predictor in a recommender system to produce a dynamic strategy. Depending on how the predictor is introduced we analyze two different problems: dynamic neighbor weighting in collaborative filtering and dynamic weighting of ensemble recommenders.",10.1145/2043932.2044009,https://doi.org/10.1145/2043932.2044009,"New York, NY, USA",Association for Computing Machinery,9781450306836,2011,Predicting performance in recommender systems,"Bellogin, Alejandro",inproceedings,10.1145/2043932.2044009,
10.1145/2063576.2063680,10.1145/2063576.2063680,CIKM.bib,1,['CIKM.bib'],8,CIKM '11,"Glasgow, Scotland, UK","user modelling, topic models, recommender systems",10,699–708,Proceedings of the 20th ACM International Conference on Information and Knowledge Management,"Collaborative filtering systems based on ratings make it easier for users to find content of interest on the Web and as such they constitute an area of much research. In this paper we first present a Bayesian latent variable model for rating prediction that models ratings over each user's latent interests and also each item's latent topics. We describe a Gibbs sampling procedure that can be used to estimate its parameters and show by experiment that it is competitive with the gradient descent SVD methods commonly used in state-of-the-art systems. We then proceed to make an important and novel extension to this model, enhancing it with user-dependent and item-dependant biases to significantly improve rating estimation. We show by experiment on a large set of real ratings data that these models are able to outperform 3 common baselines, including a very competitive and modern SVD-based model. Furthermore we illustrate other advantages of our approach beyond simply its ability to provide more accurate ratings and show that it is able to perform better on the common and important case where the user profile is short.",10.1145/2063576.2063680,https://doi.org/10.1145/2063576.2063680,"New York, NY, USA",Association for Computing Machinery,9781450307178,2011,Bayesian latent variable models for collaborative item rating prediction,"Harvey, Morgan and Carman, Mark J. and Ruthven, Ian and Crestani, Fabio",inproceedings,10.1145/2063576.2063680,
10.1145/2063576.2063915,10.1145/2063576.2063915,CIKM.bib,1,['CIKM.bib'],8,CIKM '11,"Glasgow, Scotland, UK","social media analysis, popularity prediction, brand pages",4,2157–2160,Proceedings of the 20th ACM International Conference on Information and Knowledge Management,"In this paper, we deal with the problem of predicting how much attention a newly submitted post would receive from fellow community members of closed communities in social networking sites. Though the concept of attention is subjective, the number of comments received by a post serves as a very good indicator of the same. Unlike previous work which primarily made use of either content features or the network features (friendship links on the network), we exploit both the content features and community level features (for instance, what time of the day is the community more active) for tackling this problem. Further, we focus on dedicated pages of corporate brands on social media websites and accordingly extract important features from the content and community activity of such brand pages. The attention prediction task finds direct application in the listening, monitoring and engaging activities of the businesses that have such brand-pages. In this paper, we formulate the problem of attention prediction on social media brand pages.We further propose Attention Prediction (AP) framework which integrates the various features that influence the attention received by a post using classification and regression based approaches. Experimental results on real world data extracted from some highly active brand pages on Facebook demonstrate the efficacy of the proposed framework.",10.1145/2063576.2063915,https://doi.org/10.1145/2063576.2063915,"New York, NY, USA",Association for Computing Machinery,9781450307178,2011,Attention prediction on social media brand pages,"Lakkaraju, Himabindu and Ajmera, Jitendra",inproceedings,10.1145/2063576.2063915,
10.1145/2063576.2063938,10.1145/2063576.2063938,CIKM.bib,1,['CIKM.bib'],8,CIKM '11,"Glasgow, Scotland, UK","tensor factorization, review recommendation, personalized review quality prediction, matrix factorization",4,2249–2252,Proceedings of the 20th ACM International Conference on Information and Knowledge Management,"The problem of identifying high quality and helpful reviews automatically has attracted many attention recently. Current methods assume that the helpfulness of a review is independent from the readers of that review. However, we argue that the quality of a review may not be the same for different users. In this paper, we employ latent factor models to address this problem. We evaluate the proposed models using a real life database from Epinions.com. The experiments demonstrate that the latent factor models outperform the state-of-the-art approaches and confirms that the helpfulness of a review is indeed not the same for all users.",10.1145/2063576.2063938,https://doi.org/10.1145/2063576.2063938,"New York, NY, USA",Association for Computing Machinery,9781450307178,2011,Review recommendation: personalized prediction of the quality of online reviews,"Moghaddam, Samaneh and Jamali, Mohsen and Ester, Martin",inproceedings,10.1145/2063576.2063938,
10.1145/2124295.2124309,10.1145/2124295.2124309,WSDM.bib,1,['WSDM.bib'],8,WSDM '12,"Seattle, Washington, USA","heterogeneous trust, multi-dimension tie strength, multi-faceted trust, trust network",10,93–102,Proceedings of the Fifth ACM International Conference on Web Search and Data Mining,"Traditionally, research about trust assumes a single type of trust between users. However, trust, as a social concept, inherently has many facets indicating multiple and heterogeneous trust relationships between users. Due to the presence of a large trust network for an online user, it is necessary to discern multi-faceted trust as there are naturally experts of different types. Our study in product review sites reveals that people place trust differently to different people. Since the widely used adjacency matrix cannot capture multi-faceted trust relationships between users, we propose a novel approach by incorporating these relationships into traditional rating prediction algorithms to reliably estimate their strengths. Our work results in interesting findings such as heterogeneous pairs of reciprocal links. Experimental results on real-world data from Epinions and Ciao show that our work of discerning multi-faceted trust can be applied to improve the performance of tasks such as rating prediction, facet-sensitive ranking, and status theory.",10.1145/2124295.2124309,https://doi.org/10.1145/2124295.2124309,"New York, NY, USA",Association for Computing Machinery,9781450307475,2012,mTrust: discerning multi-faceted trust in a connected world,"Tang, Jiliang and Gao, Huiji and Liu, Huan",inproceedings,10.1145/2124295.2124309,
10.1145/2124295.2124316,10.1145/2124295.2124316,WSDM.bib,1,['WSDM.bib'],8,WSDM '12,"Seattle, Washington, USA","matrix factorization, personalized review quality prediction, review recommendation, tensor factorization",10,163–172,Proceedings of the Fifth ACM International Conference on Web Search and Data Mining,"Online reviews are valuable sources of information for a variety of decision-making processes such as purchasing products. As the number of online reviews is growing rapidly, it becomes increasingly difficult for users to identify those that are helpful. This has motivated research into the problem of identifying high quality and helpful reviews automatically. The current methods assume that the helpfulness of a review is independent from the readers of that review. However, we argue that the quality of a review may not be the same for different users. For example, a professional and an amateur photographer may rate the helpfulness of a review very differently. In this paper, we introduce the problem of predicting a personalized review quality for recommendation of helpful reviews. To address this problem, we propose a series of increasingly sophisticated probabilistic graphical models, based on Matrix Factorization and Tensor Factorization. We evaluate the proposed models using a database of 1.5 million reviews and more than 13 million quality ratings obtained from Epinions.com. The experiments demonstrate that the proposed latent factor models outperform the state-of-the art approaches using textual and social features. Finally, our experiments confirm that the helpfulness of a review is indeed not the same for all users and that there are some latent factors that affect a user's evaluation of the review quality.",10.1145/2124295.2124316,https://doi.org/10.1145/2124295.2124316,"New York, NY, USA",Association for Computing Machinery,9781450307475,2012,ETF: extended tensor factorization model for personalizing prediction of review helpfulness,"Moghaddam, Samaneh and Jamali, Mohsen and Ester, Martin",inproceedings,10.1145/2124295.2124316,
10.1145/2124295.2124317,10.1145/2124295.2124317,WSDM.bib,1,['WSDM.bib'],8,WSDM '12,"Seattle, Washington, USA","cold-start, item prediction, item recommendation, joint factorization, matrix factorization, multi-relational learning, ranking, recommender systems, social network",10,173–182,Proceedings of the Fifth ACM International Conference on Web Search and Data Mining,"A key element of the social networks on the internet such as Facebook and Flickr is that they encourage users to create connections between themselves, other users and objects.One important task that has been approached in the literature that deals with such data is to use social graphs to predict user behavior (e.g. joining a group of interest). More specifically, we study the cold-start problem, where users only participate in some relations, which we will call social relations, but not in the relation on which the predictions are made, which we will refer to as target relations.We propose a formalization of the problem and a principled approach to it based on multi-relational factorization techniques. Furthermore, we derive a principled feature extraction scheme from the social data to extract predictors for a classifier on the target relation. Experiments conducted on real world datasets show that our approach outperforms current methods.",10.1145/2124295.2124317,https://doi.org/10.1145/2124295.2124317,"New York, NY, USA",Association for Computing Machinery,9781450307475,2012,Multi-relational matrix factorization using bayesian personalized ranking for social network data,"Krohn-Grimberghe, Artus and Drumond, Lucas and Freudenthaler, Christoph and Schmidt-Thieme, Lars",inproceedings,10.1145/2124295.2124317,
10.1145/2124295.2124365,10.1145/2124295.2124365,WSDM.bib,1,['WSDM.bib'],8,WSDM '12,"Seattle, Washington, USA","posterior evaluation, social influence, word-of-mouth recommendation",10,573–582,Proceedings of the Fifth ACM International Conference on Web Search and Data Mining,"Word-of-mouth has proven an effective strategy for promoting products through social relations. Particularly, existing studies have convincingly demonstrated that word-of-mouth recommendations can boost users' prior expectation and hence encourage them to adopt a certain innovation, such as buying a book or watching a movie. However, less attention has been paid to studying the posterior effect of word-of-mouth recommendations, i.e., whether or not word-of-mouth recommendations can influence users' posterior evaluation on the products or services recommended to them, the answer to which is critical to estimating user satisfaction when proposing a word-of-mouth marketing strategy. In order to fill this gap, in this paper we empirically study the above issue and verify that word-of-mouth recommendations are strongly associated with users' posterior evaluation. Through elaborately designed statistical hypothesis tests we prove the causality that word-of-mouth recommendations directly prompt the posterior evaluation of receivers. Finally, we propose a method for investigating users' social influence, namely, their ability to affect followers' posterior evaluation via word-of-mouth recommendations, by examining the number of their followers and their sensitivity of discovering good items. The experimental results on real datasets show that our method can successfully identify 78% influential friends with strong social influence.",10.1145/2124295.2124365,https://doi.org/10.1145/2124295.2124365,"New York, NY, USA",Association for Computing Machinery,9781450307475,2012,Exploring social influence via posterior effect of word-of-mouth recommendations,"Huang, Junming and Cheng, Xue-Qi and Shen, Hua-Wei and Zhou, Tao and Jin, Xiaolong",inproceedings,10.1145/2124295.2124365,
10.1145/2124295.2124370,10.1145/2124295.2124370,WSDM.bib,1,['WSDM.bib'],8,WSDM '12,"Seattle, Washington, USA","conformer, generative model, maverick, popular ranking",10,623–632,Proceedings of the Fifth ACM International Conference on Web Search and Data Mining,"Prediction of popular items in online content sharing systems has recently attracted a lot of attention due to the tremendous need of users and its commercial values. Different from previous works that make prediction by fitting a popularity growth model, we tackle this problem by exploiting the latent conforming and maverick personalities of those who vote to assess the quality of on-line items. We argue that the former personality prompts a user to cast her vote conforming to the majority of the service community while on the contrary the later personality makes her vote different from the community. We thus propose a Conformer-Maverick (CM) model to simulate the voting process and use it to rank top-k potentially popular items based on the early votes they received. Through an extensive experimental evaluation, we validate our ideas and find that our proposed CM model achieves better performance than baseline solutions, especially for smaller k.",10.1145/2124295.2124370,https://doi.org/10.1145/2124295.2124370,"New York, NY, USA",Association for Computing Machinery,9781450307475,2012,A straw shows which way the wind blows: ranking potentially popular items from early votes,"Yin, Peifeng and Luo, Ping and Wang, Min and Lee, Wang-Chien",inproceedings,10.1145/2124295.2124370,
10.1145/2187836.2187838,10.1145/2187836.2187838,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12,"Lyon, France","music recommendation, internet radio, collaborative filtering",10,1–10,Proceedings of the 21st International Conference on World Wide Web,"In the Internet music scene, where recommendation technology is key for navigating huge collections, large market players enjoy a considerable advantage. Accessing a wider pool of user feedback leads to an increasingly more accurate analysis of user tastes, effectively creating a ""rich get richer"" effect. This work aims at significantly lowering the entry barrier for creating music recommenders, through a paradigm coupling a public data source and a new collaborative filtering (CF) model. We claim that Internet radio stations form a readily available resource of abundant fresh human signals on music through their playlists, which are essentially cohesive sets of related tracks. In a way, our models rely on the knowledge of a diverse group of experts in lieu of the commonly used wisdom of crowds. Over several weeks, we aggregated publicly available playlists of thousands of Internet radio stations, resulting in a dataset encompassing millions of plays, and hundreds of thousands of tracks and artists. This provides the large scale ground data necessary to mitigate the cold start problem of new items at both mature and emerging services.Furthermore, we developed a new probabilistic CF model, tailored to the Internet radio resource. The success of the model was empirically validated on the collected dataset. Moreover, we tested the model at a cross-source transfer learning manner -- the same model trained on the Internet radio data was used to predict behavior of Yahoo! Music users. This demonstrates the ability to tap the Internet radio signals in other music recommendation setups. Based on encouraging empirical results, our hope is that the proposed paradigm will make quality music recommendation accessible to all interested parties in the community.",10.1145/2187836.2187838,https://doi.org/10.1145/2187836.2187838,"New York, NY, USA",Association for Computing Machinery,9781450312295,2012,Build your own music recommender by modeling internet radio streams,"Aizenberg, Natalie and Koren, Yehuda and Somekh, Oren",inproceedings,10.1145/2187836.2187838,
10.1145/2187836.2187839,10.1145/2187836.2187839,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12,"Lyon, France","temporal analysis, recommender systems, control theory",10,11–20,Proceedings of the 21st International Conference on World Wide Web,"The aim of a web-based recommender system is to provide highly accurate and up-to-date recommendations to its users; in practice, it will hope to retain its users over time. However, this raises unique challenges. To achieve complex goals such as keeping the recommender model up-to-date over time, we need to consider a number of external requirements. Generally, these requirements arise from the physical nature of the system, for instance the available computational resources. Ideally, we would like to design a system that does not deviate from the required outcome. Modeling such a system over time requires to describe the internal dynamics as a combination of the underlying recommender model and the its users' behavior. We propose to solve this problem by applying the principles of modern control theory - a powerful set of tools to deal with dynamical systems - to construct and maintain a stable and robust recommender system for dynamically evolving environments. In particular, we introduce a design principle by focusing on the dynamic relationship between the recommender system's performance and the number of new training samples the system requires. This enables us to automate the control other external factors such as the system's update frequency. We show that, by using a Proportional-Integral-Derivative controller, a recommender system is able to automatically and accurately estimate the required input to keep the output close to a pre-defined requirements. Our experiments on a standard rating dataset show that, by using a feedback loop between system performance and training, the trade-off between the effectiveness and efficiency of the system can be well maintained. We close by discussing the widespread applicability of our approach to a variety of scenarios that recommender systems face.",10.1145/2187836.2187839,https://doi.org/10.1145/2187836.2187839,"New York, NY, USA",Association for Computing Machinery,9781450312295,2012,Using control theory for stable and efficient recommender systems,"Jambor, Tamas and Wang, Jun and Lathia, Neal",inproceedings,10.1145/2187836.2187839,
10.1145/2187836.2187870,10.1145/2187836.2187870,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12,"Lyon, France","social content diffusion, online video sharing, geographic popularity analysis",10,241–250,Proceedings of the 21st International Conference on World Wide Web,"One of the most popular user activities on the Web is watching videos. Services like YouTube, Vimeo, and Hulu host and stream millions of videos, providing content that is on par with TV. While some of this content is popular all over the globe, some videos might be only watched in a confined, local region.In this work we study the relationship between popularity and locality of online YouTube videos. We investigate whether YouTube videos exhibit geographic locality of interest, with views arising from a confined spatial area rather than from a global one. Our analysis is done on a corpus of more than 20 millions YouTube videos, uploaded over one year from different regions. We find that about 50% of the videos have more than 70% of their views in a single region. By relating locality to viralness we show that social sharing generally widens the geographic reach of a video. If, however, a video cannot carry its social impulse over to other means of discovery, it gets stuck in a more confined geographic region. Finally, we analyze how the geographic properties of a video's views evolve on a daily basis during its lifetime, providing new insights on how the geographic reach of a video changes as its popularity peaks and then fades away.Our results demonstrate how, despite the global nature of the Web, online video consumption appears constrained by geographic locality of interest: this has a potential impact on a wide range of systems and applications, spanning from delivery networks to recommendation and discovery engines, providing new directions for future research.",10.1145/2187836.2187870,https://doi.org/10.1145/2187836.2187870,"New York, NY, USA",Association for Computing Machinery,9781450312295,2012,YouTube around the world: geographic popularity of videos,"Brodersen, Anders and Scellato, Salvatore and Wattenhofer, Mirjam",inproceedings,10.1145/2187836.2187870,
10.1145/2187836.2187871,10.1145/2187836.2187871,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12,"Lyon, France","online social networks, micro-blogging, content analysis",10,251–260,Proceedings of the 21st International Conference on World Wide Web,"Micro-blogging systems such as Twitter expose digital traces of social discourse with an unprecedented degree of resolution of individual behaviors. They offer an opportunity to investigate how a large-scale social system responds to exogenous or endogenous stimuli, and to disentangle the temporal, spatial and topical aspects of users' activity. Here we focus on spikes of collective attention in Twitter, and specifically on peaks in the popularity of hashtags. Users employ hashtags as a form of social annotation, to define a shared context for a specific event, topic, or meme. We analyze a large-scale record of Twitter activity and find that the evolution of hashtag popularity over time defines discrete classes of hashtags. We link these dynamical classes to the events the hashtags represent and use text mining techniques to provide a semantic characterization of the hashtag classes. Moreover, we track the propagation of hashtags in the Twitter social network and find that epidemic spreading plays a minor role in hashtag popularity, which is mostly driven by exogenous factors.",10.1145/2187836.2187871,https://doi.org/10.1145/2187836.2187871,"New York, NY, USA",Association for Computing Machinery,9781450312295,2012,Dynamical classes of collective attention in twitter,"Lehmann, Janette and Gon\c{c}alves, Bruno and Ramasco, Jos\'{e} J. and Cattuto, Ciro",inproceedings,10.1145/2187836.2187871,
10.1145/2187836.2187894,10.1145/2187836.2187894,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12,"Lyon, France","multi-objective ranking, hodge decomposition, active learning",10,419–428,Proceedings of the 21st International Conference on World Wide Web,"With the explosion of information on any topic, the need for ranking is becoming very critical. Ranking typically depends on several aspects. Products, for example, have several aspects like price, recency, rating, etc. Product ranking has to bring the ""best"" product which is recent and highly rated. Hence ranking has to satisfy multiple objectives. In this paper, we explore multi-objective ranking of comments using Hodge decomposition. While Hodge decomposition produces a globally consistent ranking, a globally inconsistent component is also present. We propose an active learning strategy for the reduction of this component. Finally, we develop techniques for online Hodge decomposition. We experimentally validate the ideas presented in this paper.",10.1145/2187836.2187894,https://doi.org/10.1145/2187836.2187894,"New York, NY, USA",Association for Computing Machinery,9781450312295,2012,Multi-objective ranking of comments on web,"Dalal, Onkar and Sengemedu, Srinivasan H. and Sanyal, Subhajit",inproceedings,10.1145/2187836.2187894,
10.1145/2187836.2187895,10.1145/2187836.2187895,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12,"Lyon, France","user generated content, recommendation system, personalization, latent factor models, comment recommendation, collaborative filtering",10,429–438,Proceedings of the 21st International Conference on World Wide Web,"Many websites provide commenting facilities for users to express their opinions or sentiments with regards to content items, such as, videos, news stories, blog posts, etc. Previous studies have shown that user comments contain valuable information that can provide insight on Web documents and may be utilized for various tasks. This work presents a model that predicts, for a given user, suitable news stories for commenting. The model achieves encouraging results regarding the ability to connect users with stories they are likely to comment on. This provides grounds for personalized recommendations of stories to users who may want to take part in their discussion. We combine a content-based approach with a collaborative-filtering approach (utilizing users' co-commenting patterns) in a latent factor modeling framework. We experiment with several variations of the model's loss function in order to adjust it to the problem domain. We evaluate the results on two datasets and show that employing co-commenting patterns improves upon using content features alone, even with as few as two available comments per story. Finally, we try to incorporate available social network data into the model. Interestingly, the social data does not lead to substantial performance gains, suggesting that the value of social data for this task is quite negligible.",10.1145/2187836.2187895,https://doi.org/10.1145/2187836.2187895,"New York, NY, USA",Association for Computing Machinery,9781450312295,2012,Care to comment? recommendations for commenting on news stories,"Shmueli, Erez and Kagian, Amit and Koren, Yehuda and Lempel, Ronny",inproceedings,10.1145/2187836.2187895,
10.1145/2187836.2187896,10.1145/2187836.2187896,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12,"Lyon, France","visual aesthetics modeling, user comments, sentiment analysis, opinion mining, image search reranking",10,439–448,Proceedings of the 21st International Conference on World Wide Web,"The increasing number of images available online has created a growing need for efficient ways to search for relevant content. Text-based query search is the most common approach to retrieve images from the Web. In this approach, the similarity between the input query and the metadata of images is used to find relevant information. However, as the amount of available images grows, the number of relevant images also increases, all of them sharing very similar metadata but differing in other visual characteristics. This paper studies the influence of visual aesthetic quality in search results as a complementary attribute to relevance. By considering aesthetics, a new ranking parameter is introduced aimed at improving the quality at the top ranks when large amounts of relevant results exist. Two strategies for aesthetic rating inference are proposed: one based on visual content, another based on the analysis of user comments to detect opinions about the quality of images. The results of a user study with $58$ participants show that the comment-based aesthetic predictor outperforms the visual content-based strategy, and reveals that aesthetic-aware rankings are preferred by users searching for photographs on the Web.",10.1145/2187836.2187896,https://doi.org/10.1145/2187836.2187896,"New York, NY, USA",Association for Computing Machinery,9781450312295,2012,Leveraging user comments for aesthetic aware image search reranking,"San Pedro, Jose and Yeh, Tom and Oliver, Nuria",inproceedings,10.1145/2187836.2187896,
10.1145/2187980.2188077,10.1145/2187980.2188077,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12 Companion,"Lyon, France","temporal dynamics, online audience, long tail, catch up TV",2,461–462,Proceedings of the 21st International Conference on World Wide Web,"This paper studies the demand for TV contents on online catch up platforms, in order to assess how catch up TV offers transform TV consumption. We build upon empirical data on French TV consumption in June 2011: a daily monitoring of online audience on web catch up platforms, and live audience ratings of traditional broadcast TV. We provide three main results: 1) online consumption is more concentrated than off-line audience, contradicting the hypothesis of a long tail effect of catch up TV; 2) the temporality of replay TV consumption on the web is very close to the live broadcasting of the programs, thus softening rather than breaking the synchrony of traditional TV; 3) detailed data on online consumption of news reveals two patterns of consumption (""alternative TV ritual"" vs. ""\`{a} la carte"").",10.1145/2187980.2188077,https://doi.org/10.1145/2187980.2188077,"New York, NY, USA",Association for Computing Machinery,9781450312301,2012,Audience dynamics of online catch up TV,"Beauvisage, Thomas and Beuscart, Jean-Samuel",inproceedings,10.1145/2187980.2188077,
10.1145/2187980.2188215,10.1145/2187980.2188215,TheWebConf.bib,1,['TheWebConf.bib'],7,WWW '12 Companion,"Lyon, France","tags, music recommender systems, mobile services, context awareness",2,865–866,Proceedings of the 21st International Conference on World Wide Web,,10.1145/2187980.2188215,https://doi.org/10.1145/2187980.2188215,"New York, NY, USA",Association for Computing Machinery,9781450312301,2012,Context-aware music recommender systems: workshop keynote abstract,"Ricci, Francesco",inproceedings,10.1145/2187980.2188215,
10.1145/2187980.2188259,10.1145/2187980.2188259,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12 Companion,"Lyon, France","video game, twitch.tv, starcraft ii, social community, ranking, popularity prediction, e-sport",8,1181–1188,Proceedings of the 21st International Conference on World Wide Web,"""Electronic-sport"" (E-Sport) is now established as a new entertainment genre. More and more players enjoy streaming their games, which attract even more viewers. In fact, in a recent social study, casual players were found to prefer watching professional gamers rather than playing the game themselves. Within this context, advertising provides a significant source of revenue to the professional players, the casters (displaying other people's games) and the game streaming platforms. For this paper, we crawled, during more than 100 days, the most popular among such specialized platforms: Twitch.tv. Thanks to these gigabytes of data, we propose a first characterization of a new Web community, and we show, among other results, that the number of viewers of a streaming session evolves in a predictable way, that audience peaks of a game are explainable and that a Condorcet method can be used to sensibly rank the streamers by popularity. Last but not least, we hope that this paper will bring to light the study of E-Sport and its growing community. They indeed deserve the attention of industrial partners (for the large amount of money involved) and researchers (for interesting problems in social network dynamics, personalized recommendation, sentiment analysis, etc.).",10.1145/2187980.2188259,https://doi.org/10.1145/2187980.2188259,"New York, NY, USA",Association for Computing Machinery,9781450312301,2012,"Watch me playing, i am a professional: a first study on video game live streaming","Kaytoue, Mehdi and Silva, Arlei and Cerf, Lo\""{\i}c and Meira, Wagner and Ra\""{\i}ssi, Chedy",inproceedings,10.1145/2187980.2188259,
10.1145/2187980.2188262,10.1145/2187980.2188262,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '12 Companion,"Lyon, France","purchase dynamics, group deals, collective attention",8,1205–1212,Proceedings of the 21st International Conference on World Wide Web,"We present a study of the group purchasing behavior of daily deals in Groupon and LivingSocial and formulate a predictive dynamic model of collective attention for group buying behavior. Using large data sets from both Groupon and LivingSocial we show how the model is able to predict the success of group deals as a function of time.We find that Groupon deals are easier to predict accurately earlier in the deal lifecycle than LivingSocial deals due to the total number of deal purchases saturating quicker. One possible explanation for this is that the incentive to socially propagate a deal is based on an individual threshold in LivingSocial, whereas in Groupon it is based on a collective threshold which is reached very early. Furthermore, the personal benefit of propagating a deal is greater in LivingSocial.",10.1145/2187980.2188262,https://doi.org/10.1145/2187980.2188262,"New York, NY, USA",Association for Computing Machinery,9781450312301,2012,Collective attention and the dynamics of group deals,"Ye, Mao and Sandholm, Thomas and Wang, Chunyan and Aperjis, Christina and Huberman, Bernardo A.",inproceedings,10.1145/2187980.2188262,
10.1145/2237827.2237831,10.1145/2237827.2237831,KDD.bib,1,['KDD.bib'],6,MDMKDD '11,"San Diego, California",,9,,Proceedings of the Eleventh International Workshop on Multimedia Data Mining,"User-generated content (UGC) systems such as Twitter, Face-book, and YouTube are quickly becoming the dominant form of information exchange on the web: shifting informational power from media conglomerates to individual users. Understanding the popularity trends in UGC content has proven problematic as traditional content popularity techniques (e.g. those developed for television) are not suited for the disparate origins and ephemeral lifecycle of UGC. Content-based trend detection with UGC systems has been an intensely growing field of research in recent years, yet surprisingly, there is no single method or approach that can be used to track and compare trends in user posts across multiple UGC sources. Therefore, in this work, we develop a standard system for detecting emerging trends in user posts for UGC that contains some form of textual data. We demonstrate the use and implementation of this system through a case study with approximately 2 million YouTube video posts. Furthermore, to help facilitate future comparative studies in UGC trend analysis, we have made this system open-source and straightforward to integrate with various UGC systems (Twitter, Facebook, Flickr, Digg, Blogger, etc.).",10.1145/2237827.2237831,https://doi.org/10.1145/2237827.2237831,"New York, NY, USA",Association for Computing Machinery,9781450308410,2011,What's trending? mining topical trends in UGC systems with YouTube as a case study,"Reed, Colorado and Elvers, Todd and Srinivasan, Padmini",inproceedings,10.1145/2237827.2237831,4
10.1145/2339530.2339552,10.1145/2339530.2339552,KDD.bib,1,['KDD.bib'],8,KDD '12,"Beijing, China","mining social media data, temporal language models, topic transition modeling",9,123–131,Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Latent topic analysis has emerged as one of the most effective methods for classifying, clustering and retrieving textual data. However, existing models such as Latent Dirichlet Allocation (LDA) were developed for static corpora of relatively large documents. In contrast, much of the textual content on the web, and especially social media, is temporally sequenced, and comes in short fragments, including microblog posts on sites such as Twitter and Weibo, status updates on social networking sites such as Facebook and LinkedIn, or comments on content sharing sites such as YouTube. In this paper we propose a novel topic model, Temporal-LDA or TM-LDA, for efficiently mining text streams such as a sequence of posts from the same author, by modeling the topic transitions that naturally arise in these data. TM-LDA learns the transition parameters among topics by minimizing the prediction error on topic distribution in subsequent postings. After training, TM-LDA is thus able to accurately predict the expected topic distribution in future posts. To make these predictions more efficient for a realistic online setting, we develop an efficient updating algorithm to adjust the topic transition parameters, as new documents stream in. Our empirical results, over a corpus of over 30 million microblog posts, show that TM-LDA significantly outperforms state-of-the-art static LDA models for estimating the topic distribution of new documents over time. We also demonstrate that TM-LDA is able to highlight interesting variations of common topic transitions, such as the differences in the work-life rhythm of cities, and factors associated with area-specific problems and complaints.",10.1145/2339530.2339552,https://doi.org/10.1145/2339530.2339552,"New York, NY, USA",Association for Computing Machinery,9781450314626,2012,TM-LDA: efficient online modeling of latent topic transitions in social media,"Wang, Yu and Agichtein, Eugene and Benzi, Michele",inproceedings,10.1145/2339530.2339552,
10.1145/2339530.2339563,10.1145/2339530.2339563,KDD.bib,1,['KDD.bib'],8,KDD '12,"Beijing, China","PCA, evaluation, mobile application, recommender system, sparse data",9,204–212,Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"The Netflix competition of 2006 [2] has spurred significant activity in the recommendations field, particularly in approaches using latent factor models [3,5,8,12] However, the near ubiquity of the Netflix and the similar MovieLens datasets1 may be narrowing the generality of lessons learned in this field. At GetJar, our goal is to make appealing recommendations of mobile applications (apps). For app usage, we observe a distribution that has higher kurtosis (heavier head and longer tail) than that for the aforementioned movie datasets. This happens primarily because of the large disparity in resources available to app developers and the low cost of app publication relative to movies.In this paper we compare a latent factor (PureSVD) and a memory-based model with our novel PCA-based model, which we call Eigenapp. We use both accuracy and variety as evaluation metrics. PureSVD did not perform well due to its reliance on explicit feedback such as ratings, which we do not have. Memory-based approaches that perform vector operations in the original high dimensional space over-predict popular apps because they fail to capture the neighborhood of less popular apps. They have high accuracy due to the concentration of mass in the head, but did poorly in terms of variety of apps exposed. Eigenapp, which exploits neighborhood information in low dimensional spaces, did well both on precision and variety, underscoring the importance of dimensionality reduction to form quality neighborhoods in high kurtosis distributions.",10.1145/2339530.2339563,https://doi.org/10.1145/2339530.2339563,"New York, NY, USA",Association for Computing Machinery,9781450314626,2012,GetJar mobile application recommendations with very sparse datasets,"Shi, Kent and Ali, Kamal",inproceedings,10.1145/2339530.2339563,
10.1145/2339530.2339574,10.1145/2339530.2339574,KDD.bib,1,['KDD.bib'],8,KDD '12,"Beijing, China","multi-faceted trust, trust evolution, user preference",9,253–261,Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Most existing research about online trust assumes static trust relations between users. As we are informed by social sciences, trust evolves as humans interact. Little work exists studying trust evolution in an online world. Researching online trust evolution faces unique challenges because more often than not, available data is from passive observation. In this paper, we leverage social science theories to develop a methodology that enables the study of online trust evolution. In particular, we propose a framework of evolution trust, eTrust, which exploits the dynamics of user preferences in the context of online product review. We present technical details about modeling trust evolution, and perform experiments to show how the exploitation of trust evolution can help improve the performance of online applications such as rating and trust prediction.",10.1145/2339530.2339574,https://doi.org/10.1145/2339530.2339574,"New York, NY, USA",Association for Computing Machinery,9781450314626,2012,eTrust: understanding trust evolution in an online world,"Tang, Jiliang and Gao, Huiji and Liu, Huan and Das Sarma, Atish",inproceedings,10.1145/2339530.2339574,
10.1145/2339530.2339717,10.1145/2339530.2339717,KDD.bib,1,['KDD.bib'],8,KDD '12,"Beijing, China","clones, content popularity, rich-get-richer, youtube",9,1186–1194,Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Video dissemination through sites such as YouTube can have widespread impacts on opinions, thoughts, and cultures. Not all videos will reach the same popularity and have the same impact. Popularity differences arise not only because of differences in video content, but also because of other ""content-agnostic"" factors. The latter factors are of considerable interest but it has been difficult to accurately study them. For example, videos uploaded by users with large social networks may tend to be more popular because they tend to have more interesting content, not because social network size has a substantial direct impact on popularity.In this paper, we develop and apply a methodology that is able to accurately assess, both qualitatively and quantitatively, the impacts of various content-agnostic factors on video popularity. When controlling for video content, we observe a strong linear ""rich-get-richer"" behavior, with the total number of previous views as the most important factor except for very young videos. The second most important factor is found to be video age. We analyze a number of phenomena that may contribute to rich-get-richer, including the first-mover advantage, and search bias towards popular videos. For young videos we find that factors other than the total number of previous views, such as uploader characteristics and number of keywords, become relatively more important. Our findings also confirm that inaccurate conclusions can be reached when not controlling for content.",10.1145/2339530.2339717,https://doi.org/10.1145/2339530.2339717,"New York, NY, USA",Association for Computing Machinery,9781450314626,2012,The untold story of the clones: content-agnostic factors that impact YouTube video popularity,"Borghol, Youmna and Ardon, Sebastien and Carlsson, Niklas and Eager, Derek and Mahanti, Anirban",inproceedings,10.1145/2339530.2339717,
10.1145/2339530.2339728,10.1145/2339530.2339728,KDD.bib,1,['KDD.bib'],8,KDD '12,"Beijing, China","collaborative filtering, friends circles, online social networks, recommender systems",9,1267–1275,Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Online social network information promises to increase recommendation accuracy beyond the capabilities of purely rating/feedback-driven recommender systems (RS). As to better serve users' activities across different domains, many online social networks now support a new feature of ""Friends Circles"", which refines the domain-oblivious ""Friends"" concept. RS should also benefit from domain-specific ""Trust Circles"". Intuitively, a user may trust different subsets of friends regarding different domains. Unfortunately, in most existing multi-category rating datasets, a user's social connections from all categories are mixed together. This paper presents an effort to develop circle-based RS. We focus on inferring category-specific social trust circles from available rating data combined with social network data. We outline several variants of weighting friends within circles based on their inferred expertise levels. Through experiments on publicly available data, we demonstrate that the proposed circle-based recommendation models can better utilize user's social trust information, resulting in increased recommendation accuracy.",10.1145/2339530.2339728,https://doi.org/10.1145/2339530.2339728,"New York, NY, USA",Association for Computing Machinery,9781450314626,2012,Circle-based recommendation in online social networks,"Yang, Xiwang and Steck, Harald and Liu, Yong",inproceedings,10.1145/2339530.2339728,
10.1145/2339530.2339732,10.1145/2339530.2339732,KDD.bib,1,['KDD.bib'],8,KDD '12,"Beijing, China","personal + social factor, social recommender system",9,1303–1311,Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Social recommendation, which aims to systematically leverage the social relationships between users as well as their past behaviors for automatic recommendation, attract much attention recently. The belief is that users linked with each other in social networks tend to share certain common interests or have similar tastes (homophily principle); such similarity is expected to help improve the recommendation accuracy and quality. There have been a few studies on social recommendations; however, they almost completely ignored the heterogeneity and diversity of the social relationship.In this paper, we develop a joint personal and social latent factor (PSLF) model for social recommendation. Specifically, it combines the state-of-the-art collaborative filtering and the social network modeling approaches for social recommendation. Especially, the PSLF extracts the social factor vectors for each user based on the state-of-the-art mixture membership stochastic blockmodel, which can explicitly express the varieties of the social relationship. To optimize the PSLF model, we develop a scalable expectation-maximization (EM) algorithm, which utilizes a novel approximate mean-field technique for fast expectation computation. We compare our approach with the latest social recommendation approaches on two real datasets, Flixter and Douban (both with large social networks). With similar training cost, our approach has shown a significant improvement in terms of prediction accuracy criteria over the existing approaches.",10.1145/2339530.2339732,https://doi.org/10.1145/2339530.2339732,"New York, NY, USA",Association for Computing Machinery,9781450314626,2012,Learning personal + social latent factor model for social recommendation,"Shen, Yelong and Jin, Ruoming",inproceedings,10.1145/2339530.2339732,
10.1145/2351333.2351337,10.1145/2351333.2351337,KDD.bib,1,['KDD.bib'],8,CDKD '12,"Beijing, China","KNN, collaborative filtering, cross domain preferences association, cross domain recommendation, tag",6,26–31,Proceedings of the 1st International Workshop on Cross Domain Knowledge Discovery in Web and Social Network Mining,"Cross domain recommendation and preferences association are emerging research topics. In this paper, we will study the two topics through experimental analysis methods: firstly, we use folksonamy to analyze the preferences association among different domains; secondly, we analyze the feasibility of cross domain rating prediction based on KNN model. The experimental results report the associative tag pairs of users' preferences on items across domains. In addition, we report the cross domain prediction results here.",10.1145/2351333.2351337,https://doi.org/10.1145/2351333.2351337,"New York, NY, USA",Association for Computing Machinery,9781450315555,2012,Experimental analysis on cross domain preferences association and rating prediction,"Dong, Zhenhua and Zhao, Qian",inproceedings,10.1145/2351333.2351337,
10.1145/2365952.2365958,10.1145/2365952.2365958,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","applications, recommender system",2,7–8,Proceedings of the Sixth ACM Conference on Recommender Systems,"In 2006, Netflix announced the Netflix Prize, a machine learning and data mining competition for movie rating prediction. We offered $1 million to whoever improved the accuracy of our existing system called Cinematch by 10%. We conducted this competition to find new ways to improve the recommendations we provide to our members, which is a key part of our business. However, we had to come up with a proxy question that was easier to evaluate and quantify: the root mean squared error (RMSE) of the predicted rating. A year into the competition, the Korbell team won the first Progress Prize with an 8.43% improvement. They reported more than 2000 hours of work in order to come up with the final combination of 107 algorithms that gave them this prize. And, they gave us the source code. We looked at the two underlying algorithms with the best performance in the ensemble. To put these algorithms to use, we had to work to overcome some limitations, for instance that they were built to handle 100 million ratings, instead of the more than 5 billion that we have, and that they were not built to adapt as members added more ratings. But once we overcame those challenges, we put the two algorithms into production, where they are still used as part of our recommendation engine.You might be wondering what happened with the final Grand Prize ensemble that won the $1M two years later. This is a truly impressive compilation and culmination of years of work, blending hundreds of predictive models to finally cross the finish line. We evaluated some of the new methods offline but the additional accuracy gains that we measured did not seem to justify the engineering effort needed to bring them into a production environment.This example highlights the fact that, besides improving offline metrics such as the RMSE, recommender systems need to take into account other practical issues such as scalability or deployment. In this tutorial, we go over some of those practical issues that many times are as important as the theory, if not more, in order to build an industrial-scale real-world recommender system.",10.1145/2365952.2365958,https://doi.org/10.1145/2365952.2365958,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Building industrial-scale real-world recommender systems,"Amatriain, Xavier",inproceedings,10.1145/2365952.2365958,
10.1145/2365952.2365962,10.1145/2365952.2365962,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","pareto-optimality, novelty, hybridization, diversity",8,19–26,Proceedings of the Sixth ACM Conference on Recommender Systems,"Performing accurate suggestions is an objective of paramount importance for effective recommender systems. Other important and increasingly evident objectives are novelty and diversity, which are achieved by recommender systems that are able to suggest diversified items not easily discovered by the users. Different recommendation algorithms have particular strengths and weaknesses when it comes to each of these objectives, motivating the construction of hybrid approaches. However, most of these approaches only focus on optimizing accuracy, with no regard for novelty and diversity. The problem of combining recommendation algorithms grows significantly harder when multiple objectives are considered simultaneously. For instance, devising multi-objective recommender systems that suggest items that are simultaneously accurate, novel and diversified may lead to a conflicting-objective problem, where the attempt to improve an objective further may result in worsening other competing objectives. In this paper we propose a hybrid recommendation approach that combines existing algorithms which differ in their level of accuracy, novelty and diversity. We employ an evolutionary search for hybrids following the Strength Pareto approach, which isolates hybrids that are not dominated by others (i.e., the so called Pareto frontier). Experimental results on two recommendation scenarios show that: (i) we can combine recommendation algorithms in order to improve an objective without significantly hurting other objectives, and (ii) we allow for adjusting the compromise between accuracy, diversity and novelty, so that the recommendation emphasis can be adjusted dynamically according to the needs of different users.",10.1145/2365952.2365962,https://doi.org/10.1145/2365952.2365962,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Pareto-efficient hybridization for multi-objective recommender systems,"Ribeiro, Marco Tulio and Lacerda, Anisio and Veloso, Adriano and Ziviani, Nivio",inproceedings,10.1145/2365952.2365962,
10.1145/2365952.2365968,10.1145/2365952.2365968,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","twitter, selective sampling, ranking, online learning, matrix factorization, collaborative filtering",8,59–66,Proceedings of the Sixth ACM Conference on Recommender Systems,"The Social Web is successfully established, and steadily growing in terms of users, content and services. People generate and consume data in real-time within social networking services, such as Twitter, and increasingly rely upon continuous streams of messages for real-time access to fresh knowledge about current affairs. In this paper, we focus on analyzing social streams in real-time for personalized topic recommendation and discovery. We consider collaborative filtering as an online ranking problem and present Stream Ranking Matrix Factorization - RMFX -, which uses a pairwise approach to matrix factorization in order to optimize the personalized ranking of topics. Our novel approach follows a selective sampling strategy to perform online model updates based on active learning principles, that closely simulates the task of identifying relevant items from a pool of mostly uninteresting ones. RMFX is particularly suitable for large scale applications and experiments on the ""476 million Twitter tweets"" dataset show that our online approach largely outperforms recommendations based on Twitter's global trend, and it is also able to deliver highly competitive Top-N recommendations faster while using less space than Weighted Regularized Matrix Factorization (WRMF), a state-of-the-art matrix factorization technique for Collaborative Filtering, demonstrating the efficacy of our approach.",10.1145/2365952.2365968,https://doi.org/10.1145/2365952.2365968,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Real-time top-n recommendation in social streams,"Diaz-Aviles, Ernesto and Drumond, Lucas and Schmidt-Thieme, Lars and Nejdl, Wolfgang",inproceedings,10.1145/2365952.2365968,
10.1145/2365952.2365972,10.1145/2365952.2365972,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","ranking, collaborative filtering, alternating least squares",8,83–90,Proceedings of the Sixth ACM Conference on Recommender Systems,"Two flavors of the recommendation problem are the explicit and the implicit feedback settings. In the explicit feedback case, users rate items and the user-item preference relationship can be modelled on the basis of the ratings. In the harder but more common implicit feedback case, the system has to infer user preferences from indirect information: presence or absence of events, such as a user viewed an item. One approach for handling implicit feedback is to minimize a ranking objective function instead of the conventional prediction mean squared error. The naive minimization of a ranking objective function is typically expensive. This difficulty is usually overcome by a trade-off: sacrificing the accuracy to some extent for computational efficiency by sampling the objective function. In this paper, we present a computationally effective approach for the direct minimization of a ranking objective function, without sampling. We demonstrate by experiments on the Y!Music and Netflix data sets that the proposed method outperforms other implicit feedback recommenders in many cases in terms of the ErrorRate, ARP and Recall evaluation metrics.",10.1145/2365952.2365972,https://doi.org/10.1145/2365952.2365972,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Alternating least squares for personalized ranking,"Tak\'{a}cs, G\'{a}bor and Tikk, Domonkos",inproceedings,10.1145/2365952.2365972,
10.1145/2365952.2365973,10.1145/2365952.2365973,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","recommender system, local implicit feedback, efficient training, collaborative filtering",8,91–98,Proceedings of the Sixth ACM Conference on Recommender Systems,"Digital music has experienced a quite fascinating transformation during the past decades. Thousands of people share or distribute their music collections on the Internet, resulting in an explosive increase of information and more user dependence on automatic recommender systems. Though there are many techniques such as collaborative filtering, most approaches focus mainly on users' global behaviors, neglecting local actions and the specific properties of music. In this paper, we propose a simple and effective local implicit feedback model mining users' local preferences to get better recommendation performance in both rating and ranking prediction. Moreover, we design an efficient training algorithm to speed up the updating procedure, and give a method to find the most appropriate time granularity to assist the performance. We conduct various experiments to evaluate the performance of this model, which show that it outperforms baseline model significantly. Integration with existing temporal models achieves a great improvement compared to the reported best single model for Yahoo! Music.",10.1145/2365952.2365973,https://doi.org/10.1145/2365952.2365973,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Local implicit feedback mining for music recommendation,"Yang, Diyi and Chen, Tianqi and Zhang, Weinan and Lu, Qiuxia and Yu, Yong",inproceedings,10.1145/2365952.2365973,
10.1145/2365952.2365981,10.1145/2365952.2365981,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","mean reciprocal rank, matrix factorization, less is more, learning to rank, collaborative filtering",8,139–146,Proceedings of the Sixth ACM Conference on Recommender Systems,"In this paper we tackle the problem of recommendation in the scenarios with binary relevance data, when only a few (k) items are recommended to individual users. Past work on Collaborative Filtering (CF) has either not addressed the ranking problem for binary relevance datasets, or not specifically focused on improving top-k recommendations. To solve the problem we propose a new CF approach, Collaborative Less-is-More Filtering (CLiMF). In CLiMF the model parameters are learned by directly maximizing the Mean Reciprocal Rank (MRR), which is a well-known information retrieval metric for measuring the performance of top-k recommendations. We achieve linear computational complexity by introducing a lower bound of the smoothed reciprocal rank metric. Experiments on two social network datasets demonstrate the effectiveness and the scalability of CLiMF, and show that CLiMF significantly outperforms a naive baseline and two state-of-the-art CF methods.",10.1145/2365952.2365981,https://doi.org/10.1145/2365952.2365981,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,CLiMF: learning to maximize reciprocal rank with collaborative less-is-more filtering,"Shi, Yue and Karatzoglou, Alexandros and Baltrunas, Linas and Larson, Martha and Oliver, Nuria and Hanjalic, Alan",inproceedings,10.1145/2365952.2365981,
10.1145/2365952.2365983,10.1145/2365952.2365983,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","sparse linear methods, side information, recommender system",8,155–162,Proceedings of the Sixth ACM Conference on Recommender Systems,"The increasing amount of side information associated with the items in E-commerce applications has provided a very rich source of information that, once properly exploited and incorporated, can significantly improve the performance of the conventional recommender systems. This paper focuses on developing effective algorithms that utilize item side information for top-N recommender systems. A set of sparse linear methods with side information (SSLIM) is proposed, which involve a regularized optimization process to learn a sparse aggregation coefficient matrix based on both user-item purchase profiles and item side information. This aggregation coefficient matrix is used within an item-based recommendation framework to generate recommendations for the users. Our experimental results demonstrate that SSLIM outperforms other methods in effectively utilizing side information and achieving performance improvement.",10.1145/2365952.2365983,https://doi.org/10.1145/2365952.2365983,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Sparse linear methods with side information for top-n recommendations,"Ning, Xia and Karypis, George",inproceedings,10.1145/2365952.2365983,
10.1145/2365952.2365984,10.1145/2365952.2365984,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","scalable collaborative filtering, MapReduce",8,163–170,Proceedings of the Sixth ACM Conference on Recommender Systems,"Similarity-based neighborhood methods, a simple and popular approach to collaborative filtering, infer their predictions by finding users with similar taste or items that have been similarly rated. If the number of users grows to millions, the standard approach of sequentially examining each item and looking at all interacting users does not scale. To solve this problem, we develop a MapReduce algorithm for the pairwise item comparison and top-N recommendation problem that scales linearly with respect to a growing number of users. This parallel algorithm is able to work on partitioned data and is general in that it supports a wide range of similarity measures. We evaluate our algorithm on a large dataset consisting of 700 million song ratings from Yahoo! Music.",10.1145/2365952.2365984,https://doi.org/10.1145/2365952.2365984,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Scalable similarity-based neighborhood methods with MapReduce,"Schelter, Sebastian and Boden, Christoph and Markl, Volker",inproceedings,10.1145/2365952.2365984,
10.1145/2365952.2365989,10.1145/2365952.2365989,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","recommender systems, privacy, obfuscation, inference",8,195–202,Proceedings of the Sixth ACM Conference on Recommender Systems,"User demographics, such as age, gender and ethnicity, are routinely used for targeting content and advertising products to users. Similarly, recommender systems utilize user demographics for personalizing recommendations and overcoming the cold-start problem. Often, privacy-concerned users do not provide these details in their online profiles. In this work, we show that a recommender system can infer the gender of a user with high accuracy, based solely on the ratings provided by users (without additional metadata), and a relatively small number of users who share their demographics. Focusing on gender, we design techniques for effectively adding ratings to a user's profile for obfuscating the user's gender, while having an insignificant effect on the recommendations provided to that user.",10.1145/2365952.2365989,https://doi.org/10.1145/2365952.2365989,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,BlurMe: inferring and obfuscating user gender based on ratings,"Weinsberg, Udi and Bhagat, Smriti and Ioannidis, Stratis and Taft, Nina",inproceedings,10.1145/2365952.2365989,
10.1145/2365952.2366000,10.1145/2365952.2366000,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","group recommender, evaluation, aggregation strategy",4,225–228,Proceedings of the Sixth ACM Conference on Recommender Systems,"Though most recommender systems make suggestions for individual users, in many circumstances the selected items (e.g., movies) are not for personal usage but rather for consumption in group. In this paper, we present a recommender system for audio-visual content that generates suggestions for groups of people (such as families or friends) in the home environment. In this context, different group recommendation strategies are evaluated for various algorithms and sizes of the group. An offline evaluation proves the assumption that for randomly composed groups the accuracy of all recommendation algorithms decreases if the group size grows. Besides, the results show that the group recommendation strategy which produces the most accurate results is depending on the algorithm that is used for generating individual recommendations. Consequently, if an existing recommender system for individuals is extended to a recommender system for groups, the group recommendation strategy has to be chosen based on the utilized recommendation algorithm in order to maximize the efficiency of the group recommendations.",10.1145/2365952.2366000,https://doi.org/10.1145/2365952.2366000,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Design and evaluation of a group recommender system,"De Pessemier, Toon and Dooms, Simon and Martens, Luc",inproceedings,10.1145/2365952.2366000,
10.1145/2365952.2366001,10.1145/2365952.2366001,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","swarm intelligence, recommender systems, matrix factorization, collaborative filtering, PSO",4,229–232,Proceedings of the Sixth ACM Conference on Recommender Systems,"Recommender systems make product suggestions that are tailored to the user's individual needs and represent powerful means to combat information overload. In this paper, we focus on the item prediction task of Recommender Systems and present SwarmRankCF, a method to automatically optimize the performance quality of recommender systems using a Swarm Intelligence perspective. Our approach, which is well-founded in a Particle Swarm Optimization framework, learns a ranking function by optimizing the combination of unique characteristics (i.e., features) of users, items and their interactions. In particular, we build feature vectors from a factorization of the user-item interaction matrix, and directly optimize Mean Average Precision metric in order to learn a linear ranking model for personalized recommendations. Our experimental evaluation, on a real world online radio dataset, indicates that our approach is able to find ranking functions that significantly improve the performance of the system for the Top-N recommendation task.",10.1145/2365952.2366001,https://doi.org/10.1145/2365952.2366001,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Swarming to rank for recommender systems,"Diaz-Aviles, Ernesto and Georgescu, Mihai and Nejdl, Wolfgang",inproceedings,10.1145/2365952.2366001,
10.1145/2365952.2366005,10.1145/2365952.2366005,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","seed items, popularity, item network, influential",4,245–248,Proceedings of the Sixth ACM Conference on Recommender Systems,"In this paper, we present a systematic perspective study on choosing and evaluating the initial seed items that will be recommended to the cold start users. We first construct an item consumption correlation network to capture the existing users' general consumption behaviors. Then, we formalize initial items recommendation as the influential seed set selection problem. Along this line, we present several methods, each of which selects seed items according to different rules. Finally, the experimental results on two real-world data sets verify that with different seed items, the users' consumption numbers will be quite different. Meanwhile, the results also provide many deep insights into these selection methods and their recommended seed items.",10.1145/2365952.2366005,https://doi.org/10.1145/2365952.2366005,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Influential seed items recommendation,"Liu, Qi and Xiang, Biao and Chen, Enhong and Ge, Yong and Xiong, Hui and Bao, Tengfei and Zheng, Yi",inproceedings,10.1145/2365952.2366005,
10.1145/2365952.2366015,10.1145/2365952.2366015,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","recommender systems, collaborative filtering, Xbox",4,281–284,Proceedings of the Sixth ACM Conference on Recommender Systems,"A recent addition to Microsoft's Xbox Live Marketplace is a recommender system which allows users to explore both movies and games in a personalized context. The system largely relies on implicit feedback, and runs on a large scale, serving tens of millions of daily users. We describe the system design, and review the core recommendation algorithm.",10.1145/2365952.2366015,https://doi.org/10.1145/2365952.2366015,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,The Xbox recommender system,"Koenigstein, Noam and Nice, Nir and Paquet, Ulrich and Schleyen, Nir",inproceedings,10.1145/2365952.2366015,
10.1145/2365952.2366026,10.1145/2365952.2366026,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","twitter, search, reputation, relevance, information retrieval, discovery, curation",2,307–308,Proceedings of the Sixth ACM Conference on Recommender Systems,"Our research involves developing technology and techniques that apply the vast sea of real-time web data to interesting problems and topics. In this demo, we will present the on- going development of a novel real-time search and discovery service named Yokie (http://yok.ie, early technology description originally published in [1]). Yokie uses the large volume of hyperlink-laden messages on social networks like Twitter as the basis of its content and ranking systems. Curated sets of users (or ""Search Parties"") form the basis of sourcing the content from the networks, and the metadata of the containing messages form the basis of ranking and contextual retrieval of the hyperlinks. Each hyperlink is in- dexed with a compound set of terms from multiple tweets (should the given hyperlink be shared more than once). This indexing step is a novel example of collaborative tagging of resources. The application is live with more than 100 users, who have performed approximately 1000 queries. We will demonstrate the main techniques and novel ranking and re- trieval techniques and user features.",10.1145/2365952.2366026,https://doi.org/10.1145/2365952.2366026,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Yokie: explorations in curated real-time search &amp; discovery using twitter,"Phelan, Owen and McCarthy, Kevin and Smyth, Barry",inproceedings,10.1145/2365952.2366026,
10.1145/2365952.2366042,10.1145/2365952.2366042,RecSys.bib,1,['RecSys.bib'],8,RecSys '12,"Dublin, Ireland","evaluation, methodology, metrics, recommender systems, utility",2,351–352,Proceedings of the Sixth ACM Conference on Recommender Systems,"Measuring the error in rating prediction has been by far the dominant evaluation methodology in the Recommender Systems literature. Yet there seems to be a general consensus that this criterion alone is far from being enough to assess the practical effectiveness of a recommender system. Information Retrieval metrics have started to be used to evaluate item selection and ranking rather than rating prediction, but considerable divergence remains in the adoption of such metrics by different authors. On the other hand, recommendation utility includes other key dimensions and concerns beyond accuracy, such as novelty and diversity, user engagement, and business performance. While the need for further extension, formalization, clarification and standardization of evaluation methodologies is recognized in the community, this need is still unmet for a large extent. The RUE 2012 workshop sought to identify and better understand the current gaps in recommender system evaluation methodologies, help lay directions for progress in addressing them, and contribute to the consolidation and convergence of experimental methods and practice.",10.1145/2365952.2366042,https://doi.org/10.1145/2365952.2366042,"New York, NY, USA",Association for Computing Machinery,9781450312707,2012,Workshop on recommendation utility evaluation: beyond RMSE -- RUE 2012,"Amatriain, Xavier and Castells, Pablo and de Vries, Arjen and Posse, Christian",inproceedings,10.1145/2365952.2366042,
10.1145/2389661.2389665,10.1145/2389661.2389665,CIKM.bib,1,['CIKM.bib'],8,PLEAD '12,"Maui, Hawaii, USA","popularity, politics, internet, emotion, agent-based modelling",8,3–10,"Proceedings of the First Edition Workshop on Politics, Elections and Data","We present our approach to online popularity and its applications to political science, aiming at the creation of agent-based models that reproduce patterns of popularity in participatory media. We illustrate our approach analyzing a dataset from Youtube, composed of the view statistics and comments for the videos of the U.S. presidential campaigns of 2008 and 2012. Using sentiment analysis, we quantify the collective emotions expressed by the viewers, finding that democrat campaigns elicited more positive collective emotions than republican campaigns. Techniques from computational social science allow us to measure virality of the videos of each campaign, to find that democrat videos are shared faster but republican ones are remembered longer inside the community. Last we present our work in progress in voting advice applications, and our results analyzing the data from choose4greece.com. We show how we assess the policy differences between parties and their voters, and how voting advice applications can be extended to test our agent-based models.",10.1145/2389661.2389665,https://doi.org/10.1145/2389661.2389665,"New York, NY, USA",Association for Computing Machinery,9781450317139,2012,Political polarization and popularity in online participatory media: an integrated approach,"Garcia, David and Mendez, Fernando and Serd\""{u}lt, Uwe and Schweitzer, Frank",inproceedings,10.1145/2389661.2389665,
10.1145/2390116.2390125,10.1145/2390116.2390125,CIKM.bib,1,['CIKM.bib'],8,BooksOnline '12,"Maui, Hawaii, USA","stylometry, relevance-feedback, recommendation systems, book recommendation",4,13–16,Proceedings of the Fifth ACM Workshop on Research Advances in Large Digital Book Repositories and Complementary Media,"Reading is an important activity for individuals. Content-based recommendation systems are, typically, used to recommend scientific papers or news, where search is driven by topic. Literary reading or reading for leisure differs from scientific reading, because users search books not only for their topic but also by author or writing style. Choosing a new book to read can be tricky and recommendation systems can make it easy by selecting books that the user will like. In this paper we study recommendation through writing style and the influence of negative examples in user preferences. Our experiments were conducted in a hybrid set-up that combines a collaborative filtering algorithm with stylometric relevance feedback. Using the LitRec data set, we demonstrate that writing style influences book selection; that book content, characterized with writing style, can be used to improve collaborative filtering results; and that negative examples do not improve final predictions.",10.1145/2390116.2390125,https://doi.org/10.1145/2390116.2390125,"New York, NY, USA",Association for Computing Machinery,9781450317146,2012,Stylometric relevance-feedback towards a hybrid book recommendation algorithm,"Vaz, Paula Cristina and Martins de Matos, David and Martins, Bruno",inproceedings,10.1145/2390116.2390125,
10.1145/2396761.2396767,10.1145/2396761.2396767,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","upper confidence bound, logistic regression, explore-exploit, comment ratings",10,6–15,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"The highly dynamic nature of online commenting environments makes accurate ratings prediction for new comments challenging. In such a setting, in addition to exploiting comments with high predicted ratings, it is also critical to explore comments with high uncertainty in the predictions. In this paper, we propose a novel upper confidence bound (UCB) algorithm called LOGUCB that balances exploration with exploitation when the average rating of a comment is modeled using logistic regression on its features. At the core of our LOGUCB algorithm lies a novel variance approximation technique for the Bayesian logistic regression model that is used to compute the UCB value for each comment. In experiments with a real-life comments dataset from Yahoo! News, we show that LOGUCB with bag-of-words and topic features outperforms state-of-the-art explore-exploit algorithms.",10.1145/2396761.2396767,https://doi.org/10.1145/2396761.2396767,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,LogUCB: an explore-exploit algorithm for comments recommendation,"Mahajan, Dhruv Kumar and Rastogi, Rajeev and Tiwari, Charu and Mitra, Adway",inproceedings,10.1145/2396761.2396767,
10.1145/2396761.2396798,10.1145/2396761.2396798,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","topic model, master-slave document, comments summarization",10,265–274,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Readers of a news article often read its comments contributed by other readers. By reading comments, readers obtain not only complementary information about this news article but also the opinions from other readers. However, the existing ranking mechanisms for comments (e.g., by recency or by user rating) fail to offer an overall picture of topics discussed in comments. In this paper, we first propose to study Topic-driven Reader Comments Summarization (Torcs) problem. We observe that many news articles from a news stream are related to each other; so are their comments. Hence, news articles and their associated comments provide context information for user commenting. To implicitly capture the context information, we propose two topic models to address the Torcs problem, namely, Master-Slave Topic Model (MSTM) and Extended Master-Slave Topic Model (EXTM). Both models treat a news article as a master document and each of its comments as a slave document. MSTM model constrains that the topics discussed in comments have to be derived from the commenting news article. On the other hand, EXTM model allows generating words of comments using both the topics derived from the commenting news article, and the topics derived from all comments themselves. Both models are used to group comments into topic clusters. We then use two ranking mechanisms Maximal Marginal Relevance (MMR) and Rating &amp; Length (RL) to select a few most representative comments from each comment cluster. To evaluate the two models, we conducted experiments on 1005 Yahoo! News articles with more than one million comments. Our experimental results show that EXTM significantly outperforms MSTM by perplexity. Through a user study, we also confirm that the comment summary generated by EXTM achieves better intra-cluster topic cohesion and inter-cluster topic diversity.",10.1145/2396761.2396798,https://doi.org/10.1145/2396761.2396798,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Topic-driven reader comments summarization,"Ma, Zongyang and Sun, Aixin and Yuan, Quan and Cong, Gao",inproceedings,10.1145/2396761.2396798,
10.1145/2396761.2396817,10.1145/2396761.2396817,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","transfer learning, recommender systems, cross domains, collaborative filtering",10,425–434,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Most collaborative Recommender Systems (RS) operate in a single domain (such as movies, books, etc.) and are capable of providing recommendations based on historical usage data which is collected in the specific domain only. Cross-domain recommenders address the sparsity problem by using Machine Learning (ML) techniques to transfer knowledge from a dense domain into a sparse target domain. In this paper we propose a transfer learning technique that extracts knowledge from multiple domains containing rich data (e.g., movies and music) and generates recommendations for a sparse target domain (e.g., games). Our method learns the relatedness between the different source domains and the target domain, without requiring overlapping users between domains. The model integrates the appropriate amount of knowledge from each domain in order to enrich the target domain data. Experiments with several datasets reveal that, using multiple sources and the relatedness between domains improves accuracy of results.",10.1145/2396761.2396817,https://doi.org/10.1145/2396761.2396817,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,TALMUD: transfer learning for multiple domains,"Moreno, Orly and Shapira, Bracha and Rokach, Lior and Shani, Guy",inproceedings,10.1145/2396761.2396817,
10.1145/2396761.2396825,10.1145/2396761.2396825,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","online advertising, hierarchical bayesian regression",10,485–494,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"With the development of Web applications, large scale data are popular; and they are not only getting richer, but also ubiquitously interconnected with users and other objects in various ways, which brings about multi-view data with implicit structure. In this paper, we propose a novel hierarchical Bayesian mixture regression model, which discovers and then exploits the relationships among multiple views of the data to perform various machine learning tasks. A stochastic EM inference and learning algorithm is derived; and a parallel implementation in Hadoop MapReduce [9] paradigm is developed to scale up the learning. We apply the developed model and algorithm on click-through-rate (CTR) prediction and campaign targeting recommendation in online advertising to measure its effectiveness. The experiments on both synthetic data and large scale ads serving data from a real world online advertising exchange demonstrate the superior CTR prediction accuracy of our method compared to existing state-of-the-art methods. The results also show that our model can recommend high performance targeting features for online advertising campaigns.",10.1145/2396761.2396825,https://doi.org/10.1145/2396761.2396825,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Multiview hierarchical bayesian regression model andapplication to online advertising,"Xu, Tianbing and Zhang, Ruofei and Guo, Zhen",inproceedings,10.1145/2396761.2396825,
10.1145/2396761.2396828,10.1145/2396761.2396828,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","value iteration, revenue optimisation, pomdps, correlation, computational advertising",10,515–524,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Online advertising has become a key source of revenue for both web search engines and online publishers. For them, the ability of allocating right ads to right webpages is critical because any mismatched ads would not only harm web users' satisfactions but also lower the ad income. In this paper, we study how online publishers could optimally select ads to maximize their ad incomes over time. The conventional offline, content-based matching between webpages and ads is a fine start but cannot solve the problem completely because good matching does not necessarily lead to good payoff. Moreover, with the limited display impressions, we need to balance the need of selecting ads to learn true ad payoffs (exploration) with that of allocating ads to generate high immediate payoffs based on the current belief (exploitation). In this paper, we address the problem by employing Partially observable Markov decision processes (POMDPs) and discuss how to utilize the correlation of ads to improve the efficiency of the exploration and increase ad incomes in a long run. Our mathematical derivation shows that the belief states of correlated ads can be naturally updated using a formula similar to collaborative filtering. To test our model, a real world ad dataset from a major search engine is collected and categorized. Experimenting over the data, we provide an analyse of the effect of the underlying parameters, and demonstrate that our algorithms significantly outperform other strong baselines.",10.1145/2396761.2396828,https://doi.org/10.1145/2396761.2396828,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Sequential selection of correlated ads by POMDPs,"Yuan, Shuai and Wang, Jun",inproceedings,10.1145/2396761.2396828,
10.1145/2396761.2396831,10.1145/2396761.2396831,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","inner-product, fast retrieval, collaborative filtering",10,535–544,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Low-rank Matrix Factorization (MF) methods provide one of the simplest and most effective approaches to collaborative filtering. This paper is the first to investigate the problem of efficient retrieval of recommendations in a MF framework. We reduce the retrieval in a MF model to an apparently simple task of finding the maximum dot-product for the user vector over the set of item vectors. However, to the best of our knowledge the problem of efficiently finding the maximum dot-product in the general case has never been studied. To this end, we propose two techniques for efficient search -- (i) We index the item vectors in a binary spatial-partitioning metric tree and use a simple branch and-bound algorithm with a novel bounding scheme to efficiently obtain exact solutions. (ii) We use spherical clustering to index the users on the basis of their preferences and pre-compute recommendations only for the representative user of each cluster to obtain extremely efficient approximate solutions. We obtain a theoretical error bound which determines the quality of any approximate result and use it to control the approximation. Both these simple techniques are fairly independent of each other and hence are easily combined to further improve recommendation retrieval efficiency. We evaluate our algorithms on real-world collaborative-filtering datasets, demonstrating more than \texttimes{}7 speedup (with respect to the naive linear search) for the exact solution and over \texttimes{}250 speedup for approximate solutions by combining both techniques.",10.1145/2396761.2396831,https://doi.org/10.1145/2396761.2396831,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Efficient retrieval of recommendations in a matrix factorization framework,"Koenigstein, Noam and Ram, Parikshit and Shavitt, Yuval",inproceedings,10.1145/2396761.2396831,
10.1145/2396761.2396849,10.1145/2396761.2396849,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","recommender systems, imputation, collaborative filtering",10,684–693,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"As each user tends to rate a small proportion of available items, the resulted Data Sparsity issue brings significant challenges to the research of recommender systems. This issue becomes even more severe for neighborhood-based collaborative filtering methods, as there are even lower numbers of ratings available in the neighborhood of the query item. In this paper, we aim to address the Data Sparsity issue in the context of the neighborhood-based collaborative filtering. Given the (user, item) query, a set of key ratings are identified, and an auto-adaptive imputation method is proposed to fill the missing values in the set of key ratings. The proposed method can be used with any similarity metrics, such as the Pearson Correlation Coefficient and Cosine-based similarity, and it is theoretically guaranteed to outperform the neighborhood-based collaborative filtering approaches. Results from experiments prove that the proposed method could significantly improve the accuracy of recommendations for neighborhood-based Collaborative Filtering algorithms.",10.1145/2396761.2396849,https://doi.org/10.1145/2396761.2396849,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,The efficient imputation method for neighborhood-based collaborative filtering,"Ren, Yongli and Li, Gang and Zhang, Jun and Zhou, Wanlei",inproceedings,10.1145/2396761.2396849,
10.1145/2396761.2396850,10.1145/2396761.2396850,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","tensor model, post-read, multi-faceted",10,694–703,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Personalized article recommendation is important for news portals to improve user engagement. Existing work quantifies engagement primarily through click rates. We suggest that quality of recommendations may be improved by exploiting different types of ""post-read"" engagement signals like sharing, commenting, printing and e-mailing article links. Specifically, we propose a multi-faceted ranking problem for recommending articles, where each facet corresponds to a ranking task that seeks to maximize actions of a particular post-read type (e.g., ranking articles to maximize sharing actions). Our approach is to predict the probability that a user would take a post-read action on an article, so that articles can be ranked according to such probabilities. However, post-read actions are rare events --- enormous data sparsity makes the problem challenging. We meet the challenge by exploiting correlations across different post-read action types through a novel locally augmented tensor (LAT) model, so that the ranking performance of a particular action type can be improved by leveraging data from all other action types. Through extensive experiments, we show that our LAT model significantly outperforms a variety of state-of-the-art factor models, logistic regression and IR models.",10.1145/2396761.2396850,https://doi.org/10.1145/2396761.2396850,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Multi-faceted ranking of news articles using post-read actions,"Agarwal, Deepak and Chen, Bee-Chung and Wang, Xuanhui",inproceedings,10.1145/2396761.2396850,
10.1145/2396761.2396863,10.1145/2396761.2396863,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","variational methods, rating prediction, latent dirichlet allocation, aspect-based opinion mining, aspect identification",10,803–812,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Aspect-based opinion mining, which aims to extract aspects and their corresponding ratings from customers reviews, provides very useful information for customers to make purchase decisions. In the past few years several probabilistic graphical models have been proposed to address this problem, most of them based on Latent Dirichlet Allocation (LDA). While these models have a lot in common, there are some characteristics that distinguish them from each other. These fundamental differences correspond to major decisions that have been made in the design of the LDA models. While research papers typically claim that a new model outperforms the existing ones, there is normally no ""one-size-fits-all"" model. In this paper, we present a set of design guidelines for aspect-based opinion mining by discussing a series of increasingly sophisticated LDA models. We argue that these models represent the essence of the major published methods and allow us to distinguish the impact of various design decisions. We conduct extensive experiments on a very large real life dataset from Epinions.com (500K reviews) and compare the performance of different models in terms of the likelihood of the held-out test set and in terms of the accuracy of aspect identification and rating prediction.",10.1145/2396761.2396863,https://doi.org/10.1145/2396761.2396863,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,On the design of LDA models for aspect-based opinion mining,"Moghaddam, Samaneh and Ester, Martin",inproceedings,10.1145/2396761.2396863,
10.1145/2396761.2398458,10.1145/2396761.2398458,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","vector space model, term weighting, recommender systems, ranking-based collaborative filtering, collaborative filtering",5,1487–1491,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Collaborative filtering (CF) is an effective technique addressing the information overload problem. Recently ranking-based CF methods have shown advantages in recommendation accuracy, being able to capture the preference similarity between users even if their rating scores differ significantly. In this study, we seek accuracy improvement of ranking-based CF through adaptation of the vector space model, where we consider each user as a document and her pairwise relative preferences as terms. We then use a novel degree-specialty weighting scheme resembling TF-IDF to weight the terms. Then we use cosine similarity to select a neighborhood of users for the target user to make recommendations. Experiments on benchmarks in comparison with the state-of-the-art methods demonstrate the promise of our approach.",10.1145/2396761.2398458,https://doi.org/10.1145/2396761.2398458,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Adapting vector space model to ranking-based collaborative filtering,"Wang, Shuaiqiang and Sun, Jiankai and Gao, Byron J. and Ma, Jun",inproceedings,10.1145/2396761.2398458,
10.1145/2396761.2398479,10.1145/2396761.2398479,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","twitter, online ranking, collaborative filtering",5,1592–1596,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Users engaged in the Social Web increasingly rely upon continuous streams of Twitter messages (tweets) for real-time access to information and fresh knowledge about current affairs. However, given the deluge of tweets, it is a challenge for individuals to find relevant and appropriately ranked information. We propose to address this knowledge management problem by going beyond the general perspective of information finding in Twitter, that asks: ""What is happening right now?"", towards an individual user perspective, and ask: ""What is interesting to me right now?"" In this paper, we consider collaborative filtering as an online ranking problem and present RMFO, a method that creates, in real-time, user-specific rankings for a set of tweets based on individual preferences that are inferred from the user's past system interactions. Experiments on the 476 million Twitter tweets dataset show that our online approach largely outperforms recommendations based on Twitter's global trend and Weighted Regularized Matrix Factorization (WRMF), a highly competitive state-of-the-art Collaborative Filtering technique, demonstrating the efficacy of our approach.",10.1145/2396761.2398479,https://doi.org/10.1145/2396761.2398479,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,What is happening right now ... that interests me? online topic discovery and recommendation in twitter,"Diaz-Aviles, Ernesto and Drumond, Lucas and Gantner, Zeno and Schmidt-Thieme, Lars and Nejdl, Wolfgang",inproceedings,10.1145/2396761.2398479,
10.1145/2396761.2398482,10.1145/2396761.2398482,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","social network, news recommendation, matrix factorization, expert",5,1607–1611,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"A variety of news recommender systems based on different strategies have been proposed to provide news personalization services for online news readers. However, little research work has been reported on utilizing the implicit ""social"" factors (i.e., the potential influential experts in news reading community) among news readers to facilitate news personalization. In this paper, we investigate the feasibility of integrating content-based methods, collaborative filtering and information diffusion models by employing probabilistic matrix factorization techniques. We propose PRemiSE, a novel Personalized news Recommendation framework via implicit Social Experts, in which the opinions of potential influencers on virtual social networks extracted from implicit feedbacks are treated as auxiliary resources for recommendation. Empirical results demonstrate the efficacy and effectiveness of our method, particularly, on handling the so-called cold-start problem.",10.1145/2396761.2398482,https://doi.org/10.1145/2396761.2398482,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,PRemiSE: personalized news recommendation via implicit social experts,"Lin, Chen and Xie, Runquan and Li, Lei and Huang, Zhenhua and Li, Tao",inproceedings,10.1145/2396761.2398482,
10.1145/2396761.2398515,10.1145/2396761.2398515,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","trust prediction, transfer learning, social network, nonnegative matrix factorization",5,1774–1778,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Along with the increasing popularity of social web sites, users rely more on the trustworthiness information for many online activities among users. However, such social network data often suffers from severe data sparsity and are not able to provide users with enough information. Therefore, trust prediction has emerged as an important topic in social network research. Traditional approaches explore the topology of trust graph. Previous research in sociology and our life experience suggest that people who are in the same social circle often exhibit similar behavior and tastes. Such ancillary information, is often accessible and therefore could potentially help the trust prediction. In this paper, we address the link prediction problem by aggregating heterogeneous social networks and propose a novel joint manifold factorization (JMF) method. Our new joint learning model explores the user group level similarity between correlated graphs and simultaneously learns the individual graph structure, therefore the shared structures and patterns from multiple social networks can be utilized to enhance the prediction tasks. As a result, we not only improve the trust prediction in the target graph, but also facilitate other information retrieval tasks in the auxiliary graphs. To optimize the objective function, we break down the proposed objective function into several manageable sub-problems, then further establish the theoretical convergence with the aid of auxiliary function. Extensive experiments were conducted on real world data sets and all empirical results demonstrated the effectiveness of our method.",10.1145/2396761.2398515,https://doi.org/10.1145/2396761.2398515,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Trust prediction via aggregating heterogeneous social networks,"Huang, Jin and Nie, Feiping and Huang, Heng and Tu, Yi-Cheng",inproceedings,10.1145/2396761.2398515,
10.1145/2396761.2398573,10.1145/2396761.2398573,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","trend analysis, topic model, text analysis, graphical models, bayesian hierarchical model",5,2065–2069,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"This paper presents a topic model that discovers the correlation patterns in a given time-stamped document collection and how these patterns evolve over time. Our proposal, the theme chronicle model (TCM) divides traditional topics into temporal and stable topics to detect the change of each theme over time; previous topic models ignore these differences and characterize trends as merely bursts of topics.TCM introduces a theme topic (stable topic), a trend topic (temporal topic), timestamps, and a latent switch variable in each token to realize these differences. Its topic layers allow TCM to capture not only word co-occurrence patterns in each theme, but also word co-occurrence patterns at any given time in each theme as trends. Experiments on various data sets show that the proposed model is useful as a generative model to discover fine-grained tightly coherent topics, takes advantage of previous models, and then assigns values for new documents.",10.1145/2396761.2398573,https://doi.org/10.1145/2396761.2398573,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Theme chronicle model: chronicle consists of timestamp and topical words over each theme,"Kawamae, Noriaki",inproceedings,10.1145/2396761.2398573,
10.1145/2396761.2398610,10.1145/2396761.2398610,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","recommender systems, learning to rank, features, collaborative filtering",4,2239–2242,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Most existing recommender systems can be classified into two categories: collaborative filtering and content-based filtering. Hybrid recommender systems combine the advantages of the two for improved recommendation performance. Traditional recommender systems are rating-based. However, predicting ratings is an intermediate step towards their ultimate goal of generating rankings or recommendation lists. Learning to rank is an established means of predicting rankings and has recently demonstrated high promise in improving quality of recommendations. In this paper, we propose LRHR, the first attempt that adapts learning to rank to hybrid recommender systems. LRHR first defines novel representations for both users and items so that they can be content-comparable. Then, LRHR identifies a set of novel meta-level features for learning purposes. Finally, LRHR adopts RankSVM, a pairwise learning to rank algorithm, to generate recommendation lists of items for users. Extensive experiments on benchmarks in comparison with the state-of-the-art algorithms demonstrate the performance gain of our approach.",10.1145/2396761.2398610,https://doi.org/10.1145/2396761.2398610,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Learning to rank for hybrid recommendation,"Sun, Jiankai and Wang, Shuaiqiang and Gao, Byron J. and Ma, Jun",inproceedings,10.1145/2396761.2398610,
10.1145/2396761.2398628,10.1145/2396761.2398628,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","time features, recommender systems, household member identification, feature selection",4,2311–2314,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Popular online rental services such as Netflix and MoviePilot often manage household accounts. A household account is usually shared by various users who live in the same house, but in general does not provide a mechanism by which current active users are identified, and thus leads to considerable difficulties for making effective personalized recommendations. The identification of the active household members, defined as the discrimination of the users from a given household who are interacting with a system (e.g. an on-demand video service), is thus an interesting challenge for the recommender systems research community. In this paper, we formulate the above task as a classification problem, and address it by means of global and local feature selection methods and classifiers that only exploit time features from past item consumption records. The results obtained from a series of experiments on a real dataset show that some of the proposed methods are able to select relevant time features, which allow simple classifiers to accurately identify active members of household accounts.",10.1145/2396761.2398628,https://doi.org/10.1145/2396761.2398628,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Time feature selection for identifying active household members,"Campos, Pedro G. and Bellogin, Alejandro and D\'{\i}ez, Fernando and Cantador, Iv\'{a}n",inproceedings,10.1145/2396761.2398628,
10.1145/2396761.2398634,10.1145/2396761.2398634,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","retweet cascade, information diffusion, influence",4,2335–2338,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Retweet cascades play an essential role in information diffusion in Twitter. Popular tweets reflect the current trends in Twitter, while Twitter itself is one of the most important online media. Thus, understanding the reasons why a tweet becomes popular is of great interest for sociologists, marketers and social media researches. What is even more important is the possibility to make a prognosis of a tweet's future popularity. Besides the scientific significance of such possibility, this sort of prediction has lots of practical applications such as breaking news detection, viral marketing etc. In this paper we try to forecast how many retweets a given tweet will gain during a fixed time period. We train an algorithm that predicts the number of retweets during time T since the initial moment. In addition to a standard set of features we utilize several new ones. One of the most important features is the flow of the cascade. Another one is PageRank on the retweet graph, which can be considered as the measure of influence of users.",10.1145/2396761.2398634,https://doi.org/10.1145/2396761.2398634,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Prediction of retweet cascade size over time,"Kupavskii, Andrey and Ostroumova, Liudmila and Umnov, Alexey and Usachev, Svyatoslav and Serdyukov, Pavel and Gusev, Gleb and Kustarev, Andrey",inproceedings,10.1145/2396761.2398634,
10.1145/2396761.2398636,10.1145/2396761.2398636,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","top-n recommendation, data mining, belief propagation",4,2343–2346,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"The top-n recommendation focuses on finding the top-n items that the target user is likely to purchase rather than predicting his/her ratings on individual items. In this paper, we propose a novel method that provides top-n recommendation by probabilistically determining the target user's preference on items. This method models the purchasing relationships between users and items as a bipartite graph and employs Belief Propagation to compute the preference of the target user on items. We analyze the proposed method in detail by examining the changes in recommendation accuracy under different parameter settings. We also show that the proposed method is up to 40% more accurate than an existing method by comparing it with an RWR-based method via extensive experiments.",10.1145/2396761.2398636,https://doi.org/10.1145/2396761.2398636,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Top-N recommendation through belief propagation,"Ha, Jiwoon and Kwon, Soon-Hyoung and Kim, Sang-Wook and Faloutsos, Christos and Park, Sunju",inproceedings,10.1145/2396761.2398636,
10.1145/2396761.2398643,10.1145/2396761.2398643,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","similarity graph, scalability, link prediction, incremental update, collaborative filtering",4,2371–2374,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"The traditional collaborative filtering approaches have been shown to suffer from two fundamental problems: data sparsity and difficulty in scalability. To address these problems, we present a novel scalable item-based collaborative filtering method by using incremental update and local link prediction. By subdividing the computations and analyzing the factors in different cases of item-to-item similarity, we design the incremental update strategies in item-based CF, which can make the recommender system more efficient and scalable. Based on the transitive structure of item similarity graph, we use the local link prediction method to find implicit candidates to alleviate the lack of neighbors in predictions and recommendations caused by the sparsity of data. The experiment results validate that our algorithm can improve the performance of traditional CF, and can increase the efficiency in recommendations.",10.1145/2396761.2398643,https://doi.org/10.1145/2396761.2398643,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Scalable collaborative filtering using incremental update and local link prediction,"Yang, Xiao and Zhang, Zhaoxin and Wang, Ke",inproceedings,10.1145/2396761.2398643,
10.1145/2396761.2398693,10.1145/2396761.2398693,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","recommender systems, pairwise preferences, implicit feedback",4,2567–2570,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Most of the current recommender systems heavily rely on explicit user feedback such as ratings on items to model users' interests. However, in many applications, it is very hard to collect the explicit feedback, while implicit feedback such as user clicks may be more available. Furthermore, it is often more suitable for many recommender systems to address a ranking problem than a rating predicting problem. This paper proposes a latent pairwise preference learning (LPPL) approach for recommendation with implicit feedback. LPPL directly models user preferences with respect to a set of items rather than the rating scores on individual items, which are modeled with a set of features by analyzing clickthrough data available in many real-world recommender systems. The LPPL approach models both the latent variables of group structure of users and the pairwise preferences simultaneously. We conduct experiments on the testbed from a real-world recommender system and demonstrate that the proposed approach can effectively improve the recommendation performance against several baseline algorithms.",10.1145/2396761.2398693,https://doi.org/10.1145/2396761.2398693,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,A latent pairwise preference learning approach for recommendation from implicit feedback,"Fang, Yi and Si, Luo",inproceedings,10.1145/2396761.2398693,
10.1145/2396761.2398701,10.1145/2396761.2398701,CIKM.bib,1,['CIKM.bib'],8,CIKM '12,"Maui, Hawaii, USA","social recommendation, social network, recommender systems, matrix factorization, item relation",4,2599–2602,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Recommender systems with social networks (RSSN) have been well studied in recent works. However, these methods ignore the relationships among items, which may affect the quality of recommendations. Motivated by the observation that related items often have similar ratings, we propose a framework integrating items' relations, users' social graph and user-item rating matrix for recommendation. Experimental results show that our approach performs better than the state-of-art algorithm and the method with only users' social graph ensemble in terms of MAP and RMSE.",10.1145/2396761.2398701,https://doi.org/10.1145/2396761.2398701,"New York, NY, USA",Association for Computing Machinery,9781450311564,2012,Learning to recommend with social relation ensemble,"Guo, Lei and Ma, Jun and Chen, Zhumin and Jiang, Haoran",inproceedings,10.1145/2396761.2398701,
10.1145/2433396.2433442,10.1145/2433396.2433442,WSDM.bib,1,['WSDM.bib'],8,WSDM '13,"Rome, Italy","deep-web crawl, entities, web data",10,355–364,Proceedings of the Sixth ACM International Conference on Web Search and Data Mining,"Deep-web crawl is concerned with the problem of surfacing hidden content behind search interfaces on the Web. While many deep-web sites maintain document-oriented textual content (e.g., Wikipedia, PubMed, Twitter, etc.), which has traditionally been the focus of the deep-web literature, we observe that a significant portion of deep-web sites, including almost all online shopping sites, curate structured entities as opposed to text documents. Although crawling such entity-oriented content is clearly useful for a variety of purposes, existing crawling techniques optimized for document oriented content are not best suited for entity-oriented sites. In this work, we describe a prototype system we have built that specializes in crawling entity-oriented deep-web sites. We propose techniques tailored to tackle important subproblems including query generation, empty page filtering and URL deduplication in the specific context of entity oriented deep-web sites. These techniques are experimentally evaluated and shown to be effective.",10.1145/2433396.2433442,https://doi.org/10.1145/2433396.2433442,"New York, NY, USA",Association for Computing Machinery,9781450318693,2013,Crawling deep web entity pages,"He, Yeye and Xin, Dong and Ganti, Venkatesh and Rajaraman, Sriram and Shah, Nirav",inproceedings,10.1145/2433396.2433442,
10.1145/2433396.2433443,10.1145/2433396.2433443,WSDM.bib,1,['WSDM.bib'],8,WSDM '13,"Rome, Italy","popularity prediction, regression models, youtube",10,365–374,Proceedings of the Sixth ACM International Conference on Web Search and Data Mining,"Predicting Web content popularity is an important task for supporting the design and evaluation of a wide range of systems, from targeted advertising to effective search and recommendation services. We here present two simple models for predicting the future popularity of Web content based on historical information given by early popularity measures. Our approach is validated on datasets consisting of videos from the widely used YouTube video-sharing portal. Our experimental results show that, compared to a state-of-the-art baseline model, our proposed models lead to significant decreases in relative squared errors, reaching up to 20% reduction on average, and larger reductions (of up to 71%) for videos that experience a high peak in popularity in their early days followed by a sharp decrease in popularity.",10.1145/2433396.2433443,https://doi.org/10.1145/2433396.2433443,"New York, NY, USA",Association for Computing Machinery,9781450318693,2013,Using early view patterns to predict the popularity of youtube videos,"Pinto, Henrique and Almeida, Jussara M. and Gon\c{c}alves, Marcos A.",inproceedings,10.1145/2433396.2433443,
10.1145/2433396.2433445,10.1145/2433396.2433445,WSDM.bib,1,['WSDM.bib'],8,WSDM '13,"Rome, Italy","inference, latent variable models, recomcollaborative filtering, recomfactor models, recommendation",10,385–394,Proceedings of the Sixth ACM International Conference on Web Search and Data Mining,"Items in recommender systems are usually associated with annotated attributes: for e.g., brand and price for products; agency for news articles, etc. Such attributes are highly informative and must be exploited for accurate recommendation. While learning a user preference model over these attributes can result in an interpretable recommender system and can hands the cold start problem, it suffers from two major drawbacks: data sparsity and the inability to model random effects. On the other hand, latent-factor collaborative filtering models have shown great promise in recommender systems; however, its performance on rare items is poor. In this paper we propose a novel model LFUM, which provides the advantages of both of the above models. We learn user preferences (over the attributes) using a personalized Bayesian hierarchical model that uses a combination(additive model) of a globally learned preference model along with user-specific preferences. To combat data-sparsity, we smooth these preferences over the item-taxonomy using an efficient forward-filtering and backward-smoothing inference algorithm. Our inference algorithms can handle both discrete attributes (e.g., item brands) and continuous attributes (e.g., item prices). We combine the user preferences with the latent-factor models and train the resulting collaborative filtering system end-to-end using the successful BPR ranking algorithm. In our extensive experimental analysis, we show that our proposed model outperforms several commonly used baselines and we carry out an ablation study showing the benefits of each component of our model.",10.1145/2433396.2433445,https://doi.org/10.1145/2433396.2433445,"New York, NY, USA",Association for Computing Machinery,9781450318693,2013,Latent factor models with additive and hierarchically-smoothed user preferences,"Ahmed, Amr and Kanagal, Bhargav and Pandey, Sandeep and Josifovski, Vanja and Pueyo, Lluis Garcia and Yuan, Jeff",inproceedings,10.1145/2433396.2433445,
10.1145/2433396.2433451,10.1145/2433396.2433451,WSDM.bib,1,['WSDM.bib'],8,WSDM '13,"Rome, Italy","cold-start problem, collaborative filtering, decision tree, recommender systems",10,445–454,Proceedings of the Sixth ACM International Conference on Web Search and Data Mining,"For cold-start recommendation, it is important to rapidly profile new users and generate a good initial set of recommendations through an interview process --- users should be queried adaptively in a sequential fashion, and multiple items should be offered for opinion solicitation at each trial. In this work, we propose a novel algorithm that learns to conduct the interview process guided by a decision tree with multiple questions at each split. The splits, represented as sparse weight vectors, are learned through an L_1-constrained optimization framework. The users are directed to child nodes according to the inner product of their responses and the corresponding weight vector. More importantly, to account for the variety of responses coming to a node, a linear regressor is learned within each node using all the previously obtained answers as input to predict item ratings. A user study, preliminary but first in its kind in cold-start recommendation, is conducted to explore the efficient number and format of questions being asked in a recommendation survey to minimize user cognitive efforts. Quantitative experimental validations also show that the proposed algorithm outperforms state-of-the-art approaches in terms of both the prediction accuracy and user cognitive efforts.",10.1145/2433396.2433451,https://doi.org/10.1145/2433396.2433451,"New York, NY, USA",Association for Computing Machinery,9781450318693,2013,Learning multiple-question decision trees for cold-start recommendation,"Sun, Mingxuan and Li, Fuxin and Lee, Joonseok and Zhou, Ke and Lebanon, Guy and Zha, Hongyuan",inproceedings,10.1145/2433396.2433451,
10.1145/2433396.2433467,10.1145/2433396.2433467,WSDM.bib,1,['WSDM.bib'],8,WSDM '13,"Rome, Italy","collaborative filtering, latent factor models, recommender systems, twitter",10,557–566,Proceedings of the Sixth ACM International Conference on Web Search and Data Mining,"Users of popular services like Twitter and Facebook are often simultaneously overwhelmed with the amount of information delivered via their social connections and miss out on much content that they might have liked to see, even though it was distributed outside of their social circle. Both issues serve as difficulties to the users and drawbacks to the services.Social media service providers can benefit from understanding user interests and how they interact with the service, potentially predicting their behaviors in the future. In this paper, we address the problem of simultaneously predicting user decisions and modeling users' interests in social media by analyzing rich information gathered from Twitter. The task differs from conventional recommender systems as the cold-start problem is ubiquitous, and rich features, including textual content, need to be considered. We build predictive models for user decisions in Twitter by proposing Co-Factorization Machines (CoFM), an extension of a state-of-the-art recommendation model, to handle multiple aspects of the dataset at the same time. Additionally, we discuss and compare ranking-based loss functions in the context of recommender systems, providing the first view of how they vary from each other and perform in real tasks. We explore an extensive set of features and conduct experiments on a real-world dataset, concluding that CoFM with ranking-based loss functions is superior to state-of-the-art methods and yields interpretable latent factors.",10.1145/2433396.2433467,https://doi.org/10.1145/2433396.2433467,"New York, NY, USA",Association for Computing Machinery,9781450318693,2013,Co-factorization machines: modeling user interests and predicting individual decisions in Twitter,"Hong, Liangjie and Doumith, Aziz S. and Davison, Brian D.",inproceedings,10.1145/2433396.2433467,
10.1145/2433396.2433473,10.1145/2433396.2433473,WSDM.bib,1,['WSDM.bib'],8,WSDM '13,"Rome, Italy","social media, time series clustering",10,607–616,Proceedings of the Sixth ACM International Conference on Web Search and Data Mining,"Content popularity prediction finds application in many areas, including media advertising, content caching, movie revenue estimation, traffic management and macro-economic trends forecasting, to name a few. However, predicting this popularity is difficult due to, among others, the effects of external phenomena, the influence of context such as locality and relevance to users,and the difficulty of forecasting information cascades.In this paper we identify patterns of temporal evolution that are generalisable to distinct types of data, and show that we can (1) accurately classify content based on the evolution of its popularity over time and (2) predict the value of the content's future popularity. We verify the generality of our method by testing it on YouTube, Digg and Vimeo data sets and find our results to outperform the K-Means baseline when classifying the behaviour of content and the linear regression baseline when predicting its popularity.",10.1145/2433396.2433473,https://doi.org/10.1145/2433396.2433473,"New York, NY, USA",Association for Computing Machinery,9781450318693,2013,A peek into the future: predicting the evolution of popularity in user generated content,"Ahmed, Mohamed and Spagna, Stella and Huici, Felipe and Niccolini, Saverio",inproceedings,10.1145/2433396.2433473,
10.1145/2433396.2433489,10.1145/2433396.2433489,WSDM.bib,1,['WSDM.bib'],8,WSDM '13,"Rome, Italy","popularity, trends, ugc, video",6,741–746,Proceedings of the Sixth ACM International Conference on Web Search and Data Mining,"User generated content (UGC) has emerged as the predominant form of media publishing on the Web 2.0. Motivated by the large adoption of video sharing on the Web 2.0, the objective of our work is to understand and predict popularity trends (e.g, will a video be viral?) and hits (e.g, how may views will a video receive?) of user generated videos. Such knowledge is paramount to the effective design of various services including content distribution and advertising. Thus, in this paper we formalize the problem of predicting trends and hits in user generated videos. Also, we describe our research methodology on approaching this problem. To the best of knowledge, our work is novel in focusing on the problem of predicting popularity trends complementary to hits. Moreover, we intend on evaluating efficacy of our results not only based on common statistical error metrics, but also on the possible online advertising revenues our predictions can generate. After describing our proposal, we here summarize our latest findings regarding (1) uncovering common popularity trends; (2) measuring associations between UGC features and popularity trends; and (3) assessing the effectiveness of models for predicting popularity trends.",10.1145/2433396.2433489,https://doi.org/10.1145/2433396.2433489,"New York, NY, USA",Association for Computing Machinery,9781450318693,2013,On the prediction of popularity of trends and hits for user generated videos,"Figueiredo, Flavio",inproceedings,10.1145/2433396.2433489,
10.1145/2487575.2487589,10.1145/2487575.2487589,KDD.bib,1,['KDD.bib'],8,KDD '13,"Chicago, Illinois, USA","item similarity, recommender systems, sparse data, topn",9,659–667,Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"The effectiveness of existing top-N recommendation methods decreases as the sparsity of the datasets increases. To alleviate this problem, we present an item-based method for generating top-N recommendations that learns the item-item similarity matrix as the product of two low dimensional latent factor matrices. These matrices are learned using a structural equation modeling approach, wherein the value being estimated is not used for its own estimation. A comprehensive set of experiments on multiple datasets at three different sparsity levels indicate that the proposed methods can handle sparse datasets effectively and outperforms other state-of-the-art top-N recommendation methods. The experimental results also show that the relative performance gains compared to competing methods increase as the data gets sparser.",10.1145/2487575.2487589,https://doi.org/10.1145/2487575.2487589,"New York, NY, USA",Association for Computing Machinery,9781450321747,2013,FISM: factored item similarity models for top-N recommender systems,"Kabbur, Santosh and Ning, Xia and Karypis, George",inproceedings,10.1145/2487575.2487589,
10.1145/2487575.2487614,10.1145/2487575.2487614,KDD.bib,1,['KDD.bib'],8,KDD '13,"Chicago, Illinois, USA","heterogeneous social network, link prediction, probabilistic graphical model, social network mining",9,775–783,Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"The concern of privacy has become an important issue for online social networks. In services such as Foursquare.com, whether a person likes an article is considered private and therefore not disclosed; only the aggregative statistics of articles (i.e., how many people like this article) is revealed. This paper tries to answer a question: can we predict the opinion holder in a heterogeneous social network without any labeled data? This question can be generalized to a link prediction with aggregative statistics problem. This paper devises a novel unsupervised framework to solve this problem, including two main components: (1) a three-layer factor graph model and three types of potential functions; (2) a ranked-margin learning and inference algorithm. Finally, we evaluate our method on four diverse prediction scenarios using four datasets: preference (Foursquare), repost (Twitter), response (Plurk), and citation (DBLP). We further exploit nine unsupervised models to solve this problem as baselines. Our approach not only wins out in all scenarios, but on the average achieves 9.90% AUC and 12.59% NDCG improvement over the best competitors. The resources are available at http://www.csie.ntu.edu.tw/~d97944007/aggregative/",10.1145/2487575.2487614,https://doi.org/10.1145/2487575.2487614,"New York, NY, USA",Association for Computing Machinery,9781450321747,2013,Unsupervised link prediction using aggregative statistics on heterogeneous social networks,"Kuo, Tsung-Ting and Yan, Rui and Huang, Yu-Yang and Kung, Perng-Hwa and Lin, Shou-De",inproceedings,10.1145/2487575.2487614,
10.1145/2487575.2487624,10.1145/2487575.2487624,KDD.bib,1,['KDD.bib'],8,KDD '13,"Chicago, Illinois, USA","bayesian inference, latent variable models, poisson processes, social community",9,266–274,Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Many people share their activities with others through online communities. These shared activities have an impact on other users' activities. For example, users are likely to become interested in items that are adopted (e.g. liked, bought and shared) by their friends. In this paper, we propose a probabilistic model for discovering latent influence from sequences of item adoption events. An inhomogeneous Poisson process is used for modeling a sequence, in which adoption by a user triggers the subsequent adoption of the same item by other users. For modeling adoption of multiple items, we employ multiple inhomogeneous Poisson processes, which share parameters, such as influence for each user and relations between users. The proposed model can be used for finding influential users, discovering relations between users and predicting item popularity in the future. We present an efficient Bayesian inference procedure of the proposed model based on the stochastic EM algorithm. The effectiveness of the proposed model is demonstrated by using real data sets in a social bookmark sharing service.",10.1145/2487575.2487624,https://doi.org/10.1145/2487575.2487624,"New York, NY, USA",Association for Computing Machinery,9781450321747,2013,Discovering latent influence in online social activities via shared cascade poisson processes,"Iwata, Tomoharu and Shah, Amar and Ghahramani, Zoubin",inproceedings,10.1145/2487575.2487624,
10.1145/2487575.2487632,10.1145/2487575.2487632,KDD.bib,1,['KDD.bib'],8,KDD '13,"Chicago, Illinois, USA","embedding, music playlists, parallel computing, recommendation, sequences",9,865–873,Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Learning algorithms that embed objects into Euclidean space have become the methods of choice for a wide range of problems, ranging from recommendation and image search to playlist prediction and language modeling. Probabilistic embedding methods provide elegant approaches to these problems, but can be expensive to train and store as a large monolithic model. In this paper, we propose a method that trains not one monolithic model, but multiple local embeddings for a class of pairwise conditional models especially suited for sequence and co-occurrence modeling. We show that computation and memory for training these multi-space models can be efficiently parallelized over many nodes of a cluster. Focusing on sequence modeling for music playlists, we show that the method substantially speeds up training while maintaining high model quality.",10.1145/2487575.2487632,https://doi.org/10.1145/2487575.2487632,"New York, NY, USA",Association for Computing Machinery,9781450321747,2013,Multi-space probabilistic sequence modeling,"Chen, Shuo and Xu, Jiexun and Joachims, Thorsten",inproceedings,10.1145/2487575.2487632,
10.1145/2487575.2487646,10.1145/2487575.2487646,KDD.bib,1,['KDD.bib'],8,KDD '13,"Chicago, Illinois, USA","event-based group recommendation, latent factor model, location feature",9,910–918,Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Groups play an essential role in many social websites which promote users' interactions and accelerate the diffusion of information. Recommending groups that users are really interested to join is significant for both users and social media. While traditional group recommendation problem has been extensively studied, we focus on a new type of the problem, i.e., event-based group recommendation. Unlike the other forms of groups, users join this type of groups mainly for participating offline events organized by group members or inviting other users to attend events sponsored by them. These characteristics determine that previously proposed approaches for group recommendation cannot be adapted to the new problem easily as they ignore the geographical influence and other explicit features of groups and users.In this paper, we propose a method called Pairwise Tag enhAnced and featuRe-based Matrix factorIzation for Group recommendAtioN (PTARMIGAN), which considers location features, social features, and implicit patterns simultaneously in a unified model. More specifically, we exploit matrix factorization to model interactions between users and groups. Meanwhile, we incorporate their profile information into pairwise enhanced latent factors respectively. We also utilize the linear model to capture explicit features. Due to the reinforcement between explicit features and implicit patterns, our approach can provide better group recommendations. We conducted a comprehensive performance evaluation on real word data sets and the experimental results demonstrate the effectiveness of our method.",10.1145/2487575.2487646,https://doi.org/10.1145/2487575.2487646,"New York, NY, USA",Association for Computing Machinery,9781450321747,2013,Combining latent factor model with location features for event-based group recommendation,"Zhang, Wei and Wang, Jianyong and Feng, Wei",inproceedings,10.1145/2487575.2487646,
10.1145/2487575.2487656,10.1145/2487575.2487656,KDD.bib,1,['KDD.bib'],8,KDD '13,"Chicago, Illinois, USA","aggregate diversity, item-item similarity, long tail, niche items, recommender systems, usage context",9,955–963,Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"In order to satisfy and positively surprise the users, a recommender system needs to recommend items the users will like and most probably would not have found on their own. This requires the recommender system to recommend a broader range of items including niche items as well. Such an approach also support online-stores that often offer more items than traditional stores and need recommender systems to enable users to find the not so popular items as well. However, popular items that hold a lot of usage data are more easy to recommend and, thus, niche items are often excluded from the recommendations. In this paper, we propose a new collaborative filtering approach that is based on the items' usage contexts. The approach increases the rating predictions for niche items with fewer usage data available and improves the aggragate diversity of the recommendations.",10.1145/2487575.2487656,https://doi.org/10.1145/2487575.2487656,"New York, NY, USA",Association for Computing Machinery,9781450321747,2013,A new collaborative filtering approach for increasing the aggregate diversity of recommender systems,"Niemann, Katja and Wolpers, Martin",inproceedings,10.1145/2487575.2487656,
10.1145/2487575.2487673,10.1145/2487575.2487673,KDD.bib,1,['KDD.bib'],8,KDD '13,"Chicago, Illinois, USA","human mobility, location-based social networks, point-of-interest, recommender systems, user profiling",9,1043–1051,Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"The problem of point of interest (POI) recommendation is to provide personalized recommendations of places of interests, such as restaurants, for mobile users. Due to its complexity and its connection to location based social networks (LBSNs), the decision process of a user choose a POI is complex and can be influenced by various factors, such as user preferences, geographical influences, and user mobility behaviors. While there are some studies on POI recommendations, it lacks of integrated analysis of the joint effect of multiple factors. To this end, in this paper, we propose a novel geographical probabilistic factor analysis framework which strategically takes various factors into consideration. Specifically, this framework allows to capture the geographical influences on a user's check-in behavior. Also, the user mobility behaviors can be effectively exploited in the recommendation model. Moreover, the recommendation model can effectively make use of user check-in count data as implicity user feedback for modeling user preferences. Finally, experimental results on real-world LBSNs data show that the proposed recommendation method outperforms state-of-the-art latent factor models with a significant margin.",10.1145/2487575.2487673,https://doi.org/10.1145/2487575.2487673,"New York, NY, USA",Association for Computing Machinery,9781450321747,2013,Learning geographical preferences for point-of-interest recommendation,"Liu, Bin and Fu, Yanjie and Yao, Zijun and Xiong, Hui",inproceedings,10.1145/2487575.2487673,
10.1145/2487788.2487805,10.1145/2487788.2487805,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13 Companion,"Rio de Janeiro, Brazil","sentiment analysis, author preference, aspect rating",2,47–48,Proceedings of the 22nd International Conference on World Wide Web,"Traditional works in sentiment analysis do not incorporate author preferences during sentiment classification of reviews. In this work, we show that the inclusion of author preferences in sentiment rating prediction of reviews improves the correlation with ground ratings, over a generic author independent rating prediction model. The overall sentiment rating prediction for a review has been shown to improve by capturing facet level rating. We show that this can be further developed by considering author preferences in predicting the facet level ratings, and hence the overall review rating. To the best of our knowledge, this is the first work to incorporate author preferences in rating prediction.",10.1145/2487788.2487805,https://doi.org/10.1145/2487788.2487805,"New York, NY, USA",Association for Computing Machinery,9781450320382,2013,Incorporating author preference in sentiment rating prediction of reviews,"Mukherjee, Subhabrata and Basu, Gaurab and Joshi, Sachindra",inproceedings,10.1145/2487788.2487805,
10.1145/2487788.2487877,10.1145/2487788.2487877,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13 Companion,"Rio de Janeiro, Brazil","structural diversity, social network, popularity prediction, microblogging, information diffusion",2,177–178,Proceedings of the 22nd International Conference on World Wide Web,"Predicting the popularity of content is important for both the host and users of social media sites. The challenge of this problem comes from the inequality of the popularity of content. Existing methods for popularity prediction are mainly based on the quality of content, the interface of social media site to highlight contents, and the collective behavior of users. However, little attention is paid to the structural characteristics of the networks spanned by early adopters, i.e., the users who view or forward the content in the early stage of content dissemination. In this paper, taking the Sina Weibo as a case, we empirically study whether structural characteristics can provide clues for the popularity of short messages. We find that the popularity of content is well reflected by the structural diversity of the early adopters. Experimental results demonstrate that the prediction accuracy is significantly improved by incorporating the factor of structural diversity into existing methods.",10.1145/2487788.2487877,https://doi.org/10.1145/2487788.2487877,"New York, NY, USA",Association for Computing Machinery,9781450320382,2013,Popularity prediction in microblogging network: a case study on sina weibo,"Bao, Peng and Shen, Hua-Wei and Huang, Junming and Cheng, Xue-Qi",inproceedings,10.1145/2487788.2487877,
10.1145/2487788.2487947,10.1145/2487788.2487947,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13 Companion,"Rio de Janeiro, Brazil","user modeling, context, advertising",6,383–388,Proceedings of the 22nd International Conference on World Wide Web,"Predictive Web Analytics is aimed at understanding behavioural patterns of users of various web-based applications: e-commerce, ubiquitous and mobile computing, and computational advertising. Within these applications business decisions often rely on two types of predictions: an overall or particular user segment demand predictions and individualised recommendations for visitors. Visitor behaviour is inherently sensitive to the context, which can be defined as a collection of external factors. Context-awareness allows integrating external explanatory information into the learning process and adapting user behaviour accordingly. The importance of context-awareness has been recognised by researchers and practitioners in many disciplines, including recommendation systems, information retrieval, personalisation, data mining, and marketing. We focus on studying ways of context discovery and its integration into predictive analytics.",10.1145/2487788.2487947,https://doi.org/10.1145/2487788.2487947,"New York, NY, USA",Association for Computing Machinery,9781450320382,2013,Context mining and integration into predictive web analytics,"Kiseleva, Julia",inproceedings,10.1145/2487788.2487947,
10.1145/2487788.2488090,10.1145/2487788.2488090,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13 Companion,"Rio de Janeiro, Brazil","nash equilibrium, group recommendation, game theory",8,951–958,Proceedings of the 22nd International Conference on World Wide Web,"A major difficulty in a recommendation system for groups is to use a group aggregation strategy to ensure, among other things, the maximization of the average satisfaction of group members. This paper presents an approach based on the theory of noncooperative games to solve this problem. While group members can be seen as game players, the items for potential recommendation for the group comprise the set of possible actions. Achieving group satisfaction as a whole becomes, then, a problem of finding the Nash equilibrium. Experiments with a MovieLens dataset and a function of arithmetic mean to compute the prediction of group satisfaction for the generated recommendation have shown statistically significant results when compared to state-of-the-art aggregation strategies, in particular, when evaluation among group members are more heterogeneous. The feasibility of this unique approach is shown by the development of an application for Facebook, which recommends movies to groups of friends.",10.1145/2487788.2488090,https://doi.org/10.1145/2487788.2488090,"New York, NY, USA",Association for Computing Machinery,9781450320382,2013,Users' satisfaction in recommendation systems for groups: an approach based on noncooperative games,"Carvalho, Lucas Augusto Montalv\~{a}o Costa and Macedo, Hendrik Teixeira",inproceedings,10.1145/2487788.2488090,
10.1145/2488388.2488396,10.1145/2488388.2488396,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","user modeling, time-based features, display advertising, behavioral targeting",12,71–82,Proceedings of the 22nd International Conference on World Wide Web,"Modern web-scale behavioral targeting platforms leverage historical activity of billions of users to predict user interests and inclinations, and consequently future activities. Future activities of particular interest involve purchases or transactions, and are referred to as conversions. Unlike ad-clicks, conversions directly translate to advertiser's revenue, and thus provide a very concrete metric for return on advertising investment. A typical behavioral targeting system faces two main challenges: the web-scale amounts of user histories to process on a daily basis, and the relative sparsity of conversions (compared to clicks in a traditional setting). These challenges call for generation of effective and efficient user profiles. Most existing works use the historical intensity of a user's interest in various topics to model future interest. In this paper we explore how the change in user behavior can be used to predict future actions and show how it complements the traditional models of decaying interest and action recency to build a complete picture about the user interests and better predict conversions. Our evaluation over a real-world set of campaigns indicates that the combination of change of interest, decaying intensity, and action recency helps in: 1) scoring significant improvements in optimizing for conversions over traditional baselines, 2) substantially improving the targeting efficiency for campaigns with highly sparse conversions, and 3) highly reducing the overall history sizes used in targeting. Furthermore, our techniques have been deployed to production and scored a substantial improvement in targeting performance while imposing a negligible overhead in terms of overall platform running time.",10.1145/2488388.2488396,https://doi.org/10.1145/2488388.2488396,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,Towards a robust modeling of temporal interest change patterns for behavioral targeting,"Aly, Mohamed and Pandey, Sandeep and Josifovski, Vanja and Punera, Kunal",inproceedings,10.1145/2488388.2488396,
10.1145/2488388.2488407,10.1145/2488388.2488407,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","privacy, mobile app, maturity rating, ios apps, children safety, application permissions, android apps",12,201–212,Proceedings of the 22nd International Conference on World Wide Web,"There is a rising concern among parents who have experienced unreliable content maturity ratings for mobile applications (apps) that result in inappropriate risk exposure for their children and adolescents. In reality, there is no consistent maturity rating policy for mobile applications. The maturity ratings of Android apps are provided purely by developers' self-disclosure and are rarely verified. While Apple's iOS app ratings are considered to be more accurate, they can also be inconsistent with Apple's published policies. To address these issues, this research aims to systematically uncover the extent and severity of unreliable maturity ratings for mobile apps. Specifically, we develop mechanisms to verify the maturity ratings of mobile apps and investigate possible reasons behind the incorrect ratings. We believe that our findings have important implications for platform providers (e.g., Google or Apple) as well as for regulatory bodies and application developers.",10.1145/2488388.2488407,https://doi.org/10.1145/2488388.2488407,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,Is this app safe for children? a comparison study of maturity ratings on Android and iOS applications,"Chen, Ying and Xu, Heng and Zhou, Yilu and Zhu, Sencun",inproceedings,10.1145/2488388.2488407,
10.1145/2488388.2488432,10.1145/2488388.2488432,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","relevance ranking, probabilistic modelling, information matching, group recommendation",10,495–504,Proceedings of the 22nd International Conference on World Wide Web,"Increasingly, web recommender systems face scenarios where they need to serve suggestions to groups of users; for example, when families share e-commerce or movie rental web accounts. Research to date in this domain has proposed two approaches: computing recommendations for the group by merging any members' ratings into a single profile, or computing ranked recommendations for each individual that are then merged via a range of heuristics. In doing so, none of the past approaches reason on the preferences that arise in individuals when they are members of a group. In this work, we present a probabilistic framework, based on the notion of information matching, for group recommendation. This model defines group relevance as a combination of the item's relevance to each user as an individual and as a member of the group; it can then seamlessly incorporate any group recommendation strategy in order to rank items for a set of individuals. We evaluate the model's efficacy at generating recommendations for both single individuals and groups using the MovieLens and MoviePilot data sets. In both cases, we compare our results with baselines and state-of-the-art collaborative filtering algorithms, and show that the model outperforms all others over a variety of ranking metrics.",10.1145/2488388.2488432,https://doi.org/10.1145/2488388.2488432,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,Probabilistic group recommendation via information matching,"Gorla, Jagadeesh and Lathia, Neal and Robertson, Stephen and Wang, Jun",inproceedings,10.1145/2488388.2488432,
10.1145/2488388.2488441,10.1145/2488388.2488441,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","triadic factorization, recommender system, cross-domain collaborative filtering",12,595–606,Proceedings of the 22nd International Conference on World Wide Web,"Collaborative filtering (CF) is a major technique in recommender systems to help users find their potentially desired items. Since the data sparsity problem is quite commonly encountered in real-world scenarios, Cross-Domain Collaborative Filtering (CDCF) hence is becoming an emerging research topic in recent years. However, due to the lack of sufficient dense explicit feedbacks and even no feedback available in users' uninvolved domains, current CDCF approaches may not perform satisfactorily in user preference prediction. In this paper, we propose a generalized Cross Domain Triadic Factorization (CDTF) model over the triadic relation user-item-domain, which can better capture the interactions between domain-specific user factors and item factors. In particular, we devise two CDTF algorithms to leverage user explicit and implicit feedbacks respectively, along with a genetic algorithm based weight parameters tuning algorithm to trade off influence among domains optimally. Finally, we conduct experiments to evaluate our models and compare with other state-of-the-art models by using two real world datasets. The results show the superiority of our models against other comparative models.",10.1145/2488388.2488441,https://doi.org/10.1145/2488388.2488441,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,Personalized recommendation via cross-domain triadic factorization,"Hu, Liang and Cao, Jian and Xu, Guandong and Cao, Longbing and Gu, Zhiping and Zhu, Can",inproceedings,10.1145/2488388.2488441,
10.1145/2488388.2488442,10.1145/2488388.2488442,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","social media, social correlation, sentiment classification, sentiment analysis, emotional signals, emoticon, Twitter",12,607–618,Proceedings of the 22nd International Conference on World Wide Web,"The explosion of social media services presents a great opportunity to understand the sentiment of the public via analyzing its large-scale and opinion-rich data. In social media, it is easy to amass vast quantities of unlabeled data, but very costly to obtain sentiment labels, which makes unsupervised sentiment analysis essential for various applications. It is challenging for traditional lexicon-based unsupervised methods due to the fact that expressions in social media are unstructured, informal, and fast-evolving. Emoticons and product ratings are examples of emotional signals that are associated with sentiments expressed in posts or words. Inspired by the wide availability of emotional signals in social media, we propose to study the problem of unsupervised sentiment analysis with emotional signals. In particular, we investigate whether the signals can potentially help sentiment analysis by providing a unified way to model two main categories of emotional signals, i.e., emotion indication and emotion correlation. We further incorporate the signals into an unsupervised learning framework for sentiment analysis. In the experiment, we compare the proposed framework with the state-of-the-art methods on two Twitter datasets and empirically evaluate our proposed framework to gain a deep understanding of the effects of emotional signals.",10.1145/2488388.2488442,https://doi.org/10.1145/2488388.2488442,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,Unsupervised sentiment analysis with emotional signals,"Hu, Xia and Tang, Jiliang and Gao, Huiji and Liu, Huan",inproceedings,10.1145/2488388.2488442,
10.1145/2488388.2488445,10.1145/2488388.2488445,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","recommendation, multi-context, matrix factorization, cold start",12,643–654,Proceedings of the 22nd International Conference on World Wide Web,"With the growing amount of information available online, recommender systems are starting to provide a viable alternative and complement to search engines, in helping users to find objects of interest. Methods based on Matrix Factorization (MF) models are the state-of-the-art in recommender systems. The input to MF is user feedback, in the form of a rating matrix. However, users can be engaged in interactions with multiple types of entities across different contexts, leading to multiple rating matrices. In other words, users can have interactions in a heterogeneous information network. Generally, in a heterogeneous network, entities from any two entity types can have interactions with a weight (rating) indicating the level of endorsement. Collective Matrix Factorization (CMF) has been proposed to address the recommendation problem in heterogeneous networks. However, a main issue with CMF is that entities share the same latent factor across different contexts. This is particularly problematic in two cases: Latent factors for entities that are cold-start in a context will be learnt mainly based on the data from other contexts where these entities are not cold-start, and therefore the factors are not properly learned for the cold-start context. Also, if a context has more data compared to another context, then the dominant context will dominate the learning process for the latent factors for entities shared in these two contexts. In this paper, we propose a context-dependent matrix factorization model, HeteroMF, that considers a general latent factor for entities of every entity type and context-dependent latent factors for every context in which the entities are involved. We learn a general latent factor for every entity and transfer matrices for every context to convert the general latent factors into a context-dependent latent factor. Experiments on two real life datasets from Epinions and Flixster demonstrate that HeteroMF substantially outperforms CMF, particularly for cold-start entities and for contexts where interactions in one contexts are dominated by other contexts.",10.1145/2488388.2488445,https://doi.org/10.1145/2488388.2488445,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,HeteroMF: recommendation in heterogeneous information networks using context dependent factor models,"Jamali, Mohsen and Lakshmanan, Laks",inproceedings,10.1145/2488388.2488445,
10.1145/2488388.2488463,10.1145/2488388.2488463,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","short urls, security, measurement, crowdsourcing",12,861–872,Proceedings of the 22nd International Conference on World Wide Web,"URL shortening services have become extremely popular. However, it is still unclear whether they are an effective and reliable tool that can be leveraged to hide malicious URLs, and to what extent these abuses can impact the end users. With these questions in mind, we first analyzed existing countermeasures adopted by popular shortening services. Surprisingly, we found such countermeasures to be ineffective and trivial to bypass. This first measurement motivated us to proceed further with a large-scale collection of the HTTP interactions that originate when web users access live pages that contain short URLs. To this end, we monitored 622 distinct URL shortening services between March 2010 and April 2012, and collected 24,953,881 distinct short URLs. With this large dataset, we studied the abuse of short URLs. Despite short URLs are a significant, new security risk, in accordance with the reports resulting from the observation of the overall phishing and spamming activity, we found that only a relatively small fraction of users ever encountered malicious short URLs. Interestingly, during the second year of measurement, we noticed an increased percentage of short URLs being abused for drive-by download campaigns and a decreased percentage of short URLs being abused for spam campaigns. In addition to these security-related findings, our unique monitoring infrastructure and large dataset allowed us to complement previous research on short URLs and analyze these web services from the user's perspective.",10.1145/2488388.2488463,https://doi.org/10.1145/2488388.2488463,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,Two years of short URLs internet measurement: security threats and countermeasures,"Maggi, Federico and Frossi, Alessandro and Zanero, Stefano and Stringhini, Gianluca and Stone-Gross, Brett and Kruegel, Christopher and Vigna, Giovanni",inproceedings,10.1145/2488388.2488463,
10.1145/2488388.2488467,10.1145/2488388.2488467,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","user modeling, rating prediction, latent dirichlet allocation, cold start item, aspect-based opinion mining, aspect identification",10,909–918,Proceedings of the 22nd International Conference on World Wide Web,"Aspect-based opinion mining from online reviews has attracted a lot of attention recently. The main goal of all of the proposed methods is extracting aspects and/or estimating aspect ratings. Recent works, which are often based on Latent Dirichlet Allocation (LDA), consider both tasks simultaneously. These models are normally trained at the item level, i.e., a model is learned for each item separately. Learning a model per item is fine when the item has been reviewed extensively and has enough training data. However, in real-life data sets such as those from Epinions.com and Amazon.com more than 90% of items have less than 10 reviews, so-called cold start items. State-of-the-art LDA models for aspect-based opinion mining are trained at the item level and therefore perform poorly for cold start items due to the lack of sufficient training data. In this paper, we propose a probabilistic graphical model based on LDA, called Factorized LDA (FLDA), to address the cold start problem. The underlying assumption of FLDA is that aspects and ratings of a review are influenced not only by the item but also by the reviewer. It further assumes that both items and reviewers can be modeled by a set of latent factors which represent their aspect and rating distributions. Different from state-of-the-art LDA models, FLDA is trained at the category level and learns the latent factors using the reviews of all the items of a category, in particular the non cold start items, and uses them as prior for cold start items. Our experiments on three real-life data sets demonstrate the improved effectiveness of the FLDA model in terms of likelihood of the held-out test set. We also evaluate the accuracy of FLDA based on two application-oriented measures.",10.1145/2488388.2488467,https://doi.org/10.1145/2488388.2488467,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,The FLDA model for aspect-based opinion mining: addressing the cold start problem,"Moghaddam, Samaneh and Ester, Martin",inproceedings,10.1145/2488388.2488467,
10.1145/2488388.2488475,10.1145/2488388.2488475,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","variational inference, random graph, one-class collaborative filtering",10,999–1008,Proceedings of the 22nd International Conference on World Wide Web,"The bane of one-class collaborative filtering is interpreting and modelling the latent signal from the missing class. In this paper we present a novel Bayesian generative model for implicit collaborative filtering. It forms a core component of the Xbox Live architecture, and unlike previous approaches, delineates the odds of a user disliking an item from simply being unaware of it. The latent signal is treated as an unobserved random graph connecting users with items they might have encountered. We demonstrate how large-scale distributed learning can be achieved through a combination of stochastic gradient descent and mean field variational inference over random graph samples. A fine-grained comparison is done against a state of the art baseline on real world data.",10.1145/2488388.2488475,https://doi.org/10.1145/2488388.2488475,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,One-class collaborative filtering with random graphs,"Paquet, Ulrich and Koenigstein, Noam",inproceedings,10.1145/2488388.2488475,
10.1145/2488388.2488503,10.1145/2488388.2488503,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","inter-event times, generative model, communication dynamics",12,1319–1330,Proceedings of the 22nd International Conference on World Wide Web,"How often do individuals perform a given communication activity in the Web, such as posting comments on blogs or news? Could we have a generative model to create communication events with realistic inter-event time distributions (IEDs)? Which properties should we strive to match? Current literature has seemingly contradictory results for IED: some studies claim good fits with power laws; others with non-homogeneous Poisson processes. Given these two approaches, we ask: which is the correct one? Can we reconcile them all? We show here that, surprisingly, both approaches are correct, being corner cases of the proposed Self-Feeding Process (SFP). We show that the SFP (a) exhibits a unifying power, which generates power law tails (including the so-called ""top-concavity"" that real data exhibits), as well as short-term Poisson behavior; (b) avoids the ""i.i.d. fallacy"", which none of the prevailing models have studied before; and (c) is extremely parsimonious, requiring usually only one, and in general, at most two parameters. Experiments conducted on eight large, diverse real datasets (e.g., Youtube and blog comments, e-mails, SMSs, etc) reveal that the SFP mimics their properties very well.",10.1145/2488388.2488503,https://doi.org/10.1145/2488388.2488503,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,The self-feeding process: a unifying model for communication dynamics in the web,"Vaz de Melo, Pedro Olmo S. and Faloutsos, Christos and Assun\c{c}\~{a}o, Renato and Loureiro, Antonio",inproceedings,10.1145/2488388.2488503,
10.1145/2488388.2488519,10.1145/2488388.2488519,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","social network, recommender systems, probabilistic topic modeling, collaborative filtering",10,1501–1510,Proceedings of the 22nd International Conference on World Wide Web,"Traditionally, Collaborative Filtering assumes that similar users have similar responses to similar items. However, human activities exhibit heterogenous features across multiple domains such that users own similar tastes in one domain may behave quite differently in other domains. Moreover, highly sparse data presents crucial challenge in preference prediction. Intuitively, if users' interested domains are captured first, the recommender system is more likely to provide the enjoyed items while filter out those uninterested ones. Therefore, it is necessary to learn preference profiles from the correlated domains instead of the entire user-item matrix. In this paper, we propose a unified framework, TopRec, which detects topical communities to construct interpretable domains for domain-specific collaborative filtering. In order to mine communities as well as the corresponding topics, a semi-supervised probabilistic topic model is utilized by integrating user guidance with social network. Experimental results on real-world data from Epinions and Ciao demonstrate the effectiveness of the proposed framework.",10.1145/2488388.2488519,https://doi.org/10.1145/2488388.2488519,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,TopRec: domain-specific recommendation through community topic mining in social network,"Zhang, Xi and Cheng, Jian and Yuan, Ting and Niu, Biao and Lu, Hanqing",inproceedings,10.1145/2488388.2488519,
10.1145/2488388.2488520,10.1145/2488388.2488520,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '13,"Rio de Janeiro, Brazil","matrix factorization, graph partitioning, collaborative filtering, block diagonal form",10,1511–1520,Proceedings of the 22nd International Conference on World Wide Web,"Matrix factorization on user-item rating matrices has achieved significant success in collaborative filtering based recommendation tasks. However, it also encounters the problems of data sparsity and scalability when applied in real-world recommender systems. In this paper, we present the Localized Matrix Factorization (LMF) framework, which attempts to meet the challenges of sparsity and scalability by factorizing Block Diagonal Form (BDF) matrices. In the LMF framework, a large sparse matrix is first transformed into Recursive Bordered Block Diagonal Form (RBBDF), which is an intuitionally interpretable structure for user-item rating matrices. Smaller and denser submatrices are then extracted from this RBBDF matrix to construct a BDF matrix for more effective collaborative prediction. We show formally that the LMF framework is suitable for matrix factorization and that any decomposable matrix factorization algorithm can be integrated into this framework. It has the potential to improve prediction accuracy by factorizing smaller and denser submatrices independently, which is also suitable for parallelization and contributes to system scalability at the same time. Experimental results based on a number of real-world public-access benchmarks show the effectiveness and efficiency of the proposed LMF framework.",10.1145/2488388.2488520,https://doi.org/10.1145/2488388.2488520,"New York, NY, USA",Association for Computing Machinery,9781450320351,2013,Localized matrix factorization for recommendation based on matrix block diagonal forms,"Zhang, Yongfeng and Zhang, Min and Liu, Yiqun and Ma, Shaoping and Feng, Shi",inproceedings,10.1145/2488388.2488520,
10.1145/2492517.2492551,10.1145/2492517.2492551,KDD.bib,1,['KDD.bib'],7,ASONAM '13,"Niagara, Ontario, Canada",,8,684–691,Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"The problem of Twitter user classification using the contents of tweets is studied. We generate time series from tweets by exploiting the latent temporal information and solve the classification problem in time series domain. Our approach is inspired by the fact that Twitter users sometimes exhibit the periodicity pattern when they share their activities or express their opinions. We apply our proposed methods to both binary and multi-class classification of sports and political interests of Twitter users and compare the performance against eight conventional classification methods using textual features. Experimental results using 2.56 million tweets show that our best binary and multi-class approaches improve the classification accuracy over the best baseline binary and multi-class approaches by 15% and 142%, respectively.",10.1145/2492517.2492551,https://doi.org/10.1145/2492517.2492551,"New York, NY, USA",Association for Computing Machinery,9781450322409,2013,"Steeler nation, 12th man, and boo birds: classifying Twitter user interests using time series","Yang, Tao and Lee, Dongwon and Yan, Su",inproceedings,10.1145/2492517.2492551,
10.1145/2492517.2492565,10.1145/2492517.2492565,KDD.bib,1,['KDD.bib'],7,ASONAM '13,"Niagara, Ontario, Canada",,8,628–635,Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"In the context of collaborative filtering, the well-known data sparsity issue makes two like-minded users have little similarity, and consequently renders the k nearest neighbour rule inapplicable. In this paper, we address the data sparsity problem in the neighbourhood-based CF methods by proposing an Adaptive-Maximum imputation method (AdaM). The basic idea is to identify an imputation area that can maximize the imputation benefit for recommendation purposes, while minimizing the imputation error brought in. To achieve the maximum imputation benefit, the imputation area is determined from both the user and the item perspectives; to minimize the imputation error, there is at least one real rating preserved for each item in the identified imputation area. A theoretical analysis is provided to prove that the proposed imputation method outperforms the conventional neighbourhood-based CF methods through more accurate neighbour identification. Experiment results on benchmark datasets show that the proposed method significantly outperforms the other related state-of-the-art imputation-based methods in terms of accuracy.",10.1145/2492517.2492565,https://doi.org/10.1145/2492517.2492565,"New York, NY, USA",Association for Computing Machinery,9781450322409,2013,AdaM: adaptive-maximum imputation for neighborhood-based collaborative filtering,"Ren, Yongli and Li, Gang and Zhang, Jun and Zhou, Wanlei",inproceedings,10.1145/2492517.2492565,
10.1145/2492517.2500234,10.1145/2492517.2500234,KDD.bib,1,['KDD.bib'],8,ASONAM '13,"Niagara, Ontario, Canada","Twitter, authorship attribution, clustering, malicious campaigns, online social networks, suspicious profiles",8,1307–1314,Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"In the last few decades social networking sites have encountered their first large-scale security issues. The high number of users associated with the presence of sensitive data (personal or professional) is certainly an unprecedented opportunity for malicious activities. As a result, one observes that malicious users are progressively turning their attention from traditional e-mail to online social networks to carry out their attacks. Moreover, it is now observed that attacks are not only performed by individual profiles, but that on a larger scale, a set of profiles can act in coordination in making such attacks. The latter are referred to as malicious social campaigns. In this paper, we present a novel approach that combines authorship attribution techniques with a behavioural analysis for detecting and characterizing social campaigns. The proposed approach is performed in three steps: first, suspicious profiles are identified from a behavioural analysis; second, connections between suspicious profiles are retrieved using a combination of authorship attribution and temporal similarity; third, a clustering algorithm is performed to identify and characterise the suspicious campaigns obtained. We provide a real-life application of the methodology on a sample of 1,000 suspicious Twitter profiles tracked over a period of forty days. Our results show that a large set of suspicious profiles behaves in coordination (70%) and propagates mainly, but not only, trustworthy URLs on the online social network. Among the three largest detected campaigns, we have highlighted that one represents an important security issue for the platform by promoting a significant set of malicious URLs.",10.1145/2492517.2500234,https://doi.org/10.1145/2492517.2500234,"New York, NY, USA",Association for Computing Machinery,9781450322409,2013,REPLOT: REtrieving profile links on Twitter for suspicious networks detection,"Perez, Charles and Birregah, Babiga and Layton, Robert and Lemercier, Marc and Watters, Paul",inproceedings,10.1145/2492517.2500234,
10.1145/2492517.2500273,10.1145/2492517.2500273,KDD.bib,1,['KDD.bib'],7,ASONAM '13,"Niagara, Ontario, Canada",,8,1139–1146,Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Social networks are platforms where millions of users interact frequently and share variety of digital content with each other. Users express their feelings and opinions on every topic of interest. These opinions carry import value for personal, academic and commercial applications, but the volume and the speed at which these are produced make it a challenging task for researchers and the underlying technologies to provide useful insights to such data. We attempt to extend the established OLAP(On-line Analytical Processing) technology to allow multidimensional analysis of social media data by integrating text and opinion mining methods into the data warehousing system and by exploiting various knowledge discovery techniques to deal with semi-structured and unstructured data from social media.The capabilities of OLAP are extended by semantic enrichment of the underlying dataset to discover new measures and dimensions for building data cubes and by supporting up-to-date analysis of the evolving as well as the historical social media data. The benefits of such an analysis platform are demonstrated by building a data warehouse for a social network of Twitter, dynamically enriching the underlying dataset and enabling multidimensional analysis.",10.1145/2492517.2500273,https://doi.org/10.1145/2492517.2500273,"New York, NY, USA",Association for Computing Machinery,9781450322409,2013,OLAPing social media: the case of Twitter,"Rehman, Nafees Ur and Weiler, Andreas and Scholl, Marc H.",inproceedings,10.1145/2492517.2500273,
10.1145/2501221.2501222,10.1145/2501221.2501222,KDD.bib,1,['KDD.bib'],7,BigMine '13,"Chicago, Illinois",,6,1–6,"Proceedings of the 2nd International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications","Since the Netflix $1 million Prize, announced in 2006, our company has been known to have personalization at the core of our product. Even at that point in time, the dataset that we released was considered ""large"", and we stirred innovation in the (Big) Data Mining research field. Our current product offering is now focused around instant video streaming, and our data is now many orders of magnitude larger. Not only do we have many more users in many more countries, but we also receive many more streams of data. Besides the ratings, we now also use information such as what our members play, browse, or search.In this paper, we will discuss the different approaches we follow to deal with these large streams of data in order to extract information for personalizing our service. We will describe some of the machine learning models used, as well as the architectures that allow us to combine complex offline batch processes with real-time data streams.",10.1145/2501221.2501222,https://doi.org/10.1145/2501221.2501222,"New York, NY, USA",Association for Computing Machinery,9781450323246,2013,Big &amp; personal: data and models behind netflix recommendations,"Amatriain, Xavier",inproceedings,10.1145/2501221.2501222,
10.1145/2501221.2501230,10.1145/2501221.2501230,KDD.bib,1,['KDD.bib'],8,BigMine '13,"Chicago, Illinois","SmartTV, algorithms, collaborative filtering, content-based filtering, hybrid TV, offline, online, recommendation",8,63–70,"Proceedings of the 2nd International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications","Switching through the variety of available TV channels to find the most acceptable program at the current time can be very time-consuming. Especially at the prime time when there are lots of different channels offering quality content it is hard to find the best fitting channel.This paper introduces the TV Predictor, a new application that allows for obtaining personalized program recommendations without leaving the lean back position in front of the TV. Technically the usage of common Standards and Specifications, such as HbbTV, OIPF and W3C, leverage the convergence of broadband and broadcast media. Hints and details can overlay the broadcasting signal and so the user gets predictions in appropriate situations, for instance the most suitable movies playing tonight. Additionally the TV Predictor Autopilot enables the TV set to automatically change the currently viewed channel. A Second Screen Application mirrors the TV screen or displays additional content on tablet PCs and Smartphones.Based on the customers viewing behavior and explicit given ratings the server side application predicts what the viewer is going to favor. Different data mining approaches are combined in order to calculate the users preferences: Content Based Filtering algorithms for similar items, Collaborative Filtering algorithms for rating predictions, Clustering for increasing the performance, Association Rules for analyzing item relations and Support Vector Machines for the identification of behavior patterns. A ten fold cross validation shows an accuracy in prediction of about 80%.TV specialized User Interfaces, user generated feedback data and calculated algorithm results, such as Association Rules, are analyzed to underline the characteristics of such a TV based application.",10.1145/2501221.2501230,https://doi.org/10.1145/2501221.2501230,"New York, NY, USA",Association for Computing Machinery,9781450323246,2013,TV predictor: personalized program recommendations to be displayed on SmartTVs,"Krauss, Christopher and George, Lars and Arbanowski, Stefan",inproceedings,10.1145/2501221.2501230,
10.1145/2505515.2505517,10.1145/2505515.2505517,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","collaborative filtering, indian buffet process, multitask learning",10,2149–2158,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"The dramatic rates new digital content becomes available has brought collaborative filtering systems to the epicenter of computer science research in the last decade. One of the greatest challenges collaborative filtering systems are confronted with is the data sparsity problem: users typically rate only very few items; thus, availability of historical data is not adequate to effectively perform prediction. To alleviate these issues, in this paper we propose a novel multitask collaborative filtering approach. Our approach is based on a coupled latent factor model of the users rating functions, which allows for coming up with an agile information sharing mechanism that extracts much richer task-correlation information compared to existing approaches. Formulation of our method is based on concepts from the field of Bayesian nonparametrics, specifically Indian Buffet Process priors, which allow for data-driven determination of the optimal number of underlying latent features (item characteristics and user traits) assumed in the context of the model. We experiment on several real-world datasets, demonstrating both the efficacy of our method, and its superiority over existing approaches.",10.1145/2505515.2505517,https://doi.org/10.1145/2505515.2505517,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,Nonparametric bayesian multitask collaborative filtering,"Chatzis, Sotirios",inproceedings,10.1145/2505515.2505517,
10.1145/2505515.2505523,10.1145/2505515.2505523,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","popularity prediction, propagation, social network, video sharing",10,169–178,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"Popularity prediction, with both technological and economic importance, has been extensively studied for conventional video sharing sites (VSSes), where the videos are mainly found via searching, browsing, or related links. Recent statistics however suggest that online social network (OSN) users regularly share video contents from VSSes, which has contributed to a significant portion of the accesses; yet the popularity prediction in this new context remains largely unexplored. In this paper, we present an initial study on the popularity prediction of videos propagated in OSNs along friendship links.We conduct a large-scale measurement and analysis of viewing patterns of videos shared in one of largest OSNs in China, and examine the performance of typical views-based prediction models. We find that they are generally ineffective, if not totally fail, especially when predicting the early peaks and later bursts of accesses, which are common during video propagations in OSNs. To overcome these limits, we track the propagation process of videos shared in a Facebook-like OSN in China, and analyze the user viewing and sharing behaviors. We accordingly develop a novel propagation-based video popularity prediction solution, namely SoVP. Instead of relying solely on the early views for prediction, SoVP considers both the intrinsic attractiveness of a video and the influence from the underlying propagation structure. The effectiveness of SoVP, particularly for predicting the peaks and bursts, have been validated through our trace-driven experiments.",10.1145/2505515.2505523,https://doi.org/10.1145/2505515.2505523,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,On popularity prediction of videos shared in online social networks,"Li, Haitao and Ma, Xiaoqiang and Wang, Feng and Liu, Jiangchuan and Xu, Ke",inproceedings,10.1145/2505515.2505523,
10.1145/2505515.2505569,10.1145/2505515.2505569,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","co-training, multiclass svm, semi-supervised learning, sentiment classification, topic-adaptive, tweet sentiment",10,2079–2088,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"Sentiment classification is an important problem in tweets mining. There lack labeled data and rating mechanism for generating them in Twitter service. And topics in Twitter are more diverse while sentiment classifiers always dedicate themselves to a specific domain or topic. Thus it is a challenge to make sentiment classification adaptive to diverse topics without sufficient labeled data. Therefore we formally propose an adaptive multiclass SVM model which transfers an initial common sentiment classifier to a topic-adaptive one. To tackle the tweet sparsity, non-text features are explored besides the conventional text features, which are intuitively split into two views. An iterative algorithm is proposed for solving this model by alternating among three steps: optimization, unlabeled data selection and adaptive feature expansion steps. The algorithm alternatively minimizes the margins of two independent objectives on different views to learn coefficient matrices, which are collaboratively used for unlabeled tweets selection from the topic that the algorithm is adapting to. And then topic-adaptive sentiment words are expended based on the above selection, in turn to help the first two steps find more confident and unlabeled tweets and boost the final performance. Comparing with the well-known supervised sentiment classifiers and semi-supervised approaches, our algorithm achieves promising increases in accuracy averagely on the 6 topics from public tweet corpus.",10.1145/2505515.2505569,https://doi.org/10.1145/2505515.2505569,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,Adaptive co-training SVM for sentiment classification on tweets,"Liu, Shenghua and Li, Fuxin and Li, Fangtao and Cheng, Xueqi and Shen, Huawei",inproceedings,10.1145/2505515.2505569,
10.1145/2505515.2505587,10.1145/2505515.2505587,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","diffusion of innovations, innovation networks",10,499–508,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"The spreading of innovations among individuals and organizations in a social network has been extensively studied. Although the recent studies among the social computing and data mining communities have produced various insightful conclusions about the diffusion process of innovations by focusing on the properties and evolution of social network structures, less attention has been paid to the interrelationships among the multiple innovations being diffused, such as the competitive and collaborative relationships between innovations. In this paper, we take a formal quantitative approach to address how different pieces of innovations socialize with each other and how the interrelationships among innovations affect users' adoption behavior, which provides a novel perspective of understanding the diffusion of innovations. Networks of innovations are constructed by mining large scale text collections in an unsupervised fashion. We are particularly interested in the following questions: what are the meaningful metrics on the network of innovations? What effects do these metrics exert on the diffusion of innovations? Do these effects vary among users with different adoption preferences or communication styles? While existing studies primarily address social influence, we provide a detailed discussion of how innovations interrelate and influence the diffusion process.",10.1145/2505515.2505587,https://doi.org/10.1145/2505515.2505587,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,Diffusion of innovations revisited: from social network to innovation network,"Rong, Xin and Mei, Qiaozhu",inproceedings,10.1145/2505515.2505587,
10.1145/2505515.2505653,10.1145/2505515.2505653,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","collaborative filtering, graded average precision, latent factor model, ranking, recommender systems, top-n recommendation",6,2261–2266,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"Recommender systems are frequently used in domains in which users express their preferences in the form of graded judgments, such as ratings. Current ranking techniques are based on one of two sub-optimal approaches: either they optimize for a binary metric such as Average Precision, which discards information on relevance levels, or they optimize for Normalized Discounted Cumulative Gain (NDCG), which ignores the dependence of an item's contribution on the relevance of more highly ranked items. We address the shortcomings of existing approaches by proposing GAPfm, the Graded Average Precision factor model, which is a latent factor model for top-N recommendation in domains with graded relevance data. The model optimizes the Graded Average Precision metric that has been proposed recently for assessing the quality of ranked results lists for graded relevance. GAPfm's advantages are twofold: it maintains full information about graded relevance and also addresses the limitations of models that optimize NDCG. Experimental results show that GAPfm achieves substantial improvements on the top-N recommendation task, compared to several state-of-the-art approaches.",10.1145/2505515.2505653,https://doi.org/10.1145/2505515.2505653,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,GAPfm: optimal top-n recommendations for graded relevance domains,"Shi, Yue and Karatzoglou, Alexandros and Baltrunas, Linas and Larson, Martha and Hanjalic, Alan",inproceedings,10.1145/2505515.2505653,
10.1145/2505515.2505667,10.1145/2505515.2505667,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","agreement, microblog, relevance, search, trust, twitter",6,2345–2350,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"The increasing popularity of Twitter renders improved trust- worthiness and relevance assessment of tweets much more important for search. However, given the limitations on the size of tweets, it is hard to extract measures for ranking from the tweets? content alone. We present a novel ranking method called RAProp, which combines two orthogonal measures of relevance and trustworthiness of a tweet. The first, called Feature Score, measures the trustworthiness of the source of the tweet by extracting features from a 3-layer Twitter ecosystem consisting of users, tweets and webpages. The second measure, called agreement analysis, estimates the trustworthiness of the content of a tweet by analyzing whether the content is independently corroborated by other tweets. We view the candidate result set of tweets as the vertices of a graph, with the edges measuring the estimated agreement between each pair of tweets. The feature score is propagated over this agreement graph to compute the top-k tweets that have both trustworthy sources and independent corroboration. The evaluation of our method on 16 million tweets from the TREC 2011 Microblog Dataset shows that for top-30 precision, we achieve 53% better precision than the current best performing method on the data set, and an improvement of 300% over current Twitter Search.",10.1145/2505515.2505667,https://doi.org/10.1145/2505515.2505667,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,RAProp: ranking tweets by exploiting the tweet/user/web ecosystem and inter-tweet agreement,"Ravikumar, Srijith and Talamadupula, Kartik and Balakrishnan, Raju and Kambhampati, Subbarao",inproceedings,10.1145/2505515.2505667,
10.1145/2505515.2505712,10.1145/2505515.2505712,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","google places, latent variables, restaurant ratings, zagat survey",10,1127–1136,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"Consumer review sites and recommender systems typically rely on a large volume of user-contributed ratings, which makes rating acquisition an essential component in the design of such systems. User ratings are then summarized to provide an aggregate score representing a popular evaluation of an item. An inherent problem in such summarization is potential bias due to raters self-selection and heterogeneity in terms of experience, tastes and rating scale interpretation. There are two major approaches to collecting ratings, which have different advantages and disadvantages. One is to allow a large number of volunteers to choose and rate items directly (a method employed by e.g. Yelp and Google Places). Alternatively, a panel of raters may be maintained and invited to rate a predefined set of items at regular intervals (such as in Zagat Survey). The latter approach arguably results in more consistent reviews and reduced selection bias, however, at the expense of much smaller coverage (fewer rated items).In this paper, we examine the two different approaches to collecting user ratings of restaurants and explore the question of whether it is possible to reconcile them. Specifically, we study the problem of inferring the more calibrated Zagat Survey ratings (which we dub 'expert ratings') from the user-generated ratings ('grassroots') in Google Places. To that effect, we employ latent factor models and provide a probabilistic treatment of the ordinal rankings. We can predict Zagat Survey ratings accurately from ad hoc user-generated ratings by joint optimization on two datasets. We analyze the resulting model, and find that users become more discerning as they submit more ratings. We also describe an approach towards cross-city recommendations, answering questions such as 'What is the equivalent of the Per Se restaurant in Chicago'?",10.1145/2505515.2505712,https://doi.org/10.1145/2505515.2505712,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,Instant foodie: predicting expert ratings from grassroots,"Tan, Chenhao and Chi, Ed H. and Huffaker, David and Kossinets, Gueorgi and Smola, Alexander J.",inproceedings,10.1145/2505515.2505712,
10.1145/2505515.2505720,10.1145/2505515.2505720,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","community question answering, expert recommendation, gaussian mixture model, latent topic modelling, link analysis",10,99–108,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"Community Question Answering (CQA) websites, where people share expertise on open platforms, have become large repositories of valuable knowledge. To bring the best value out of these knowledge repositories, it is critically important for CQA services to know how to find the right experts, retrieve archived similar questions and recommend best answers to new questions. To tackle this cluster of closely related problems in a principled approach, we proposed Topic Expertise Model (TEM), a novel probabilistic generative model with GMM hybrid, to jointly model topics and expertise by integrating textual content model and link structure analysis. Based on TEM results, we proposed CQARank to measure user interests and expertise score under different topics. Leveraging the question answering history based on long-term community reviews and voting, our method could find experts with both similar topical preference and high topical expertise. Experiments carried out on Stack Overflow data, the largest CQA focused on computer programming, show that our method achieves significant improvement over existing methods on multiple metrics.",10.1145/2505515.2505720,https://doi.org/10.1145/2505515.2505720,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,CQArank: jointly model topics and expertise in community question answering,"Yang, Liu and Qiu, Minghui and Gottipati, Swapna and Zhu, Feida and Jiang, Jing and Sun, Huiping and Chen, Zhong",inproceedings,10.1145/2505515.2505720,
10.1145/2505515.2505810,10.1145/2505515.2505810,CIKM.bib,1,['CIKM.bib'],7,CIKM '13,"San Francisco, California, USA","big data, information retrieval, natural language processing, text mining",2,2547–2548,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,,10.1145/2505515.2505810,https://doi.org/10.1145/2505515.2505810,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,Workshop summary for the 2013 international workshop on mining unstructured big data using natural language processing,"Liu, Xiaozhong and Chen, Miao and Ding, Ying and Song, Min",inproceedings,10.1145/2505515.2505810,
10.1145/2505515.2507827,10.1145/2505515.2507827,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","assessment of student response, collaborative filtering, feature-based matrix factorization",4,1493–1496,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"The automatic assessment of free-text responses of students is a relatively newer task in both computational linguistics and educational technology. The goal of the task is to produce an assessment of student answers to explanation and definition questions typically asked in problems seen in practice exercises or tests. Unlike some conventional methods which assess the student responses based on only information about their corresponding questions, this paper exploits idea of collaborative filtering to analyze student responses and used an effective collaborative filtering model -- feature-based matrix factorization model to deal with this challenge. The experimental results show that our feature-based matrix factorization model outperforms the baseline models and the model with a re-ranking phase can achieve a better and competitive performance -- 63.6% overall accuracy on the Beetle dataset.",10.1145/2505515.2507827,https://doi.org/10.1145/2505515.2507827,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,Exploiting collaborative filtering techniques for automatic assessment of student free-text responses,"Ge, Tao and Sui, Zhifang and Chang, Baobao",inproceedings,10.1145/2505515.2507827,
10.1145/2505515.2507882,10.1145/2505515.2507882,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","industry classification, information retrieval, recommender systems, venture finance",4,1865–1868,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"This paper concerns the task of top-N investment opportunity recommendation in the domain of venture finance. By venture finance, specifically, we are interested in the investment activity of venture capital (VC) firms and their investment partners. We have access to a dataset of recorded venture financings (i.e., investments) by VCs and their investment partners in private US companies. This research was undertaken in partnership with Correlation Ventures, a venture capital firm who are pioneering the use of predictive analytics in order to better inform investment decision making. This paper undertakes a detailed empirical study and data analysis then demonstrates the efficacy of recommender systems in this novel application domain.",10.1145/2505515.2507882,https://doi.org/10.1145/2505515.2507882,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,An empirical study of top-n recommendation for venture finance,"Stone, Thomas and Zhang, Weinan and Zhao, Xiaoxue",inproceedings,10.1145/2505515.2507882,
10.1145/2505515.2514690,10.1145/2505515.2514690,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","computational advertising, machine learning, social networks",2,1585–1586,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"LinkedIn is the largest professional social network in the world with more than 238M members. It provides a platform for advertisers to reach out to professionals and target them using rich profile and behavioral data. Thus, online advertising is an important business for LinkedIn. In this talk, I will give an overview of machine learning and optimization components that power LinkedIn self-serve display advertising systems. The talk will not only focus on machine learning and optimization methods, but various practical challenges that arise when running such components in a real production environment. I will describe how we overcome some of these challenges to bridge the gap between theory and practice.The major components that will be described in details include Response prediction: The goal of this component is to estimate click-through rates (CTR) when an ad is shown to a user in a given context. Given the data sparseness due to low CTR for advertising applications in general and the curse of dimensionality, estimating such interactions is known to be a challenging. Furthermore, the goal of the system is to maximize expected revenue, hence this is an explore/exploit problem and not a supervised learning problem. Our approach takes recourse to supervised learning to reduce dimensionality and couples it with classical explore/exploit schemes to balance the explore/exploit tradeoff. In particular, we use a large scale logistic regression to estimate user and ad interactions. Such interactions are comprised of two additive terms a) stable interactions captured by using features for both users and ads whose coefficients change slowly over time, and b) ephemeral interactions that capture ad-specific residual idiosyncrasies that are missed by the stable component. Exploration is introduced via Thompson sampling on the ephemeral interactions (sample coefficients from the posterior distribution), since the stable part is estimated using large amounts of data and subject to very little statistical variance. Our model training pipeline estimates the stable part using a scatter and gather approach via the ADMM algorithm, ephemeral part is estimated more frequently by learning a per ad correction through an ad-specific logistic regression. Scoring thousands of ads at runtime under tight latency constraints is a formidable challenge when using such models, the talk will describe methods to scale such computations at runtime.Automatic Format Selection: The presentation of ads in a given slot on a page has a significant impact on how users interact with them. Web designers are adept at creating good formats to facilitate ad display but selecting the best among those automatically is a machine learning task. I will describe a machine learning approach we use to solve this problem. It is again an explore/exploit problem but the dimensionality of this problem is much less than the ad selection problem. I will also provide a detailed description of how we deal with issues like budget pacing, bid forecasting, supply forecasting and targeting. Throughout, the ML components will be illustrated with real examples from production and evaluation metrics would be reported from live tests. Offline metrics that can be useful in evaluating methods before launching them on live traffic will also be discussed.",10.1145/2505515.2514690,https://doi.org/10.1145/2505515.2514690,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,Computational advertising: the linkedin way,"Agarwal, Deepak",inproceedings,10.1145/2505515.2514690,
10.1145/2505515.2514701,10.1145/2505515.2514701,CIKM.bib,1,['CIKM.bib'],8,CIKM '13,"San Francisco, California, USA","big data, machine learning, personalization, recommender systems",8,2201–2208,Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,"Since the Netflix $1 million Prize, announced in 2006, Netflix has been known for having personalization at the core of our product. Our current product offering is nowadays focused around instant video streaming, and our data is now many orders of magnitude larger. Not only do we have many more users in many more countries, but we also receive many more streams of data. Besides the ratings, we now also use information such as what our members play, browse, or search.In this paper I will discuss the different approaches we follow to deal with these large streams of user data in order to extract information for personalizing our service. I will describe some of the machine learning models used, and their application in the service. I will also describe our data-driven approach to innovation that combines rapid offline explorations as well as online A/B testing. This approach enables us to convert user information into real and measurable business value.",10.1145/2505515.2514701,https://doi.org/10.1145/2505515.2514701,"New York, NY, USA",Association for Computing Machinery,9781450322638,2013,Beyond data: from user information to business value through personalized recommendations and consumer science,"Amatriain, Xavier",inproceedings,10.1145/2505515.2514701,
10.1145/2507157.2507160,10.1145/2507157.2507160,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","ranking, rating prediction, recommender systems, selection bias",8,213–220,Proceedings of the 7th ACM Conference on Recommender Systems,"The literature on recommender systems distinguishes typically between two broad categories of measuring recommendation accuracy: rating prediction, often quantified in terms of the root mean square error (RMSE), and ranking, measured in terms of metrics like precision and recall, among others. In this paper, we examine both approaches in detail, and find that the dominating difference lies instead in the training and test data considered: rating prediction is concerned with only the observed ratings, while ranking typically accounts for all items in the collection, whether the user has rated them or not. Furthermore, we show that predicting observed ratings, while popular in the literature, only solves a (small) part of the rating prediction task for any item in the collection, which is a common real-world problem. The reasons are selection bias in the data, combined with data sparsity. We show that the latter rating-prediction task involves the prediction task 'Who rated What' as a sub-problem, which can be cast as a classification or ranking problem. This suggests that solving the ranking problem is not only valuable by itself, but also for predicting the rating value of any item.",10.1145/2507157.2507160,https://doi.org/10.1145/2507157.2507160,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Evaluation of recommendations: rating-prediction and ranking,"Steck, Harald",inproceedings,10.1145/2507157.2507160,
10.1145/2507157.2507163,10.1145/2507157.2507163,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","recommender systems, topic models",8,165–172,Proceedings of the 7th ACM Conference on Recommender Systems,"In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example, in order to predict whether a user will enjoy Harry Potter, it helps to identify that the book is about wizards, as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However, traditional methods often discard review text, which makes user and product latent dimensions difficult to interpret, since they ignore the very text that justifies a user's rating. In this paper, we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our approach has several advantages. Firstly, we obtain highly interpretable textual labels for latent rating dimensions, which helps us to `justify' ratings with text. Secondly, our approach more accurately predicts product ratings by harnessing the information present in review text; this is especially true for new products and users, who may have too few ratings to model their latent factors, yet may still provide substantial information from the text of even a single review. Thirdly, our discovered topics can be used to facilitate other tasks such as automated genre discovery, and to identify useful and representative reviews.",10.1145/2507157.2507163,https://doi.org/10.1145/2507157.2507163,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Hidden factors and hidden topics: understanding rating dimensions with review text,"McAuley, Julian and Leskovec, Jure",inproceedings,10.1145/2507157.2507163,
10.1145/2507157.2507167,10.1145/2507157.2507167,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","collaborative filtering, personalization, portfolio theory, recommender systems",8,229–236,Proceedings of the 7th ACM Conference on Recommender Systems,"Personalization techniques have been widely adopted in many recommender systems. However, experiments on real-world datasets show that for some users in certain contexts, personalized recommendations do not necessarily perform better than recommendations that rely purely on popularity. Broadly, this can be interpreted by the fact that the parameters of a personalization model are usually estimated from sparse data; the resulting personalized prediction, despite of its low bias, is often volatile. In this paper, we study the problem further by investigating into the ranking of recommendation lists. From a risk management and portfolio retrieval perspective, there is no difference between the popularity-based and the personalized ranking as both of the recommendation outputs can be represented as the trade-off between expected relevance (reward) and associated uncertainty (risk). Through our analysis, we discover common scenarios and provide a technique to predict whether personalization will fail. Besides the theoretical understanding, our experimental results show that the resulting switch algorithm, which decides whether or not to personalize, outperforms the mainstream recommendation algorithms.",10.1145/2507157.2507167,https://doi.org/10.1145/2507157.2507167,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,To personalize or not: a risk management perspective,"Zhang, Weinan and Wang, Jun and Chen, Bowei and Zhao, Xiaoxue",inproceedings,10.1145/2507157.2507167,
10.1145/2507157.2507172,10.1145/2507157.2507172,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","top-n recommendations, linked data, learning to rank, implicit feedback, hybrid recommender system, dbpedia",8,85–92,Proceedings of the 7th ACM Conference on Recommender Systems,"The advent of the Linked Open Data (LOD) initiative gave birth to a variety of open knowledge bases freely accessible on the Web. They provide a valuable source of information that can improve conventional recommender systems, if properly exploited. In this paper we present SPrank, a novel hybrid recommendation algorithm able to compute top-N item recommendations from implicit feedback exploiting the information available in the so called Web of Data. We leverage DBpedia, a well-known knowledge base in the LOD compass, to extract semantic path-based features and to eventually compute recommendations using a learning to rank algorithm. Experiments with datasets on two different domains show that the proposed approach outperforms in terms of prediction accuracy several state-of-the-art top-N recommendation algorithms for implicit feedback in situations affected by different degrees of data sparsity.",10.1145/2507157.2507172,https://doi.org/10.1145/2507157.2507172,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Top-N recommendations from implicit feedback leveraging linked open data,"Ostuni, Vito Claudio and Di Noia, Tommaso and Di Sciascio, Eugenio and Mirizzi, Roberto",inproceedings,10.1145/2507157.2507172,
10.1145/2507157.2507176,10.1145/2507157.2507176,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","recommender systems, online learning, multi-task learning, collaborative filtering",8,237–244,Proceedings of the 7th ACM Conference on Recommender Systems,"Traditional batch model-based Collaborative Filtering (CF) approaches typically assume a collection of users' rating data is given a priori for training the model. They suffer from a common yet critical drawback, i.e., the model has to be re-trained completely from scratch whenever new training data arrives, which is clearly non-scalable for large real recommender systems where users' rating data often arrives sequentially and frequently. In this paper, we investigate a novel efficient and scalable online collaborative filtering technique for on-the-fly recommender systems, which is able to effectively online update the recommendation model from a sequence of rating observations. Specifically, we propose a family of online multi-task collaborative filtering (OMTCF) algorithms, which tackle the online collaborative filtering task by exploiting the similar principle as online multitask learning. Encouraging empirical results on large-scale datasets showed that the proposed technique is significantly more effective than the state-of-the-art algorithms.",10.1145/2507157.2507176,https://doi.org/10.1145/2507157.2507176,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Online multi-task collaborative filtering for on-the-fly recommender systems,"Wang, Jialei and Hoi, Steven C.H. and Zhao, Peilin and Liu, Zhi-Yong",inproceedings,10.1145/2507157.2507176,
10.1145/2507157.2507178,10.1145/2507157.2507178,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","hypergraph, matrix factorization, recommender system",8,41–48,Proceedings of the 7th ACM Conference on Recommender Systems,"Matrix factorization techniques such as the singular value decomposition (SVD) have had great success in recommender systems. We present a new perspective of SVD for constructing a latent space from the training data, which is justified by the theory of hypergraph model. We show that the vectors representing the items in the latent space can be grouped into (approximately) orthogonal clusters which correspond to the vertex clusters in the co-rating hypergraph, and the lengths of the vectors are indicators of the representativeness of the items. These properties are used for making top-$N$ recommendations in a two-phase algorithm. In this work, we provide a new explanation for the significantly better performance of the asymmetric SVD approaches and a novel algorithm for better diversity in top-N recommendations.",10.1145/2507157.2507178,https://doi.org/10.1145/2507157.2507178,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Understanding and improving relational matrix factorization in recommender systems,"Pu, Li and Faltings, Boi",inproceedings,10.1145/2507157.2507178,
10.1145/2507157.2507179,10.1145/2507157.2507179,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","user modeling, recommendation, hybrid methods",8,177–184,Proceedings of the 7th ACM Conference on Recommender Systems,"This paper explores a method for incorporating into a recommender system explicit representations of user's preferences over non-content attributes such as popularity, recency, and similarity of recommended items. We show how such attributes can be modeled as a preference vector that can be used in a vector-space content-based recommender, and how that content-based recommender can be integrated with various collaborative filtering techniques through re-weighting of Top-M recommendations. We evaluate this approach on several recommender systems datasets and collaborative filtering methods, and find that incorporating the three preference attributes can lead to a substantial increase in Top-50 precision while also enhancing diversity and novelty.",10.1145/2507157.2507179,https://doi.org/10.1145/2507157.2507179,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Exploiting non-content preference attributes through hybrid recommendation method,"Mour\~{a}o, Fernando and Rocha, Leonardo and Konstan, Joseph A. and Meira, Wagner",inproceedings,10.1145/2507157.2507179,
10.1145/2507157.2507183,10.1145/2507157.2507183,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","content context, review rating prediction, review recommendation, social context",8,1–8,Proceedings of the 7th ACM Conference on Recommender Systems,"Online reviews play a vital role in the decision-making process for online users. Helpful reviews are usually buried in a large number of unhelpful reviews, and with the consistently increasing number of reviews, it becomes more and more difficult for online users to find helpful reviews. Therefore most online review websites allow online users to rate the helpfulness of a review and a global helpfulness score is computed for the review based on its available ratings. However, in reality, user-specified helpfulness ratings for reviews are very sparse - a few reviews attract large numbers of helpfulness ratings while most reviews obtain few or even no helpfulness ratings. The available helpfulness ratings are too sparse for online users to assess the helpfulness of reviews. Also the helpfulness of a review is not necessarily equally useful for all users and users with different background may treat the helpfulness of a review very differently. The user idiosyncracy of review helpfulness motivates us to study the problem of review helpfulness rating prediction in this paper. We first identify various types of context information, model them mathematically, and propose a context-aware review helpfulness rating prediction framework CAP. Experimental results demonstrate the effectiveness of the proposed framework and the importance of context awareness in solving the review helpfulness rating prediction problem.",10.1145/2507157.2507183,https://doi.org/10.1145/2507157.2507183,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Context-aware review helpfulness rating prediction,"Tang, Jiliang and Gao, Huiji and Hu, Xia and Liu, Huan",inproceedings,10.1145/2507157.2507183,
10.1145/2507157.2507186,10.1145/2507157.2507186,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","personalized pagerank, markov model, interactional context, context-aware, collaborative filtering",8,201–208,Proceedings of the 7th ACM Conference on Recommender Systems,"The application a smart phone user will launch next intuitively depends on the sequence of apps used recently. More generally, when users interact with systems such as shopping websites or online radio, they click on items that are of interest in the current context. We call the sequence of clicks made in the current session interactional context. It is desirable for a recommender system to use the context set by the user to update recommendations. Most current context-aware recommender systems focus on a relatively less dynamic representational context defined by attributes such as season, location and tastes. In this paper, we study the problem of collaborative filtering with interactional context, where the goal is to make personalized and dynamic recommendations to a user engaged in a session. To this end, we propose the methodname algorithm that works in two stages. First, users are clustered by their transition behavior (one-step Markov transition probabilities between items), and cluster-level Markov models are computed. Then personalized PageRank is computed for a given user on the corresponding cluster Markov graph, with a personalization vector derived from the current context. We give an interpretation of the second stage of the algorithm as adding an appropriate context bias, in addition to click bias (or rating bias), to a classical neighborhood-based collaborative filtering model, where the neighborhood is determined from a Markov graph. Experimental results on two real-life datasets demonstrate the superior performance of our algorithm, where we achieve at least 20% (up to 37%) improvement over competitive methods in the recall level at top-20.",10.1145/2507157.2507186,https://doi.org/10.1145/2507157.2507186,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Which app will you use next? collaborative filtering with interactional context,"Natarajan, Nagarajan and Shin, Donghyuk and Dhillon, Inderjit S.",inproceedings,10.1145/2507157.2507186,
10.1145/2507157.2507191,10.1145/2507157.2507191,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","relevance models, recommender systems, collaborative filtering",4,387–390,Proceedings of the 7th ACM Conference on Recommender Systems,"Relevance-Based Language Models are an effective IR approach which explicitly introduces the concept of relevance in the statistical Language Modelling framework of Information Retrieval. These models have shown to achieve state-of-the-art retrieval performance in the pseudo relevance feedback task. In this paper we propose a novel adaptation of this language modeling approach to rating-based Collaborative Filtering. In a memory-based approach, we apply the model to the formation of user neighbourhoods, and the generation of recommendations based on such neighbourhoods. We report experimental results where our method outperforms other standard memory-based algorithms in terms of ranking precision.",10.1145/2507157.2507191,https://doi.org/10.1145/2507157.2507191,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Probabilistic collaborative filtering with negative cross entropy,"Bellogin, Alejandro and Parapar, Javier and Castells, Pablo",inproceedings,10.1145/2507157.2507191,
10.1145/2507157.2507195,10.1145/2507157.2507195,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","scalable collaborative filtering, mapreduce",4,281–284,Proceedings of the 7th ACM Conference on Recommender Systems,"The efficient, distributed factorization of large matrices on clusters of commodity machines is crucial to applying latent factor models in industrial-scale recommender systems. We propose an efficient, data-parallel low-rank matrix factorization with Alternating Least Squares which uses a series of broadcast-joins that can be efficiently executed with MapReduce.We empirically show that the performance of our solution is suitable for real-world use cases. We present experiments on two publicly available datasets and on a synthetic dataset termed Bigflix, generated from the Netflix dataset. Bigflix contains 25 million users and more than 5 billion ratings, mimicking data sizes recently reported as Netflix' production workload. We demonstrate that our approach is able to run an iteration of Alternating Least Squares in six minutes on this dataset. Our implementation has been contributed to the open source machine learning library Apache Mahout.",10.1145/2507157.2507195,https://doi.org/10.1145/2507157.2507195,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Distributed matrix factorization with mapreduce using a series of broadcast-joins,"Schelter, Sebastian and Boden, Christoph and Schenck, Martin and Alexandrov, Alexander and Markl, Volker",inproceedings,10.1145/2507157.2507195,
10.1145/2507157.2507196,10.1145/2507157.2507196,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","trip planning, reconfiguration, recommender systems",4,391–394,Proceedings of the 7th ACM Conference on Recommender Systems,"Users often configure complex objects with many possible internal choices. Recommendation engines that automatically configure such objects given user preferences and constraints, may provide much value in such cases. These applications generate appropriate recommendations based on user preferences. It is likely, though, that the user will not be able to fully express her preferences and constraints, requiring a phase of manual tuning of the recommended configuration. We suggest that following this manual revision, additional constraints and preferences can be automatically collected, and the recommended configuration can be automatically improved. Specifically, we suggest a recommender component that takes as input an initial manual configuration of a complex object, deduces certain user preferences and constraints from this configuration, and constructs an alternative configuration. We show an appealing application for our method in complex trip planning, and demonstrate its usability in a user study.",10.1145/2507157.2507196,https://doi.org/10.1145/2507157.2507196,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Recommending improved configurations for complex objects with an application in travel planning,"Savir, Amihai and Brafman, Ronen and Shani, Guy",inproceedings,10.1145/2507157.2507196,
10.1145/2507157.2507218,10.1145/2507157.2507218,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","collaborative filtering, context-aware recommender systems, implicit semantics, matrix factorization",4,363–366,Proceedings of the 7th ACM Conference on Recommender Systems,"Context-Aware Recommender Systems locally adapt to a specific contextual situation the rating prediction computed by a traditional context-free recommender. In this paper we present a novel semantic pre-filtering approach that can be tuned to the optimal level of contextualization by aggregating contextual situations that are similar to the target one. The similarities of contextual situations are derived from the available contextually tagged users' ratings according to how similarly the contextual conditions influence the user's rating behavior. We present an extensive evaluation of the performance of our pre-filtering approach on several data sets, showing that it outperforms state-of-the-art context-aware Matrix Factorization approaches.",10.1145/2507157.2507218,https://doi.org/10.1145/2507157.2507218,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Local context modeling with semantic pre-filtering,"Codina, Victor and Ricci, Francesco and Ceccaroni, Luigi",inproceedings,10.1145/2507157.2507218,
10.1145/2507157.2507226,10.1145/2507157.2507226,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","relevance, diversity",4,379–382,Proceedings of the 7th ACM Conference on Recommender Systems,"In this paper we discuss a method to incorporate diversity into a personalised ranking objective, in the context of ranking-based recommendation using implicit feedback. The goal is to provide a ranking of items that respects user preferences while also tending to rank diverse items closely together. A prediction formula is learned as the product of user and item feature vectors, in order to minimise the mean squared error objective used previously in the RankALS and RankSGD methods, but modified to weight the difference in ratings between two items by the dissimilarity of those items. We report on preliminary experiments with this modified objective, in which the minimisation is carried out using stochastic gradient descent. We show that rankings based on the output of the minimisation succeed in producing recommendation lists with greater diversity, with just a small loss in relevance of the recommendation, as measured by the error rate.",10.1145/2507157.2507226,https://doi.org/10.1145/2507157.2507226,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Personalised ranking with diversity,"Hurley, Neil J.",inproceedings,10.1145/2507157.2507226,
10.1145/2507157.2507229,10.1145/2507157.2507229,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","collaborative filtering, item accuracy, recommendations, recommender systems, weighted percentiles",4,351–354,Proceedings of the 7th ACM Conference on Recommender Systems,"This paper proposes a novel method for estimating unknown ratings and recommendation opportunities and illustrates the practical implementation of the proposed approach by presenting a certain variation of the classical k-NN method in neighborhood-based collaborative filtering systems using weighted percentiles. We conduct an empirical study showing that the proposed method outperforms the standard user-based collaborative filtering approach by a wide margin in terms of item prediction accuracy and utility-based ranking metrics across various experimental settings. We also demonstrate that this performance improvement is not achieved at the expense of other popular performance measures, such as catalog coverage and aggregate diversity. The proposed approach can also be applied to other popular methods for rating estimation.",10.1145/2507157.2507229,https://doi.org/10.1145/2507157.2507229,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Recommendation opportunities: improving item prediction using weighted percentile methods in collaborative filtering systems,"Adamopoulos, Panagiotis and Tuzhilin, Alexander",inproceedings,10.1145/2507157.2507229,
10.1145/2507157.2508063,10.1145/2507157.2508063,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","recommender systems, ranking, learning to rank, collaborative filtering",2,493–494,Proceedings of the 7th ACM Conference on Recommender Systems,"Recommender system aim at providing a personalized list of items ranked according to the preferences of the user, as such ranking methods are at the core of many recommendation algorithms. The topic of this tutorial focuses on the cutting-edge algorithmic development in the area of recommender systems. This tutorial will provide an in depth picture of the progress of ranking models in the field, summarizing the strengths and weaknesses of existing methods, and discussing open issues that could be promising for future research in the community. A qualitative and quantitative comparison between different models will be provided while we will also highlight recent developments in the areas of Reinforcement Learning.",10.1145/2507157.2508063,https://doi.org/10.1145/2507157.2508063,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Learning to rank for recommender systems,"Karatzoglou, Alexandros and Baltrunas, Linas and Shi, Yue",inproceedings,10.1145/2507157.2508063,
10.1145/2507157.2508073,10.1145/2507157.2508073,RecSys.bib,1,['RecSys.bib'],8,RecSys '13,"Hong Kong, China","diversity, item accuracy, novelty, recommendation opportunities, recommendation sets, recommender systems, serendipity, unexpectedness",4,459–462,Proceedings of the 7th ACM Conference on Recommender Systems,"This paper proposes a number of studies in order to move recommender systems beyond the traditional paradigm and the classical perspective of rating prediction accuracy. We contribute to existing helpful but less explored paradigms and also propose new approaches aiming at more useful recommendations for both users and businesses. Working toward this direction, we discuss the studies we have conducted so far and present our future research plans. In particular, we move our focus from even more accurate rating predictions and aim at offering a holistic experience to the users by avoiding the over-specialization of generated recommendations and providing the users with sets of non-obvious but high quality recommendations that fairly match their interests and they will remarkably like.",10.1145/2507157.2508073,https://doi.org/10.1145/2507157.2508073,"New York, NY, USA",Association for Computing Machinery,9781450324090,2013,Beyond rating prediction accuracy: on new perspectives in recommender systems,"Adamopoulos, Panagiotis",inproceedings,10.1145/2507157.2508073,
10.1145/2513549.2513554,10.1145/2513549.2513554,CIKM.bib,1,['CIKM.bib'],8,UnstructureNLP '13,"San Francisco, California, USA","strong social relations, social relations, review rating prediction, regularization, opinion mining",8,23–30,Proceedings of the 2013 International Workshop on Mining Unstructured Big Data Using Natural Language Processing,"Review rating is more helpful than review binary classification for many decision processes such as consumption decision-making, company product quality tracking and public opinion mining. In the review rating, reviewers are influenced not only by their own subjective feelings, but also by others' rating to the same product. Existing review rating prediction methods are mainly based on the content of reviews, which only consider the subjective factors of reviewers, but not consider the impact of other people in the social relations of reviewers. Based on it, we propose a review rating prediction method by incorporating the character of reviewer's social relations, as regularization constraints, into content-based methods. In addition, we further propose a method to classify the social relations of reviewers into strong social relation and ordinary social relation. For strong social relation of reviewers, we give higher weight than ordinary social relation when incorporating the two social relations into content-based methods. Experiments on two real movie review datasets demonstrate that the method of considering different social relations has better performance than the content-based methods and the method of considering social relations as a whole.",10.1145/2513549.2513554,https://doi.org/10.1145/2513549.2513554,"New York, NY, USA",Association for Computing Machinery,9781450324151,2013,Review rating prediction based on the content and weighting strong social relation of reviewers,"Wang, Bingkun and Min, Yulin and Huang, Yongfeng and Li, Xing and Wu, Fangzhao",inproceedings,10.1145/2513549.2513554,
10.1145/2556195.2556204,10.1145/2556195.2556204,WSDM.bib,1,['WSDM.bib'],8,WSDM '14,"New York, New York, USA","algorithm design, recommender systems, unexpectedness",6,655–660,Proceedings of the 7th ACM International Conference on Web Search and Data Mining,"This paper proposes a number of studies in order to move the field of recommender systems beyond the traditional paradigm and the classical perspective of rating prediction accuracy. We contribute to existing helpful but less explored recommendation strategies and propose new approaches targeting to more useful recommendations for both users and businesses. Working toward this direction, we discuss the studies we have conducted so far and present our future research plans. The overall goal of this research program is to expand our focus from even more accurate rating predictions toward a more holistic experience for the users, by providing them with non-obvious but high quality recommendations and avoiding the over-specialization and concentration bias problems. In particular, we propose a new probabilistic neighborhood-based method as an improvement of the standard $k$-nearest neighbors approach, alleviating some of the most common problems of collaborative filtering recommender systems, based on classical metrics of dispersion and diversity as well as some newly proposed metrics. Furthermore, we propose a concept of unexpectedness in recommender systems and operationalize it by suggesting various mechanisms for specifying the expectations of the users and proposing a recommendation method for providing the users with unexpected but high quality personalized recommendations that fairly match their interests. Besides, in order to generate utility-based recommendations for Massive Open Online Courses (MOOCs) that better serve the educational needs of students, we study the satisfaction of users with online courses vis-a-vis student retention. Finally, we summarize the conclusions of the conducted studies, discuss the limitations of our work and also outline the managerial implications of the proposed stream of research.",10.1145/2556195.2556204,https://doi.org/10.1145/2556195.2556204,"New York, NY, USA",Association for Computing Machinery,9781450323512,2014,On discovering non-obvious recommendations: using unexpectedness and neighborhood selection methods in collaborative filtering systems,"Adamopoulos, Panagiotis",inproceedings,10.1145/2556195.2556204,
10.1145/2556195.2556240,10.1145/2556195.2556240,WSDM.bib,1,['WSDM.bib'],8,WSDM '14,"New York, New York, USA","factorization machine, hierarchy, importance weight, mobile advertising, response prediction",10,123–132,Proceedings of the 7th ACM International Conference on Web Search and Data Mining,"Mobile advertising has recently seen dramatic growth, fueled by the global proliferation of mobile phones and devices. The task of predicting ad response is thus crucial for maximizing business revenue. However, ad response data change dynamically over time, and are subject to cold-start situations in which limited history hinders reliable prediction. There is also a need for a robust regression estimation for high prediction accuracy, and good ranking to distinguish the impacts of different ads. To this end, we develop a Hierarchical Importance-aware Factorization Machine (HIFM), which provides an effective generic latent factor framework that incorporates importance weights and hierarchical learning. Comprehensive empirical studies on a real-world mobile advertising dataset show that HIFM outperforms the contemporary temporal latent factor models. The results also demonstrate the efficacy of the HIFM's importance-aware and hierarchical learning in improving the overall prediction and prediction in cold-start scenarios, respectively.",10.1145/2556195.2556240,https://doi.org/10.1145/2556195.2556240,"New York, NY, USA",Association for Computing Machinery,9781450323512,2014,Predicting response in mobile advertising with hierarchical importance-aware factorization machine,"Oentaryo, Richard J. and Lim, Ee-Peng and Low, Jia-Wei and Lo, David and Finegold, Michael",inproceedings,10.1145/2556195.2556240,
10.1145/2556195.2556248,10.1145/2556195.2556248,WSDM.bib,1,['WSDM.bib'],8,WSDM '14,"New York, New York, USA","factorization model, item recommendation, matrix factorization, recommender systems",10,273–282,Proceedings of the 7th ACM International Conference on Web Search and Data Mining,"Pairwise algorithms are popular for learning recommender systems from implicit feedback. For each user, or more generally context, they try to discriminate between a small set of selected items and the large set of remaining (irrelevant) items. Learning is typically based on stochastic gradient descent (SGD) with uniformly drawn pairs. In this work, we show that convergence of such SGD learning algorithms slows down considerably if the item popularity has a tailed distribution. We propose a non-uniform item sampler to overcome this problem. The proposed sampler is context-dependent and oversamples informative pairs to speed up convergence. An efficient implementation with constant amortized runtime costs is developed. Furthermore, it is shown how the proposed learning algorithm can be applied to a large class of recommender models. The properties of the new learning algorithm are studied empirically on two real-world recommender system problems. The experiments indicate that the proposed adaptive sampler improves the state-of-the art learning algorithm largely in convergence without negative effects on prediction quality or iteration runtime.",10.1145/2556195.2556248,https://doi.org/10.1145/2556195.2556248,"New York, NY, USA",Association for Computing Machinery,9781450323512,2014,Improving pairwise learning for item recommendation from implicit feedback,"Rendle, Steffen and Freudenthaler, Christoph",inproceedings,10.1145/2556195.2556248,
10.1145/2556195.2556251,10.1145/2556195.2556251,WSDM.bib,1,['WSDM.bib'],8,WSDM '14,"New York, New York, USA","crowdfunding, early prediction, social media",10,573–582,Proceedings of the 7th ACM International Conference on Web Search and Data Mining,"Crowdfunding -- in which people can raise funds through collaborative contributions of general public (i.e., crowd) -- has emerged as a billion dollars business for supporting more than one million ventures. However, very few research works have examined the process of crowdfunding. In particular, none has studied how social networks help crowdfunding projects to succeed. To gain insights into the effects of social networks in crowdfunding, we analyze the hidden connections between the fundraising results of projects on crowdfunding websites and the corresponding promotion campaigns in social media. Our analysis considers the dynamics of crowdfunding from two aspects: how fundraising activities and promotional activities on social media simultaneously evolve over time, and how the promotion campaigns influence the final outcomes. From our investigation, we identify a number of important principles that provide a useful guide for devising effective campaigns. For example, we observe temporal distribution of customer interest, strong correlations between a crowdfunding project's early promotional activities and the final outcomes, and the importance of concurrent promotion from multiple sources. We then show that these discoveries can help predict several important quantities, including overall popularity and the success rate of the project. Finally, we show how to use these discoveries to help design crowdfunding sites.",10.1145/2556195.2556251,https://doi.org/10.1145/2556195.2556251,"New York, NY, USA",Association for Computing Machinery,9781450323512,2014,Inferring the impacts of social media on crowdfunding,"Lu, Chun-Ta and Xie, Sihong and Kong, Xiangnan and Yu, Philip S.",inproceedings,10.1145/2556195.2556251,
10.1145/2556195.2556252,10.1145/2556195.2556252,WSDM.bib,1,['WSDM.bib'],8,WSDM '14,"New York, New York, USA","computational advertising, logistic regression, machine learning, response prediction, scalability",10,173–182,Proceedings of the 7th ACM International Conference on Web Search and Data Mining,"We describe LASER, a scalable response prediction platform currently used as part of a social network advertising system. LASER enables the familiar logistic regression model to be applied to very large scale response prediction problems, including ones beyond advertising. Though the underlying model is well understood, we apply a whole-system approach to address model accuracy, scalability, explore-exploit, and real-time inference. To facilitate training with both large numbers of training examples and high dimensional features on commodity clustered hardware, we employ the Alternating Direction Method of Multipliers (ADMM). Because online advertising applications are much less static than classical presentations of response prediction, LASER employs a number of techniques that allows it to adapt in real time. LASER models can be divided into components with different re-training frequencies, allowing us to learn from changes in ad campaign performance frequently without incurring the cost of retraining larger, more stable sections of the model. Thompson sampling during online inference further helps by efficiently balancing exploration of new ads with exploitation of long running ones. To enable predictions made with the most recent feature data, we employ a range of techniques, including extensive caching and lazy evaluation, to permit real time, low latency scoring. LASER models are defined using a configuration language that ties together the training, validation, and inference pieces and permits even non-programming analysts to experiment with different model structures without modifications to code or interruptions to running servers. Finally, we show via extensive offline experiments and online A/B tests that this system provides significant benefits to prediction accuracy, gains in revenue and CTR, and reductions in system latency.",10.1145/2556195.2556252,https://doi.org/10.1145/2556195.2556252,"New York, NY, USA",Association for Computing Machinery,9781450323512,2014,LASER: a scalable response prediction platform for online advertising,"Agarwal, Deepak and Long, Bo and Traupman, Jonathan and Xin, Doris and Zhang, Liang",inproceedings,10.1145/2556195.2556252,
10.1145/2556195.2559895,10.1145/2556195.2559895,WSDM.bib,1,['WSDM.bib'],8,WSDM '14,"New York, New York, USA","graphical models, latent variable models, n-gram topic model, nonparametric bayes models, nonparametric dirichlet process, sentiment analysis, topic models",10,473–482,Proceedings of the 7th ACM International Conference on Web Search and Data Mining,"We propose a Bayesian nonparametric topic model that rep- resents relationships between given labels and the corre- sponding words/phrases, from supervised articles. Unlike existing supervised topic models, our proposal, supervised N-gram topic model (SNT), focuses on both a number of topics and power-law distribution in the word frequencies to extract topic specific N-grams. To achieve this goal, SNT takes a Bayesian nonparametric approach to topic sampling, which generates word distribution jointly with the given variable in textual order, and then form each N-gram word as a hierarchy of Pitman-Yor process priors. Experiments on labeled text data show that SNT is useful as a generative model for discovering more phrases that complement human experts and domain specific knowledge than the existing al- ternatives. The results show that SNT can be applied to various tasks such as automatic annotation.",10.1145/2556195.2559895,https://doi.org/10.1145/2556195.2559895,"New York, NY, USA",Association for Computing Machinery,9781450323512,2014,Supervised N-gram topic model,"Kawamae, Noriaki",inproceedings,10.1145/2556195.2559895,
10.1145/2556195.2566589,10.1145/2556195.2566589,WSDM.bib,1,['WSDM.bib'],8,WSDM '14,"New York, New York, USA","aggregate diversity, collaborative filtering, long tail, recommendation diversity, recommender system",10,253–262,Proceedings of the 7th ACM International Conference on Web Search and Data Mining,"Recommender systems are useful tools that help people to filter and explore massive information. While the accuracy of recommender systems is important, many recent research indicated that focusing merely on accuracy not only is insufficient to meet user needs, but also may be harmful. Other characteristics such as novelty, unexpectedness and diversity should also be taken into consideration. Previous work has shown that more the sales of long-tail items could be more beneficial to both customers and some business models. However, the majority of collaborative filtering approaches tends to recommend popular selling items. In this work, we focus on long-tail item promotion and aggregate diversity enhancement, and propose a novel approach which diversifies the results of recommender systems by considering ``recommendations"" as resources to be allocated to the items. Our approach increases the quantity and quality of long-tail item recommendations by adding more variation into the recommendation and maintains a certain level of accuracy simultaneously. The experimental results show that this approach can discover more worth-recommending items from Long Tails and improves user experience.",10.1145/2556195.2566589,https://doi.org/10.1145/2556195.2566589,"New York, NY, USA",Association for Computing Machinery,9781450323512,2014,Who likes it more? mining worth-recommending items from long tails by modeling relative preference,"Ho, Yu-Chieh and Chiang, Yi-Ting and Hsu, Jane Yung-Jen",inproceedings,10.1145/2556195.2566589,
10.1145/2566486.2567968,10.1145/2566486.2567968,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14,"Seoul, Korea","tie direction inference, social networks, redirect, directionality",12,807–818,Proceedings of the 23rd International Conference on World Wide Web,"Together with the sign (positive or negative) and strength (strong or weak), the directionality is also an important property of social ties, though usually ignored in undirected social networks for its invisibility. However, we believe most social ties are natively directed, and the awareness of directionality can improve our understanding about the network structures and further benefit social network analysis and mining tasks. Thus it's appealing to study whether there exist interesting patterns about directionality in social networks and whether we can learn the directions for undirected networks based on these patterns. In this study, we engage in the investigation of directionality patterns on real-world directed social networks and summarize our findings using four consistency hypotheses. Based on these hypotheses, we propose ReDirect, an optimization framework which makes it possible to infer the hidden directions of undirected social ties based on the network topology only. This general framework can incorporate various predictive models under specific scenarios. Furthermore, we show how to improve ReDirect by introducing semi/self-supervision in the framework and how to construct the self-labeled training data using simple but effective heuristics. Experimental results show that even without external information, our approach can recover the directions of networks effectively.Moreover, we're quite surprising to find that ReDirect can benefit predictive tasks remarkably, with a case study of link prediction. In experiments the redirected networks inferred using ReDirect are proven much more informative than original undirected ones and can improve the prediction performance significantly. It convinces us that ReDirect can be a beneficial general data preprocess tool for various network analysis and mining tasks by uncovering the hidden directions of undirected social networks.",10.1145/2566486.2567968,https://doi.org/10.1145/2566486.2567968,"New York, NY, USA",Association for Computing Machinery,9781450327442,2014,Who proposed the relationship? recovering the hidden directions of undirected social networks,"Zhang, Jun and Wang, Chaokun and Wang, Jianmin",inproceedings,10.1145/2566486.2567968,
10.1145/2566486.2567970,10.1145/2566486.2567970,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14,"Seoul, Korea","recommender systems, ranking, collaborative filtering",12,85–96,Proceedings of the 23rd International Conference on World Wide Web,"Personalized recommendation systems are used in a wide variety of applications such as electronic commerce, social networks, web search, and more. Collaborative filtering approaches to recommendation systems typically assume that the rating matrix (e.g., movie ratings by viewers) is low-rank. In this paper, we examine an alternative approach in which the rating matrix is locally low-rank. Concretely, we assume that the rating matrix is low-rank within certain neighborhoods of the metric space defined by (user, item) pairs. We combine a recent approach for local low-rank approximation based on the Frobenius norm with a general empirical risk minimization for ranking losses. Our experiments indicate that the combination of a mixture of local low-rank matrices each of which was trained to minimize a ranking loss outperforms many of the currently used state-of-the-art recommendation systems. Moreover, our method is easy to parallelize, making it a viable approach for large scale real-world rank-based recommendation systems.",10.1145/2566486.2567970,https://doi.org/10.1145/2566486.2567970,"New York, NY, USA",Association for Computing Machinery,9781450327442,2014,Local collaborative ranking,"Lee, Joonseok and Bengio, Samy and Kim, Seungyeon and Lebanon, Guy and Singer, Yoram",inproceedings,10.1145/2566486.2567970,
10.1145/2566486.2567978,10.1145/2566486.2567978,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14,"Seoul, Korea","random walk on bipartite graph, preference propagation, monte carlo simulation, cold start",10,327–336,Proceedings of the 23rd International Conference on World Wide Web,"Recommendation systems have been widely used in E-commerce sites, social networks, etc. One of the core tasks in recommendation systems is to predict the users' ratings on items. Although many models and algorithms have been proposed, how to make accurate prediction for new users with extremely few rating records still remains a big challenge, which is called the cold start problem. Many existing methods utilize additional information, such as social graphs, to cope with the cold start problem. However, the side information may not always be available. In contrast to such methods, we propose a more general solution to address the cold start problem based on the observed user rating records only. Specifically we define a random walk on a bipartite graph of users and items to simulate the preference propagation among users, in order to alleviate the data sparsity problem for cold start users. Then we propose a Monte Carlo algorithm to estimate the similarity between different users. This algorithm takes a precomputation approach, and thus can efficiently compute the user similarity given any new user for rating prediction. In addition, our algorithm can easily handle dynamic updates and can be parallelized naturally, which are crucial for large recommendation systems. Theoretical analysis is presented to demonstrate the efficiency and effectiveness of our algorithm, and extensive experiments also confirm our theoretical findings.",10.1145/2566486.2567978,https://doi.org/10.1145/2566486.2567978,"New York, NY, USA",Association for Computing Machinery,9781450327442,2014,A Monte Carlo algorithm for cold start recommendation,"Rong, Yu and Wen, Xiao and Cheng, Hong",inproceedings,10.1145/2566486.2567978,
10.1145/2566486.2567996,10.1145/2566486.2567996,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14,"Seoul, Korea","regression, popularity, images, flickr, deep learning",10,867–876,Proceedings of the 23rd International Conference on World Wide Web,"Hundreds of thousands of photographs are uploaded to the internet every minute through various social networking and photo sharing platforms. While some images get millions of views, others are completely ignored. Even from the same users, different photographs receive different number of views. This begs the question: What makes a photograph popular? Can we predict the number of views a photograph will receive even before it is uploaded? These are some of the questions we address in this work. We investigate two key components of an image that affect its popularity, namely the image content and social context. Using a dataset of about 2.3 million images from Flickr, we demonstrate that we can reliably predict the normalized view count of images with a rank correlation of 0.81 using both image content and social cues. In this paper, we show the importance of image cues such as color, gradients, deep learning features and the set of objects present, as well as the importance of various social cues such as number of friends or number of photos uploaded that lead to high or low popularity of images.",10.1145/2566486.2567996,https://doi.org/10.1145/2566486.2567996,"New York, NY, USA",Association for Computing Machinery,9781450327442,2014,What makes an image popular?,"Khosla, Aditya and Das Sarma, Atish and Hamid, Raffay",inproceedings,10.1145/2566486.2567996,
10.1145/2566486.2567997,10.1145/2566486.2567997,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14,"Seoul, Korea","information diffusion, contagion, cascade prediction",12,925–936,Proceedings of the 23rd International Conference on World Wide Web,"On many social networking web sites such as Facebook and Twitter, resharing or reposting functionality allows users to share others' content with their own friends or followers. As content is reshared from user to user, large cascades of reshares can form. While a growing body of research has focused on analyzing and characterizing such cascades, a recent, parallel line of work has argued that the future trajectory of a cascade may be inherently unpredictable. In this work, we develop a framework for addressing cascade prediction problems. On a large sample of photo reshare cascades on Facebook, we find strong performance in predicting whether a cascade will continue to grow in the future. We find that the relative growth of a cascade becomes more predictable as we observe more of its reshares, that temporal and structural features are key predictors of cascade size, and that initially, breadth, rather than depth in a cascade is a better indicator of larger cascades. This prediction performance is robust in the sense that multiple distinct classes of features all achieve similar performance. We also discover that temporal features are predictive of a cascade's eventual shape. Observing independent cascades of the same content, we find that while these cascades differ greatly in size, we are still able to predict which ends up the largest.",10.1145/2566486.2567997,https://doi.org/10.1145/2566486.2567997,"New York, NY, USA",Association for Computing Machinery,9781450327442,2014,Can cascades be predicted?,"Cheng, Justin and Adamic, Lada and Dow, P. Alex and Kleinberg, Jon Michael and Leskovec, Jure",inproceedings,10.1145/2566486.2567997,
10.1145/2566486.2568006,10.1145/2566486.2568006,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14,"Seoul, Korea","user preference, generative model, contextual agreement",12,315–326,Proceedings of the 23rd International Conference on World Wide Web,"Personalization, or customizing the experience of each individual user, is seen as a useful way to navigate the huge variety of choices on the Web today. A key tenet of personalization is the capacity to model user preferences. The paradigm has shifted from that of individual preferences, whereby we look at a user's past activities alone, to that of shared preferences, whereby we model the similarities in preferences between pairs of users (e.g., friends, people with similar interests). However, shared preferences are still too granular, because it assumes that a pair of users would share preferences across all items. We therefore postulate the need to pay attention to ""context"", which refers to the specific item on which the preferences between two users are to be estimated. In this paper, we propose a generative model for contextual agreement in preferences. For every triplet consisting of two users and an item, the model estimates both the prior probability of agreement between the two users, as well as the posterior probability of agreement with respect to the item at hand. The model parameters are estimated from ratings data. To extend the model to unseen ratings, we further propose several matrix factorization techniques focused on predicting agreement, rather than ratings. Experiments on real-life data show that our model yields context-specific similarity values that perform better on a prediction task than models relying on shared preferences.",10.1145/2566486.2568006,https://doi.org/10.1145/2566486.2568006,"New York, NY, USA",Association for Computing Machinery,9781450327442,2014,Modeling contextual agreement in preferences,"Do, Loc and Lauw, Hady W.",inproceedings,10.1145/2566486.2568006,
10.1145/2566486.2568009,10.1145/2566486.2568009,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14,"Seoul, Korea","time, text, temporal, recency, query, completion, auto-completion",12,971–982,Proceedings of the 23rd International Conference on World Wide Web,"Query auto-completion (QAC) is a common interactive feature that assists users in formulating queries by providing completion suggestions as they type. In order for QAC to minimise the user's cognitive and physical effort, it must: (i) suggest the user's intended query after minimal input keystrokes, and (ii) rank the user's intended query highly in completion suggestions. Typically, QAC approaches rank completion suggestions by their past popularity. Accordingly, QAC is usually very effective for previously seen and consistently popular queries. Users are increasingly turning to search engines to find out about unpredictable emerging and ongoing events and phenomena, often using previously unseen or unpopular queries. Consequently, QAC must be both robust and time-sensitive -- that is, able to sufficiently rank both consistently and recently popular queries in completion suggestions. To address this trade-off, we propose several practical completion suggestion ranking approaches, including: (i) a sliding window of query popularity evidence from the past 2-28 days, (ii) the query popularity distribution in the last N queries observed with a given prefix, and (iii) short-range query popularity prediction based on recently observed trends. Using real-time simulation experiments, we extensively investigated the parameters necessary to maximise QAC effectiveness for three openly available query log datasets with prefixes of 2-5 characters: MSN and AOL (both English), and Sogou 2008 (Chinese). Optimal parameters vary for each query log, capturing the differing temporal dynamics and querying distributions. Results demonstrate consistent and language-independent improvements of up to 9.2% over a non-temporal QAC baseline for all query logs with prefix lengths of 2-3 characters. This work is an important step towards more effective QAC approaches.",10.1145/2566486.2568009,https://doi.org/10.1145/2566486.2568009,"New York, NY, USA",Association for Computing Machinery,9781450327442,2014,Recent and robust query auto-completion,"Whiting, Stewart and Jose, Joemon M.",inproceedings,10.1145/2566486.2568009,
10.1145/2566486.2568018,10.1145/2566486.2568018,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14,"Seoul, Korea","repeat consumption, recency, quality, copying process",12,419–430,Proceedings of the 23rd International Conference on World Wide Web,"We study the patterns by which a user consumes the same item repeatedly over time, in a wide variety domains ranging from check-ins at the same business location to re-watches of the same video. We find that recency of consumption is the strongest predictor of repeat consumption. Based on this, we develop a model by which the item from $t$ timesteps ago is reconsumed with a probability proportional to a function of t. We study theoretical properties of this model, develop algorithms to learn reconsumption likelihood as a function of t, and show a strong fit of the resulting inferred function via a power law with exponential cutoff. We then introduce a notion of item quality, show that it alone underperforms our recency-based model, and develop a hybrid model that predicts user choice based on a combination of recency and quality. We show how the parameters of this model may be jointly estimated, and show that the resulting scheme outperforms other alternatives.",10.1145/2566486.2568018,https://doi.org/10.1145/2566486.2568018,"New York, NY, USA",Association for Computing Machinery,9781450327442,2014,The dynamics of repeat consumption,"Anderson, Ashton and Kumar, Ravi and Tomkins, Andrew and Vassilvitskii, Sergei",inproceedings,10.1145/2566486.2568018,
10.1145/2567948.2577270,10.1145/2567948.2577270,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14 Companion,"Seoul, Korea","social spam, social media, misinformation, crowdturfing, campaign",2,199–200,Proceedings of the 23rd International Conference on World Wide Web,"This tutorial will introduce peer-reviewed research work on information quality on social systems. Specifically, we will address new threats such as social spam, campaigns, misinformation and crowdturfing, and overview modern techniques to improve information quality by revealing and detecting malicious participants (e.g., social spammers, content polluters and crowdturfers) and low quality contents.",10.1145/2567948.2577270,https://doi.org/10.1145/2567948.2577270,"New York, NY, USA",Association for Computing Machinery,9781450327459,2014,"Social spam, campaigns, misinformation and crowdturfing","Lee, Kyumin and Caverlee, James and Pu, Calton",inproceedings,10.1145/2567948.2577270,
10.1145/2567948.2577298,10.1145/2567948.2577298,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14 Companion,"Seoul, Korea","trend prediction, social media services, collective attention",2,223–224,Proceedings of the 23rd International Conference on World Wide Web,"We investigate patterns of adoption of 175 social media services and Web businesses using data from Google Trends. For each service, we collect aggregated search frequencies from 45 countries as well as global averages. This results in more than 8.000 time series which we analyze using economic diffusion models. The models are found to provide accurate and statistically significant fits to the data and show that collective attention to social media grows and subsides in a highly regular manner. Regularities persist across regions, cultures, and topics and thus hint at general mechanisms that govern the adoption of Web-based services.",10.1145/2567948.2577298,https://doi.org/10.1145/2567948.2577298,"New York, NY, USA",Association for Computing Machinery,9781450327459,2014,Collective attention to social media evolves according to diffusion models,"Bauckhage, Christian and Kersting, Kristian and Rastegarpanah, Bashir",inproceedings,10.1145/2567948.2577298,
10.1145/2567948.2577312,10.1145/2567948.2577312,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14 Companion,"Seoul, Korea","temporal features, social network, popularity prediction, microblogging, classification",2,269–270,Proceedings of the 23rd International Conference on World Wide Web,"Predicting popularity of online contents is of remarkable practical value in various business and administrative applications. Existing studies mainly focus on finding the most effective features for prediction. However, some effective features, such as structural features which are extracted from the underlying user network, are hard to access. In this paper, we aim to identify features that are both effective and effortless (easy to obtain or compute). Experiments on Sina Weibo show the effectiveness and effortlessness of the temporal features and satisfying prediction performance can be obtained based on only the temporal features of first 10 retweets.",10.1145/2567948.2577312,https://doi.org/10.1145/2567948.2577312,"New York, NY, USA",Association for Computing Machinery,9781450327459,2014,Effective and effortless features for popularity prediction in microblogging network,"Gao, Shuai and Ma, Jun and Chen, Zhumin",inproceedings,10.1145/2567948.2577312,
10.1145/2567948.2577342,10.1145/2567948.2577342,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14 Companion,"Seoul, Korea","recommendation system, rating prediction, generative model",2,361–362,Proceedings of the 23rd International Conference on World Wide Web,"Recommender systems have attracted attentions lately due to their wide and successful applications in online advertising. In this paper, we propose a bayesian generative model to describe the generative process of rating, which combines geographical information of users and content of items. The generative model consists of two interacting LDA models, where one LDA model for location-based user groups (user dimension) and the other for the topics of content of items(item dimension). A Gibbs sampling algorithm is proposed for parameter estimation. Experiments have shown our proposed method outperforms baseline methods.",10.1145/2567948.2577342,https://doi.org/10.1145/2567948.2577342,"New York, NY, USA",Association for Computing Machinery,9781450327459,2014,Combining geographical information of users and content of items for accurate rating prediction,"Qiao, Zhi and Zhang, Peng and He, Jing and Cao, Yanan and Zhou, Chuan and Guo, Li",inproceedings,10.1145/2567948.2577342,
10.1145/2567948.2577363,10.1145/2567948.2577363,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14 Companion,"Seoul, Korea","trust network, recommendation system, matrix factorization, data imputation",2,299–300,Proceedings of the 23rd International Conference on World Wide Web,"Recommendation methods suffer from the data sparsity and cold-start user problems, often resulting in low accuracy. To address these problems, we propose a novel imputation method, which effectively densifies a rating matrix by filling unevaluated ratings with probable values. In our method, we use a trust network to estimate the unevaluated ratings accurately. We conduct experiments on the Epinions dataset and demonstrate that our method helps provide better recommendation accuracy than previous methods, especially for cold-start users.",10.1145/2567948.2577363,https://doi.org/10.1145/2567948.2577363,"New York, NY, USA",Association for Computing Machinery,9781450327459,2014,Data imputation using a trust network for recommendation,"Hwang, Won-Seok and Li, Shaoyu and Kim, Sang-Wook and Lee, Kichun",inproceedings,10.1145/2567948.2577363,
10.1145/2567948.2579208,10.1145/2567948.2579208,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '14 Companion,"Seoul, Korea","social media, fluctuation-response relation, exogenous, endogenous, burst",6,1037–1042,Proceedings of the 23rd International Conference on World Wide Web,"A salient dynamic property of social media is bursting be- havior. In this paper, we study bursting behavior in relation to the structure of fluctuation, known as fluctuation-response relation, to reveal the origin of bursts. More specifically, we study the temporal relation between a preceding baseline fluctuation and the successive burst response using a frequency time series of 3,000 keywords on Twitter. We find three types of keyword time series in terms of the fluctuation-response relation. For the first type of keyword, the baseline fluctuation has a positive correlation with the burst size; as the preceding fluctuation increases, the burst size increases. These bursts are caused endogenously as a result of word-of-mouth interactions in a social network; the keyword is sensitive only to the internal context of the system. For the second type, there is a critical threshold in the fluctuation value up to which a positive correlation is observed. Beyond this value, the size of the bursts becomes independent from the fluctuation size. Our analysis shows that this critical threshold emerges because the bursts in the time series are endogenous and exogenous. This type of keyword is sensitive to internal and external stimuli. The third type is mainly bursts caused by exogenous bursts. This type of keyword is mostly sensitive only to external stimuli. These results are useful for characterizing how excitable a keyword is on Twitter and could be used, for example, for marketing purposes.",10.1145/2567948.2579208,https://doi.org/10.1145/2567948.2579208,"New York, NY, USA",Association for Computing Machinery,9781450327459,2014,Fluctuation and burst response in social media,"Oka, Mizuki and Hashimoto, Yasuhiro and Ikegami, Takashi",inproceedings,10.1145/2567948.2579208,
10.1145/2623330.2623657,10.1145/2623330.2623657,KDD.bib,1,['KDD.bib'],8,KDD '14,"New York, New York, USA","collaborative filtering, matrix factorization, transfer learning",10,801–810,Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Given two homogeneous rating matrices with some overlapped users/items whose mappings are unknown, this paper aims at answering two questions. First, can we identify the unknown mapping between the users and/or items? Second, can we further utilize the identified mappings to improve the quality of recommendation in either domain? Our solution integrates a latent space matching procedure and a refining process based on the optimization of prediction to identify the matching. Then, we further design a transfer-based method to improve the recommendation performance. Using both synthetic and real data, we have done extensive experiments given different real life scenarios to verify the effectiveness of our models. The code and other materials are available at http://www.csie.ntu.edu.tw/~r00922051/matching/",10.1145/2623330.2623657,https://doi.org/10.1145/2623330.2623657,"New York, NY, USA",Association for Computing Machinery,9781450329569,2014,Matching users and items across domains to improve the recommendation quality,"Li, Chung-Yi and Lin, Shou-De",inproceedings,10.1145/2623330.2623657,
10.1145/2623330.2623670,10.1145/2623330.2623670,KDD.bib,1,['KDD.bib'],8,KDD '14,"New York, New York, USA","information spread, news dynamics, sentiment analysis, social media",10,901–910,Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"The analysis of social sentiment expressed on the Web is becoming increasingly relevant to a variety of applications, and it is important to understand the underlying mechanisms which drive the evolution of sentiments in one way or another, in order to be able to predict these changes in the future. In this paper, we study the dynamics of news events and their relation to changes of sentiment expressed on relevant topics. We propose a novel framework, which models the behavior of news and social media in response to events as a convolution between event's importance and media response function, specific to media and event type. This framework is suitable for detecting time and duration of events, as well as their impact and dynamics, from time series of publication volume. These data can greatly enhance events analysis; for instance, they can help distinguish important events from unimportant, or predict sentiment and stock market shifts. As an example of such application, we extracted news events for a variety of topics and then correlated this data with the corresponding sentiment time series, revealing the connection between sentiment shifts and event dynamics.",10.1145/2623330.2623670,https://doi.org/10.1145/2623330.2623670,"New York, NY, USA",Association for Computing Machinery,9781450329569,2014,Dynamics of news events and social media reaction,"Tsytsarau, Mikalai and Palpanas, Themis and Castellanos, Malu",inproceedings,10.1145/2623330.2623670,
10.1145/2623330.2623700,10.1145/2623330.2623700,KDD.bib,1,['KDD.bib'],8,KDD '14,"New York, New York, USA","ideal point estimation, legislative voting network, topic model, voting prediction",10,183–192,Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Ideal point estimation that estimates legislators' ideological positions and understands their voting behavior has attracted studies from political science and computer science. Typically, a legislator is assigned a global ideal point based on her voting or other social behavior. However, it is quite normal that people may have different positions on different policy dimensions. For example, some people may be more liberal on economic issues while more conservative on cultural issues. In this paper, we propose a novel topic-factorized ideal point estimation model for a legislative voting network in a unified framework. First, we model the ideal points of legislators and bills for each topic instead of assigning them to a global one. Second, the generation of topics are guided by the voting matrix in addition to the text information contained in bills. A unified model that combines voting behavior modeling and topic modeling is presented, and an iterative learning algorithm is proposed to learn the topics of bills as well as the topic-factorized ideal points of legislators and bills. By comparing with the state-of-the-art ideal point estimation models, our method has a much better explanation power in terms of held-out log-likelihood and other measures. Besides, case studies show that the topic-factorized ideal points coincide with human intuition. Finally, we illustrate how to use these topic-factorized ideal points to predict voting results for unseen bills.",10.1145/2623330.2623700,https://doi.org/10.1145/2623330.2623700,"New York, NY, USA",Association for Computing Machinery,9781450329569,2014,Topic-factorized ideal point estimation model for legislative voting network,"Gu, Yupeng and Sun, Yizhou and Jiang, Ning and Wang, Bingyu and Chen, Ting",inproceedings,10.1145/2623330.2623700,
10.1145/2623330.2623720,10.1145/2623330.2623720,KDD.bib,1,['KDD.bib'],8,KDD '14,"New York, New York, USA","crowd wisdom, herding effect, social influence",10,1087–1096,Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"In many diverse settings, aggregated opinions of others play an increasingly dominant role in shaping individual decision making. One key prerequisite of harnessing the ""crowd wisdom"" is the independency of individuals' opinions, yet in real settings collective opinions are rarely simple aggregations of independent minds. Recent experimental studies document that disclosing prior collective opinions distorts individuals' decision making as well as their perceptions of quality and value, highlighting a fundamental disconnect from current modeling efforts: How to model social influence and its impact on systems that are constantly evolving? In this paper, we develop a mechanistic framework to model social influence of prior collective opinions (e.g., online product ratings) on subsequent individual decision making. We find our method successfully captures the dynamics of rating growth, helping us separate social influence bias from inherent values. Using large-scale longitudinal customer rating datasets, we demonstrate that our model not only effectively assesses social influence bias, but also accurately predicts long-term cumulative growth of ratings solely based on early rating trajectories. We believe our framework will play an increasingly important role as our understanding of social processes deepens. It promotes strategies to untangle manipulations and social biases and provides insights towards a more reliable and effective design of social platforms.",10.1145/2623330.2623720,https://doi.org/10.1145/2623330.2623720,"New York, NY, USA",Association for Computing Machinery,9781450329569,2014,Quantifying herding effects in crowd wisdom,"Wang, Ting and Wang, Dashun and Wang, Fei",inproceedings,10.1145/2623330.2623720,
10.1145/2623330.2623744,10.1145/2623330.2623744,KDD.bib,1,['KDD.bib'],8,KDD '14,"New York, New York, USA","attraction, aversion, interest evolution, recommender systems",10,811–820,Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"People's interests are dynamically evolving, often affected by external factors such as trends promoted by the media or adopted by their friends. In this work, we model interest evolution through dynamic interest cascades: we consider a scenario where a user's interests may be affected by (a) the interests of other users in her social circle, as well as (b) suggestions she receives from a recommender system. In the latter case, we model user reactions through either attraction or aversion towards past suggestions. We study this interest evolution process, and the utility accrued by recommendations, as a function of the system's recommendation strategy. We show that, in steady state, the optimal strategy can be computed as the solution of a semi-definite program (SDP). Using datasets of user ratings, we provide evidence for the existence of aversion and attraction in real-life data, and show that our optimal strategy can lead to significantly improved recommendations over systems that ignore aversion and attraction.",10.1145/2623330.2623744,https://doi.org/10.1145/2623330.2623744,"New York, NY, USA",Association for Computing Machinery,9781450329569,2014,"Optimal recommendations under attraction, aversion, and social influence","Lu, Wei and Ioannidis, Stratis and Bhagat, Smriti and Lakshmanan, Laks V.S.",inproceedings,10.1145/2623330.2623744,
10.1145/2623330.2623752,10.1145/2623330.2623752,KDD.bib,1,['KDD.bib'],8,KDD '14,"New York, New York, USA","bayesian model, content sharing services, topic-specific authority analysis",10,1506–1515,Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"With the rapid growth of Web 2.0, a variety of content sharing services, such as Flickr, YouTube, Blogger, and TripAdvisor etc, have become extremely popular over the last decade. On these websites, users have created and shared with each other various kinds of resources, such as photos, video, and travel blogs. The sheer amount of user-generated content varies greatly in quality, which calls for a principled method to identify a set of authorities, who created high-quality resources, from a massive number of contributors of content. Since most previous studies only infer global authoritativeness of a user, there is no way to differentiate the authoritativeness in different aspects of life (topics).In this paper, we propose a novel model of Topic-specific Authority Analysis (TAA), which addresses the limitations of the previous approaches, to identify authorities specific to given query topic(s) on a content sharing service. This model jointly leverages the usage data collected from the sharing log and the favorite log. The parameters in TAA are learned from a constructed training dataset, for which a novel logistic likelihood function is specifically designed. To perform Bayesian inference for TAA with the new logistic likelihood, we extend typical Gibbs sampling by introducing auxiliary variables. Thorough experiments with two real-world datasets demonstrate the effectiveness of TAA in topic-specific authority identification as well as the generalizability of the TAA generative model.",10.1145/2623330.2623752,https://doi.org/10.1145/2623330.2623752,"New York, NY, USA",Association for Computing Machinery,9781450329569,2014,Who are experts specializing in landscape photography? analyzing topic-specific authority on content sharing services,"Bi, Bin and Kao, Ben and Wan, Chang and Cho, Junghoo",inproceedings,10.1145/2623330.2623752,
10.1145/2645710.2645717,10.1145/2645710.2645717,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","recommender systems, open source library",2,377–378,Proceedings of the 8th ACM Conference on Recommender Systems,"WrapRec is an easy-to-use Recommender Systems toolkit, which allows users to easily implement or wrap recommendation algorithms from other frameworks. The main goals of WrapRec are to provide a flexible I/O, evaluation mechanism and code reusability. WrapRec provides a rich data model which makes it easy to implement algorithms for different recommender system problems, such as context-aware and cross-domain recommendation. The toolkit is written in C# and the source code is publicly available on Github under the GPL license.",10.1145/2645710.2645717,https://doi.org/10.1145/2645710.2645717,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,WrapRec: an easy extension of recommender system libraries,"Loni, Babak and Said, Alan",inproceedings,10.1145/2645710.2645717,
10.1145/2645710.2645720,10.1145/2645710.2645720,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","learning to rank, matrix factorization, top-n recommendation, topic modeling",8,217–224,Proceedings of the 8th ACM Conference on Recommender Systems,"Real world large-scale recommender systems are always dynamic: new users and items continuously enter the system, and the status of old ones (e.g., users' preference and items' popularity) evolve over time. In order to handle such dynamics, we propose a recommendation framework consisting of an online component and an offline component, where the newly arrived items are processed by the online component such that users are able to get suggestions for fresh information, and the influence of longstanding items is captured by the offline component. Based on individual users' rating behavior, recommendations from the two components are combined to provide top-N recommendation. We formulate recommendation problem as a ranking problem where learning to rank is applied to extend upon matrix factorization to optimize item rankings by minimizing a pairwise loss function. Furthermore, to better model interactions between users and items, Latent Dirichlet Allocation is incorporated to fuse rating information and textual information. Real data based experiments demonstrate that our approach outperforms the state-of-the-art models by at least 61.21% and 50.27% in terms of mean average precision (MAP) and normalized discounted cumulative gain (NDCG) respectively.",10.1145/2645710.2645720,https://doi.org/10.1145/2645710.2645720,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Towards a dynamic top-N recommendation framework,"Liu, Xin and Aberer, Karl",inproceedings,10.1145/2645710.2645720,
10.1145/2645710.2645726,10.1145/2645710.2645726,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","browsegraph, browsing behavior, cold-start, news recommendation, sessions",8,81–88,Proceedings of the 8th ACM Conference on Recommender Systems,"Online social networks and mash-up services create opportunities to connect different web services otherwise isolated. Specifically in the case of news, users are very much exposed to news articles while performing other activities, such as social networking or web searching. Browsing behavior aimed at the consumption of news, especially in relation to the visits coming from other domains, has been mainly overlooked in previous work. To address that, we build a BrowseGraph out of the collective browsing traces extracted from a large viewlog of Yahoo News (0.5B entries), and we define the ReferrerGraph as its subgraph induced by the sessions with the same referrer domain. The structural and temporal properties of the graph show that browsing behavior in news is highly dependent on the referrer URL of the session, in terms of type of content consumed and time of consumption. We build on this observation and propose a news recommender that addresses the cold-start problem: given a user landing on a page of the site for the first time, we aim to predict the page she will visit next. We compare 24 flavors of recommenders belonging to the families of content-based, popularity-based, and browsing-based models. We show that the browsing-based recommender that takes into account the referrer URL is the best performing, achieving a prediction accuracy of 48% in conditions of heavy data sparsity.",10.1145/2645710.2645726,https://doi.org/10.1145/2645710.2645726,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Cold-start news recommendation with domain-dependent browse graph,"Trevisiol, Michele and Aiello, Luca Maria and Schifanella, Rossano and Jaimes, Alejandro",inproceedings,10.1145/2645710.2645726,
10.1145/2645710.2645728,10.1145/2645710.2645728,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","content-based filtering, collaborative filtering, cold-start problem",8,105–112,Proceedings of the 8th ACM Conference on Recommender Systems,"Most existing recommender systems focus on modeling the ratings while ignoring the abundant information embedded in the review text. In this paper, we propose a unified model that combines content-based filtering with collaborative filtering, harnessing the information of both ratings and reviews. We apply topic modeling techniques on the review text and align the topics with rating dimensions to improve prediction accuracy. With the information embedded in the review text, we can alleviate the cold-start problem. Furthermore, our model is able to learn latent topics that are interpretable. With these interpretable topics, we can explore the prior knowledge on items or users and recommend completely ""cold""' items. Empirical study on 27 classes of real-life datasets show that our proposed model lead to significant improvement compared with strong baseline methods, especially for datasets which are extremely sparse where rating-only methods cannot make accurate predictions.",10.1145/2645710.2645728,https://doi.org/10.1145/2645710.2645728,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,"Ratings meet reviews, a combined approach to recommend","Ling, Guang and Lyu, Michael R. and King, Irwin",inproceedings,10.1145/2645710.2645728,
10.1145/2645710.2645730,10.1145/2645710.2645730,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","collaborative filtering, factorization machines, gradient boosting, recommender systems",8,265–272,Proceedings of the 8th ACM Conference on Recommender Systems,"Recommendation techniques have been well developed in the past decades. Most of them build models only based on user item rating matrix. However, in real world, there is plenty of auxiliary information available in recommendation systems. We can utilize these information as additional features to improve recommendation performance. We refer to recommendation with auxiliary information as context-aware recommendation. Context-aware Factorization Machines (FM) is one of the most successful context-aware recommendation models. FM models pairwise interactions between all features, in such way, a certain feature latent vector is shared to compute the factorized parameters it involved. In practice, there are tens of context features and not all the pairwise feature interactions are useful. Thus, one important challenge for context-aware recommendation is how to effectively select ""good"" interaction features. In this paper, we focus on solving this problem and propose a greedy interaction feature selection algorithm based on gradient boosting. Then we propose a novel Gradient Boosting Factorization Machine (GBFM) model to incorporate feature selection algorithm with Factorization Machines into a unified framework. The experimental results on both synthetic and real datasets demonstrate the efficiency and effectiveness of our algorithm compared to other state-of-the-art methods.",10.1145/2645710.2645730,https://doi.org/10.1145/2645710.2645730,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Gradient boosting factorization machines,"Cheng, Chen and Xia, Fen and Zhang, Tong and King, Irwin and Lyu, Michael R.",inproceedings,10.1145/2645710.2645730,
10.1145/2645710.2645736,10.1145/2645710.2645736,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","supervised latent dirichlet allocation, question recommendation, learning to rank, latent topics model, expert modeling, community question answering",8,193–200,Proceedings of the 8th ACM Conference on Recommender Systems,"Collaborative question answering (CQA) communities rely on user participation for their success. This paper presents a supervised Bayesian approach to model expertise in on-line CQA communities with application to question recommendation, aimed at reducing waiting times for responses and avoiding question starvation. We propose a novel algorithm called RankSLDA which extends the supervised Latent Dirichlet Allocation model by considering a learning-to-rank paradigm. This allows us to exploit the inherent collaborative effects that are present in CQA communities where users tend to answer questions in their topics of expertise. Users can thus be modeled on the basis of the topics in which they demonstrate expertise. In the supervised stage of the method we model the pairwise order of expertise of users on a given question. We compare RankSLDA against several alternative methods on data from the Cross Validate community, part of the Stack Exchange network. RankSLDA outperforms all alternative methods by a significant margin.",10.1145/2645710.2645736,https://doi.org/10.1145/2645710.2645736,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Question recommendation for collaborative question answering systems with RankSLDA,"San Pedro, Jose and Karatzoglou, Alexandros",inproceedings,10.1145/2645710.2645736,
10.1145/2645710.2645743,10.1145/2645710.2645743,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","diversity, genres, recommender systems",8,209–216,Proceedings of the 8th ACM Conference on Recommender Systems,"There is increasing awareness in the Recommender Systems field that diversity is a key property that enhances the usefulness of recommendations. Genre information can serve as a means to measure and enhance the diversity of recommendations and is readily available in domains such as movies, music or books. In this work we propose a new Binomial framework for defining genre diversity in recommender systems that takes into account three key properties: genre coverage, genre redundancy and recommendation list size-awareness. We show that methods previously proposed for measuring and enhancing recommendation diversity - including those adapted from search result diversification - fail to address adequately these three properties. We also propose an efficient greedy optimization technique to optimize Binomial diversity. Experiments with the Netflix dataset show the properties of our framework and comparison with state of the art methods.",10.1145/2645710.2645743,https://doi.org/10.1145/2645710.2645743,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,"Coverage, redundancy and size-awareness in genre diversity for recommender systems","Vargas, Sa\'{u}l and Baltrunas, Linas and Karatzoglou, Alexandros and Castells, Pablo",inproceedings,10.1145/2645710.2645743,
10.1145/2645710.2645744,10.1145/2645710.2645744,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","novelty, recommender systems, sales diversity",8,145–152,Proceedings of the 8th ACM Conference on Recommender Systems,"Sales diversity is considered a key feature of Recommender Systems from a business perspective. Sales diversity is also linked with the long-tail novelty of recommendations, a quality dimension from the user perspective. We explore the inversion of the recommendation task as a means to enhance sales diversity - and indirectly novelty - by selecting which users an item should be recommended to instead of the other way around. We address the inverted task by two approaches: a) inverting the rating matrix, and b) defining a probabilistic reformulation which isolates the popularity component of arbitrary recommendation algorithms. We find that the first approach gives rise to interesting reformulations of nearest-neighbor algorithms, which essentially introduce a new neighbor selection policy. The second approach, as well as the first, ultimately result in substantial sales diversity enhancements, and improved trade-offs with recommendation precision and novelty. Two experiments on movie and music recommendation datasets show the effectiveness of the resulting approach, even when compared to direct optimization approaches of the target metrics proposed in prior work.",10.1145/2645710.2645744,https://doi.org/10.1145/2645710.2645744,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Improving sales diversity by recommending users to items,"Vargas, Sa\'{u}l and Castells, Pablo",inproceedings,10.1145/2645710.2645744,
10.1145/2645710.2645746,10.1145/2645710.2645746,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","benchmarking, evaluation, recommender systems",8,129–136,Proceedings of the 8th ACM Conference on Recommender Systems,"Recommender systems research is often based on comparisons of predictive accuracy: the better the evaluation scores, the better the recommender. However, it is difficult to compare results from different recommender systems due to the many options in design and implementation of an evaluation strategy. Additionally, algorithmic implementations can diverge from the standard formulation due to manual tuning and modifications that work better in some situations.In this work we compare common recommendation algorithms as implemented in three popular recommendation frameworks. To provide a fair comparison, we have complete control of the evaluation dimensions being benchmarked: dataset, data splitting, evaluation strategies, and metrics. We also include results using the internal evaluation mechanisms of these frameworks. Our analysis points to large differences in recommendation accuracy across frameworks and strategies, i.e. the same baselines may perform orders of magnitude better or worse across frameworks. Our results show the necessity of clear guidelines when reporting evaluation of recommender systems to ensure reproducibility and comparison of results.",10.1145/2645710.2645746,https://doi.org/10.1145/2645710.2645746,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Comparative recommender system evaluation: benchmarking recommendation frameworks,"Said, Alan and Bellog\'{\i}n, Alejandro",inproceedings,10.1145/2645710.2645746,
10.1145/2645710.2645747,10.1145/2645710.2645747,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","recommendations, privacy, active learning",8,65–72,Proceedings of the 8th ACM Conference on Recommender Systems,"Recommender systems leverage user demographic information, such as age, gender, etc., to personalize recommendations and better place their targeted ads. Oftentimes, users do not volunteer this information due to privacy concerns, or due to a lack of initiative in filling out their online profiles. We illustrate a new threat in which a recommender learns private attributes of users who do not voluntarily disclose them. We design both passive and active attacks that solicit ratings for strategically selected items, and could thus be used by a recommender system to pursue this hidden agenda. Our methods are based on a novel usage of Bayesian matrix factorization in an active learning setting. Evaluations on multiple datasets illustrate that such attacks are indeed feasible and use significantly fewer rated items than static inference methods. Importantly, they succeed without sacrificing the quality of recommendations to users.",10.1145/2645710.2645747,https://doi.org/10.1145/2645710.2645747,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Recommending with an agenda: active learning of private attributes using matrix factorization,"Bhagat, Smriti and Weinsberg, Udi and Ioannidis, Stratis and Taft, Nina",inproceedings,10.1145/2645710.2645747,
10.1145/2645710.2645751,10.1145/2645710.2645751,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","recommender systems, matrix factorization, collective embeddings, cold-start",8,89–96,Proceedings of the 8th ACM Conference on Recommender Systems,"Recommender systems suggest to users items that they might like (e.g., news articles, songs, movies) and, in doing so, they help users deal with information overload and enjoy a personalized experience. One of the main problems of these systems is the item cold-start, i.e., when a new item is introduced in the system and no past information is available, then no effective recommendations can be produced. The item cold-start is a very common problem in practice: modern online platforms have hundreds of new items published every day. To address this problem, we propose to learn Local Collective Embeddings: a matrix factorization that exploits items' properties and past user preferences while enforcing the manifold structure exhibited by the collective embeddings. We present a learning algorithm based on multiplicative update rules that are efficient and easy to implement. The experimental results on two item cold-start use cases: news recommendation and email recipient recommendation, demonstrate the effectiveness of this approach and show that it significantly outperforms six state-of-the-art methods for item cold-start.",10.1145/2645710.2645751,https://doi.org/10.1145/2645710.2645751,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Item cold-start recommendations: learning local collective embeddings,"Saveski, Martin and Mantrach, Amin",inproceedings,10.1145/2645710.2645751,
10.1145/2645710.2645752,10.1145/2645710.2645752,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","probabilistic neighborhood selection, popularity reinforcement, over-specialization, mobility, long tail, k-pn, diversity, concentration bias, collaborative filtering",8,153–160,Proceedings of the 8th ACM Conference on Recommender Systems,"Focusing on the problems of over-specialization and concentration bias, this paper presents a novel probabilistic method for recommending items in the neighborhood-based collaborative filtering framework. For the probabilistic neighborhood selection phase, we use an efficient method for weighted sampling of k neighbors that takes into consideration the similarity levels between the target user (or item) and the candidate neighbors. We conduct an empirical study showing that the proposed method increases the coverage, dispersion, and diversity reinforcement of recommendations by selecting diverse sets of representative neighbors. We also demonstrate that the proposed approach outperforms popular methods in terms of item prediction accuracy, utility-based ranking, and other popular measures, across various experimental settings. This performance improvement is in accordance with ensemble learning theory and the phenomenon of ""hubness"" in recommender systems.",10.1145/2645710.2645752,https://doi.org/10.1145/2645710.2645752,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,On over-specialization and concentration bias of recommendations: probabilistic neighborhood selection in collaborative filtering systems,"Adamopoulos, Panagiotis and Tuzhilin, Alexander",inproceedings,10.1145/2645710.2645752,
10.1145/2645710.2645754,10.1145/2645710.2645754,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","collaborative filtering, non-random missing data, probabilistic models, recommender systems, variational bayesian inference",8,201–208,Proceedings of the 8th ACM Conference on Recommender Systems,"Collaborative prediction involves filling in missing entries of a user-item matrix to predict preferences of users based on their observed preferences. Most of existing models assume that the data is missing at random (MAR), which is often violated in recommender systems in practice. Incorrect assumption on missing data ignores the missing data mechanism, leading to biased inferences and prediction. In this paper we present a Bayesian binomial mixture model for collaborative prediction, where the generative process for data and missing data mechanism are jointly modeled to handle non-random missing data. Missing data mechanism is modeled by three factors, each of which is related to users, items, and rating values. Each factor is modeled by Bernoulli random variable, and the observation of rating value is determined by the Boolean OR operation of three binary variables. We develop computationally-efficient variational inference algorithms, where variational parameters have closed-form update rules and the computational complexity depends on the number of observed ratings, instead of the size of the rating data matrix. We also discuss implementation issues on hyperparameter tuning and estimation based on empirical Bayes. Experiments on Yahoo! Music and MovieLens datasets confirm the useful behavior of our model by demonstrating that: (1) it outperforms state-of-the-art methods in yielding higher predictive performance; (2) it finds meaningful solutions instead of undesirable boundary solutions; (3) it provides rating trend analysis on why ratings are observed.",10.1145/2645710.2645754,https://doi.org/10.1145/2645710.2645754,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Bayesian binomial mixture model for collaborative prediction with non-random missing data,"Kim, Yong-Deok and Choi, Seungjin",inproceedings,10.1145/2645710.2645754,
10.1145/2645710.2645757,10.1145/2645710.2645757,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","switching hybrid system, context-aware recommender systems, cold-start problem",4,349–352,Proceedings of the 8th ACM Conference on Recommender Systems,"Finding effective solutions for cold-starting Context-Aware Recommender Systems (CARSs) is important because usually low quality recommendations are produced for users, items or contextual situations that are new to the system. In this paper, we tackle this problem with a switching hybrid solution that exploits a custom selection of two CARS algorithms, each one suited for a particular cold-start situation, and switches between these algorithms depending on the detected recommendation situation (new user, new item or new context). We evaluate the proposed algorithms in an off-line experiment by using various contextually-tagged rating datasets. We illustrate some significant performance differences between the considered algorithms and show that they can be effectively combined into the proposed switching hybrid to cope with different types of cold-start problems.",10.1145/2645710.2645757,https://doi.org/10.1145/2645710.2645757,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Switching hybrid for cold-starting context-aware recommender systems,"Braunhofer, Matthias and Codina, Victor and Ricci, Francesco",inproceedings,10.1145/2645710.2645757,
10.1145/2645710.2645766,10.1145/2645710.2645766,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","implicit trust, matrix factorization, rating, recommender system, similarity, social network",4,317–320,Proceedings of the 8th ACM Conference on Recommender Systems,"Incorporating social trust in Matrix Factorization (MF) methods demonstrably improves accuracy of rating prediction. Such approaches mainly use the trust scores explicitly expressed by users. However, it is often challenging to have users provide explicit trust scores of each other. There exist quite a few works, which propose Trust Metrics (TM) to compute and predict trust scores between users based on their interactions. In this paper, we first evaluate several TMs to find out which one can best predict trust scores compared to the actual trust scores explicitly expressed by users. And, second, we propose to incorporate these trust scores inferred from the candidate TMs into social matrix factorization (MF). We investigate if incorporating the implicit trust scores in MF can make rating prediction as accurate as the MF on explicit trust scores. The reported results support the idea of employing implicit trust into MF whenever explicit trust is not available, since the performance of both models is similar.",10.1145/2645710.2645766,https://doi.org/10.1145/2645710.2645766,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Implicit vs. explicit trust in social matrix factorization,"Fazeli, Soude and Loni, Babak and Bellogin, Alejandro and Drachsler, Hendrik and Sloep, Peter",inproceedings,10.1145/2645710.2645766,
10.1145/2645710.2645768,10.1145/2645710.2645768,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","recommender systems, tailored health communications",4,329–332,Proceedings of the 8th ACM Conference on Recommender Systems,"The goal of computer tailored health communications (CTHC) is to elicit healthy behavior changes by sending motivational messages personalized to individual patients. One prominent weakness of many existing CTHC systems is that they are based on expert-written rules and thus have no ability to learn from their users over time. One solution to this problem is to develop CTHC systems based on the principles of collaborative filtering, but this approach has not been widely studied. In this paper, we present a case study evaluating nine rating prediction methods for use in the Patient Experience Recommender System for Persuasive Communication Tailoring, a system developed for use in a clinical trial of CTHC-based smoking cessation support interventions.",10.1145/2645710.2645768,https://doi.org/10.1145/2645710.2645768,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,PERSPeCT: collaborative filtering for tailored health communications,"Adams, Roy J. and Sadasivam, Rajani S. and Balakrishnan, Kavitha and Kinney, Rebecca L. and Houston, Thomas K. and Marlin, Benjamin M.",inproceedings,10.1145/2645710.2645768,
10.1145/2645710.2645771,10.1145/2645710.2645771,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","cluster encoding, collaborative filtering, cross-domain collaborative filtering, factorization machines",4,281–284,Proceedings of the 8th ACM Conference on Recommender Systems,"The advantage of Factorization Machines over other factorization models is their ability to easily integrate and efficiently exploit auxiliary information to improve Collaborative Filtering. Until now, this auxiliary information has been drawn from external knowledge sources beyond the user-item matrix. In this paper, we demonstrate that Factorization Machines can exploit additional representations of information inherent in the user-item matrix to improve recommendation performance. We refer to our approach as 'Free Lunch' enhancement since it leverages clusters that are based on information that is present in the user-item matrix, but not otherwise directly exploited during matrix factorization. Borrowing clustering concepts from codebook sharing, our approach can also make use of 'Free Lunch' information inherent in a user-item matrix from a auxiliary domain that is different from the target domain of the recommender. Our approach improves performance both in the joint case, in which the auxiliary and target domains share users, and in the disjoint case, in which they do not. Although 'Free Lunch' enhancement does not apply equally well to any given domain or domain combination, our overall conclusion is that Factorization Machines present an opportunity to exploit information that is ubiquitously present, but commonly under-appreciated by Collaborative Filtering algorithms.",10.1145/2645710.2645771,https://doi.org/10.1145/2645710.2645771,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014, 'Free lunch' enhancement for collaborative filtering with factorization machines,"Loni, Babak and Said, Alan and Larson, Martha and Hanjalic, Alan",inproceedings,10.1145/2645710.2645771,
10.1145/2645710.2645772,10.1145/2645710.2645772,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","recommender systems, cold-start problem",4,345–348,Proceedings of the 8th ACM Conference on Recommender Systems,"We examine the cold-start recommendation task in an online retail setting for users who have not yet purchased (or interacted in a meaningful way with) any available items but who have granted access to limited side information, such as basic demographic data (gender, age, location) or social network information (Facebook friends or page likes). We formalize neighborhood-based methods for cold-start collaborative filtering in a generalized matrix algebra framework that does not require purchase data for target users when their side information is available. In real-data experiments with 30,000 users who purchased 80,000+ books and had 9,000,000+ Facebook friends and 6,000,000+ page likes, we show that using Facebook page likes for cold-start recommendation yields up to a 3-fold improvement in mean average precision (mAP) and up to 6-fold improvements in Precision@k and Recall@k compared to most-popular-item, demographic, and Facebook friend cold-start recommenders. These results demonstrate the substantial predictive power of social network content, and its significant utility in a challenging problem - recommendation for cold-start users.",10.1145/2645710.2645772,https://doi.org/10.1145/2645710.2645772,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Social collaborative filtering for cold-start recommendations,"Sedhain, Suvash and Sanner, Scott and Braziunas, Darius and Xie, Lexing and Christensen, Jordan",inproceedings,10.1145/2645710.2645772,
10.1145/2645710.2645775,10.1145/2645710.2645775,RecSys.bib,1,['RecSys.bib'],7,RecSys '14,"Foster City, Silicon Valley, California, USA",,2,397–398,Proceedings of the 8th ACM Conference on Recommender Systems,"In 2006, Netflix announced a $1M prize competition to advance recommendation algorithms. The recommendation problem was simplified as the accuracy in predicting a user rating measured by the Root Mean Squared Error (RMSE). While that formulation helped get the attention of the research community in the area, it may have put an excessive focus on what is simply one of the many possible approaches to recommendations.In this tutorial we will describe different components of modern recommender systems such as: personalized ranking, similarity, explanations, context-awareness, or search as recommendation. We will use the Netflix use case as a driving example of a prototypical industrial-scale recommender system that has evolved from focusing on rating prediction to full page optimization. We will also review the usage of modern algorithmic approaches that include algorithms such as Factorization Machines [9], Restricted Boltzmann Machines [10], SimRank [7], Deep Neural Networks, or Listwise Learning-to-rank [6, 12, 11].The original recommendation problem was formulated around the existence of explicit user ratings. However, recommender systems can be built using different kinds of data including implicit behavioral data, social connections, or demographics. In this tutorial we will review the usage of different data types and discuss what the availability of Big Data has brought into the research area.Finally, and also related to the availability of large quantities of data, we will talk about how system and architectural decisions play a role in understanding the recommender problem.This tutorial is in part based on recent publications by the author [5, 1, 8, 2, 4, 3].",10.1145/2645710.2645775,https://doi.org/10.1145/2645710.2645775,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,The recommender problem revisited,"Amatriain, Xavier",inproceedings,10.1145/2645710.2645775,
10.1145/2645710.2645779,10.1145/2645710.2645779,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","recommender systems, dataset, context-aware, competition, challenge, benchmarking",2,387–388,Proceedings of the 8th ACM Conference on Recommender Systems,"The 2014 ACM Recommender Systems Challenge invited researchers and practitioners to work towards a common goal, this goal being the prediction of users engagement in movie ratings expressed on Twitter. More than 200 participants sought to join the challenge and work on the new dataset released in its scope. The participants were asked to develop new algorithms to predict user engagement and evaluate them in a common setting, ensuring that the comparison was objective and unbiased, within the challenge.",10.1145/2645710.2645779,https://doi.org/10.1145/2645710.2645779,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Recommender systems challenge 2014,"Said, Alan and Dooms, Simon and Loni, Babak and Tikk, Domonkos",inproceedings,10.1145/2645710.2645779,
10.1145/2645710.2645781,10.1145/2645710.2645781,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","a/b testing, controlled experiments, experiment systems, experimental design, online experiments",1,389,Proceedings of the 8th ACM Conference on Recommender Systems,"In this workshop, we have several leading industry experts sharing their knowledge and experiences on how online controlled experiments are used in their applications. The individual talks are followed by a panel discussion.",10.1145/2645710.2645781,https://doi.org/10.1145/2645710.2645781,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,"Controlled experimentation in recommendations, ranking &amp; response prediction","Xu, Ya and Parekh, Rajesh and Aurisset, Juliette",inproceedings,10.1145/2645710.2645781,
10.1145/2645710.2653360,10.1145/2645710.2653360,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","cold-start problem, context-aware recommender systems, hybrid system",4,405–408,Proceedings of the 8th ACM Conference on Recommender Systems,"Context-Aware Recommender Systems (CARSs) suffer from the cold-start problem, i.e., the inability to provide accurate recommendations for new users, items or contextual situations. In this research, we aim at solving this problem by exploiting various hybridisation techniques, from simple heuristic-based solutions to complex adaptive solutions, in order to take advantage of the strengths of different CARS algorithms while avoiding their weaknesses in a given (cold-start) situation. Our initial research based on offline experiments using various contextually-tagged rating datasets has shown that basic CARS algorithms perform very differently in different recommendation scenarios, and that they can be effectively hybridised to achieve an overall optimal performance. Further research is now required to find the optimal method for hybridisation.",10.1145/2645710.2653360,https://doi.org/10.1145/2645710.2653360,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Hybridisation techniques for cold-starting context-aware recommender systems,"Braunhofer, Matthias",inproceedings,10.1145/2645710.2653360,
10.1145/2645710.2653361,10.1145/2645710.2653361,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","top-n recommendation, recommender systems, recommendation sets, intra-set dependencies, higher-order relations, cross-feature interactions",4,409–412,Proceedings of the 8th ACM Conference on Recommender Systems,"This paper suggests a number of research directions in which the recommender systems can improve their quality, by moving beyond the assumptions of linearity and independence that are traditionally made. These assumptions, while producing effective and meaningful results, can be suboptimal, as in lots of cases they do not represent the real datasets. In this paper, we discuss three different ways to address some of the previous constraints. More specifically, we focus on the development of methods capturing higher-order relations between the items, cross-feature interactions and intra-set dependencies which can potentially lead to a considerable enhancement of the recommendation accuracy.",10.1145/2645710.2653361,https://doi.org/10.1145/2645710.2653361,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Moving beyond linearity and independence in top-N recommender systems,"Christakopoulou, Evangelia",inproceedings,10.1145/2645710.2653361,
10.1145/2645710.2653367,10.1145/2645710.2653367,RecSys.bib,1,['RecSys.bib'],8,RecSys '14,"Foster City, Silicon Valley, California, USA","recommender systems, matrix factorization, collaborative filtering, browser logs, block diagonal form",4,433–436,Proceedings of the 8th ACM Conference on Recommender Systems,"Our research aims to bridge the gap between different websites to provide cross-site recommendations based on browsers. Recent advances have made recommender systems essential to various online applications, such as e-commerce, social networks, and review service websites. However, practical systems mainly focus on recommending inner-site homogeneous items. For example, a movie review website usually recommends other movies within the site when a user has enjoyed a movie online. However, it would be exciting if the system recommends some attractive products related to this movie from some e-commerce websites like Amazon or eBay.Such an ability to provide heterogeneous cross-site recommendations may shed light on brand new and promising business models, which could benefit both the online shops in expanding the marketing efforts, and the online users in discovering items of interest from a wider scope. In this research, we propose and formalize the problem of universal recommendation, record and analyze user browsing actions in web browsers, and provide browser-oriented cross-site recommendations when the users are surfing online.",10.1145/2645710.2653367,https://doi.org/10.1145/2645710.2653367,"New York, NY, USA",Association for Computing Machinery,9781450326681,2014,Browser-oriented universal cross-site recommendation and explanation based on user browsing logs,"Zhang, Yongfeng",inproceedings,10.1145/2645710.2653367,
10.1145/2659480.2659501,10.1145/2659480.2659501,KDD.bib,1,['KDD.bib'],7,SNAKDD'14,"New York, NY, USA","Coupled Geometry, Haar Basis, Multiresolution Analysis, Partition Tree, Recommender System, Sparse Matrix",5,,Proceedings of the 8th Workshop on Social Network Mining and Analysis,"Recommender systems face performance challenges when dealing with sparse data. This paper addresses these challenges and proposes the use of Harmonic Analysis. The method provides a novel approach to the user-item matrix and extracts the interplay between users and items at multiple resolution levels. New affinity matrices are defined to measure similarities among users, among items, and across items and users. Furthermore, the similarities are assessed at multiple levels of granularity allowing individual and group level similarities. These affinity matrices thus produce multiresolution groupings of items and users, and in turn lead to higher accuracy in matching similar context for ratings, and more accurate prediction of new ratings. Evaluation results show superiority of the approach compared to state of the art solutions.",10.1145/2659480.2659501,https://doi.org/10.1145/2659480.2659501,"New York, NY, USA",Association for Computing Machinery,9781450331920,2014,A Multiresolution Approach to Recommender Systems,"Badaro, Gilbert and Hajj, Hazem and Haddad, Ali and El-Hajj, Wassim and Shaban, Khaled Bashir",inproceedings,10.1145/2659480.2659501,9
10.1145/2661829.2661903,10.1145/2661829.2661903,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","hashtag, hashtag annotation, topic model, twitter",10,999–1008,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"The adoption of hashtags in major social networks including Twitter, Facebook, and Google+ is a strong evidence of its importance in facilitating information diffusion and social chatting. To understand the factors (e.g., user interest, posting time and tweet content) that may affect hashtag annotation in Twitter and to capture the implicit relations between latent topics in tweets and their corresponding hashtags, we propose two PLSA-style topic models to model the hashtag annotation behavior in Twitter. Content-Pivoted Model (CPM) assumes that tweet content guides the generation of hashtags while Hashtag-Pivoted Model (HPM) assumes that hashtags guide the generation of tweet content. Both models jointly incorporate user, time, hashtag and tweet content in a probabilistic framework. The PLSA-style models also enable us to verify the impact of social factor on hashtag annotation by introducing social network regularization in the two models. We evaluate the proposed models using perplexity and demonstrate their effectiveness in two applications: retrospective hashtag annotation and related hashtag discovery. Our results show that HPM outperforms CPM by perplexity and both user and time are important factors that affect model performance. In addition, incorporating social network regularization does not improve model performance. Our experimental results also demonstrate the effectiveness of our models in both applications compared with baseline methods.",10.1145/2661829.2661903,https://doi.org/10.1145/2661829.2661903,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Tagging Your Tweets: A Probabilistic Modeling of Hashtag Annotation in Twitter,"Ma, Zongyang and Sun, Aixin and Yuan, Quan and Cong, Gao",inproceedings,10.1145/2661829.2661903,
10.1145/2661829.2661921,10.1145/2661829.2661921,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","personalization, query auto-completion, time-sensitive",10,1599–1608,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"Query auto-completion (QAC) is a prominent feature of modern search engines. It is aimed at saving user's time and enhancing the search experience. Current QAC models mostly rank matching QAC candidates according to their past popularity, i.e., frequency. However, query popularity changes over time and may vary drastically across users. Hence, rankings of QAC candidates should be adjusted accordingly. In previous work time-sensitive QAC models and user-specific QAC models have been developed separately. Both types of QAC model lead to important improvements over models that are neither time-sensitive nor personalized. We propose a hybrid QAC model that considers both of these aspects: time-sensitivity and personalization.Using search logs, we return the top N QAC candidates by predicted popularity based on their recent trend and cyclic behavior. We use auto-correlation to detect query periodicity by long-term time-series analysis, and anticipate the query popularity trend based on observations within an optimal time window returned by a regression model. We rerank the returned top N candidates by integrating their similarities with a user's preceding queries (both in the current session and in previous sessions by the same user) on a character level to produce a final QAC list. Our experimental results on two real-world datasets show that our hybrid QAC model outperforms state-of-the-art time-sensitive QAC baseline, achieving total improvements of between 3% and 7% in terms of MRR.",10.1145/2661829.2661921,https://doi.org/10.1145/2661829.2661921,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Time-sensitive Personalized Query Auto-Completion,"Cai, Fei and Liang, Shangsong and de Rijke, Maarten",inproceedings,10.1145/2661829.2661921,
10.1145/2661829.2661976,10.1145/2661829.2661976,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","collaborative filtering, compressed sensing, matrix factorization, optimization, recommender systems",10,1189–1198,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"An important problem of matrix completion/approximation based on Matrix Factorization (MF) algorithms is the existence of multiple global optima; this problem is especially serious when the matrix is sparse, which is common in real-world applications such as personalized recommender systems. In this work, we clarify data sparsity by bounding the solution space of MF algorithms. We present the conditions that an MF algorithm should satisfy for reliable completion of the unobservables, and we further propose to augment current MF algorithms with extra constraints constructed by compressive sampling on the unobserved values, which is well-motivated by the theoretical analysis. Model learning and optimal solution searching is conducted in a properly reduced solution space to achieve more accurate and efficient rating prediction performances. We implemented the proposed algorithms in the Map-Reduce framework, and comprehensive experimental results on Yelp and Dianping datasets verified the effectiveness and efficiency of the augmented matrix factorization algorithms.",10.1145/2661829.2661976,https://doi.org/10.1145/2661829.2661976,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Understanding the Sparsity: Augmented Matrix Factorization with Sampled Constraints on Unobservables,"Zhang, Yongfeng and Zhang, Min and Zhang, Yi and Liu, Yiqun and Ma, Shaoping",inproceedings,10.1145/2661829.2661976,
10.1145/2661829.2661992,10.1145/2661829.2661992,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","latent dirichlet allocation, one-class collaborative filtering, topic model",4,1991–1994,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"Previous work studied one-class collaborative filtering (OCCF) problems including pointwise methods, pairwise methods, and content-based methods. The fundamental assumptions made on these approaches are roughly the same. They regard all missing values as negative. However, this is unreasonable since the missing values actually are the mixture of negative and positive examples. A user does not give a positive feedback on an item probably only because she/he is unaware of the item, but in fact, she/he is fond of it. Furthermore, content-based methods, e.g. collaborative topic regression (CTR), usually require textual content information of items. This cannot be satisfied in some cases. In this paper, we exploit latent Dirichlet allocation (LDA) model on OCCF problem. It assumes missing values unknown and only models the observed data, and it also does not need content information of items. In our model items are regarded as words and users are considered as documents and the user-item feedback matrix denotes the corpus. Experimental results show that our proposed method outperforms the previous methods on various ranking-oriented evaluation metrics.",10.1145/2661829.2661992,https://doi.org/10.1145/2661829.2661992,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Exploit Latent Dirichlet Allocation for One-Class Collaborative Filtering,"Zhang, Haijun and Li, Zhoujun and Chen, Yan and Zhang, Xiaoming and Wang, Senzhang",inproceedings,10.1145/2661829.2661992,
10.1145/2661829.2661996,10.1145/2661829.2661996,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","admm, distributed computing, matrix factorization, recommender systems, stochastic learning",10,1259–1268,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"Matrix factorization (MF) has become the most popular technique for recommender systems due to its promising performance. Recently, distributed (parallel) MF models have received much attention from researchers of big data community. In this paper, we propose a novel model, called distributed stochastic alternating direction methods of multipliers (DS-ADMM), for large-scale MF problems. DS-ADMM is a distributed stochastic variant of ADMM. In particular, we first devise a new data split strategy to make the distributed MF problem fit for the ADMM framework. Then, a stochastic ADMM scheme is designed for learning. Finally, we implement DS-ADMM based on message passing interface (MPI), which can run on clusters with multiple machines (nodes). Experiments on several data sets from recommendation applications show that our DS-ADMM model can outperform other state-of-the-art distributed MF models in terms of both efficiency and accuracy.",10.1145/2661829.2661996,https://doi.org/10.1145/2661829.2661996,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Distributed Stochastic ADMM for Matrix Factorization,"Yu, Zhi-Qin and Shi, Xing-Jian and Yan, Ling and Li, Wu-Jun",inproceedings,10.1145/2661829.2661996,
10.1145/2661829.2661998,10.1145/2661829.2661998,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","personalized ranking, recommender systems, social networks",10,261–270,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"Recommending products to users means estimating their preferences for certain items over others. This can be cast either as a problem of estimating the rating that each user will give to each item, or as a problem of estimating users' relative preferences in the form of a ranking. Although collaborative-filtering approaches can be used to identify users who rate and rank products similarly, another source of data that informs us about users' preferences is their set of social connections. Both rating- and ranking-based paradigms are important in real-world recommendation settings, though rankings are especially important in settings where explicit feedback in the form of a numerical rating may not be available. Although many existing works have studied how social connections can be used to build better models for rating prediction, few have used social connections as a means to derive more accurate ranking-based models. Using social connections to better estimate users' rankings of products is the task we consider in this paper. We develop a model, SBPR (Social Bayesian Personalized Ranking), based on the simple observation that users tend to assign higher ranks to items that their friends prefer. We perform experiments on four real-world recommendation data sets, and show that SBPR outperforms alternatives in ranking prediction both in warm- and cold-start settings.",10.1145/2661829.2661998,https://doi.org/10.1145/2661829.2661998,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Leveraging Social Connections to Improve Personalized Ranking for Collaborative Filtering,"Zhao, Tong and McAuley, Julian and King, Irwin",inproceedings,10.1145/2661829.2661998,
10.1145/2661829.2662002,10.1145/2661829.2662002,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","geographical neighborhood, location recommendation, location-based social networks, matrix factorization",10,739–748,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"Geographical characteristics derived from the historical check-in data have been reported effective in improving location recommendation accuracy. However, previous studies mainly exploit geographical characteristics from a user's perspective, via modeling the geographical distribution of each individual user's check-ins. In this paper, we are interested in exploiting geographical characteristics from a location perspective, by modeling the geographical neighborhood of a location. The neighborhood is modeled at two levels: the instance-level neighborhood defined by a few nearest neighbors of the location, and the region-level neighborhood for the geographical region where the location exists. We propose a novel recommendation approach, namely Instance-Region Neighborhood Matrix Factorization (IRenMF), which exploits two levels of geographical neighborhood characteristics: a) instance-level characteristics, i.e., nearest neighboring locations tend to share more similar user preferences; and b) region-level characteristics, i.e., locations in the same geographical region may share similar user preferences. In IRenMF, the two levels of geographical characteristics are naturally incorporated into the learning of latent features of users and locations, so that IRenMF predicts users' preferences on locations more accurately. Extensive experiments on the real data collected from Gowalla, a popular LBSN, demonstrate the effectiveness and advantages of our approach.",10.1145/2661829.2662002,https://doi.org/10.1145/2661829.2662002,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Exploiting Geographical Neighborhood Characteristics for Location Recommendation,"Liu, Yong and Wei, Wei and Sun, Aixin and Miao, Chunyan",inproceedings,10.1145/2661829.2662002,
10.1145/2661829.2662014,10.1145/2661829.2662014,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","bayesian parameter estimation, emerging outbreak monitoring, microblog, plda, sir, topic modeling",10,1099–1108,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"A recent study on collective attention in Twitter shows that an epidemic spreading of hashtags is predominantly driven by external factors. We extend a time-series form of susceptible-infectious-recovered (SIR) model to monitor microblog emerging outbreaks by considering both endogenous and exogenous drivers. In addition, we adopt partially labeled Dirichlet allocation (PLDA) model to generate both background latent topics and hashtag topics. It overcomes the problem of small available samples in hashtag analysis by including related but unlabeled tweets through inference. We standardize hashtag topic contagiousness measure as the estimated effective-reproduction-number R derived from epidemiology. It is obtained by Bayesian parameter estimation. Guided by R, one can profile and categorize emerging topics, and generate alerts on potential outbreaks. Experiment results confirm the effectiveness of this approach.",10.1145/2661829.2662014,https://doi.org/10.1145/2661829.2662014,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Microblog Topic Contagiousness Measurement and Emerging Outbreak Monitoring,"Chu, Victor W. and Wong, Raymond K. K. and Chen, Fang and Chi, Chi-Hung",inproceedings,10.1145/2661829.2662014,
10.1145/2661829.2662021,10.1145/2661829.2662021,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","collaborative filtering, hierarchical structure, item group, user group",10,769–778,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"Matrix factorization is one of the most powerful techniques in collaborative filtering, which models the (user, item) interactions behind historical explicit or implicit feedbacks. However, plain matrix factorization may not be able to uncover the structure correlations among users and items well such as communities and taxonomies. As a response, we design a novel algorithm, i.e., hierarchical group matrix factorization (HGMF), in order to explore and model the structure correlations among users and items in a principled way. Specifically, we first define four types of correlations, including (user, item), (user, item group), (user group, item) and (user group, item group); we then extend plain matrix factorization with a hierarchical group structure; finally, we design a novel clustering algorithm to mine the hidden structure correlations. In the experiments, we study the effectiveness of our HGMF for both rating prediction and item recommendation, and find that it is better than some state-of-the-art methods on several real-world data sets.",10.1145/2661829.2662021,https://doi.org/10.1145/2661829.2662021,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,HGMF: Hierarchical Group Matrix Factorization for Collaborative Recommendation,"Wang, Xin and Pan, Weike and Xu, Congfu",inproceedings,10.1145/2661829.2662021,
10.1145/2661829.2662055,10.1145/2661829.2662055,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","autoregressive models, online serials, popularity prediction",10,1339–1348,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"Recent years have witnessed the rapid prevalence of online serials, which play an important role in our daily entertainment. A critical demand along this line is to predict the popularity of online serials, which can enable a wide range of applications, such as online advertising, and serial recommendation. However, compared with traditional online media such as user-generated content (UGC), online serials have unique characteristics of sequence dependence, release date dependence as well as unsynchronized update regularity. Therefore, the popularity prediction for online serials is a nontrivial task and still under-addressed. To this end, in this paper we present a comprehensive study for predicting the popularity of online serials with autoregressive models. Specifically, we first introduce a straightforward yet effective Naive Autoregressive (NAR) model based on the correlations of serial episodes. Furthermore, we develop a sophisticated model, namely Transfer Autoregressive (TAR) model, to capture the dynamic behaviors of audiences, which can achieve better prediction performance than the NAR model. Indeed, the two models can reveal the popularity generation from different perspectives. In addition, as a derivative of the TAR model, we also design a novel metric, namely favor, for evaluating the quality of online serials. Finally, extensive experiments on two real-world data sets clearly show that both models are effective and outperform baselines in terms of the popularity prediction for online serials. And the new metric performs better than other metrics for quality estimation.",10.1145/2661829.2662055,https://doi.org/10.1145/2661829.2662055,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Predicting the Popularity of Online Serials with Autoregressive Models,"Chang, Biao and Zhu, Hengshu and Ge, Yong and Chen, Enhong and Xiong, Hui and Tan, Chang",inproceedings,10.1145/2661829.2662055,
10.1145/2661829.2662059,10.1145/2661829.2662059,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","co-clustering, collaborative filtering, item group, topic model, user community",10,251–260,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"Most collaborative filtering (CF) algorithms only make use of the rating scores given by users for items. However, it is often the case that each rating score is associated with a piece of review text. Such review texts, which are capable of providing us valuable information to reveal the reasons why users give a certain rating, have not been exploited and they are usually ignored by most CF algorithms. Moreover, the underlying relationship buried in users and items has not been fully exploited. Items we would recommend can often be characterized into hidden groups (e.g. comedy, horror movie and action movie), and users can also be organized as hidden communities. We propose a new generative model to predict user's ratings on previously unrated items by considering review texts as well as hidden user communities and item groups relationship. Regarding the rating scores, traditional algorithms would not perform well on uncovering the community and group information of each user and each item since the user-item rating matrix is dyadic involving the mutual interactions between users and items. Instead, co-clustering, which is capable of conducting simultaneous clustering of two variables, is able to take advantage of such user-item relationships to better predict the rating scores. Additionally, co-clustering would be more effective for modeling the generation of review texts since different user communities would discuss different topics and vary their own wordings or expression patterns when dealing with different item groups. Besides, by modeling as a mixed membership over community and group respectively, each user or item can belong to multiple communities or groups with varying degrees. We have conducted extensive experiments to predict the missing rating scores on 22 real word datasets. The experimental results demonstrate the superior performance of our proposed model comparing with the state-of-the-art methods.",10.1145/2661829.2662059,https://doi.org/10.1145/2661829.2662059,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Collaborative Filtering Incorporating Review Text and Co-clusters of Hidden User Communities and Item Groups,"Xu, Yinqing and Lam, Wai and Lin, Tianyi",inproceedings,10.1145/2661829.2662059,
10.1145/2661829.2662062,10.1145/2661829.2662062,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","aspect mining, sparse coding, topic model",10,879–888,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"We investigate latent aspect mining problem that aims at automatically discovering aspect information from a collection of review texts in a domain in an unsupervised manner. One goal is to discover a set of aspects which are previously unknown for the domain, and predict the user's ratings on each aspect for each review. Another goal is to detect key terms for each aspect. Existing works on predicting aspect ratings fail to handle the aspect sparsity problem in the review texts leading to unreliable prediction. We propose a new generative model to tackle the latent aspect mining problem in an unsupervised manner. By considering the user and item side information of review texts, we introduce two latent variables, namely, user intrinsic aspect interest and item intrinsic aspect quality facilitating better modeling of aspect generation leading to improvement on the accuracy and reliability of predicted aspect ratings. Furthermore, we provide an analytical investigation on the Maximum A Posterior (MAP) optimization problem used in our proposed model and develop a new block coordinate gradient descent algorithm to efficiently solve the optimization with closed-form updating formulas. We also study its convergence analysis. Experimental results on the two real-world product review corpora demonstrate that our proposed model outperforms existing state-of-the-art models.",10.1145/2661829.2662062,https://doi.org/10.1145/2661829.2662062,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,Latent Aspect Mining via Exploring Sparsity and Intrinsic Information,"Xu, Yinqing and Lin, Tianyi and Lam, Wai and Zhou, Zirui and Cheng, Hong and So, Anthony Man-Cho",inproceedings,10.1145/2661829.2662062,
10.1145/2661829.2662070,10.1145/2661829.2662070,CIKM.bib,1,['CIKM.bib'],8,CIKM '14,"Shanghai, China","collaborative filtering, context-aware recommendation, latent factor models, learning representations",10,291–300,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,"Rich contextual information is typically available in many recommendation domains allowing recommender systems to model the subtle effects of context on preferences. Most contextual models assume that the context shares the same latent space with the users and items. In this work we propose CARS2, a novel approach for learning context-aware representations for context-aware recommendations. We show that the context-aware representations can be learned using an appropriate model that aims to represent the type of interactions between context variables, users and items. We adapt the CARS2 algorithms to explicit feedback data by using a quadratic loss function for rating prediction, and to implicit feedback data by using a pairwise and a listwise ranking loss functions for top-N recommendations. By using stochastic gradient descent for parameter estimation we ensure scalability. Experimental evaluation shows that our CARS2 models achieve competitive recommendation performance, compared to several state-of-the-art approaches.",10.1145/2661829.2662070,https://doi.org/10.1145/2661829.2662070,"New York, NY, USA",Association for Computing Machinery,9781450325981,2014,CARS2: Learning Context-aware Representations for Context-aware Recommendations,"Shi, Yue and Karatzoglou, Alexandros and Baltrunas, Linas and Larson, Martha and Hanjalic, Alan",inproceedings,10.1145/2661829.2662070,
10.1145/2665994.2665995,10.1145/2665994.2665995,CIKM.bib,1,['CIKM.bib'],8,DUBMOD '14,"Shanghai, China","user activity, recommendation system, collaborative filtering",4,7–10,Proceedings of the 3rd Workshop on Data-Driven User Behavioral Modeling and Mining from Social Media,"Collaborative filtering (CF), which plays an important role in making personalized recommendation, is one of the most traditional and effective recommendation algorithms. However, there are several factors that impact its recommendation accuracy, e.g., the sparse matrix problem. In the past studies, most researchers merely focused on user ratings to model user profile but ignored the implying patterns. In this paper, we utilize user activity to discriminate user rating patterns and propose a new method of user-based collaborative filtering based on user activity level. Experimental results on movie-lens data-set has proved that the algorithm we proposed improves recommendation accuracy significantly compared with traditional user-based CF algorithm with respect to various evaluation metrics.",10.1145/2665994.2665995,https://doi.org/10.1145/2665994.2665995,"New York, NY, USA",Association for Computing Machinery,9781450313032,2014,An Improved Collaborative Filtering Algorithm Combining User Activity Level,"Fan, Jiaqi and Jiang, Lisi and Pan, Weimin",inproceedings,10.1145/2665994.2665995,
10.1145/2668067.2668069,10.1145/2668067.2668069,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '14,"Foster City, CA, USA","Twitter, Tweet Recommendation, Personalization, Collaborative Ranking",4,19–22,Proceedings of the 2014 Recommender Systems Challenge,In this paper we describe our approach to solve RecSys Challenge 2014. The challenge is to rank user's auto generated IMDB rating tweets by their favorited and shared count. Our approach is to formulate this as a ranking problem. We treat a single user as a query and all of the known tweets are treated as matching documents. We then apply various learning to rank approaches and pick the best performing.,10.1145/2668067.2668069,https://doi.org/10.1145/2668067.2668069,"New York, NY, USA",Association for Computing Machinery,9781450331883,2014,Ranking approach to RecSys Challenge,"Singh, Pallavi and Singh, Gyanit and Bhardwaj, Anurag",inproceedings,10.1145/2668067.2668069,
10.1145/2668067.2668072,10.1145/2668067.2668072,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '14,"Foster City, CA, USA","Learning to Rank, Recommender Systems, Twitter, User Engagement",6,41–46,Proceedings of the 2014 Recommender Systems Challenge,"Collaborative Filtering (CF) is a core component of popular web-based services such as Amazon, YouTube, Netflix, and Twitter. Most applications use CF to recommend a small set of items to the user. For instance, YouTube presents to a user a list of top-n videos she would likely watch next based on her rating and viewing history. Current methods of CF evaluation have been focused on assessing the quality of a predicted rating or the ranking performance for top-n recommended items. However, restricting the recommender system evaluation to these two aspects is rather limiting and neglects other dimensions that could better characterize a well-perceived recommendation. In this paper, instead of optimizing rating or top-n recommendation, we focus on the task of predicting which items generate the highest user engagement. In particular, we use Twitter as our testbed and cast the problem as a Collaborative Ranking task where the rich features extracted from the metadata of the tweets help to complement the transaction information limited to user ids, item ids, ratings and timestamps. We learn a scoring function that directly optimizes the user engagement in terms of nDCG@10 on the predicted ranking. Experiments conducted on an extended version of the MovieTweetings dataset, released as part of the RecSys Challenge 2014, show the effectiveness of our approach.",10.1145/2668067.2668072,https://doi.org/10.1145/2668067.2668072,"New York, NY, USA",Association for Computing Machinery,9781450331883,2014,Predicting User Engagement in Twitter with Collaborative Ranking,"Diaz-Aviles, Ernesto and Lam, Hoang Thanh and Pinelli, Fabio and Braghin, Stefano and Gkoufas, Yiannis and Berlingerio, Michele and Calabrese, Francesco",inproceedings,10.1145/2668067.2668072,
10.1145/2668067.2668075,10.1145/2668067.2668075,RecSys.bib,1,['RecSys.bib'],7,RecSysChallenge '14,"Foster City, CA, USA",,5,47–51,Proceedings of the 2014 Recommender Systems Challenge,"While much recommender system research has been driven by the rating prediction task, there is an emphasis in recent research on exploring new methods to evaluate the effectiveness of a recommendation. The Recommender Systems Challenge 2014 takes up this theme by challenging researchers to explore engagement as an evaluation criterion. In this paper we discuss how predicting engagement differs from the traditional rating prediction task and motivate the rationale behind our approach to the challenge. We show that standard matrix factorization recommender algorithms do not perform well on the task. Our solution depends on clustering items according to their time-dependent profile to distinguish topical movies from other movies. Our prediction engine also exploits the observation that extreme ratings are more likely to attract engagement.",10.1145/2668067.2668075,https://doi.org/10.1145/2668067.2668075,"New York, NY, USA",Association for Computing Machinery,9781450331883,2014,Exploring Tweet Engagement in the RecSys 2014 Data Challenge,"Wasilewski, Jacek and Hurley, Neil",inproceedings,10.1145/2668067.2668075,
10.1145/2668067.2668077,10.1145/2668067.2668077,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '14,"Foster City, CA, USA","User engagement, Twitter, Ranking aggregation",6,29–34,Proceedings of the 2014 Recommender Systems Challenge,"User engagement refers to the amount of interaction an instance (e.g., tweet, news, and forum post) achieves. Ranking the items in social media websites based on the amount of user participation in them, can be used in different applications, such as recommender systems. In this paper, we consider a tweet containing a rating for a movie as an instance and focus on ranking the instances of each user based on their engagement, i.e., the total number of retweets and favorites it will gain.For this task, we define several features which can be extracted from the meta-data of each tweet. The features are partitioned into three categories: user-based, movie-based, and tweet-based. We show that in order to obtain good results, features from all categories should be considered. We exploit regression and learning to rank methods to rank the tweets and propose to aggregate the results of regression and learning to rank methods to achieve better performance.We have run our experiments on an extended version of MovieTweeting dataset provided by ACM RecSys Challenge 2014. The results show that learning to rank approach outperforms most of the regression models and the combination can improve the performance significantly.",10.1145/2668067.2668077,https://doi.org/10.1145/2668067.2668077,"New York, NY, USA",Association for Computing Machinery,9781450331883,2014,Regression and Learning to Rank Aggregation for User Engagement Evaluation,"Zamani, Hamed and Shakery, Azadeh and Moradi, Pooya",inproceedings,10.1145/2668067.2668077,
10.1145/2668067.2668080,10.1145/2668067.2668080,RecSys.bib,1,['RecSys.bib'],7,RecSysChallenge '14,"Foster City, CA, USA",,4,66–69,Proceedings of the 2014 Recommender Systems Challenge,"Evaluation is a key factor to reflect the quality of a recommender system algorithm. Traditional recommenders pose the problem as an optimization task where they seek to minimize the error in predicted rating for an item or predicted top-n items of interest with respect a user. However, these predictions do not often translate to a well-perceived recommendation. In this work, instead of the typical rating prediction task, we predict the amount of interaction an item would receive through a social network. In particular, we propose a simple and efficient model to generate a ranked list of tweets of a user in the order of expected user interaction that they would receive on Twitter, which is expressed in terms of retweets and favorites. We evaluate our proposed model on an extended version of the MovieTweetings dataset, which contains tweets that are generated when users rate movies on IMDb (using the IMDb iOS app), and show that the proposed model performs better compared to the baselines.",10.1145/2668067.2668080,https://doi.org/10.1145/2668067.2668080,"New York, NY, USA",Association for Computing Machinery,9781450331883,2014,How popular are your tweets?,"Saha, Avijit and Rajendran, Janarthanan and Shekhar, Shubhranshu and Ravindran, Balaraman",inproceedings,10.1145/2668067.2668080,
10.1145/2668067.2668081,10.1145/2668067.2668081,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '14,"Foster City, CA, USA","Social Media Mining, Learning to Rank, Classification",6,35–40,Proceedings of the 2014 Recommender Systems Challenge,"In this paper, we describe our solution to the RecSys2014 challenge and results on the test set. We briefly describe some of the challenges, then describe the methodology which starts with feature extraction and construction using the provided tweet data, in combination with IMDB as an external source. Feature construction also involved computing similarity values in a latent factor space to deal with the sparsity and lack of semantics of text-based and other nominal features. We also describe our machine learning models which consist of several stages, including a classifier, followed by a Learning to Rank (LTR) model, with a repairing mechanism to further correct minority class (non-zero engagement) predictions that are close to the boundary. Finally, we draw conclusions in the form of lessons learned and future work toward improving our results.",10.1145/2668067.2668081,https://doi.org/10.1145/2668067.2668081,"New York, NY, USA",Association for Computing Machinery,9781450331883,2014,A Two Step Ranking Solution for Twitter User Engagement,"Abdollahi, Behnoush and Badami, Mahsa and Nutakki, Gopi Chand and Sun, Wenlong and Nasraoui, Olfa",inproceedings,10.1145/2668067.2668081,
10.1145/2684822.2685291,10.1145/2684822.2685291,WSDM.bib,1,['WSDM.bib'],8,WSDM '15,"Shanghai, China","collaborative filtering, opinion mining, text mining",10,199–208,Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,"Aspect-based opinion mining from online reviews has attracted a lot of attention recently. Given a set of reviews, the main task of aspect-based opinion mining is to extract major aspects of the items and to infer the latent aspect ratings from each review. However, users may have different preferences which might lead to different opinions on the same aspect of an item. Even if fine-grained aspect rating analysis is provided for each review, it is still difficult for a user to judge whether a specific aspect of an item meets his own expectation. In this paper, we study the problem of estimating personalized sentiment polarities on different aspects of the items. We propose a unified probabilistic model called Factorized Latent Aspect ModEl (FLAME), which combines the advantages of collaborative filtering and aspect based opinion mining. FLAME learns users' personalized preferences on different aspects from their past reviews, and predicts users' aspect ratings on new items by collective intelligence. Experiments on two online review datasets show that FLAME outperforms state-of-the-art methods on the tasks of aspect identification and aspect rating prediction.",10.1145/2684822.2685291,https://doi.org/10.1145/2684822.2685291,"New York, NY, USA",Association for Computing Machinery,9781450333177,2015,FLAME: A Probabilistic Model Combining Aspect Based Opinion Mining and Collaborative Filtering,"Wu, Yao and Ester, Martin",inproceedings,10.1145/2684822.2685291,
10.1145/2684822.2685303,10.1145/2684822.2685303,WSDM.bib,1,['WSDM.bib'],8,WSDM '15,"Shanghai, China","microblogging platforms, popularity prediction, reinforced poisson process, retweeting dynamics",10,107–116,Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,"Popularity prediction on microblogging platforms aims to predict the future popularity of a message based on its retweeting dynamics in the early stages. Existing works mainly focus on exploring effective features for prediction, while ignoring the underlying arrival process of retweets. Also, the effect of user activity variation on the retweeting dynamics in the early stages has been neglected. In this paper, we propose an extended reinforced Poisson process model with time mapping process to model the retweeting dynamics and predict the future popularity. The proposed model explicitly characterizes the process through which a message gain its retweets, by capturing a power-law temporal relaxation function corresponding to the aging in the ability of the message to attract new retweets and an exponential reinforcement mechanism characterizing the ""richer-get-richer"" phenomenon. Further, we introduce the notation of weibo time and integrate a time mapping process into the proposed model to eliminate the effect of user activity variation. Extensive experiments on two Weibo datasets, with 10K and 18K messages respectively, well demonstrate the effectiveness of our proposed model in popularity prediction.",10.1145/2684822.2685303,https://doi.org/10.1145/2684822.2685303,"New York, NY, USA",Association for Computing Machinery,9781450333177,2015,Modeling and Predicting Retweeting Dynamics on Microblogging Platforms,"Gao, Shuai and Ma, Jun and Chen, Zhumin",inproceedings,10.1145/2684822.2685303,
10.1145/2684822.2685314,10.1145/2684822.2685314,WSDM.bib,1,['WSDM.bib'],8,WSDM '15,"Shanghai, China","citation prediction, popularity prediction, science of science, scientific impact",10,149–158,Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,"Scientific impact plays a central role in the evaluation of the output of scholars, departments, and institutions. A widely used measure of scientific impact is citations, with a growing body of literature focused on predicting the number of citations obtained by any given publication. The effectiveness of such predictions, however, is fundamentally limited by the power-law distribution of citations, whereby publications with few citations are extremely common and publications with many citations are relatively rare. Given this limitation, in this work we instead address a related question asked by many academic researchers in the course of writing a paper, namely: ""Will this paper increase my h-index?"" Using a real academic dataset with over 1.7 million authors, 2 million papers, and 8 million citation relationships from the premier online academic service ArnetMiner, we formalize a novel scientific impact prediction problem to examine several factors that can drive a paper to increase the primary author's h-index. We find that the researcher's authority on the publication topic and the venue in which the paper is published are crucial factors to the increase of the primary author's h-index, while the topic popularity and the co-authors' h-indices are of surprisingly little relevance. By leveraging relevant factors, we find a greater than 87.5% potential predictability for whether a paper will contribute to an author's h-index within five years. As a further experiment, we generate a self-prediction for this paper, estimating that there is a 76% probability that it will contribute to the h-index of the co-author with the highest current h-index in five years. We conclude that our findings on the quantification of scientific impact can help researchers to expand their influence and more effectively leverage their position of ""standing on the shoulders of giants.""",10.1145/2684822.2685314,https://doi.org/10.1145/2684822.2685314,"New York, NY, USA",Association for Computing Machinery,9781450333177,2015,Will This Paper Increase Your h-index? Scientific Impact Prediction,"Dong, Yuxiao and Johnson, Reid A. and Chawla, Nitesh V.",inproceedings,10.1145/2684822.2685314,
10.1145/2684822.2697033,10.1145/2684822.2697033,WSDM.bib,1,['WSDM.bib'],8,WSDM '15,"Shanghai, China","collaborative filtering, personalized recommendation, sentiment analysis, text mining",6,435–440,Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,"Previous research on Recommender Systems (RS), especially the continuously popular approach of Collaborative Filtering (CF), has been mostly focusing on the information resource of explicit user numerical ratings or implicit (still numerical) feedbacks. However, the ever-growing availability of textual user reviews has become an important information resource, where a wealth of explicit product attributes/features and user attitudes/sentiments are expressed therein. This information rich resource of textual reviews have clearly exhibited brand-new approaches to solving many of the important problems that have been perplexing the research community for years, such as the paradox of cold-start, the explanation of recommendation, and the automatic generation of user or item profiles. However, it is only recently that the fundamental importance of textual reviews has gained wide recognition, perhaps mainly because of the difficulty in formatting, structuring and analyzing the free-texts. In this research, we stress the importance of incorporating textual reviews for recommendation through phrase-level sentiment analysis, and further investigate the role that the texts play in various important recommendation tasks.",10.1145/2684822.2697033,https://doi.org/10.1145/2684822.2697033,"New York, NY, USA",Association for Computing Machinery,9781450333177,2015,Incorporating Phrase-level Sentiment Analysis on Textual Reviews for Personalized Recommendation,"Zhang, Yongfeng",inproceedings,10.1145/2684822.2697033,
10.1145/2736277.2741087,10.1145/2736277.2741087,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15,"Florence, Italy","time series analysis, sentiment analysis, recommender systems, collaborative filtering",11,1373–1383,Proceedings of the 24th International Conference on World Wide Web,"The frequently changing user preferences and/or item profiles have put essential importance on the dynamic modeling of users and items in personalized recommender systems. However, due to the insufficiency of per user/item records when splitting the already sparse data across time dimension, previous methods have to restrict the drifting purchasing patterns to pre-assumed distributions, and were hardly able to model them rather directly with, for example, time series analysis. Integrating content information helps to alleviate the problem in practical systems, but the domain-dependent content knowledge is expensive to obtain due to the large amount of manual efforts.In this paper, we make use of the large volume of textual reviews for the automatic extraction of domain knowledge, namely, the explicit features/aspects in a specific product domain. We thus degrade the product-level modeling of user preferences, which suffers from the lack of data, to the feature-level modeling, which not only grants us the ability to predict user preferences through direct time series analysis, but also allows us to know the essence under the surface of product-level changes in purchasing patterns. Besides, the expanded feature space also helps to make cold-start recommendations for users with few purchasing records.Technically, we develop the Fourier-assisted Auto-Regressive Integrated Moving Average (FARIMA) process to tackle with the year-long seasonal period of purchasing data to achieve daily-aware preference predictions, and we leverage the conditional opportunity models for daily-aware personalized recommendation. Extensive experimental results on real-world cosmetic purchasing data from a major e-commerce website (JD.com) in China verified both the effectiveness and efficiency of our approach.",10.1145/2736277.2741087,https://doi.org/10.1145/2736277.2741087,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450334693,2015,Daily-Aware Personalized Recommendation based on Feature-Level Time Series Analysis,"Zhang, Yongfeng and Zhang, Min and Zhang, Yi and Lai, Guokun and Liu, Yiqun and Zhang, Honghui and Ma, Shaoping",inproceedings,10.1145/2736277.2741087,
10.1145/2736277.2741092,10.1145/2736277.2741092,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15,"Florence, Italy","time-series, parameter-free, non-linear, ecosystem",11,721–731,Proceedings of the 24th International Conference on World Wide Web,"Given a large collection of co-evolving online activities, such as searches for the keywords ""Xbox"", ""PlayStation"" and ""Wii"", how can we find patterns and rules? Are these keywords related? If so, are they competing against each other? Can we forecast the volume of user activity for the coming month? We conjecture that online activities compete for user attention in the same way that species in an ecosystem compete for food. We present ECOWEB, (i.e., Ecosystem on the Web), which is an intuitive model designed as a non-linear dynamical system for mining large-scale co-evolving online activities. Our second contribution is a novel, parameter-free, and scalable fitting algorithm, ECOWEB-FIT, that estimates the parameters of ECOWEB. Extensive experiments on real data show that ECOWEB is effective, in that it can capture long-range dynamics and meaningful patterns such as seasonalities, and practical, in that it can provide accurate long-range forecasts. ECOWEB consistently outperforms existing methods in terms of both accuracy and execution speed.",10.1145/2736277.2741092,https://doi.org/10.1145/2736277.2741092,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450334693,2015,The Web as a Jungle: Non-Linear Dynamical Systems for Co-evolving Online Activities,"Matsubara, Yasuko and Sakurai, Yasushi and Faloutsos, Christos",inproceedings,10.1145/2736277.2741092,
10.1145/2736277.2741109,10.1145/2736277.2741109,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15,"Florence, Italy","optimal design, item cold-start, collaborative filtering",10,45–54,Proceedings of the 24th International Conference on World Wide Web,"It is well known that collaborative filtering (CF) based recommender systems provide better modeling of users and items associated with considerable rating history. The lack of historical ratings results in the user and the item cold-start problems. The latter is the main focus of this work. Most of the current literature addresses this problem by integrating content-based recommendation techniques to model the new item. However, in many cases such content is not available, and the question arises is whether this problem can be mitigated using CF techniques only. We formalize this problem as an optimization problem: given a new item, a pool of available users, and a budget constraint, select which users to assign with the task of rating the new item in order to minimize the prediction error of our model. We show that the objective function is monotone-supermodular, and propose efficient optimal design based algorithms that attain an approximation to its optimum. Our findings are verified by an empirical study using the Netflix dataset, where the proposed algorithms outperform several baselines for the problem at hand.",10.1145/2736277.2741109,https://doi.org/10.1145/2736277.2741109,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450334693,2015,Budget-Constrained Item Cold-Start Handling in Collaborative Filtering Recommenders via Optimal Design,"Anava, Oren and Golan, Shahar and Golbandi, Nadav and Karnin, Zohar and Lempel, Ronny and Rokhlenko, Oleg and Somekh, Oren",inproceedings,10.1145/2736277.2741109,
10.1145/2736277.2741116,10.1145/2736277.2741116,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15,"Florence, Italy","user engagement, sensitivity, quality metrics, online controlled experiment, engagement prediction",11,256–266,Proceedings of the 24th International Conference on World Wide Web,"Modern Internet companies improve their services by means of data-driven decisions that are based on online controlled experiments (also known as A/B tests). To run more online controlled experiments and to get statistically significant results faster are the emerging needs for these companies. The main way to achieve these goals is to improve the sensitivity of A/B experiments. We propose a novel approach to improve the sensitivity of user engagement metrics (that are widely used in A/B tests) by utilizing prediction of the future behavior of an individual user. This problem of prediction of the exact value of a user engagement metric is also novel and is studied in our work. We demonstrate the effectiveness of our sensitivity improvement approach on several real online experiments run at Yandex. Especially, we show how it can be used to detect the treatment effect of an A/B test faster with the same level of statistical significance.",10.1145/2736277.2741116,https://doi.org/10.1145/2736277.2741116,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450334693,2015,Future User Engagement Prediction and Its Application to Improve the Sensitivity of Online Experiments,"Drutsa, Alexey and Gusev, Gleb and Serdyukov, Pavel",inproceedings,10.1145/2736277.2741116,
10.1145/2736277.2741122,10.1145/2736277.2741122,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15,"Florence, Italy","sampling, differential privacy, data analytics",11,311–321,Proceedings of the 24th International Conference on World Wide Web,"The availability of an increasing amount of user generated data is transformative to our society. We enjoy the benefits of analyzing big data for public interest, such as disease outbreak detection and traffic control, as well as for commercial interests, such as smart grid and product recommendation. However, the large collection of user generated data contains unique patterns and can be used to re-identify individuals, which has been exemplified by the AOL search log release incident. In this paper, we propose a practical framework for data analytics, while providing differential privacy guarantees to individual data contributors. Our framework generates differentially private aggregates which can be used to perform data mining and recommendation tasks. To alleviate the high perturbation errors introduced by the differential privacy mechanism, we present two methods with different sampling techniques to draw a subset of individual data for analysis. Empirical studies with real-world data sets show that our solutions enable accurate data analytics on a small fraction of the input data, reducing user privacy risk and data storage requirement without compromising the analysis results.",10.1145/2736277.2741122,https://doi.org/10.1145/2736277.2741122,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450334693,2015,A Practical Framework for Privacy-Preserving Data Analytics,"Fan, Liyue and Jin, Hongxia",inproceedings,10.1145/2736277.2741122,
10.1145/2736277.2741678,10.1145/2736277.2741678,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15,"Florence, Italy","recommender systems, infinite push, collaborative ranking",11,205–215,Proceedings of the 24th International Conference on World Wide Web,"The goal of collaborative filtering is to get accurate recommendations at the top of the list for a set of users. From such a perspective, collaborative ranking based formulations with suitable ranking loss functions are natural. While recent literature has explored the idea based on objective functions such as NDCG or Average Precision, such objectives are difficult to optimize directly. In this paper, building on recent advances from the learning to rank literature, we introduce a novel family of collaborative ranking algorithms which focus on accuracy at the top of the list for each user while learning the ranking functions collaboratively. We consider three specific formulations, based on collaborative p-norm push, infinite push, and reverse-height push, and propose efficient optimization methods for learning these models. Experimental results illustrate the value of collaborative ranking, and show that the proposed methods are competitive, usually better than existing popular approaches to personalized recommendation.",10.1145/2736277.2741678,https://doi.org/10.1145/2736277.2741678,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450334693,2015,Collaborative Ranking with a Push at the Top,"Christakopoulou, Konstantina and Banerjee, Arindam",inproceedings,10.1145/2736277.2741678,
10.1145/2740908.2741694,10.1145/2740908.2741694,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15 Companion,"Florence, Italy","machine-generated email, email arrival prediction, causal relations",6,1327–1332,Proceedings of the 24th International Conference on World Wide Web,"The majority of Web email is known to be generated by machines even when one excludes spam. Many machine-generated email messages such as invoices or travel itineraries are critical to users. Recent research studies establish that causality relations between certain types of machine-generated email messages exist and can be mined. These relations exhibit a link between a given message to a past message that gave rise to its creation. For example, a shipment notification message can often be linked to a past online purchase message. Instead of studying how an incoming message can be linked to the past, we propose here to focus on predicting future email arrival as implied by causality relations. Such a prediction method has several potential applications, ranging from improved ad targeting in up sell scenarios to reducing false positives in spam detection.We introduce a novel approach for predicting which types of machine-generated email messages, represented by so-called ""email templates"", a user should receive in future time windows. Our prediction approach relies on (1) statistically inferring causality relations between email templates, (2) building a generative model that explains the inbox of each user using those causality relations, and (3) combining those results to predict which email templates are likely to appear in future time frames. We present preliminary experimental results and some data insights obtained by analyzing several million inboxes of Yahoo Mail users, who voluntarily opted-in for such research.",10.1145/2740908.2741694,https://doi.org/10.1145/2740908.2741694,"New York, NY, USA",Association for Computing Machinery,9781450334730,2015,You Will Get Mail!Predicting the Arrival of Future Email,"Gamzu, Iftah and Karnin, Zohar and Maarek, Yoelle and Wajc, David",inproceedings,10.1145/2740908.2741694,
10.1145/2740908.2741698,10.1145/2740908.2741698,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15 Companion,"Florence, Italy","temporal query classification, query intent, events",6,1339–1344,Proceedings of the 24th International Conference on World Wide Web,"In many cases, a user turns to search engines to find information about real-world situations, namely, political elections, sport competitions, or natural disasters. Such temporal querying behavior can be observed through a significant number of event-related queries generated in web search. In this paper, we study the task of detecting event-related queries, which is the first step for understanding temporal query intent and enabling different temporal search applications, e.g., time-aware query auto-completion, temporal ranking, and result diversification. We propose a two-step approach to detecting events from query logs. We first identify a set of event candidates by considering both implicit and explicit temporal information needs. The next step further classifies the candidates into two main categories, namely, event or non-event. In more detail, we leverage different machine learning techniques for query classification, which are trained using the feature set composed of time series features from signal processing, along with features derived from click-through information, and standard statistical features. In order to evaluate our proposed approach, we conduct an experiment using two real-world query logs with manually annotated relevance assessments for 837 events. To this end, we provide a large set of event-related queries made available for fostering research on this challenging task.",10.1145/2740908.2741698,https://doi.org/10.1145/2740908.2741698,"New York, NY, USA",Association for Computing Machinery,9781450334730,2015,Learning to Detect Event-Related Queries for Web Search,"Kanhabua, Nattiya and Ngoc Nguyen, Tu and Nejdl, Wolfgang",inproceedings,10.1145/2740908.2741698,
10.1145/2740908.2742140,10.1145/2740908.2742140,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15 Companion,"Florence, Italy","neighbor selection, diversity, coverage, collaborative filtering systems",6,1463–1468,Proceedings of the 24th International Conference on World Wide Web,"Since the first introduced Collaborative Filtering Recommenders (CFR) there have been many attempts to improve their performance by enhancing the prediction accuracy. Even though rating prediction is the prevailing paradigm in CFR, there are other issues which have gained significant attention with respect to the content and its variety. Coverage, which constitutes the degree to which recommendations cover the set of available items, is an important factor along with diversity of the items proposed to an individual, often measured by an average dissimilarity between all pairs of recommended items. In this paper, we argue that coverage and diversity cannot be effectively addressed by conventional CFR with pure similarity-based neighborhood creation processes, especially in sparse datasets. Motivated by the need for including wider content characteristics, we propose a novel neighbor selection technique which emphasizes on variety in preferences (to cover polyphony in selection). Our approach consists of a new metric, named ""Exploriometer"", which acts as a personality trait for users based on their rating behavior. We favor users who are explorers in order to increase polyphony, and subsequently coverage and diversity; but we still select similar users when we create neighborhoods as a solid basis in order to keep accuracy levels high. The proposed approach has been experimented by two real-world datasets (MovieLens and Yahoo! Music ) with coverage, diversity and accuracy aware recommendations extracted by both traditional CFR and CFR enhanced with our neighborhood creation process. We also introduce a new metric, inspired by the Pearson Correlation Coefficient, to estimate the diversity of recommended items. The derived results demonstrate that our neighbor selection technique can enhance coverage and diversity of the recommendations, especially on sparse datasets.",10.1145/2740908.2742140,https://doi.org/10.1145/2740908.2742140,"New York, NY, USA",Association for Computing Machinery,9781450334730,2015,Exploriometer: Leveraging Personality Traits for Coverage and Diversity Aware Recommendations,"Chatzicharalampous, Evangelos and Christos, Zigkolis and Vakali, Athena",inproceedings,10.1145/2740908.2742140,
10.1145/2740908.2742566,10.1145/2740908.2742566,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15 Companion,"Florence, Italy","response prediction, online advertising, metrics, auction",4,919–922,Proceedings of the 24th International Conference on World Wide Web,Click-through rates and conversion rates are two core machine learning problems in online advertising. The evaluation of such systems is often based on traditional supervised learning metrics that ignore how the predictions are used. These predictions are in fact part of bidding systems in online advertising auctions. We present here an empirical evaluation of a metric that is specifically tailored for auctions in online advertising and show that it correlates better than standard metrics with A/B test results.,10.1145/2740908.2742566,https://doi.org/10.1145/2740908.2742566,"New York, NY, USA",Association for Computing Machinery,9781450334730,2015,Offline Evaluation of Response Prediction in Online Advertising Auctions,"Chapelle, Olivier",inproceedings,10.1145/2740908.2742566,
10.1145/2740908.2742711,10.1145/2740908.2742711,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15 Companion,"Florence, Italy","recommendation, multiple domains, heterogeneity",2,95–96,Proceedings of the 24th International Conference on World Wide Web,"To address the recommendation problems in the scenarios of multiple domains, in this paper, we propose a novel method, HMRec, which models both consistency and heterogeneity of users' multiple behaviors in a unified framework. Moreover, the decisive factors of each domain can also be captured by our approach successfully. Experiments on the real multi-domain dataset demonstrate the effectiveness of our model.",10.1145/2740908.2742711,https://doi.org/10.1145/2740908.2742711,"New York, NY, USA",Association for Computing Machinery,9781450334730,2015,Exploring Heterogeneity for Multi-Domain Recommendation with Decisive Factors Selection,"Qiu, Shuang and Cheng, Jian and Zhang, Xi and Lu, Hanqing",inproceedings,10.1145/2740908.2742711,
10.1145/2740908.2742726,10.1145/2740908.2742726,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15 Companion,"Florence, Italy","recommender systems, collaborative filtering, autoencoders",2,111–112,Proceedings of the 24th International Conference on World Wide Web,"This paper proposes AutoRec, a novel autoencoder framework for collaborative filtering (CF). Empirically, AutoRec's compact and efficiently trainable model outperforms state-of-the-art CF techniques (biased matrix factorization, RBM-CF and LLORMA) on the Movielens and Netflix datasets.",10.1145/2740908.2742726,https://doi.org/10.1145/2740908.2742726,"New York, NY, USA",Association for Computing Machinery,9781450334730,2015,AutoRec: Autoencoders Meet Collaborative Filtering,"Sedhain, Suvash and Menon, Aditya Krishna and Sanner, Scott and Xie, Lexing",inproceedings,10.1145/2740908.2742726,
10.1145/2740908.2742744,10.1145/2740908.2742744,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15 Companion,"Florence, Italy","popularity prediction, popularity dynamics, microblogs",2,9–10,Proceedings of the 24th International Conference on World Wide Web,"The ability to model and predict the popularity dynamics of individual user generated items on online media has important implications in a wide range of areas. In this paper, we propose a probabilistic model using a Self-Excited Hawkes Process (SEHP) to characterize the process through which individual microblogs gain their popularity. This model explicitly captures the triggering effect of each forwarding, distinguishing itself from the reinforced Poisson process based model where all previous forwardings are simply aggregated as a single triggering effect. We validate the proposed model by applying it on Sina Weibo, the most popular microblogging network in China. Experimental results demonstrate that the SEHP model consistently outperforms the model based on reinforced Poisson process.",10.1145/2740908.2742744,https://doi.org/10.1145/2740908.2742744,"New York, NY, USA",Association for Computing Machinery,9781450334730,2015,Modeling and Predicting Popularity Dynamics of Microblogs using Self-Excited Hawkes Processes,"Bao, Peng and Shen, Hua-Wei and Jin, Xiaolong and Cheng, Xue-Qi",inproceedings,10.1145/2740908.2742744,
10.1145/2740908.2742825,10.1145/2740908.2742825,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '15 Companion,"Florence, Italy","web browsing, random projection, latent semantic analysis, information retrieval, content-based filter, big data",4,251–254,Proceedings of the 24th International Conference on World Wide Web,"The Internet is overloading its users with excessive information flows, so that effective content-based filtering becomes crucial in improving user experience and work efficiency. We build Kvasir, a semantic recommendation system, atop latent semantic analysis and other state-of-art technologies to seamlessly integrate an automated and proactive content provision service into web browsing. We utilize the power of Apache Spark to scale up Kvasir to a practical Internet service. Herein we present the architecture of Kvasir, along with our solutions to the technical challenges in the actual system implementation.",10.1145/2740908.2742825,https://doi.org/10.1145/2740908.2742825,"New York, NY, USA",Association for Computing Machinery,9781450334730,2015,Kvasir: Seamless Integration of Latent Semantic Analysis-Based Content Provision into Web Browsing,"Wang, Liang and Tasoulis, Sotiris and Roos, Teemu and Kangasharju, Jussi",inproceedings,10.1145/2740908.2742825,
10.1145/2783258.2783260,10.1145/2783258.2783260,KDD.bib,1,['KDD.bib'],8,KDD '15,"Sydney, NSW, Australia","nonparametric models, personalization, real time recommendations, recommendations, serendipitous, topic models",10,537–546,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"The information overload problem remains serious for both consumers and service/content providers, leading to heightened demands for personalized recommendations. For recommender systems, updating user models is one of the most important tasks to keep up with their changing preferences and trends. Especially since new consumers and items emerge every day, which are promptly rated or reviewed, updating lists of items and rankings is crucial. In this paper, we set the goal of real time recommendation, to present these items instantly. Unlike standard collaborative filtering algorithms, our offline approach focuses only innovative consumers for these predictions, and then uses as few consumers as possible while keeping the same precision. Since innovators exist in many communities, and their opinions will spread and then stimulate their followers to adopt the same behavior, our approach is based on the hypothesis that a set of innova- tive consumers is sufficient to represent the most representative opinions in each community. Following this hypothesis, we derive a scalable method to detect both communities and innovative consumers in each community from a web- scale data from a behavior log. Our evaluation shows that our proposed weighting method can accurately sample given logs, and be compatible only with previous algorithms for real time recommendations.",10.1145/2783258.2783260,https://doi.org/10.1145/2783258.2783260,"New York, NY, USA",Association for Computing Machinery,9781450336642,2015,Real Time Recommendations from Connoisseurs,"Kawamae, Noriaki",inproceedings,10.1145/2783258.2783260,
10.1145/2783258.2783340,10.1145/2783258.2783340,KDD.bib,1,['KDD.bib'],8,KDD '15,"Sydney, NSW, Australia","joint predictive model, long term impact prediction",10,655–664,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Understanding the dynamic mechanisms that drive the high-impact scientific work (e.g., research papers, patents) is a long-debated research topic and has many important implications, ranging from personal career development and recruitment search, to the jurisdiction of research resources. Recent advances in characterizing and modeling scientific success have made it possible to forecast the long-term impact of scientific work, where data mining techniques, supervised learning in particular, play an essential role. Despite much progress, several key algorithmic challenges in relation to predicting long-term scientific impact have largely remained open. In this paper, we propose a joint predictive model to forecast the long-term scientific impact at the early stage, which simultaneously addresses a number of these open challenges, including the scholarly feature design, the non-linearity, the domain-heterogeneity and dynamics. In particular, we formulate it as a regularized optimization problem and propose effective and scalable algorithms to solve it. We perform extensive empirical evaluations on large, real scholarly data sets to validate the effectiveness and the efficiency of our method.",10.1145/2783258.2783340,https://doi.org/10.1145/2783258.2783340,"New York, NY, USA",Association for Computing Machinery,9781450336642,2015,The Child is Father of the Man: Foresee the Success at the Early Stage,"Li, Liangyue and Tong, Hanghang",inproceedings,10.1145/2783258.2783340,
10.1145/2783258.2783346,10.1145/2783258.2783346,KDD.bib,1,['KDD.bib'],8,KDD '15,"Sydney, NSW, Australia","collaborative filtering, matrix factorization, recommender systems",10,189–198,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Advanced and effective collaborative filtering methods based on explicit feedback assume that unknown ratings do not follow the same model as the observed ones not missing at random). In this work, we build on this assumption, and introduce a novel dynamic matrix factorization framework that allows to set an explicit prior on unknown values. When new ratings, users, or items enter the system, we can update the factorization in time independent of the size of data (number of users, items and ratings). Hence, we can quickly recommend items even to very recent users. We test our methods on three large datasets, including two very sparse ones, in static and dynamic conditions. In each case, we outrank state-of-the-art matrix factorization methods that do not use a prior on unknown ratings.",10.1145/2783258.2783346,https://doi.org/10.1145/2783258.2783346,"New York, NY, USA",Association for Computing Machinery,9781450336642,2015,Dynamic Matrix Factorization with Priors on Unknown Values,"Devooght, Robin and Kourtellis, Nicolas and Mantrach, Amin",inproceedings,10.1145/2783258.2783346,
10.1145/2783258.2783348,10.1145/2783258.2783348,KDD.bib,1,['KDD.bib'],8,KDD '15,"Sydney, NSW, Australia","a network of time series, tensor factorization",10,79–88,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Mining time series data has been a very active research area in the past decade, exactly because of its prevalence in many high-impact applications, ranging from environmental monitoring, intelligent transportation systems, computer network forensics, to smart buildings and many more. It has posed many fascinating research questions. Among others, three prominent challenges shared by a variety of real applications are (a) high-order; (b) contextual constraints and (c) temporal smoothness. The state-of-the-art mining algorithms are rich in addressing each of these challenges, but relatively short of comprehensiveness in attacking the coexistence of multiple or even all of these three challenges.In this paper, we propose a comprehensive method, FACETS, to simultaneously model all these three challenges. We formulate it as an optimization problem from a dynamic graphical model perspective. The key idea is to use tensor factorization to address multi-aspect challenges, and perform careful regularizations to attack both contextual and temporal challenges. Based on that, we propose an effective and scalable algorithm to solve the problem. Our experimental evaluations on three real datasets demonstrate that our method (1) outperforms its competitors in two common data mining tasks (imputation and prediction); and (2) enjoys a linear scalability w.r.t. the length of time series.",10.1145/2783258.2783348,https://doi.org/10.1145/2783258.2783348,"New York, NY, USA",Association for Computing Machinery,9781450336642,2015,Facets: Fast Comprehensive Mining of Coevolving High-order Time Series,"Cai, Yongjie and Tong, Hanghang and Fan, Wei and Ji, Ping and He, Qing",inproceedings,10.1145/2783258.2783348,
10.1145/2783258.2783358,10.1145/2783258.2783358,KDD.bib,1,['KDD.bib'],8,KDD '15,"Sydney, NSW, Australia","gauc, link recommendation, recommender systems, signed networks",10,1105–1114,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Signed networks, in which the relationship between two nodes can be either positive (indicating a relationship such as trust) or negative (indicating a relationship such as distrust), are becoming increasingly common. A plausible model for user behavior analytics in signed networks can be based upon the assumption that more extreme positive and negative relationships are explored and exploited before less extreme ones. Such a model implies that a personalized ranking list of latent links should place positive links on the top, negative links at the bottom, and unknown status links in between. Traditional ranking metrics, e.g., area under the receiver operating characteristic curve (AUC), are however not suitable for quantifying such a ranking list which includes positive, negative, and unknown status links. To address this issue, a generalized AUC (GAUC) which can measure both the head and tail of a ranking list has been introduced. Since GAUC weights each pairwise comparison equally and the calculation of GAUC requires quadratic time, we derive two lower bounds of GAUC which can be computed in linear time and put more emphasis on ranking positive links on the top and negative links at the bottom of a ranking list. Next, we develop two efficient latent link recommendation (ELLR) algorithms in order to recommend links by directly optimizing these two lower bounds, respectively. Finally, we compare these two ELLR algorithms with top-performing baseline methods over four benchmark datasets, among which the largest network has more than 100 thousand nodes and seven million entries. Thorough empirical studies demonstrate that the proposed ELLR algorithms outperform state-of-the-art approaches for link recommendation in signed networks at no cost in efficiency.",10.1145/2783258.2783358,https://doi.org/10.1145/2783258.2783358,"New York, NY, USA",Association for Computing Machinery,9781450336642,2015,Efficient Latent Link Recommendation in Signed Networks,"Song, Dongjin and Meyer, David A. and Tao, Dacheng",inproceedings,10.1145/2783258.2783358,
10.1145/2783258.2788562,10.1145/2783258.2788562,KDD.bib,1,['KDD.bib'],8,KDD '15,"Sydney, NSW, Australia","e-commerce, life stage, recommender system",10,1879–1888,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Although marketing researchers and sociologists have recognized the large impact of life stage on consumer's purchasing behaviors, existing recommender systems have not taken this impact into consideration. In this paper, we found obvious correlation between life stage and purchasing behavior in many E-commerce categories. For example, a mum may look for different suitable products when her baby is at different ages. Motivated by this, we introduce the conception of life stage into recommender systems and propose to predict a user's current life-stage and recommend products correspondingly. We propose a new Maximum Entropy Semi Markov Model to segment and label consumer life stage based on the observed purchasing data over time. In the mom-baby product category where the life stage transition is deterministic, we develop an efficient approximate solution using large scale logistic regression and a Viterbi-like algorithm. We also propose a Gaussian mixture model to efficiently handle multi-kids life stage prediction problem. We integrate the life stage information predicted into the recommender system behind the largest online shopping website taobao.com. Both offline and online experiments demonstrate the effectiveness of the proposed life-stage based recommendation approach.",10.1145/2783258.2788562,https://doi.org/10.1145/2783258.2788562,"New York, NY, USA",Association for Computing Machinery,9781450336642,2015,Life-stage Prediction for Product Recommendation in E-commerce,"Jiang, Peng and Zhu, Yadong and Zhang, Yi and Yuan, Quan",inproceedings,10.1145/2783258.2788562,
10.1145/2783258.2788586,10.1145/2783258.2788586,KDD.bib,1,['KDD.bib'],8,KDD '15,"Sydney, NSW, Australia","bayesian online learning, multi-armed bandits, online advertising, online algorithms, randomized probability matching",10,1869–1878,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"We study online meta-learners for real-time bid prediction that predict by selecting a single best predictor among several subordinate prediction algorithms, here called ""experts"". These predictors belong to the family of context-dependent past performance estimators that make a prediction only when the instance to be predicted falls within their areas of expertise. Within the advertising ecosystem, it is very common for the contextual information to be incomplete, hence, it is natural for some of the experts to abstain from making predictions on some of the instances. Experts' areas of expertise can overlap, which makes their predictions less suitable for merging; as such, they lend themselves better to the problem of best expert selection. In addition, their performance varies over time, which gives the expert selection problem a non-stochastic, adversarial flavor. In this paper we propose to use probability sampling (via Thompson Sampling) as a meta-learning algorithm that samples from the pool of experts for the purpose of bid prediction. We show performance results from the comparison of our approach to multiple state-of-the-art algorithms using exploration scavenging on a log file of over 300 million ad impressions, as well as comparison to a baseline rule-based model using production traffic from a leading DSP platform.",10.1145/2783258.2788586,https://doi.org/10.1145/2783258.2788586,"New York, NY, USA",Association for Computing Machinery,9781450336642,2015,Real-Time Bid Prediction using Thompson Sampling-Based Expert Selection,"Ikonomovska, Elena and Jafarpour, Sina and Dasdan, Ali",inproceedings,10.1145/2783258.2788586,
10.1145/2783258.2788614,10.1145/2783258.2788614,KDD.bib,1,['KDD.bib'],8,KDD '15,"Sydney, NSW, Australia","feed relevance, large scale learning, personalization",10,1651–1660,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"LinkedIn dynamically delivers update activities from a user's interpersonal network to more than 300 million members in the personalized feed that ranks activities according their ""relevance"" to the user. This paper discloses the implementation details behind this personalized feed system at LinkedIn which can not be found from related work, and addresses the scalability and data sparsity challenges for deploying the system online. More specifically, we focus on the personalization models by generating three kinds of affinity scores: Viewer-ActivityType Affinity, Viewer-Actor Affinity, and Viewer-Actor-ActivityType Affinity. Extensive experiments based on online bucket tests (A/B experiments) and offline evaluation illustrate the effect of our personalization models in LinkedIn feed.",10.1145/2783258.2788614,https://doi.org/10.1145/2783258.2788614,"New York, NY, USA",Association for Computing Machinery,9781450336642,2015,Personalizing LinkedIn Feed,"Agarwal, Deepak and Chen, Bee-Chung and He, Qi and Hua, Zhenhao and Lebanon, Guy and Ma, Yiming and Shivaswamy, Pannagadatta and Tseng, Hsiao-Ping and Yang, Jaewon and Zhang, Liang",inproceedings,10.1145/2783258.2788614,
10.1145/2783258.2788615,10.1145/2783258.2788615,KDD.bib,1,['KDD.bib'],8,KDD '15,"Sydney, NSW, Australia","budget pacing, campaign optimization, demand-side platform",10,2217–2226,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"In targeted online advertising, advertisers look for maximizing campaign performance under delivery constraint within budget schedule. Most of the advertisers typically prefer to impose the delivery constraint to spend budget smoothly over the time in order to reach a wider range of audiences and have a sustainable impact. Since lots of impressions are traded through public auctions for online advertising today, the liquidity makes price elasticity and bid landscape between demand and supply change quite dynamically. Therefore, it is challenging to perform smooth pacing control and maximize campaign performance simultaneously. In this paper, we propose a smart pacing approach in which the delivery pace of each campaign is learned from both offline and online data to achieve smooth delivery and optimal performance goals. The implementation of the proposed approach in a real DSP system is also presented. Experimental evaluations on both real online ad campaigns and offline simulations show that our approach can effectively improve campaign performance and achieve delivery goals.",10.1145/2783258.2788615,https://doi.org/10.1145/2783258.2788615,"New York, NY, USA",Association for Computing Machinery,9781450336642,2015,Smart Pacing for Effective Online Ad Campaign Optimization,"Xu, Jian and Lee, Kuang-chih and Li, Wentong and Qi, Hang and Lu, Quan",inproceedings,10.1145/2783258.2788615,
10.1145/2792838.2792839,10.1145/2792838.2792839,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","stream recommendation, offline evaluation, A/B testing",2,361–362,Proceedings of the 9th ACM Conference on Recommender Systems,"This tutorial addressed two trending topics in the field of recommender systems research, namely A/B testing and real-time recommendations of streamed data. Focusing on the news domain, participants learned how to benchmark the performance of stream-based recommendation algorithms in a live recommender system and in a simulated environment.",10.1145/2792838.2792839,https://doi.org/10.1145/2792838.2792839,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Real-time Recommendation of Streamed Data,"Hopfgartner, Frank and Kille, Benjamin and Heintz, Tobias and Turrin, Roberto",inproceedings,10.1145/2792838.2792839,
10.1145/2792838.2796547,10.1145/2792838.2796547,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","language models, recommender systems",4,375–378,Proceedings of the 9th ACM Conference on Recommender Systems,"Even though there exist multiple approaches to build recommendation algorithms, algebraic techniques based on vector and matrix representations are predominant in the field. Notwithstanding the fact that these algebraic Collaborative Filtering methods have been demonstrated to be very effective in the rating prediction task, they do not generally provide good results in the top-N recommendation task. In this research, we return to the roots of recommender systems and we explore the relationship between Information Filtering and Information Retrieval. We think that probabilistic methods taken from the latter field such as statistical Language Models can be a more effective and formal way for generating personalised ranks of recommendations. We compare our improvements against several algebraic and probabilistic state-of-the-art algorithms and pave the way to future and promising research directions.",10.1145/2792838.2796547,https://doi.org/10.1145/2792838.2796547,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Exploring Statistical Language Models for Recommender Systems,"Valcarce, Daniel",inproceedings,10.1145/2792838.2796547,
10.1145/2792838.2799668,10.1145/2792838.2799668,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","sketching, recommender systems, matrix factorization",4,277–280,Proceedings of the 9th ACM Conference on Recommender Systems,"Matrix factorization is widely used in Recommender Systems. Although existing popular incremental matrix factorization methods are effectively in reducing time complexity, they simply assume that the similarity between items or users is invariant. For instance, they keep the item feature matrix unchanged and just update the user matrix without re-training the entire model. However, with the new users growing continuously, the fitting error would be accumulated since the extra distribution information of items has not been utilized. In this paper, we present an alternative and reasonable approach, with a relaxed assumption that the similarity between items (users) is relatively stable after updating. Concretely, utilizing the prediction error of the new data as the auxiliary features, our method updates both feature matrices simultaneously, and thus users' preference can be better modeled than merely adjusting one corresponded feature matrix. Besides, our method maintains the feature dimension in a smaller size through taking advantage of matrix sketching. Experimental results show that our proposal outperforms the existing incremental matrix factorization methods.",10.1145/2792838.2799668,https://doi.org/10.1145/2792838.2799668,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Incremental Matrix Factorization via Feature Space Re-learning for Recommender System,"Song, Qiang and Cheng, Jian and Lu, Hanqing",inproceedings,10.1145/2792838.2799668,
10.1145/2792838.2799675,10.1145/2792838.2799675,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","crowdsourcing, games-with-a-purpose, human computation, recommender systems",4,305–308,Proceedings of the 9th ACM Conference on Recommender Systems,This paper describes a casual Facebook game to capture recommendation data as a side-effect of gameplay. We show how this data can be used to make successful recommendations as part of a live-user trial.,10.1145/2792838.2799675,https://doi.org/10.1145/2792838.2799675,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,The Recommendation Game: Using a Game-with-a-Purpose to Generate Recommendation Data,"Banks, Sam and Rafter, Rachael and Smyth, Barry",inproceedings,10.1145/2792838.2799675,
10.1145/2792838.2799676,10.1145/2792838.2799676,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","latent representation, recommender systems, temporal dynamics",4,281–284,Proceedings of the 9th ACM Conference on Recommender Systems,"For recommender systems, time is often an important source of information but it is also a complex dimension to apprehend. We propose here to learn item and user representations such that any timely ordered sequence of items selected by a user will be represented as a trajectory of the user in a representation space. This allows us to rank new items for this user. We then enrich the item and user representations in order to perform rating prediction using a classical matrix factorization scheme. We demonstrate the interest of our approach regarding both item ranking and rating prediction on a series of classical benchmarks.",10.1145/2792838.2799676,https://doi.org/10.1145/2792838.2799676,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Latent Trajectory Modeling: A Light and Efficient Way to Introduce Time in Recommender Systems,"Gu\`{a}rdia-Sebaoun, Elie and Guigue, Vincent and Gallinari, Patrick",inproceedings,10.1145/2792838.2799676,
10.1145/2792838.2800171,10.1145/2792838.2800171,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","matrix factorization, overlapping community regularization, rating prediction, social recommender systems",8,27–34,Proceedings of the 9th ACM Conference on Recommender Systems,"Recommender systems have become de facto tools for suggesting items that are of potential interest to users. Predicting a user's rating on an item is the fundamental recommendation task. Traditional methods that generate predictions by analyzing the user-item rating matrix perform poorly when the matrix is sparse. Recent approaches use data from social networks to improve accuracy. However, most of the social-network based recommender systems only consider direct friendships and they are less effective when the targeted user has few social connections. In this paper, we propose two alternative models that incorporate the overlapping community regularization into the matrix factorization framework. Our empirical study on four real datasets shows that our approaches outperform the state-of-the-art algorithms in both traditional and social-network based recommender systems regarding both cold-start users and normal users.",10.1145/2792838.2800171,https://doi.org/10.1145/2792838.2800171,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Overlapping Community Regularization for Rating Prediction in Social Recommender Systems,"Li, Hui and Wu, Dingming and Tang, Wenbin and Mamoulis, Nikos",inproceedings,10.1145/2792838.2800171,
10.1145/2792838.2800174,10.1145/2792838.2800174,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","collaborative filtering, dynamic models, matrix factorization, probabilistic models, state space models, variational inference",8,155–162,Proceedings of the 9th ACM Conference on Recommender Systems,"Models for recommender systems use latent factors to explain the preferences and behaviors of users with respect to a set of items (e.g., movies, books, academic papers). Typically, the latent factors are assumed to be static and, given these factors, the observed pref- erences and behaviors of users are assumed to be generated without order. These assumptions limit the explorative and predictive capabilities of such models, since users' interests and item popularity may evolve over time. To address this, we propose dPF, a dynamic matrix factorization model based on the recent Poisson factorization model for recommendations. dPF models the time evolving latent factors with a Kalman filter and the actions with Poisson distributions. We derive a scalable variational inference algorithm to infer the latent factors. Finally, we demonstrate dPF on 10 years of user click data from arXiv.org, one of the largest repository of scientific papers and a formidable source of information about the behavior of scientists. Empirically we show performance improvement over both static and, more recently proposed, dynamic recommendation models. We also provide a thorough exploration of the inferred posteriors over the latent variables.",10.1145/2792838.2800174,https://doi.org/10.1145/2792838.2800174,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Dynamic Poisson Factorization,"Charlin, Laurent and Ranganath, Rajesh and McInerney, James and Blei, David M.",inproceedings,10.1145/2792838.2800174,
10.1145/2792838.2800175,10.1145/2792838.2800175,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","probabilistic soft logic, probabilistic programming, hybrid recommender systems, graphical models",8,99–106,Proceedings of the 9th ACM Conference on Recommender Systems,"As the amount of recorded digital information increases, there is a growing need for flexible recommender systems which can incorporate richly structured data sources to improve recommendations. In this paper, we show how a recently introduced statistical relational learning framework can be used to develop a generic and extensible hybrid recommender system. Our hybrid approach, HyPER (HYbrid Probabilistic Extensible Recommender), incorporates and reasons over a wide range of information sources. Such sources include multiple user-user and item-item similarity measures, content, and social information. HyPER automatically learns to balance these different information signals when making predictions. We build our system using a powerful and intuitive probabilistic programming language called probabilistic soft logic, which enables efficient and accurate prediction by formulating our custom recommender systems with a scalable class of graphical models known as hinge-loss Markov random fields. We experimentally evaluate our approach on two popular recommendation datasets, showing that HyPER can effectively combine multiple information types for improved performance, and can significantly outperform existing state-of-the-art approaches.",10.1145/2792838.2800175,https://doi.org/10.1145/2792838.2800175,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,HyPER: A Flexible and Extensible Probabilistic Framework for Hybrid Recommender Systems,"Kouki, Pigi and Fakhraei, Shobeir and Foulds, James and Eirinaki, Magdalini and Getoor, Lise",inproceedings,10.1145/2792838.2800175,
10.1145/2792838.2800179,10.1145/2792838.2800179,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","user study, user control, social computing, simulation study, recommender systems, personalization, movielens, collaborative filtering",8,3–10,Proceedings of the 9th ACM Conference on Recommender Systems,"The essence of a recommender system is that it can recommend items personalized to the preferences of an individual user. But typically users are given no explicit control over this personalization, and are instead left guessing about how their actions affect the resulting recommendations. We hypothesize that any recommender algorithm will better fit some users' expectations than others, leaving opportunities for improvement. To address this challenge, we study a recommender that puts some control in the hands of users. Specifically, we build and evaluate a system that incorporates user-tuned popularity and recency modifiers, allowing users to express concepts like ""show more popular items"". We find that users who are given these controls evaluate the resulting recommendations much more positively. Further, we find that users diverge in their preferred settings, confirming the importance of giving control to users.",10.1145/2792838.2800179,https://doi.org/10.1145/2792838.2800179,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Putting Users in Control of their Recommendations,"Harper, F. Maxwell and Xu, Funing and Kaur, Harmanpreet and Condiff, Kyle and Chang, Shuo and Terveen, Loren",inproceedings,10.1145/2792838.2800179,
10.1145/2792838.2800180,10.1145/2792838.2800180,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","bipartite graph, diversity, item ranking, long-tail, random walks, sampling, top-n recommendation",8,163–170,Proceedings of the 9th ACM Conference on Recommender Systems,"User satisfaction is often dependent on providing accurate and diverse recommendations. In this paper, we explore scalable algorithms that exploit random walks as a sampling technique to obtain diverse recommendations without compromising on accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP^3_beta that re-ranks items based on 3-hop random walk transition probabilities. We show empirically, that RP^3_beta provides accurate recommendations with high long-tail item frequency at the top of the recommendation list. We also present scalable approximate versions of RP^3_beta and the two most accurate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with increasing number of samples.",10.1145/2792838.2800180,https://doi.org/10.1145/2792838.2800180,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,"Blockbusters and Wallflowers: Accurate, Diverse, and Scalable Recommendations with Random Walks","Christoffel, Fabian and Paudel, Bibek and Newell, Chris and Bernstein, Abraham",inproceedings,10.1145/2792838.2800180,
10.1145/2792838.2800185,10.1145/2792838.2800185,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","recommender systems, matrix factorization, learning to rank, collaborative filtering",8,115–122,Proceedings of the 9th ACM Conference on Recommender Systems,"The ranking quality at the top of the list is crucial in many real-world applications of recommender systems. In this paper, we present a novel framework that allows for pointwise as well as listwise training with respect to various ranking metrics. This is based on a training objective function where we assume that, for given a user, the recommender system predicts scores for all items that follow approximately a Gaussian distribution. We motivate this assumption from the properties of implicit feedback data. As a model, we use matrix factorization and extend it by non-linear activation functions, as customary in the literature of artificial neural networks. In particular, we use non-linear activation functions derived from our Gaussian assumption. Our preliminary experimental results show that this approach is competitive with state-of-the-art methods with respect to optimizing the Area under the ROC curve, while it is particularly effective in optimizing the head of the ranked list.",10.1145/2792838.2800185,https://doi.org/10.1145/2792838.2800185,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Gaussian Ranking by Matrix Factorization,"Steck, Harald",inproceedings,10.1145/2792838.2800185,
10.1145/2792838.2800189,10.1145/2792838.2800189,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","geospatial preference, expert recommendation, GPS-tagged social media",8,67–74,Proceedings of the 9th ACM Conference on Recommender Systems,"Experts are important for providing reliable and authoritative information and opinion, as well as for improving online reviews and services. While considerable previous research has focused on finding topical experts with broad appeal -- e.g., top Java developers, best lawyers in Texas -- we tackle the problem of personalized expert recommendation, to identify experts who have special personal appeal and importance to users. One of the key insights motivating our approach is to leverage the geo-spatial preferences of users and the variation of these preferences across different regions, topics, and social communities. Through a fine-grained GPS-tagged social media trace, we characterize these geo-spatial preferences for personalized experts, and integrate these preferences into a matrix factorization-based personalized expert recommender. Through extensive experiments, we find that the proposed approach can improve the quality of recommendation by 24% in precision compared to several baselines. We also find that users' geo-spatial preference of expertise and their underlying social communities can ameliorate the cold start problem by more than 20% in precision and recall.",10.1145/2792838.2800189,https://doi.org/10.1145/2792838.2800189,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Exploiting Geo-Spatial Preference for Personalized Expert Recommendation,"Lu, Haokai and Caverlee, James",inproceedings,10.1145/2792838.2800189,
10.1145/2792838.2800190,10.1145/2792838.2800190,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","social networks, probabilistic models, probabilistic inference, preferences, group recommendation",8,35–42,Proceedings of the 9th ACM Conference on Recommender Systems,"Social networks facilitate a variety of social, economic, and political interactions. Homophily---the tendency for people to associate or interact with similar peers---and social influence---the tendency to adopt certain characteristics of those with whom one interacts---suggest that preferences (e.g., over products, services, political parties) are likely to be correlated among people whom directly interact in a social network. We develop a model, preference-oriented social networks, that captures such correlations of individual preferences, where preferences take the form of rankings over a set of options. We develop probabilistic inference methods for predicting individual preferences given observed social connections and partial observations of the preferences of others in the network. We exploit these predictions in a social choice context to make group decisions or recommendations even when the preferences of some group members are unobserved. Experiments demonstrate the effectiveness of our algorithms and the improvements made possible by accounting for social ties.",10.1145/2792838.2800190,https://doi.org/10.1145/2792838.2800190,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Preference-oriented Social Networks: Group Recommendation and Inference,"Salehi-Abari, Amirali and Boutilier, Craig",inproceedings,10.1145/2792838.2800190,
10.1145/2792838.2800192,10.1145/2792838.2800192,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","deep learning, neural networks, recommender systems",8,147–154,Proceedings of the 9th ACM Conference on Recommender Systems,"Recent work has shown that collaborative filter-based recommender systems can be improved by incorporating side information, such as natural language reviews, as a way of regularizing the derived product representations. Motivated by the success of this approach, we introduce two different models of reviews and study their effect on collaborative filtering performance. While the previous state-of-the-art approach is based on a latent Dirichlet allocation (LDA) model of reviews, the models we explore are neural network based: a bag-of-words product-of-experts model and a recurrent neural network. We demonstrate that the increased flexibility offered by the product-of-experts model allowed it to achieve state-of-the-art performance on the Amazon review dataset, outperforming the LDA-based approach. However, interestingly, the greater modeling power offered by the recurrent neural network appears to undermine the model's ability to act as a regularizer of the product representations.",10.1145/2792838.2800192,https://doi.org/10.1145/2792838.2800192,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Learning Distributed Representations from Reviews for Collaborative Filtering,"Almahairi, Amjad and Kastner, Kyle and Cho, Kyunghyun and Courville, Aaron",inproceedings,10.1145/2792838.2800192,
10.1145/2792838.2800193,10.1145/2792838.2800193,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","social networks, recommender systems, probabilistic models",8,43–50,Proceedings of the 9th ACM Conference on Recommender Systems,"Preference-based recommendation systems have transformed how we consume media. By analyzing usage data, these methods uncover our latent preferences for items (such as articles or movies) and form recommendations based on the behavior of others with similar tastes. But traditional preference-based recommendations do not account for the social aspect of consumption, where a trusted friend might point us to an interesting item that does not match our typical preferences. In this work, we aim to bridge the gap between preference- and social-based recommendations. We develop social Poisson factorization (SPF), a probabilistic model that incorporates social network information into a traditional factorization method; SPF introduces the social aspect to algorithmic recommendation. We develop a scalable algorithm for analyzing data with SPF, and demonstrate that it outperforms competing methods on six real-world datasets; data sources include a social reader and Etsy.",10.1145/2792838.2800193,https://doi.org/10.1145/2792838.2800193,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,A Probabilistic Model for Using Social Networks in Personalized Item Recommendation,"Chaney, Allison J.B. and Blei, David M. and Eliassi-Rad, Tina",inproceedings,10.1145/2792838.2800193,
10.1145/2792838.2800196,10.1145/2792838.2800196,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","sparsity, matrix factorization, cold-start problem",8,91–98,Proceedings of the 9th ACM Conference on Recommender Systems,"A major challenge in collaborative filtering based recommender systems is how to provide recommendations when rating data is sparse or entirely missing for a subset of users or items, commonly known as the cold-start problem. In recent years, there has been considerable interest in developing new solutions that address the cold-start problem. These solutions are mainly based on the idea of exploiting other sources of information to compensate for the lack of rating data. In this paper, we propose a novel algorithmic framework based on matrix factorization that simultaneously exploits the similarity information among users and items to alleviate the cold-start problem. In contrast to existing methods, the proposed algorithm decouples the following two aspects of the cold-start problem: (a) the completion of a rating sub-matrix, which is generated by excluding cold-start users and items from the original rating matrix; and (b) the transduction of knowledge from existing ratings to cold-start items/users using side information. This crucial difference significantly boosts the performance when appropriate side information is incorporated. We provide theoretical guarantees on the estimation error of the proposed two-stage algorithm based on the richness of similarity information in capturing the rating data. To the best of our knowledge, this is the first algorithm that addresses the cold-start problem with provable guarantees. We also conduct thorough experiments on synthetic and real datasets that demonstrate the effectiveness of the proposed algorithm and highlights the usefulness of auxiliary information in dealing with both cold-start users and items.",10.1145/2792838.2800196,https://doi.org/10.1145/2792838.2800196,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,Cold-Start Item and User Recommendation with Decoupled Completion and Transduction,"Barjasteh, Iman and Forsati, Rana and Masrour, Farzan and Esfahanian, Abdol-Hossein and Radha, Hayder",inproceedings,10.1145/2792838.2800196,
10.1145/2792838.2800198,10.1145/2792838.2800198,RecSys.bib,1,['RecSys.bib'],8,RecSys '15,"Vienna, Austria","social regularization, matrix factorization, collaborative social ranking, collaborative filtering",8,51–58,Proceedings of the 9th ACM Conference on Recommender Systems,"The significance of social-enhanced recommender systems is increasing, along with its practicality, as online reviews, ratings, friendship links, and follower relationships are increasingly becoming available. In recent years, there has been an upsurge of interest in exploiting social information, such as trust and distrust relations in recommendation algorithms. The goal is to improve the quality of suggestions and mitigate the data sparsity and the cold-start users problems in existing systems. In this paper, we introduce a general collaborative social ranking model to rank the latent features of users extracted from rating data based on the social context of users. In contrast to existing social regularization methods, the proposed framework is able to simultaneously leverage trust, distrust, and neutral relations, and has a linear dependency on the social network size. By integrating the ranking based social regularization idea into the matrix factorization algorithm, we propose a novel recommendation algorithm, dubbed PushTrust. Our experiments on the Epinions dataset demonstrate that collaboratively ranking the latent features of users by exploiting trust and distrust relations leads to a substantial increase in performance, and to effectively deal with cold-start users problem.",10.1145/2792838.2800198,https://doi.org/10.1145/2792838.2800198,"New York, NY, USA",Association for Computing Machinery,9781450336925,2015,PushTrust: An Efficient Recommendation Algorithm by Leveraging Trust and Distrust Relations,"Forsati, Rana and Barjasteh, Iman and Masrour, Farzan and Esfahanian, Abdol-Hossein and Radha, Hayder",inproceedings,10.1145/2792838.2800198,
10.1145/2806416.2806435,10.1145/2806416.2806435,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","social networks, network-aware search, microblogging applications, as-you-type search",10,563–572,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"We present in this paper a novel approach for as-you-type top-k keyword search over social media. We adopt a natural ""network-aware"" interpretation for information relevance, by which information produced by users who are closer to the seeker is considered more relevant. In practice, this query model poses new challenges for effectiveness and efficiency in online search, even when a complete query is given as input in one keystroke. This is mainly because it requires a joint exploration of the social space and classic IR indexes such as inverted lists. We describe a memory-efficient and incremental prefix-based retrieval algorithm, which also exhibits an anytime behavior, allowing to output the most likely answer within any chosen running-time limit. We evaluate it through extensive experiments for several applications and search scenarios, including searching for posts in micro-blogging (Twitter and Tumblr), as well as searching for businesses based on reviews in Yelp. They show that our solution is effective in answering real-time as-you-type searches over social media.",10.1145/2806416.2806435,https://doi.org/10.1145/2806416.2806435,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,A Network-Aware Approach for Searching As-You-Type in Social Media,"Lagr\'{e}e, Paul and Cautis, Bogdan and Vahabi, Hossein",inproceedings,10.1145/2806416.2806435,
10.1145/2806416.2806486,10.1145/2806416.2806486,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","wikipedia, timeline summarization, temporal ranking, news, learning to rank, entity retrieval",10,1201–1210,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Long-running, high-impact events such as the Boston Marathon bombing often develop through many stages and involve a large number of entities in their unfolding. Timeline summarization of an event by key sentences eases story digestion, but does not distinguish between what a user remembers and what she might want to re-check. In this work, we present a novel approach for timeline summarization of high-impact events, which uses entities instead of sentences for summarizing the event at each individual point in time. Such entity summaries can serve as both (1) important memory cues in a retrospective event consideration and (2) pointers for personalized event exploration. In order to automatically create such summaries, it is crucial to identify the ""right"" entities for inclusion. We propose to learn a ranking function for entities, with a dynamically adapted trade-off between the in-document salience of entities and the informativeness of entities across documents, i.e., the level of new information associated with an entity for a time point under consideration. Furthermore, for capturing collective attention for an entity we use an innovative soft labeling approach based on Wikipedia. Our experiments on a real large news datasets confirm the effectiveness of the proposed methods.",10.1145/2806416.2806486,https://doi.org/10.1145/2806416.2806486,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Balancing Novelty and Salience: Adaptive Learning to Rank Entities for Timeline Summarization of High-impact Events,"Tran, Tuan A. and Niederee, Claudia and Kanhabua, Nattiya and Gadiraju, Ujwal and Anand, Avishek",inproceedings,10.1145/2806416.2806486,
10.1145/2806416.2806503,10.1145/2806416.2806503,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","recommender system, multi-context recommendation, data sparsity, collaborative filtering",10,901–910,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Data sparsity is a long-standing challenge for recommender systems based on collaborative filtering. A promising solution for this problem is multi-context recommendation, i.e., leveraging users' explicit or implicit feedback from multiple contexts. In multi-context recommendation, various types of interactions between entities (users and items) are combined to alleviate data sparsity of a single context in a collective manner. Two issues are crucial for multi-context recommendation: (1) How to differentiate context-specific factors from entity-intrinsic factors shared across contexts? (2) How to capture the salient phenomenon that some entities are insensitive to contexts while others are remarkably context-dependent? Previous methods either do not consider context-specific factors, or assume that a context imposes equal influence on different entities, limiting their capability of combating data sparsity problem by taking full advantage of multiple contexts.In this paper, we propose a context-adaptive matrix factorization method for multi-context recommendation by simultaneously modeling context-specific factors and entity-intrinsic factors in a unified model. We learn an entity-intrinsic latent factor for every entity, and a context-specific latent factor for every entity in each context. Meanwhile, using a context-entity mixture parameter matrix we explicitly model the extent to which each context imposes influence on each entity. Experiments on two real scenarios demonstrate that our method consistently outperforms previous multi-context recommendation methods on all different sparsity levels.Such a consistent performance promotion forms the unique superiority of our method, enabling it to be a reliable model for multi-context recommendation.",10.1145/2806416.2806503,https://doi.org/10.1145/2806416.2806503,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Context-Adaptive Matrix Factorization for Multi-Context Recommendation,"Man, Tong and Shen, Huawei and Huang, Junming and Cheng, Xueqi",inproceedings,10.1145/2806416.2806503,
10.1145/2806416.2806504,10.1145/2806416.2806504,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","tripartite graph ranking, top-n recommendation, reviews, explanable recommendation, comments, aspects",10,1661–1670,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Most existing collaborative filtering techniques have focused on modeling the binary relation of users to items by extracting from user ratings. Aside from users' ratings, their affiliated reviews often provide the rationale for their ratings and identify what aspects of the item they cared most about. We explore the rich evidence source of aspects in user reviews to improve top-N recommendation. By extracting aspects (i.e., the specific properties of items) from textual reviews, we enrich the user--item binary relation to a user--item--aspect ternary relation. We model the ternary relation as a heterogeneous tripartite graph, casting the recommendation task as one of vertex ranking. We devise a generic algorithm for ranking on tripartite graphs -- TriRank -- and specialize it for personalized recommendation. Experiments on two public review datasets show that it consistently outperforms state-of-the-art methods. Most importantly, TriRank endows the recommender system with a higher degree of explainability and transparency by modeling aspects in reviews. It allows users to interact with the system through their aspect preferences, assisting users in making informed decisions.",10.1145/2806416.2806504,https://doi.org/10.1145/2806416.2806504,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,TriRank: Review-aware Explainable Recommendation by Modeling Aspects,"He, Xiangnan and Chen, Tao and Kan, Min-Yen and Chen, Xiao",inproceedings,10.1145/2806416.2806504,
10.1145/2806416.2806505,10.1145/2806416.2806505,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","sentiment propagation, popularity prediction, point process, hawkes process",10,1621–1630,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Video popularity prediction plays a foundational role in many aspects of life, such as recommendation systems and investment consulting. Because of its technological and economic importance, this problem has been extensively studied for years. However, four constraints have limited most related works' usability. First, most feature oriented models are inadequate in the social media environment, because many videos are published with no specific content features, such as a strong cast or a famous script. Second, many studies assume that there is a linear correlation existing between view counts from early and later days, but this is not the case in every scenario. Third, numerous works just take view counts into consideration, but discount associated sentiments. Nevertheless, it is the public opinions that directly drive a video's final success/failure. Also, many related approaches rely on a network topology, but such topologies are unavailable in many situations. Here, we propose a Dual Sentimental Hawkes Process (DSHP) to cope with all the problems above. DSHP's innovations are reflected in three ways: (1) it breaks the ""Linear Correlation"" assumption, and implements Hawkes Process; (2) it reveals deeper factors that affect a video's popularity; and (3) it is topology free. We evaluate DSHP on four types of videos: Movies, TV Episodes, Music Videos, and Online News, and compare its performance against 6 widely used models, including Translation Model, Multiple Linear Regression, KNN Regression, ARMA, Reinforced Poisson Process, and Univariate Hawkes Process. Our model outperforms all of the others, which indicates a promising application prospect.",10.1145/2806416.2806505,https://doi.org/10.1145/2806416.2806505,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Video Popularity Prediction by Sentiment Propagation via Implicit Network,"Ding, Wanying and Shang, Yue and Guo, Lifan and Hu, Xiaohua and Yan, Rui and He, Tingting",inproceedings,10.1145/2806416.2806505,
10.1145/2806416.2806520,10.1145/2806416.2806520,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","cold-start, collaborative filtering, helpfulness rating",10,1651–1660,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Users usually play dual roles in real-world recommender systems. One is as a reviewer who writes reviews for items with rating scores, and the other is as a rater who rates the helpfulness scores of reviews. Traditional recommender systems mainly consider the reviewer role while not taking into account the rater role. However, the rater role allows users to express their opinions toward reviews about items; hence it may indirectly indicate their opinions about items, which could be complementary to the reviewer role. Since most real-world recommender systems provide convenient mechanisms for the rater role, recent studies show that typically there are much more helpfulness ratings from the rater role than item ratings from the reviewer role. Therefore, incorporating the rater role of users may have the potentials to mitigate the data sparsity and cold-start problems in traditional recommender systems. In this paper, we investigate how to exploit dual roles of users in recommender systems. In particular, we provide a principled way to exploit the rater role mathematically and propose a novel recommender system DualRec, which captures both the reviewer role and the rater role of users simultaneously for recommendation. Experimental results on two real world datasets demonstrate the effectiveness of the proposed framework, and further experiments are conducted to understand the importance of the rater role of users in recommendation.",10.1145/2806416.2806520,https://doi.org/10.1145/2806416.2806520,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Toward Dual Roles of Users in Recommender Systems,"Wang, Suhang and Tang, Jiliang and Liu, Huan",inproceedings,10.1145/2806416.2806520,
10.1145/2806416.2806527,10.1145/2806416.2806527,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","collaborative filtering, deep learning, denoising auto-encoder, matrix factorization",10,811–820,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Collaborative filtering (CF) has been widely employed within recommender systems to solve many real-world problems. Learning effective latent factors plays the most important role in collaborative filtering. Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem. Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization. However, the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information. To tackle this problem, we learn effective latent representations via deep learning. Deep learning models have emerged as very appealing in learning effective representations in many applications. In particular, we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning. We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders. The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.",10.1145/2806416.2806527,https://doi.org/10.1145/2806416.2806527,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Deep Collaborative Filtering via Marginalized Denoising Auto-encoder,"Li, Sheng and Kawale, Jaya and Fu, Yun",inproceedings,10.1145/2806416.2806527,
10.1145/2806416.2806528,10.1145/2806416.2806528,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","similarity, recommendation, meta path, heterogeneous information network",10,453–462,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Recently heterogeneous information network (HIN) analysis has attracted a lot of attention, and many data mining tasks have been exploited on HIN. As an important data mining task, recommender system includes a lot of object types (e.g., users, movies, actors, and interest groups in movie recommendation) and the rich relations among object types, which naturally constitute a HIN. The comprehensive information integration and rich semantic information of HIN make it promising to generate better recommendations. However, conventional HINs do not consider the attribute values on links, and the widely used meta path in HIN may fail to accurately capture semantic relations among objects, due to the existence of rating scores (usually ranging from 1 to 5) between users and items in recommender system. In this paper, we are the first to propose the weighted HIN and weighted meta path concepts to subtly depict the path semantics through distinguishing different link attribute values. Furthermore, we propose a semantic path based personalized recommendation method SemRec to predict the rating scores of users on items. Through setting meta paths, SemRec not only flexibly integrates heterogeneous information but also obtains prioritized and personalized weights representing user preferences on paths. Experiments on two real datasets illustrate that SemRec achieves better recommendation performance through flexibly integrating information with the help of weighted meta paths.",10.1145/2806416.2806528,https://doi.org/10.1145/2806416.2806528,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Semantic Path based Personalized Recommendation on Weighted Heterogeneous Information Networks,"Shi, Chuan and Zhang, Zhiqiang and Luo, Ping and Yu, Philip S. and Yue, Yading and Wu, Bin",inproceedings,10.1145/2806416.2806528,
10.1145/2806416.2806530,10.1145/2806416.2806530,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","multi-entity, hierarchical representation, factorization model, collaborative prediction",10,613–622,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"With the rapid growth of Internet applications, there are more and more entities in interaction scenarios, and thus collaborative prediction for multi-entity interaction is becoming a significant problem. The state-of-the-art methods, e.g., tensor factorization and factorization machine, predict multi-entity interaction based on calculating the similarity among all entities. However, these methods are usually not able to reveal the joint characteristics of entities in the interaction. Besides, some methods may succeed in one specific application, but they can not be extended effectively for other applications or interaction scenarios with more entities. In this work, we propose a Hierarchical Interaction Representation (HIR) model, which models the mutual action among different entities as a joint representation. We generate the interaction representation of two entities via tensor multiplication, which is preformed iteratively to construct a hierarchical structure among all entities. Moreover, we employ several hidden layers to reveal the underlying properties of this interaction and enhance the model performance. After generating final representation, the prediction can be calculated using a variety of machine learning methods according to different tasks (i.e., linear regression for regression tasks, pair-wise ranking for ranking tasks and logistic regression for classification tasks). Experimental results show that our proposed HIR model yields significant improvements over the competitive compared methods in four different application scenarios (i.e., general recommendation, context-aware recommendation, latent collaborative retrieval and click-through rate prediction).",10.1145/2806416.2806530,https://doi.org/10.1145/2806416.2806530,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Collaborative Prediction for Multi-entity Interaction With Hierarchical Representation,"Liu, Qiang and Wu, Shu and Wang, Liang",inproceedings,10.1145/2806416.2806530,
10.1145/2806416.2806537,10.1145/2806416.2806537,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","probabilistic graphical models, news community, credibility",10,353–362,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Media seems to have become more partisan, often providing a biased coverage of news catering to the interest of specific groups. It is therefore essential to identify credible information content that provides an objective narrative of an event. News communities such as digg, reddit, or newstrust offer recommendations, reviews, quality ratings, and further insights on journalistic works. However, there is a complex interaction between different factors in such online communities: fairness and style of reporting, language clarity and objectivity, topical perspectives (like political viewpoint), expertise and bias of community members, and more.This paper presents a model to systematically analyze the different interactions in a news community between users, news, and sources. We develop a probabilistic graphical model that leverages this joint interaction to identify 1) highly credible news articles, 2) trustworthy news sources, and 3) expert users who perform the role of ""citizen journalists"" in the community. Our method extends CRF models to incorporate real-valued ratings, as some communities have very fine-grained scales that cannot be easily discretized without losing information. To the best of our knowledge, this paper is the first full-fledged analysis of credibility, trust, and expertise in news communities.",10.1145/2806416.2806537,https://doi.org/10.1145/2806416.2806537,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Leveraging Joint Interactions for Credibility Analysis in News Communities,"Mukherjee, Subhabrata and Weikum, Gerhard",inproceedings,10.1145/2806416.2806537,
10.1145/2806416.2806556,10.1145/2806416.2806556,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","virality, video, popularity",10,1591–1600,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"The proliferation of online video content has triggered numerous works on its evolution and popularity, as well as on the effect of social sharing on content propagation. In this paper, we focus on the observable dependencies between the virality of video content on a micro-blogging social network (in this case, Twitter) and the popularity of such content on a video distribution service (YouTube). To this end, we collected and analysed a corpus of Twitter posts containing links to YouTube clips and the corresponding video meta-data from YouTube. Our analysis highlights the unique properties of content that is both popular and viral, which allows such content to attract high number of views on YouTube and achieve fast propagation on Twitter. With this in mind, we proceed to the predictions of popular-and-viral clips and propose a framework that can, with high degree of accuracy and low amount of training data, predict videos that are likely to be popular, viral, and both. The key contribution of our work is the focus on cross-system dynamics between YouTube and Twitter. We conjecture and validate that cross-system prediction of both popularity and virality of videos is feasible, and can be performed with a reasonably high degree of accuracy. One of our key findings is that YouTube features capturing user engagement, have strong virality prediction capabilities. This findings allows to solely rely on data extracted from a video sharing service to predict popularity and virality aspects of videos.",10.1145/2806416.2806556,https://doi.org/10.1145/2806416.2806556,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Characterizing and Predicting Viral-and-Popular Video Content,"Vallet, David and Berkovsky, Shlomo and Ardon, Sebastien and Mahanti, Anirban and Kafaar, Mohamed Ali",inproceedings,10.1145/2806416.2806556,
10.1145/2806416.2806578,10.1145/2806416.2806578,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","inductive matrix completion, deep learning features, blog recommendation",10,203–212,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Popular microblogging sites such as Tumblr have attracted hundreds of millions of users as a content sharing platform, where users can create rich content in the form of posts that are shared with other users who follow them. Due to the sheer amount of posts created on such services, an important task is to make quality recommendations of blogs for users to follow. Apart from traditional recommender system settings where the follower graph is the main data source, additional side-information of users and blogs such as user activity (e.g., like and reblog) and rich content (e.g., text and images) are also available to be exploited for enhanced recommendation performance. In this paper, we propose a novel boosted inductive matrix completion method (BIMC) for blog recommendation. BIMC is an additive low-rank model for user-blog preferences consisting of two components; one component captures the low-rank structure of follow relationships and the other captures the latent structure using side-information. Our model formulation combines the power of the recently proposed inductive matrix completion (IMC) model (for side-information) together with a standard matrix completion (MC) model (for low-rank structure). Furthermore, we utilize recently developed deep learning techniques to obtain semantically rich feature representations of text and images that are incorporated in BIMC. Experiments on a large-scale real-world dataset from Tumblr illustrate the effectiveness of the proposed BIMC method.",10.1145/2806416.2806578,https://doi.org/10.1145/2806416.2806578,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Tumblr Blog Recommendation with Boosted Inductive Matrix Completion,"Shin, Donghyuk and Cetintas, Suleyman and Lee, Kuang-Chih and Dhillon, Inderjit S.",inproceedings,10.1145/2806416.2806578,
10.1145/2806416.2806579,10.1145/2806416.2806579,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","text mining, security risk, privacy risk, pearson correlation, mobile apps, deep learning, content rating",10,1111–1120,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Mobile applications (Apps) could expose children or adolescents to mature themes such as sexual content, violence and drug use, which results in an inappropriate security and privacy risk for them. Therefore, mobile platforms provide rating policies to label the maturity levels of Apps and the reasons why an App has a given maturity level, which enables parents to select maturity-appropriate Apps for their children. However, existing approaches to implement these maturity rating policies are either costly (because of expensive manually labeling) or inaccurate (because of no centralized controls). In this work, we aim to design and build a machine learning framework to automatically predict maturity levels for mobile Apps and the associated reasons with a high accuracy and a low cost.To this end, we take a multi-label classification approach to predict the mature contents in a given App and then label the maturity level according to a rating policy. Specifically, we extract novel features from App descriptions by leveraging deep learning technique to automatically capture the semantic similarity of pairwise words and adapt Support Vector Machine to capture label correlations with pearson correlation in a multi-label classification setting. Moreover, we evaluate our approach and various baseline methods using datasets that we collected from both App Store and Google Play. We demonstrate that, with only App descriptions, our approach already achieves 85% Precision for predicting mature contents and 79% Precision for predicting maturity levels, which substantially outperforms baseline methods.",10.1145/2806416.2806579,https://doi.org/10.1145/2806416.2806579,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Protecting Your Children from Inappropriate Content in Mobile Apps: An Automatic Maturity Rating Framework,"Hu, Bing and Liu, Bin and Gong, Neil Zhenqiang and Kong, Deguang and Jin, Hongxia",inproceedings,10.1145/2806416.2806579,
10.1145/2806416.2806623,10.1145/2806416.2806623,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","structured constraint, recommendation, collaborative filtering",4,1935–1938,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Matrix factorization models, as one of the most powerful Collaborative Filtering approaches, have greatly advanced the recommendation tasks. However, few of them are able to explicitly consider structured constraint for modeling user interests. To solve this problem, we propose a novel matrix factorization model with adaptive graph regularization framework, which can automatically discover latent user communities jointly with learning latent user representations, to enhance the discriminative power for recommendation. Experiments on real-world datasets demonstrate the effectiveness of the proposed method.",10.1145/2806416.2806623,https://doi.org/10.1145/2806416.2806623,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Improving Collaborative Filtering via Hidden Structured Constraint,"Zhang, Qing and Wang, Houfeng",inproceedings,10.1145/2806416.2806623,
10.1145/2806416.2806633,10.1145/2806416.2806633,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","user profiling, recommender systems, dimension reduction, auto-encoder",4,1863–1866,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"User profiling is a key component of personalized recommender systems, and is used to generate user profiles that describe individual user interests and preferences. The increasing availability of big data is driving the urgent need for user profiling algorithms that are able to generate accurate user profiles from large-scale user behavior data. In this paper, we propose a probabilistic rating auto-encoder to perform unsupervised feature learning and generate latent user feature profiles from large-scale user rating data. Based on the generated user profiles, neighbourhood based collaborative filtering approaches have been adopted to make personalized rating predictions. The effectiveness of the proposed approach is demonstrated in experiments conducted on a real-world rating dataset from yelp.com.",10.1145/2806416.2806633,https://doi.org/10.1145/2806416.2806633,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,A Probabilistic Rating Auto-encoder for Personalized Recommender Systems,"Liang, Huizhi and Baldwin, Timothy",inproceedings,10.1145/2806416.2806633,
10.1145/2806416.2806641,10.1145/2806416.2806641,CIKM.bib,1,['CIKM.bib'],8,CIKM '15,"Melbourne, Australia","structured sparse regression, structured sparse feature graph learning, structured sparse coding, hierarchical sparse coding, feature-based collaborative filtering",4,1895–1898,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,"Feature-based collaborative filtering models, such as state-of-the-art factorization machines and regression-based latent factor models, rarely consider features' structural information, ignoring the heterogeneity of inter-type and intra-type relationships. Na\""{\i}vely treating all feature pairs equally would potentially deteriorate the overall recommendation performance. In addition, human prior knowledge and other hierarchical or graphical structures are often available for some features, e.g., the country-state-city hierarchy for geographic features and the topical taxonomy for article features. It is a challenge to utilize the prior knowledge to further boost performance of state-of-the-art models. In this paper we employ rich features from both user and item sides to enhance latent factors learnt from interaction data, uncovering hidden structures from features' relationships and learning sparse pairwise and tree structural connections among features. Our framework borrows the modeling strengh from both structural sparsity modeling and latent factor models. Experiments on a real-world large-scale recommendation data set demonstrated that the proposed model outperforms several strong state-of-the-art baselines.",10.1145/2806416.2806641,https://doi.org/10.1145/2806416.2806641,"New York, NY, USA",Association for Computing Machinery,9781450337946,2015,Structured Sparse Regression for Recommender Systems,"Qian, Mingjie and Hong, Liangjie and Shi, Yue and Rajan, Suju",inproceedings,10.1145/2806416.2806641,
10.1145/2808797.2808819,10.1145/2808797.2808819,KDD.bib,1,['KDD.bib'],8,ASONAM '15,"Paris, France","arabic, credibility, microblogs, social networks, trust, twitter",8,1212–1219,Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015,"The increased usage of Twitter as a medium for reporting news and sharing information between people has caught the attention of researchers from different disciplines. One of the research directions is the analysis of online information from the perspective of its credibility. This paper aims to assess and analyze the credibility of tweets in Arabic language. In order to achieve the stated goal, first we employ the idea of crowdsourcing where users can explicitly express their opinions about credibility of a set of tweets. This information coupled with the data about tweets' features enable us to investigate which features may indicate the credibility level of a tweet, e.g. tweet with attached image and was authored by a person who posts a lot of tweets will be, with high probability, a credible tweet. We distinguish three main groups of features: authority and topical expertise (of the source), data quality (of the content), and popularity (of the content and the source). We argue that content data quality factor based on content linguistic features in addition to source authority is more important than content popularity in identifying credible messages. In addition to this, we identified three experts who also rated the credibility of tweets and based on that we investigate the level of agreement between experts and the crowd, and we identify which expert represents the crowd in the best way. This can allow us to select the most representative expert when it is needed. This study is a pilot of a large study that aims at predicting credibility of Arabic Twitter messages using machine learning approaches.",10.1145/2808797.2808819,https://doi.org/10.1145/2808797.2808819,"New York, NY, USA",Association for Computing Machinery,9781450338547,2015,Using Arabic Microblogs Features in Determining Credibility,"AlMansour, Amal Abdullah and Iliopoulos, Costas S.",inproceedings,10.1145/2808797.2808819,
10.1145/2808797.2809311,10.1145/2808797.2809311,KDD.bib,1,['KDD.bib'],7,ASONAM '15,"Paris, France",,8,667–674,Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015,"Internet and online-based social systems are rising as the dominant mode of communication in society. However, the public or semi-private environment under which most online communications operate under do not make them suitable channels for speaking with others about personal or emotional problems. This has led to the emergence of online platforms for emotional support offering free, anonymous, and confidential conversations with live listeners. Yet very little is known about the way these platforms are utilized, and if their features and design foster strong user engagement. This paper explores the utilization and the interaction features of hundreds of thousands of users on 7 Cups of Tea, a leading online platform offering online emotional support. It dissects the user's activity levels, the patterns by which they engage in conversation with each other, and uses machine learning methods to find factors promoting engagement. The study may be the first to measure activities and interactions in a large-scale online social system that fosters peer-to-peer emotional support.",10.1145/2808797.2809311,https://doi.org/10.1145/2808797.2809311,"New York, NY, USA",Association for Computing Machinery,9781450338547,2015,Stay Awhile and Listen: User Interactions in a Crowdsourced Platform Offering Emotional Support,"Doran, Derek and Yelne, Samir and Massari, Luisa and Calzarossa, Maria-Carla and Jackson, LaTrelle and Moriarty, Glen",inproceedings,10.1145/2808797.2809311,
10.1145/2808797.2809395,10.1145/2808797.2809395,KDD.bib,1,['KDD.bib'],7,ASONAM '15,"Paris, France",,4,270–273,Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015,"Contemporary modern world has witnessed the widespread emergence of online social media and similar technologies. Peoples' behaviour over different social network platform has become an interesting topic of research. In this study, we investigate whether people express analogous identity over different platforms and analysis of different social platform usage contributes to reveal more of a person. We analyse people's usage pattern in two major online platforms, the most widely used social media platform Twitter and a major online commenting platform Disqus. We extract linguistic features and infer personality traits from both of these platforms. Our study reveals differential relationship between personality traits and Disqus and Twitter usage. We also find that social media has an influence on a person's discussion topic. People share opinion on varieties of topics and entities exclusively in Twitter and Disqus. Moreover Disqus provides stronger assessment of a person's sentiment over a topic or entity. Combination of these two profiles gives an extensive view of a user's interest and sensitivity which justify the inference that people use different social network for different purposes and single social network analysis is not enough to build a comprehensive virtual identity of a person.",10.1145/2808797.2809395,https://doi.org/10.1145/2808797.2809395,"New York, NY, USA",Association for Computing Machinery,9781450338547,2015,Human behaviour in different social medias: A case study of Twitter and Disqus,"Maruf, Hasan Al and Meshkat, Nagib and Ali, Mohammed Eunus and Mahmud, Jalal",inproceedings,10.1145/2808797.2809395,
10.1145/2813448.2813510,10.1145/2813448.2813510,RecSys.bib,1,['RecSys.bib'],7,RecSys '15 Challenge,"Vienna, Austria","Recommender systems, RecSys Challenge, Purchase prediction, Ensemble Learning, Categorical input data",4,,Proceedings of the 2015 International ACM Recommender Systems Challenge,"In this paper, we describe the winning approach for the RecSys Challenge 2015. Our key points are (1) two-stage classification, (2) massive usage of categorical features, (3) strong classifiers built by gradient boosting and (4) threshold optimization based directly on the competition score. We describe our approach and discuss how it can be used to build scalable personalization systems.",10.1145/2813448.2813510,https://doi.org/10.1145/2813448.2813510,"New York, NY, USA",Association for Computing Machinery,9781450336659,2015,RecSys Challenge 2015: ensemble learning with categorical features,"Romov, Peter and Sokolov, Evgeny",inproceedings,10.1145/2813448.2813510,1
10.1145/2835776.2835777,10.1145/2835776.2835777,WSDM.bib,1,['WSDM.bib'],8,WSDM '16,"San Francisco, California, USA","factorization, feature interaction, multi-view learning",10,427–436,Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,"With rapidly growing amount of data available on the web, it becomes increasingly likely to obtain data from different perspectives for multi-view learning. Some successive examples of web applications include recommendation and target advertising. Specifically, to predict whether a user will click an ad in a query context, there are available features extracted from user profile, ad information and query description, and each of them can only capture part of the task signals from a particular aspect/view. Different views provide complementary information to learn a practical model for these applications. Therefore, an effective integration of the multi-view information is critical to facilitate the learning performance.In this paper, we propose a general predictor, named multi-view machines (MVMs), that can effectively explore the full-order interactions between features from multiple views. A joint factorization is applied for the interaction parameters which makes parameter estimation more accurate under sparsity and renders the model with the capacity to avoid overfitting. Moreover, MVMs can work in conjunction with different loss functions for a variety of machine learning tasks. The advantages of MVMs are illustrated through comparison with other methods for multi-view prediction, including support vector machines (SVMs), support tensor machines (STMs) and factorization machines (FMs).A stochastic gradient descent method and a distributed implementation on Spark are presented to learn the MVM model. Through empirical studies on two real-world web application datasets, we demonstrate the effectiveness of MVMs on modeling feature interactions in multi-view data. A 3.51% accuracy improvement is shown on MVMs over FMs for the problem of movie rating prediction, and 0.57% for ad click prediction.",10.1145/2835776.2835777,https://doi.org/10.1145/2835776.2835777,"New York, NY, USA",Association for Computing Machinery,9781450337168,2016,Multi-view Machines,"Cao, Bokai and Zhou, Hucheng and Li, Guoqiang and Yu, Philip S.",inproceedings,10.1145/2835776.2835777,
10.1145/2835776.2835789,10.1145/2835776.2835789,WSDM.bib,1,['WSDM.bib'],8,WSDM '16,"San Francisco, California, USA","marked point processes, purchase behavior, single-source data",10,543–552,Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,"This paper proposes a method for inferring from single-source data the factors that trigger purchases. Here, single-source data are the histories of item purchases and media advertisement views for each individual. We assume a sequence of purchase events to be a stochastic process incorporating the following three factors: (a) user preference, (b) social effects received from other users, and (c) media advertising effects. As our user-purchase model incorporates the latent relationships between users and advertisers, it can infer the latent triggers of purchases. Experiments on real single-source data show that our model can (a) achieve high prediction accuracy for purchases, (b) discover the key information, i.e., popular items, influential users, and influential advertisers, (c) estimate the relative impact of the three factors on purchases, and (d) find user segments according to the estimated factors.",10.1145/2835776.2835789,https://doi.org/10.1145/2835776.2835789,"New York, NY, USA",Association for Computing Machinery,9781450337168,2016,Inferring Latent Triggers of Purchases with Consideration of Social Effects and Media Advertisements,"Tanaka, Yusuke and Kurashima, Takeshi and Fujiwara, Yasuhiro and Iwata, Tomoharu and Sawada, Hiroshi",inproceedings,10.1145/2835776.2835789,
10.1145/2835776.2835819,10.1145/2835776.2835819,WSDM.bib,1,['WSDM.bib'],8,WSDM '16,"San Francisco, California, USA","content representation, entity ranking, entity retrieval, fielded retrieval",10,595–604,Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,"Entity ranking, i.e., successfully positioning a relevant entity at the top of the ranking for a given query, is inherently difficult due to the potential mismatch between the entity's description in a knowledge base, and the way people refer to the entity when searching for it. To counter this issue we propose a method for constructing dynamic collective entity representations. We collect entity descriptions from a variety of sources and combine them into a single entity representation by learning to weight the content from different sources that are associated with an entity for optimal retrieval effectiveness. Our method is able to add new descriptions in real time and learn the best representation as time evolves so as to capture the dynamics of how people search entities. Incorporating dynamic description sources into dynamic collective entity representations improves retrieval effectiveness by 7% over a state-of-the-art learning to rank baseline. Periodic retraining of the ranker enables higher ranking effectiveness for dynamic collective entity representations.",10.1145/2835776.2835819,https://doi.org/10.1145/2835776.2835819,"New York, NY, USA",Association for Computing Machinery,9781450337168,2016,Dynamic Collective Entity Representations for Entity Ranking,"Graus, David and Tsagkias, Manos and Weerkamp, Wouter and Meij, Edgar and de Rijke, Maarten",inproceedings,10.1145/2835776.2835819,
10.1145/2835776.2835833,10.1145/2835776.2835833,WSDM.bib,1,['WSDM.bib'],8,WSDM '16,"San Francisco, California, USA","attention, engagement, large scale, news reading, topic modeling, user modeling, viewport",10,113–122,Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,"Prior work on user engagement with online media identified web page dwell time as a key metric reflecting level of user engagement with online news articles. While on average, dwell time gives a reasonable estimate of user experience with a news article, it is not able to capture important aspects of user interaction with the page, such as how much time a user spends reading the article vs. viewing the comment posted by other users, or the actual proportion of article read by the user. In this paper, we propose a set of user engagement classes along with new user engagement metrics that, unlike dwell time, more accurately reflect user experience with the content. Our user engagement classes provide clear and interpretable taxonomy of user engagement with online news, and are defined based on amount of time user spends on the page, proportion of the article user actually reads and the amount of interaction users performs with the comments. Moreover, we demonstrate that our metrics are relatively easier to predict from the news article content, compared to the dwell time, making optimization of user engagement more attainable goal.",10.1145/2835776.2835833,https://doi.org/10.1145/2835776.2835833,"New York, NY, USA",Association for Computing Machinery,9781450337168,2016,Understanding User Attention and Engagement in Online News Reading,"Lagun, Dmitry and Lalmas, Mounia",inproceedings,10.1145/2835776.2835833,
10.1145/2835776.2835836,10.1145/2835776.2835836,WSDM.bib,1,['WSDM.bib'],8,WSDM '16,"San Francisco, California, USA","co-clustering, collaborative filtering, recommender systems",10,73–82,Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,"Collaborative Filtering (CF) is the most popular method for recommender systems. The principal idea of CF is that users might be interested in items that are favorited by similar users, and most of the existing CF methods measure users' preferences by their behaviours over all the items. However, users might have different interests over different topics, thus might share similar preferences with different groups of users over different sets of items. In this paper, we propose a novel and scalable method CCCF which improves the performance of CF methods via user-item co-clustering. CCCF first clusters users and items into several subgroups, where each subgroup includes a set of like-minded users and a set of items in which these users share their interests. Then, traditional CF methods can be easily applied to each subgroup, and the recommendation results from all the subgroups can be easily aggregated. Compared with previous works, CCCF has several advantages including scalability, flexibility, interpretability and extensibility. Experimental results on four real world data sets demonstrate that the proposed method significantly improves the performance of several state-of-the-art recommendation algorithms.",10.1145/2835776.2835836,https://doi.org/10.1145/2835776.2835836,"New York, NY, USA",Association for Computing Machinery,9781450337168,2016,CCCF: Improving Collaborative Filtering via Scalable User-Item Co-Clustering,"Wu, Yao and Liu, Xudong and Xie, Min and Ester, Martin and Yang, Qing",inproceedings,10.1145/2835776.2835836,
10.1145/2835776.2835837,10.1145/2835776.2835837,WSDM.bib,1,['WSDM.bib'],8,WSDM '16,"San Francisco, California, USA","collaborative filtering, denoising auto- encoders, recommender systems",10,153–162,Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,"Most real-world recommender services measure their performance based on the top-N results shown to the end users. Thus, advances in top-N recommendation have far-ranging consequences in practical applications. In this paper, we present a novel method, called Collaborative Denoising Auto-Encoder (CDAE), for top-N recommendation that utilizes the idea of Denoising Auto-Encoders. We demonstrate that the proposed model is a generalization of several well-known collaborative filtering models but with more flexible components. Thorough experiments are conducted to understand the performance of CDAE under various component settings. Furthermore, experimental results on several public datasets demonstrate that CDAE consistently outperforms state-of-the-art top-N recommendation methods on a variety of common evaluation metrics.",10.1145/2835776.2835837,https://doi.org/10.1145/2835776.2835837,"New York, NY, USA",Association for Computing Machinery,9781450337168,2016,Collaborative Denoising Auto-Encoders for Top-N Recommender Systems,"Wu, Yao and DuBois, Christopher and Zheng, Alice X. and Ester, Martin",inproceedings,10.1145/2835776.2835837,
10.1145/2835776.2855085,10.1145/2835776.2855085,WSDM.bib,1,['WSDM.bib'],8,WSDM '16,"San Francisco, California, USA","e-commerce, economics, personalized promotion, recommendation, surplus maximization",1,709,Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,"Existing recommendation algorithms treat recommendation problem as rating prediction and the recommendation quality is measured by RMSE or other similar metrics. However, we argued that when it comes to E-commerce product recommendation, recommendation is more than rating prediction by realizing the fact price plays a critical role in recommendation result. In this work, we propose to build E-commerce product recommender systems based on fundamental economic notions. We first proposed an incentive compatible method that can effectively elicit consumer's willingness-to-pay in a typical E-commerce setting and in a further step, we formalize the recommendation problem as maximizing total surplus. We validated the proposed WTP elicitation algorithm through crowd sourcing and the results demonstrated that the proposed approach can achieve higher seller profit by personalizing promotion. We also proposed a total surplus maximization (TSM) based recommendation framework. We specified TSM by three of the most representative settings - e-commerce where the product quantity can be viewed as infinity, P2P lending where the resource is bounded and freelancer marketing where the resource (job) can be assigned to one freelancer. The experimental results of the corresponding datasets shows that TSM exceeds existing approach in terms of total surplus.",10.1145/2835776.2855085,https://doi.org/10.1145/2835776.2855085,"New York, NY, USA",Association for Computing Machinery,9781450337168,2016,E-commerce Product Recommendation by Personalized Promotion and Total Surplus Maximization,"Zhao, Qi",inproceedings,10.1145/2835776.2855085,
10.1145/2872427.2882973,10.1145/2872427.2882973,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16,"Montr\'{e}al, Qu\'{e}bec, Canada","web-based services, total surplus maximization, recommendation systems, online service allocation, computational economics",11,73–83,Proceedings of the 25th International Conference on World Wide Web,"A prime function of many major World Wide Web applications is Online Service Allocation (OSA), the function of matching individual consumers with particular services/goods (which may include loans or jobs as well as products) each with its own producer. In the applications of interest, consumers are free to choose, so OSA usually takes the form of personalized recommendation or search in practice. The performance metrics of recommender and search systems currently tend to focus on just one side of the match, in some cases the consumers (e.g. satisfaction) and in other cases the producers (e.g., profit). However, a sustainable OSA platform needs benefit both consumers and producers; otherwise the neglected party eventually may stop using it. In this paper, we show how to adapt economists' traditional idea of maximizing total surplus (the sum of consumer net benefit and producer profit) to the heterogeneous world of online service allocation, in an effort to promote the web intelligence for social good in online eco-systems. Modifications of traditional personalized recommendation algorithms enable us to apply Total Surplus Maximization (TSM) to three very different types of real-world tasks -- e-commerce, P2P lending and freelancing. The results for all three tasks suggest that TSM compares very favorably to currently popular approaches, to the benefit of both producers and consumers.",10.1145/2872427.2882973,https://doi.org/10.1145/2872427.2882973,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341431,2016,Economic Recommendation with Surplus Maximization,"Zhang, Yongfeng and Zhao, Qi and Zhang, Yi and Friedman, Daniel and Zhang, Min and Liu, Yiqun and Ma, Shaoping",inproceedings,10.1145/2872427.2882973,
10.1145/2872427.2882993,10.1145/2872427.2882993,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16,"Montr\'{e}al, Qu\'{e}bec, Canada","cascade prediction, content recurrence, information diffusion, memes, virality",11,671–681,Proceedings of the 25th International Conference on World Wide Web,"Cascades of information-sharing are a primary mechanism by which content reaches its audience on social media, and an active line of research has studied how such cascades, which form as content is reshared from person to person, develop and subside. In this paper, we perform a large-scale analysis of cascades on Facebook over significantly longer time scales, and find that a more complex picture emerges, in which many large cascades recur, exhibiting multiple bursts of popularity with periods of quiescence in between. We characterize recurrence by measuring the time elapsed between bursts, their overlap and proximity in the social network, and the diversity in the demographics of individuals participating in each peak. We discover that content virality, as revealed by its initial popularity, is a main driver of recurrence, with the availability of multiple copies of that content helping to spark new bursts. Still, beyond a certain popularity of content, the rate of recurrence drops as cascades start exhausting the population of interested individuals. We reproduce these observed patterns in a simple model of content recurrence simulated on a real social network. Using only characteristics of a cascade's initial burst, we demonstrate strong performance in predicting whether it will recur in the future.",10.1145/2872427.2882993,https://doi.org/10.1145/2872427.2882993,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341431,2016,Do Cascades Recur?,"Cheng, Justin and Adamic, Lada A. and Kleinberg, Jon M. and Leskovec, Jure",inproceedings,10.1145/2872427.2882993,
10.1145/2872427.2883010,10.1145/2872427.2883010,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16,"Montr\'{e}al, Qu\'{e}bec, Canada","forecasting, non-linear, parameter-free, time-series",11,737–747,Proceedings of the 25th International Conference on World Wide Web,"Given a large collection of time-evolving activities, such as Google search queries, which consist of d keywords/activities for m locations of duration n, how can we analyze temporal patterns and relationships among all these activities and find location-specific trends? How do we go about capturing non-linear evolutions of local activities and forecasting future patterns? For example, assume that we have the online search volume for multiple keywords, e.g., ""Nokia/Nexus/Kindle"" or ""CNN/BBC"" for 236 countries/territories, from 2004 to 2015. Our goal is to analyze a large collection of multi-evolving activities, and specifically, to answer the following questions: (a) Is there any sign of interaction/competition between two different keywords? If so, who competes with whom? (b) In which country is the competition strong? (c) Are there any seasonal/annual activities? (d) How can we automatically detect important world-wide (or local) events? We present COMPCUBE, a unifying non-linear model, which provides a compact and powerful representation of co-evolving activities; and also a novel fitting algorithm, COMPCUBE-FIT, which is parameter-free and scalable. Our method captures the following important patterns: (B)asic trends, i.e., non-linear dynamics of co-evolving activities, signs of (C)ompetition and latent interaction, e.g., Nokia vs. Nexus, (S)easonality, e.g., a Christmas spike for iPod in the U.S. and Europe, and (D)eltas, e.g., unrepeated local events such as the U.S. election in 2008. Thanks to its concise but effective summarization, COMPCUBE can also forecast long-range future activities. Extensive experiments on real datasets demonstrate that COMPCUBE consistently outperforms the best state-of- the-art methods in terms of both accuracy and execution speed.",10.1145/2872427.2883010,https://doi.org/10.1145/2872427.2883010,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341431,2016,Non-Linear Mining of Competing Local Activities,"Matsubara, Yasuko and Sakurai, Yasushi and Faloutsos, Christos",inproceedings,10.1145/2872427.2883010,
10.1145/2872427.2883024,10.1145/2872427.2883024,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16,"Montr\'{e}al, Qu\'{e}bec, Canada","sequence mining, repeat consumption, boredom",11,519–529,Proceedings of the 25th International Conference on World Wide Web,"We study sequences of consumption in which the same item may be consumed multiple times. We identify two macroscopic behavior patterns of repeated consumptions. First, in a given user's lifetime, very few items live for a long time. Second, the last consumptions of an item exhibit growing inter-arrival gaps consistent with the notion of increasing boredom leading up to eventual abandonment.We then present what is to our knowledge the first holistic model of sequential repeated consumption, covering all observed aspects of this behavior. Our simple and purely combinatorial model includes no planted notion of lifetime distributions or user boredom; nonetheless, the model correctly predicts both of these phenomena. Further, we provide theoretical analysis of the behavior of the model confirming these phenomena. Additionally, the model quantitatively matches a number of microscopic phenomena across a broad range of datasets.Intriguingly, these findings suggest that the observation in a variety of domains of increasing user boredom leading to abandonment may be explained simply by probabilistic conditioning on an extinction event in a simple model, without resort to explanations based on complex human dynamics.",10.1145/2872427.2883024,https://doi.org/10.1145/2872427.2883024,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341431,2016,Modeling User Consumption Sequences,"Benson, Austin R. and Kumar, Ravi and Tomkins, Andrew",inproceedings,10.1145/2872427.2883024,
10.1145/2872427.2883049,10.1145/2872427.2883049,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16,"Montr\'{e}al, Qu\'{e}bec, Canada","recommendation system, email prioritization, active learning",10,1181–1190,Proceedings of the 25th International Conference on World Wide Web,"Email is one of the most important communication tools today, but email overload resulting from the large number of unimportant or irrelevant emails is causing trillion-level economy loss every year. Thus personalized email prioritization algorithms are of urgent need. Despite lots of previous effort on this topic, broadcast email, an important type of email, is overlooked in previous literature. Broadcast emails are significantly different from normal emails, introducing both new challenges and opportunities. On one hand, lack of real senders and limited user interactions invalidate the key features exploited by traditional email prioritization algorithms; on the other hand, thousands of receivers for one broadcast email bring us the opportunity to predict importance through collaborative filtering. However, broadcast emails face a severe cold-start problem which hinders the direct application of collaborative filtering. In this paper, we propose the first framework for broadcast email prioritization by designing a novel active learning model that considers the collaborative filtering, implicit feedback and time sensitive responsiveness features of broadcast emails. Our method is thoroughly evaluated on a large scale real world industrial dataset from Samsung Electronics. Our method is proved highly effective and outperforms state-of-the-art personalized email prioritization methods.",10.1145/2872427.2883049,https://doi.org/10.1145/2872427.2883049,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341431,2016,Which to View: Personalized Prioritization for Broadcast Emails,"Wang, Beidou and Ester, Martin and Bu, Jiajun and Zhu, Yu and Guan, Ziyu and Cai, Deng",inproceedings,10.1145/2872427.2883049,
10.1145/2872427.2883087,10.1145/2872427.2883087,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16,"Montr\'{e}al, Qu\'{e}bec, Canada","opinion spam, spam detection, time series",11,369–379,Proceedings of the 25th International Conference on World Wide Web,"Recently, the problem of opinion spam has been widespread and has attracted a lot of research attention. While the problem has been approached on a variety of dimensions, the temporal dynamics in which opinion spamming operates is unclear. Are there specific spamming policies that spammers employ? What kind of changes happen with respect to the dynamics to the truthful ratings on entities. How do buffered spamming operate for entities that need spamming to retain threshold popularity and reduced spamming for entities making better success? We analyze these questions in the light of time-series analysis on Yelp. Our analyses discover various temporal patterns and their relationships with the rate at which fake reviews are posted. Building on our analyses, we employ vector autoregression to predict the rate of deception across different spamming policies. Next, we explore the effect of filtered reviews on (long-term and imminent) future rating and popularity prediction of entities. Our results discover novel temporal dynamics of spamming which are intuitive, arguable and also render confidence on Yelp's filtering. Lastly, we leverage our discovered temporal patterns in deception detection. Experimental results on large-scale reviews show the effectiveness of our approach that significantly improves the existing approaches.",10.1145/2872427.2883087,https://doi.org/10.1145/2872427.2883087,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341431,2016,On the Temporal Dynamics of Opinion Spamming: Case Studies on Yelp,"KC, Santosh and Mukherjee, Arjun",inproceedings,10.1145/2872427.2883087,
10.1145/2872427.2883090,10.1145/2872427.2883090,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16,"Montr\'{e}al, Qu\'{e}bec, Canada","collaborative filtering, matrix factorization, recommender systems",11,951–961,Proceedings of the 25th International Conference on World Wide Web,"Collaborative filtering analyzes user preferences for items (e.g., books, movies, restaurants, academic papers) by exploiting the similarity patterns across users. In implicit feedback settings, all the items, including the ones that a user did not consume, are taken into consideration. But this assumption does not accord with the common sense understanding that users have a limited scope and awareness of items. For example, a user might not have heard of a certain paper, or might live too far away from a restaurant to experience it. In the language of causal analysis (Imbens &amp; Rubin, 2015), the assignment mechanism (i.e., the items that a user is exposed to) is a latent variable that may change for various user/item combinations. In this paper, we propose a new probabilistic approach that directly incorporates user exposure to items into collaborative filtering. The exposure is modeled as a latent variable and the model infers its value from data. In doing so, we recover one of the most successful state-of-the-art approaches as a special case of our model (Hu et al. 2008), and provide a plug-in method for conditioning exposure on various forms of exposure covariates (e.g., topics in text, venue locations). We show that our scalable inference algorithm outperforms existing benchmarks in four different domains both with and without exposure covariates.",10.1145/2872427.2883090,https://doi.org/10.1145/2872427.2883090,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341431,2016,Modeling User Exposure in Recommendation,"Liang, Dawen and Charlin, Laurent and McInerney, James and Blei, David M.",inproceedings,10.1145/2872427.2883090,
10.1145/2872518.2889360,10.1145/2872518.2889360,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","information dissemination, content analysis, bot analyser",2,37–38,Proceedings of the 25th International Conference Companion on World Wide Web,"The WWW has seen a massive growth in variety and usage of OSNs. The rising population of users on Twitter and its open nature has made it an ideal platform for various kinds of opportunistic pursuits, such as news and emergency communication, business promotion, political campaigning, spamming and spreading malicious content. Most of these opportunistic pursuits are exploited through automated programs, known as bots. In this study we propose a framework (Stweeler) to study bot impact and influence on Twitter from systems and social media perspectives.",10.1145/2872518.2889360,https://doi.org/10.1145/2872518.2889360,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,Stweeler: A Framework for Twitter Bot Analysis,"Gilani, Zafar and Wang, Liang and Crowcroft, Jon and Almeida, Mario and Farahbakhsh, Reza",inproceedings,10.1145/2872518.2889360,
10.1145/2872518.2889362,10.1145/2872518.2889362,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","social network, recommender system, learning-to-rank",2,89–90,Proceedings of the 25th International Conference Companion on World Wide Web,"Due to the data sparsity problem, social network information is often additionally used to improve the performance of recommender system. While most existing works exploit social information to reduce the rating prediction error, e.g., RMSE, a few had aimed to improve the top-k ranking prediction accuracy. This paper proposes a novel top-k oriented recommendation method, TRecSo, which incorporates social information into recommendation by modeling two different roles of users as trusters and trustees while considering the structural information of the network. Empirical studies on real-world datasets demonstrate that TRecSo leads to remarkable improvement compared to previous methods in top-k recommendation.",10.1145/2872518.2889362,https://doi.org/10.1145/2872518.2889362,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,TRecSo: Enhancing Top-k Recommendation With Social Information,"Park, Chanyoung and Kim, Donghyun and Oh, Jinoh and Yu, Hwanjo",inproceedings,10.1145/2872518.2889362,
10.1145/2872518.2889389,10.1145/2872518.2889389,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","retweeting dynamics, popularity prediction, mixture process",2,33–34,Proceedings of the 25th International Conference Companion on World Wide Web,"Modeling and predicting retweeting dynamics in social media has important implications to an array of applications. Existing models either fail to model the triggering effect of retweeting dynamics, e.g., the model based on reinforced Poisson process, or are hard to be trained using only the retweeting dynamics of individual tweet, e.g., the model based on self-exciting Hawkes process. In this paper, motivated by the observation that each retweeting dynamics is generally dominated by a handful of key nodes that separately trigger a high number of retweets, we propose a mixture process to model and predict retweeting dynamics, with each subprocess capturing the retweeting dynamics initiated by a key node. Experiments demonstrate that the proposed model outperforms the state-of-the-art model.",10.1145/2872518.2889389,https://doi.org/10.1145/2872518.2889389,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,Modeling and Predicting Retweeting Dynamics via a Mixture Process,"Gao, Jinhua and Shen, Huawei and Liu, Shenghua and Cheng, Xueqi",inproceedings,10.1145/2872518.2889389,
10.1145/2872518.2889400,10.1145/2872518.2889400,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","recommendation systems, joint modeling, co-clustering",2,127–128,Proceedings of the 25th International Conference Companion on World Wide Web,"Understanding a user's motivations provides valuable information beyond the ability to recommend items. Quite often this can be accomplished by perusing both ratings and review texts. Unfortunately matrix factorization approaches to recommendation result in large, complex models that are difficult to interpret. In this paper, we attack this problem through succinct additive co-clustering on both ratings and reviews. Our model yields accurate and interpretable recommendations.",10.1145/2872518.2889400,https://doi.org/10.1145/2872518.2889400,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,Explaining Reviews and Ratings with PACO: Poisson Additive Co-Clustering,"Wu, Chao-Yuan and Beutel, Alex and Ahmed, Amr and Smola, Alexander J.",inproceedings,10.1145/2872518.2889400,
10.1145/2872518.2889402,10.1145/2872518.2889402,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","ugc, topic, music online popularity, acoustic content",2,95–96,Proceedings of the 25th International Conference Companion on World Wide Web,"Tens of thousands of music tracks are uploaded to the Internet every day through social networks that focus on music and videos, as well as portal websites. While some of the content has been popular for decades, some tracks that have just been released have been completely ignored. So what makes a music track popular? Can we predict the popularity of a music track before it is released? In this research, we will focus on an online music social network, Last.fm, and investigate three key factors of a music track that may have impact on its popularity. They include: the music content, the artist reputation and the social context of the music. The results suggest that we can predict the future popularity of music with around 80% accuracy using just these three factors. We also found out that in the social networks scenario, the content of the music seems to be an surprisingly important factor that determines the popularity of a track online.",10.1145/2872518.2889402,https://doi.org/10.1145/2872518.2889402,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,What Makes a Music Track Popular in Online Social Networks?,"Ren, Jing and Shen, Jialie and Kauffman, Robert J.",inproceedings,10.1145/2872518.2889402,
10.1145/2872518.2889405,10.1145/2872518.2889405,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","recommender systems, matrix factorization (mf), explanations, collaborative filtering (cf)",2,5–6,Proceedings of the 25th International Conference Companion on World Wide Web,"Explanations have been shown to increase the user's trust in recommendations in addition to providing other benefits such as scrutability, which is the ability to verify the validity of recommendations. Most explanation methods are designed for classical neighborhood-based Collaborative Filtering (CF) or rule-based methods. For the state of the art Matrix Factorization (MF) recommender systems, recent explanation methods, require an additional data source, such as item content data, in addition to rating data. In this paper, we address the case where no such additional data is available and propose a new Explainable Matrix Factorization (EMF) technique that computes an accurate top-$n$ recommendation list of items that are explainable. We also introduce new explanation quality metrics, that we call Mean Explainability Precision (MEP) and Mean Explainability Recall (MER).",10.1145/2872518.2889405,https://doi.org/10.1145/2872518.2889405,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,Explainable Matrix Factorization for Collaborative Filtering,"Abdollahi, Behnoush and Nasraoui, Olfa",inproceedings,10.1145/2872518.2889405,
10.1145/2872518.2890092,10.1145/2872518.2890092,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","astroturf, diffusion networks, echo chambers, fact checking, hoaxes, misinformation, social bots, social bubbles, social media, twitter",1,717,Proceedings of the 25th International Conference Companion on World Wide Web,"As social media become major channels for the diffusion of news and information, they are also increasingly attractive and targeted for abuse and manipulation. This talk overviews ongoing network analytics, data mining, and modeling efforts to understand the spread of misinformation online and offline. I present machine learning methods to detect astroturf and social bots, and outline initial steps toward computational fact checking, as well as theoretical models to study how truthful and truthy facts compete for our collective attention. These efforts will be framed by a case study in which, ironically, our own research became the target of a coordinated disinformation campaign.",10.1145/2872518.2890092,https://doi.org/10.1145/2872518.2890092,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,The Spread of Misinformation in Social Media,"Menczer, Filippo",inproceedings,10.1145/2872518.2890092,
10.1145/2872518.2890094,10.1145/2872518.2890094,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","social network, recommender system, bfacebook, behavioral modeling",6,725–730,Proceedings of the 25th International Conference Companion on World Wide Web,"This paper analyzes two types of user interactions with online content: (1) private engagement with content, measured by page-views and click-through rate; and (2) social engagement, measured by the number of shares on Facebook as well as share-rate. Based on more than a billion data points across hundreds of publishers worldwide and two time periods, it is shown that the correlation between these signals is generally low. Potential reasons for the low correlation are discussed, and the notion of private-social dissonance is defined. A more in-depth analysis shows that the dissonance between private engagement and social engagement consistently depends on content category. Categories such as Sex, Crime and Celebrities have higher private engagement than social engagement. On the other hand, categories such as Books, Careers and Music have higher social engagement than private engagement. In addition to the offline analysis, a model which utilizes the different signals was trained and deployed on a live recommendation system. The resulting weights ranked the social signal lower than click-through rate. The results are relevant for publishers, content marketers, architects of recommendation systems and researchers who wish to use social signals in order to measure and predict user engagement.",10.1145/2872518.2890094,https://doi.org/10.1145/2872518.2890094,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,For Your Eyes Only: Consuming vs. Sharing Content,"Meshulam, Ram and Sasson, Roy",inproceedings,10.1145/2872518.2890094,
10.1145/2872518.2890096,10.1145/2872518.2890096,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","online discussion analysis, news popularity prediction",6,737–742,Proceedings of the 25th International Conference Companion on World Wide Web,"The paper presents a framework for the prediction of several news story popularity indicators, such as comment count, number of users, vote score and a measure of controversiality. The framework employs a feature engineering approach, focusing on features from two sources of social interactions inherent in online discussions: the comment tree and the user graph. We show that the proposed graph-based features capture the complexities of both these social interaction graphs and lead to improvements on the prediction of all popularity indicators in three online news post datasets and to significant improvement on the task of identifying controversial stories. Specifically, we noted a 5% relative improvement in mean square error for controversiality prediction on a news-focused Reddit dataset compared to a method employing only rudimentary comment tree features that were used by past studies.",10.1145/2872518.2890096,https://doi.org/10.1145/2872518.2890096,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,Predicting News Popularity by Mining Online Discussions,"Rizos, Georgios and Papadopoulos, Symeon and Kompatsiaris, Yiannis",inproceedings,10.1145/2872518.2890096,
10.1145/2872518.2890097,10.1145/2872518.2890097,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","twitter, news propagation, micro-blogging, article propagation",6,719–724,Proceedings of the 25th International Conference Companion on World Wide Web,"Social media has emerged as a mechanism for online news propagation. This in turn has changed the competitive landscape of news providers, a landscape that was previously partitioned based on the traditional channels of news dispersion. The channels of news distribution refer to - television, newspaper, magazine, radio, news agency and online only. In this paper, we examine similarities and differences in news propagation patterns on social media based on the primary channel of a news provider. We collected news article propagation activity data from Twitter for 32 news providers over a three-week period and analyzed their propagation networks. Our analysis shows that the structural properties of the propagation networks are statistically different based on the type of primary channel. Our study has useful implications for understanding the competition between news providers in an online environment.",10.1145/2872518.2890097,https://doi.org/10.1145/2872518.2890097,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,Understanding the Competitive Landscape of News Providers on Social Media,"Bhattacharya, Devipsita and Ram, Sudha",inproceedings,10.1145/2872518.2890097,
10.1145/2872518.2890525,10.1145/2872518.2890525,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","relatedness measure, conference rating, classification",6,425–430,Proceedings of the 25th International Conference Companion on World Wide Web,"The rating of Computer Science (CS) conferences are important as it influences how papers published at the conferences and may also be used to evaluate research. In this paper, we proposed a method, rsit{}, based on a small given set of top conference ({em pivots}) and a relatedness measure based this set as well as basic baseline methods using citation count and field rating. We experimented with a snapshot dataset from Microsoft Academic Graph together with conference data from Microsoft Academic Search. We evaluated the conference ratings from our methods with the CCF conference rating list. We showed that rsit{} correlates well with CCF rating and correlates better than ratings from using a baseline ranking with citation count or field rating.",10.1145/2872518.2890525,https://doi.org/10.1145/2872518.2890525,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,Investigations on Rating Computer Sciences Conferences: An Experiment with the Microsoft Academic Graph Dataset,"Effendy, Suhendry and Yap, Roland H.C.",inproceedings,10.1145/2872518.2890525,
10.1145/2872518.2890562,10.1145/2872518.2890562,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '16 Companion,"Montr\'{e}al, Qu\'{e}bec, Canada","weibo, twitter, topic detection on short-message, social media, social attention, online behavior",4,625–628,Proceedings of the 25th International Conference Companion on World Wide Web,"Sina Weibo, China's most popular microblogging platform, is considered to be a proxy of Chinese social life. In this study, we contrast the discussions occurring on Sina Weibo and on Chinese language Twitter in order to observe two different strands of Chinese culture: people within China who use Sina Weibo with its government imposed restrictions and those outside that are free to speak completely anonymously. We first propose a simple ad-hoc algorithm to identify topics of Tweets and Weibos. Different from previous works on micro-message topic detection, our algorithm considers topics of the same contents but with different #tags. Our algorithm can also detect topics for Tweets and Weibos without any #tags. Using a large corpus of Weibo and Chinese language tweets, covering the entire year of 2012, we obtain a list of topics using clustered #tags and compare them on two platforms. Surprisingly, we find that there are no common entries among the Top 100 most popular topics. Only 9.2% of tweets correspond to the Top 1000 topics of Weibo, and conversely only 4.4% of weibos were found to discuss the most popular Twitter topics. Our results reveal significant differences in social attention on the two platforms, with most popular topics on Weibo relating to entertainment while most tweets corresponded to cultural or political contents that is practically non existent in Weibo.",10.1145/2872518.2890562,https://doi.org/10.1145/2872518.2890562,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450341448,2016,Topical differences between Chinese language Twitter and Sina Weibo,"Zhang, Qian and Goncalves, Bruno",inproceedings,10.1145/2872518.2890562,
10.1145/2939672.2939673,10.1145/2939672.2939673,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","collaborative joint learning, knowledge base embedding, recommender systems",10,353–362,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Among different recommendation techniques, collaborative filtering usually suffer from limited performance due to the sparsity of user-item interactions. To address the issues, auxiliary information is usually used to boost the performance. Due to the rapid collection of information on the web, the knowledge base provides heterogeneous information including both structured and unstructured data with different semantics, which can be consumed by various applications. In this paper, we investigate how to leverage the heterogeneous information in a knowledge base to improve the quality of recommender systems. First, by exploiting the knowledge base, we design three components to extract items' semantic representations from structural content, textual content and visual content, respectively. To be specific, we adopt a heterogeneous network embedding method, termed as TransR, to extract items' structural representations by considering the heterogeneity of both nodes and relationships. We apply stacked denoising auto-encoders and stacked convolutional auto-encoders, which are two types of deep learning based embedding techniques, to extract items' textual representations and visual representations, respectively. Finally, we propose our final integrated framework, which is termed as Collaborative Knowledge Base Embedding (CKE), to jointly learn the latent representations in collaborative filtering as well as items' semantic representations from the knowledge base. To evaluate the performance of each embedding component as well as the whole system, we conduct extensive experiments with two real-world datasets from different scenarios. The results reveal that our approaches outperform several widely adopted state-of-the-art recommendation methods.",10.1145/2939672.2939673,https://doi.org/10.1145/2939672.2939673,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Collaborative Knowledge Base Embedding for Recommender Systems,"Zhang, Fuzheng and Yuan, Nicholas Jing and Lian, Defu and Xie, Xing and Ma, Wei-Ying",inproceedings,10.1145/2939672.2939673,
10.1145/2939672.2939683,10.1145/2939672.2939683,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","brands recommendation, recommendation explanation, topic modeling",10,175–184,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"To combat the ease of online shopping in pajamas, offline mall owners focus increasingly on driving satisfaction and improving retention by identifying customers' preferences. However, most of these studies are based on customers' offline consuming history only. Benefiting from the internet, we can also get customers' online behaviors, such as the search logs, web browsing logs, online shopping logs, and so on. Might these seemingly irrelevant information from two different modalities (i.e. online and offline) be somehow interrelated? How can we make use of the online behaviors and offline actions jointly to promote recommendation for offline retailing? In this study, we formulate this task as a cross-modality recommendation problem, and present its solution via a proposed probabilistic graphical model, called Online-to-Offline Topic Modeling (O2OTM). Specifically, this method explicitly models the relationships between online and offline topics so that the likelihood of both online and offline behaviors is maximized. Then, the recommendation is made only based on the pairs of online and offline topics, denoted by (t,l), with high values of lift, such that the existence of the online topic $t$ greatly increases the response on the corresponding offline topic $l$ compared with the average response for the population without the online topic t. Furthermore, we evaluate this solution in both live and retrospect experiments. The real-world deployment of this model for the anniversary promotion campaign of a famous shopping mall in Beijing shows that our approach increases the occurred customer purchases per promotion message by 29.75% compared with the baseline. Also, our model finds some interesting interpretable relationships between the online search topics and offline brand topics.",10.1145/2939672.2939683,https://doi.org/10.1145/2939672.2939683,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,From Online Behaviors to Offline Retailing,"Luo, Ping and Yan, Su and Liu, Zhiqiang and Shen, Zhiyong and Yang, Shengwen and He, Qing",inproceedings,10.1145/2939672.2939683,
10.1145/2939672.2939684,10.1145/2939672.2939684,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","big data, spark, statistical model",10,363–372,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Generalized linear model (GLM) is a widely used class of models for statistical inference and response prediction problems. For instance, in order to recommend relevant content to a user or optimize for revenue, many web companies use logistic regression models to predict the probability of the user's clicking on an item (e.g., ad, news article, job). In scenarios where the data is abundant, having a more fine-grained model at the user or item level would potentially lead to more accurate prediction, as the user's personal preferences on items and the item's specific attraction for users can be better captured. One common approach is to introduce ID-level regression coefficients in addition to the global regression coefficients in a GLM setting, and such models are called generalized linear mixed models (GLMix) in the statistical literature. However, for big data sets with a large number of ID-level coefficients, fitting a GLMix model can be computationally challenging. In this paper, we report how we successfully overcame the scalability bottleneck by applying parallelized block coordinate descent under the Bulk Synchronous Parallel (BSP) paradigm. We deployed the model in the LinkedIn job recommender system, and generated 20% to 40% more job applications for job seekers on LinkedIn.",10.1145/2939672.2939684,https://doi.org/10.1145/2939672.2939684,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,GLMix: Generalized Linear Mixed Models For Large-Scale Response Prediction,"Zhang, XianXing and Zhou, Yitong and Ma, Yiming and Chen, Bee-Chung and Zhang, Liang and Agarwal, Deepak",inproceedings,10.1145/2939672.2939684,
10.1145/2939672.2939688,10.1145/2939672.2939688,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","A/B test, prediction, variance reduction",10,235–244,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Nowadays, the development of most leading web services is controlled by online experiments that qualify and quantify the steady stream of their updates achieving more than a thousand concurrent experiments per day. Despite the increasing need for running more experiments, these services are limited in their user traffic. This situation leads to the problem of finding a new or improving existing key performance metric with a higher sensitivity and lower variance. We focus on the problem of variance reduction for engagement metrics of user loyalty that are widely used in A/B testing of web services. We develop a general framework that is based on evaluation of the mean difference between the actual and the approximated values of the key performance metric (instead of the mean of this metric). On the one hand, it allows us to incorporate the state-of-the-art techniques widely used in randomized experiments of clinical and social research, but limitedly used in online evaluation. On the other hand, we propose a new class of methods based on advanced machine learning algorithms, including ensembles of decision trees, that, to the best of our knowledge, have not been applied earlier to the problem of variance reduction. We validate the variance reduction approaches on a very large set of real large-scale A/B experiments run at Yandex for different engagement metrics of user loyalty. Our best approach demonstrates $63%$ average variance reduction (which is equivalent to 63% saved user traffic) and detects the treatment effect in $2$ times more A/B experiments.",10.1145/2939672.2939688,https://doi.org/10.1145/2939672.2939688,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Boosted Decision Tree Regression Adjustment for Variance Reduction in Online Controlled Experiments,"Poyarkov, Alexey and Drutsa, Alexey and Khalyavin, Andrey and Gusev, Gleb and Serdyukov, Pavel",inproceedings,10.1145/2939672.2939688,
10.1145/2939672.2939692,10.1145/2939672.2939692,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","email, machine learning, optimization",10,97–106,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Online social networking services distribute various types of messages to their members. Common types of messages include news, connection requests, membership notifications, promotions and event notifications. Such communication, if used judiciously, can provide an enormous value to members thereby keeping them engaged. However sending a message for every instance of news, connection request, or the like can result in an overwhelming number of messages in a member's mailbox. This may result in reduced effectiveness of communication if the messages are not sufficiently relevant to the member's interests. It may also result in a poor brand perception of the networking service. In this paper we discuss our strategy and experience with regard to the problem of email volume optimization at LinkedIn. In particular, we present a cost-benefit analysis of sending emails, the key factors to administer an effective volume optimization, our algorithm for volume optimization, the architecture of the supporting system and experimental results from online A/B tests.",10.1145/2939672.2939692,https://doi.org/10.1145/2939672.2939692,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Email Volume Optimization at LinkedIn,"Gupta, Rupesh and Liang, Guanfeng and Tseng, Hsiao-Ping and Holur Vijay, Ravi Kiran and Chen, Xiaoyu and Rosales, Romer",inproceedings,10.1145/2939672.2939692,
10.1145/2939672.2939713,10.1145/2939672.2939713,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","censored data, display advertising, real-time bidding, unbiased learning",10,665–674,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"In real-time display advertising, ad slots are sold per impression via an auction mechanism. For an advertiser, the campaign information is incomplete --- the user responses (e.g, clicks or conversions) and the market price of each ad impression are observed only if the advertiser's bid had won the corresponding ad auction. The predictions, such as bid landscape forecasting, click-through rate (CTR) estimation, and bid optimisation, are all operated in the pre-bid stage with full-volume bid request data. However, the training data is gathered in the post-bid stage with a strong bias towards the winning impressions. A common solution for learning over such censored data is to reweight data instances to correct the discrepancy between training and prediction. However, little study has been done on how to obtain the weights independent of previous bidding strategies and consequently integrate them into the final CTR prediction and bid generation steps. In this paper, we formulate CTR estimation and bid optimisation under such censored auction data. Derived from a survival model, we show that historic bid information is naturally incorporated to produce Bid-aware Gradient Descents (BGD) which controls both the importance and the direction of the gradient to achieve unbiased learning. The empirical study based on two large-scale real-world datasets demonstrates remarkable performance gains from our solution. The learning framework has been deployed on Yahoo!'s real-time bidding platform and provided 2.97% AUC lift for CTR estimation and 9.30% eCPC drop for bid optimisation in an online A/B test.",10.1145/2939672.2939713,https://doi.org/10.1145/2939672.2939713,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Bid-aware Gradient Descent for Unbiased Learning with Censored Data in Display Advertising,"Zhang, Weinan and Zhou, Tianxiong and Wang, Jun and Xu, Jian",inproceedings,10.1145/2939672.2939713,
10.1145/2939672.2939746,10.1145/2939672.2939746,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","cold-start, online learning, recommender systems",10,815–824,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"People often ask others for restaurant recommendations as a way to discover new dining experiences. This makes restaurant recommendation an exciting scenario for recommender systems and has led to substantial research in this area. However, most such systems behave very differently from a human when asked for a recommendation. The goal of this paper is to begin to reduce this gap. In particular, humans can quickly establish preferences when asked to make a recommendation for someone they do not know. We address this cold-start recommendation problem in an online learning setting. We develop a preference elicitation framework to identify which questions to ask a new user to quickly learn their preferences. Taking advantage of latent structure in the recommendation space using a probabilistic latent factor model, our experiments with both synthetic and real world data compare different types of feedback and question selection strategies. We find that our framework can make very effective use of online user feedback, improving personalized recommendations over a static model by 25% after asking only 2 questions. Our results demonstrate dramatic benefits of starting from offline embeddings, and highlight the benefit of bandit-based explore-exploit strategies in this setting.",10.1145/2939672.2939746,https://doi.org/10.1145/2939672.2939746,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Towards Conversational Recommender Systems,"Christakopoulou, Konstantina and Radlinski, Filip and Hofmann, Katja",inproceedings,10.1145/2939672.2939746,
10.1145/2939672.2939780,10.1145/2939672.2939780,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","brownian motion, language evolution, recommendation, review community, topic modeling, user experience",10,1075–1084,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Online review communities are dynamic as users join and leave, adopt new vocabulary, and adapt to evolving trends. Recent work has shown that recommender systems benefit from explicit consideration of user experience. However, prior work assumes a fixed number of discrete experience levels, whereas in reality users gain experience and mature continuously over time. This paper presents a new model that captures the continuous evolution of user experience, and the resulting language model in reviews and other posts. Our model is unsupervised and combines principles of Geometric Brownian Motion, Brownian Motion, and Latent Dirichlet Allocation to trace a smooth temporal progression of user experience and language model respectively. We develop practical algorithms for estimating the model parameters from data and for inference with our model (e.g., to recommend items). Extensive experiments with five real-world datasets show that our model not only fits data better than discrete-model baselines, but also outperforms state-of-the-art methods for predicting item ratings.",10.1145/2939672.2939780,https://doi.org/10.1145/2939672.2939780,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Continuous Experience-aware Language Model,"Mukherjee, Subhabrata and G\""{u}nnemann, Stephan and Weikum, Gerhard",inproceedings,10.1145/2939672.2939780,
10.1145/2939672.2939792,10.1145/2939672.2939792,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","binge watching, censored poisson regression, mixture model",10,1215–1224,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Easy accessibility can often lead to over-consumption, as seen in food and alcohol habits. On video on-demand (VOD) services, this has recently been referred to as binge watching, where potentially entire seasons of TV shows are consumed in a single viewing session. While a user viewership model may reveal this binging behavior, creating an accurate model has several challenges, including censored data, deviations in the population, and the need to consider external influences on consumption habits. In this paper, we introduce a novel statistical mixture model that incorporates these factors and presents a first of its kind characterization of viewer consumption behavior using a real-world dataset that includes playback data from a VOD service. From our modeling, we tackle various predictive tasks to infer the consumption decisions of a user in a viewing session, including estimating the number of episodes they watch and classifying if they continue watching another episode. Using these insights, we then identify binge watching sessions based on deviation from normal viewing behavior. We observe different types of binging behavior, that binge watchers often view certain content out-of-order, and that binge watching is not a consistent behavior among our users. These insights and our findings have application in VOD revenue generation, consumer health applications, and customer retention analysis.",10.1145/2939672.2939792,https://doi.org/10.1145/2939672.2939792,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Just One More: Modeling Binge Watching Behavior,"Trouleau, William and Ashkan, Azin and Ding, Weicong and Eriksson, Brian",inproceedings,10.1145/2939672.2939792,
10.1145/2939672.2939801,10.1145/2939672.2939801,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","clustering, deep learning, email, lstm, semantics",10,955–964,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"In this paper we propose and investigate a novel end-to-end method for automatically generating short email responses, called Smart Reply. It generates semantically diverse suggestions that can be used as complete email responses with just one tap on mobile. The system is currently used in Inbox by Gmail and is responsible for assisting with 10% of all mobile responses. It is designed to work at very high throughput and process hundreds of millions of messages daily. The system exploits state-of-the-art, large-scale deep learning.We describe the architecture of the system as well as the challenges that we faced while building it, like response diversity and scalability. We also introduce a new method for semantic clustering of user-generated content that requires only a modest amount of explicitly labeled data.",10.1145/2939672.2939801,https://doi.org/10.1145/2939672.2939801,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Smart Reply: Automated Response Suggestion for Email,"Kannan, Anjuli and Kurach, Karol and Ravi, Sujith and Kaufmann, Tobias and Tomkins, Andrew and Miklos, Balint and Corrado, Greg and Lukacs, Laszlo and Ganea, Marina and Young, Peter and Ramavajjala, Vivek",inproceedings,10.1145/2939672.2939801,
10.1145/2939672.2939852,10.1145/2939672.2939852,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","communication dynamics, self-exciting point process, social media",10,1405–1414,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"The problem to accurately and parsimoniously characterize random series of events (RSEs) seen in the Web, such as Yelp reviews or Twitter hashtags, is not trivial. Reports found in the literature reveal two apparent conflicting visions of how RSEs should be modeled. From one side, the Poissonian processes, of which consecutive events follow each other at a relatively regular time and should not be correlated. On the other side, the self-exciting processes, which are able to generate bursts of correlated events. The existence of many and sometimes conflicting approaches to model RSEs is a consequence of the unpredictability of the aggregated dynamics of our individual and routine activities, which sometimes show simple patterns, but sometimes results in irregular rising and falling trends. In this paper we propose a parsimonious way to characterize general RSEs, namely the Burstiness Scale (BuSca) model. BuSca views each RSE as a mix of two independent process: a Poissonian and a self-exciting one. Here we describe a fast method to extract the two parameters of BuSca that, together, gives the burstiness scale ψ, which represents how much of the RSE is due to bursty and viral effects. We validated our method in eight diverse and large datasets containing real random series of events seen in Twitter, Yelp, e-mail conversations, Digg, and online forums. Results showed that, even using only two parameters, BuSca is able to accurately describe RSEs seen in these diverse systems, what can leverage many applications.",10.1145/2939672.2939852,https://doi.org/10.1145/2939672.2939852,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Burstiness Scale: A Parsimonious Model for Characterizing Random Series of Events,"Alves, Rodrigo Augusto da Silva and Assuncao, Renato Martins and Vaz de Melo, Pedro Olmo Stancioli",inproceedings,10.1145/2939672.2939852,
10.1145/2939672.2939873,10.1145/2939672.2939873,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","click-through rate, headline prediction, large-scale analysis, online news analysis",10,1645–1654,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Headlines are particularly important for online news outlets where there are many similar news stories competing for users' attention. Traditionally, journalists have followed rules-of-thumb and experience to master the art of crafting catchy headlines, but with the valuable resource of large-scale click-through data of online news articles, we can apply quantitative analysis and text mining techniques to acquire an in-depth understanding of headlines. In this paper, we conduct a large-scale analysis and modeling of 150K news articles published over a period of four months on the Yahoo home page. We define a simple method to measure click-value of individual words, and analyze how temporal trends and linguistic attributes affect click-through rate (CTR). We then propose a novel generative model, headline click-based topic model (HCTM), that extends latent Dirichlet allocation (LDA) to reveal the effect of topical context on the click-value of words in headlines. HCTM leverages clicks in aggregate on previously published headlines to identify words for headlines that will generate more clicks in the future. We show that by jointly taking topics and clicks into account we can detect changes in user interests within topics. We evaluate HCTM in two different experimental settings and compare its performance with ALDA (adapted LDA), LDA, and TextRank. The first task, full headline, is to retrieve full headline used for a news article given the body of news article. The second task, good headline, is to specifically identify words in the headline that have high click values for current news audience. For full headline task, our model performs on par with ALDA, a state-of-the art web-page summarization method that utilizes click-through information. For good headline task, which is of more practical importance to both individual journalists and online news outlets, our model significantly outperforms all other comparative methods.",10.1145/2939672.2939873,https://doi.org/10.1145/2939672.2939873,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,How to Compete Online for News Audience: Modeling Words that Attract Clicks,"Kim, Joon Hee and Mantrach, Amin and Jaimes, Alejandro and Oh, Alice",inproceedings,10.1145/2939672.2939873,
10.1145/2939672.2945388,10.1145/2939672.2945388,KDD.bib,1,['KDD.bib'],8,KDD '16,"San Francisco, California, USA","business analytics, machine learning, machine learning platforms, predictive modeling",2,2139–2140,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Predictive modeling is the art of building statistical models that forecast probabilities and trends of future events. It has broad applications in industry across different domains. Some popular examples include user intention predictions, lead scoring, churn analysis, etc. In this tutorial, we will focus on the best practice of predictive modeling in the big data era and its applications in industry, with motivating examples across a range of business tasks and relevance products. We will start with an overview of how predictive modeling helps power and drive various key business use cases. We will introduce the essential concepts and state of the art in building end-to-end predictive modeling solutions, and discuss the challenges, key technologies, and lessons learned from our practice, including case studies of LinkedIn feed relevance and a platform for email response prediction. Moreover, we will discuss some practical solutions of building predictive modeling platform to scale the modeling efforts for data scientists and analysts, along with an overview of popular tools and platforms used across the industry.",10.1145/2939672.2945388,https://doi.org/10.1145/2939672.2945388,"New York, NY, USA",Association for Computing Machinery,9781450342322,2016,Business Applications of Predictive Modeling at Scale,"Zhu, Qiang and Guo, Songtao and Ogilvie, Paul and Liu, Yan",inproceedings,10.1145/2939672.2945388,
10.1145/2959100.2959102,10.1145/2959100.2959102,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","item cold start problem, product representation, twitter",4,451–454,Proceedings of the 10th ACM Conference on Recommender Systems,"One of the strong points of E-commerce websites is that they are often abundant with product reviews from consumers who experienced the products and testify to the usefulness of the products or otherwise. These reviews are helpful for consumers to optimize their purchasing decisions. However, while popular products receive many reviews, many other products do not have an adequate number of reviews leading to the cold item problem. In this proposal, we propose a solution outline for the cold item problem by automatically generating reviews and predicting ratings for the cold products from available reviews of similar products in e-commerce websites as well as users' opinion shared in the microblogging platforms such as Twitter. We propose a framework to build a formal semantic representation of products from unstructured product descriptions, user reviews as well as user ratings. Such presentations assist us to measure product similarity and relatedness in a accurate and cost-effective way. Besides, we propose a model to generate additional reviews for a cold product by mining users' posts shared on medium such as Twitter and transfer them to the e-commerce website. Preliminary experiments show promising results in finding products similar to the cold products.",10.1145/2959100.2959102,https://doi.org/10.1145/2959100.2959102,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Mining Information for the Cold-Item Problem,"Pourgholamali, Fatemeh",inproceedings,10.1145/2959100.2959102,
10.1145/2959100.2959131,10.1145/2959100.2959131,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","probabilistic logic programming, knowledge graph based recommendations, graph based matrix factorization",8,325–332,Proceedings of the 10th ACM Conference on Recommender Systems,"Improving the performance of recommender systems using knowledge graphs is an important task. There have been many hybrid systems proposed in the past that use a mix of content-based and collaborative filtering techniques to boost the performance. More recently, some work has focused on recommendations that use external knowledge graphs (KGs) to supplement content-based recommendation. In this paper, we investigate three methods for making KG based recommendations using a general-purpose probabilistic logic system called ProPPR. The simplest of the models, EntitySim, uses only the links of the graph. We then extend the model to TypeSim that also uses the types of the entities to boost its generalization capabilities. Next, we develop a graph based latent factor model, GraphLF, which combines the strengths of latent factorization with graphs. We compare our approaches to a recently proposed state-of-the-art graph recommendation method on two large datasets, Yelp and MovieLens-100K. The experiments illustrate that our approaches can give large performance improvements. Additionally, we demonstrate that knowledge graphs give maximum advantage when the dataset is sparse, and gradually become redundant as more training data becomes available, and hence are most useful in cold-start settings.",10.1145/2959100.2959131,https://doi.org/10.1145/2959100.2959131,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Personalized Recommendations using Knowledge Graphs: A Probabilistic Logic Programming Approach,"Catherine, Rose and Cohen, William",inproceedings,10.1145/2959100.2959131,
10.1145/2959100.2959132,10.1145/2959100.2959132,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","item recommendation, collaborative filtering, Bayesian statistics",8,333–340,Proceedings of the 10th ACM Conference on Recommender Systems,"Short-length random walks on the bipartite user-item graph have recently been shown to provide accurate and diverse recommendations. Nonetheless, these approaches suffer from severe time and space requirements, which can be alleviated via random walk sampling, at the cost of reduced recommendation quality. In addition, these approaches ignore users' ratings, which further limits their expressiveness. In this paper, we introduce a computationally efficient graph-based approach for collaborative filtering based on short-path enumeration. Moreover, we propose three scoring functions based on the Bayesian paradigm that effectively exploit distributional aspects of the users' ratings. We experiment with seven publicly available datasets against state-of-the-art graph-based and matrix factorization approaches. Our empirical results demonstrate the effectiveness of the proposed approach, with significant improvements in most settings. Furthermore, analytical results demonstrate its efficiency compared to other graph-based approaches.",10.1145/2959100.2959132,https://doi.org/10.1145/2959100.2959132,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Efficient Bayesian Methods for Graph-based Recommendation,"Lopes, Ramon and Assun\c{c}\~{a}o, Renato and Santos, Rodrygo L.T.",inproceedings,10.1145/2959100.2959132,
10.1145/2959100.2959133,10.1145/2959100.2959133,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","grade prediction, multi-granularity grouping, top-n course ranking",8,183–190,Proceedings of the 10th ACM Conference on Recommender Systems,"Automated course recommendation can help deliver personalized and effective college advising and degree planning. Nearest neighbor and matrix factorization based collaborative filtering approaches have been applied to student-course grade data to help students select suitable courses. However, the student-course enrollment patterns exhibit grouping structures that are tied to the student and course academic features, which lead to grade data that are not missing at random (NMAR). Existing approaches for dealing with NMAR data, such as Response-aware and context-aware matrix factorization, do not model NMAR data in terms of the user and item features and are not designed with the characteristics of grade data in mind. In this work we investigate how the student and course academic features influence the enrollment patterns and we use these features to define student and course groups at various levels of granularity. We show how these groups can be used to design grade prediction and top-n course ranking models for neighborhood-based user collaborative filtering, matrix factorization and popularity-based ranking approaches. These methods give lower grade prediction error and more accurate top-n course rankings than the other methods that do not take domain knowledge into account.",10.1145/2959100.2959133,https://doi.org/10.1145/2959100.2959133,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Domain-Aware Grade Prediction and Top-n Course Recommendation,"Elbadrawy, Asmaa and Karypis, George",inproceedings,10.1145/2959100.2959133,
10.1145/2959100.2959141,10.1145/2959100.2959141,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","conformity, rating prediction, user behavior",4,269–272,Proceedings of the 10th ACM Conference on Recommender Systems,"Conformity has a strong influence to user behaviors, even in online environment. When surfing online, users are usually flooded with others' opinions. These opinions implicitly contribute to the user's ongoing behaviors. However, there is no research work modeling online conformity yet. In this paper, we model user's conformity in online rating sites. We conduct analysis using real data to show the existence and strength of conformity in these scenarios. We propose a matrix-factorization-based conformity modeling technique to improve the accuracy of rating prediction. Experiments show that our model outperforms existing works significantly (with a relative improvement of 11.72% on RMSE). Therefore, we draw the conclusion that conformity modeling is important for understanding user behaviors and can contribute to further improve the online recommender systems.",10.1145/2959100.2959141,https://doi.org/10.1145/2959100.2959141,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Are You Influenced by Others When Rating? Improve Rating Prediction by Conformity Modeling,"Liu, Yiming and Cao, Xuezhi and Yu, Yong",inproceedings,10.1145/2959100.2959141,
10.1145/2959100.2959144,10.1145/2959100.2959144,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","machine learning, recommender systems",4,211–214,Proceedings of the 10th ACM Conference on Recommender Systems,"When the Netflix Prize launched in 2006, it put a spotlight on the importance and use of recommender systems in real-world applications. The competition provided many lessons, and many more have been learned since the Grand Prize was awarded in 2009. The use of recommender systems in industry has continued to grow driven by the availability of many kinds of user data and the continued interest for the area within the research community. In this paper, we will describe what we see as the past, present, and future of recommender systems from an industry perspective.",10.1145/2959100.2959144,https://doi.org/10.1145/2959100.2959144,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,"Past, Present, and Future of Recommender Systems: An Industry Perspective","Amatriain, Xavier and Basilico, Justin",inproceedings,10.1145/2959100.2959144,
10.1145/2959100.2959146,10.1145/2959100.2959146,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","GPS-tagged social media, contextual modeling, user profile",8,253–260,Proceedings of the 10th ACM Conference on Recommender Systems,"Discovering what people are known for is valuable to many important applications such as recommender systems. Unlike an individual's personal interests, what a user is known for is reflected by the views of others, and is often not easily discerned for a long-tail of the vast majority of users. In this paper, we tackle the problem of discovering what users are known for through a probabilistic model called Bayesian Contextual Poisson Factorization. Moving beyond just modeling user's content, it naturally models and integrates additional contextual factors, concretely, user's geo-spatial footprints and social influence, to overcome noisy online activities and social relations. Through GPS-tagged social media datasets, we find that the proposed method can improve known-for prediction performance by 17.5% in precision and 20.9% in recall on average, and that it can capture the implicit relationships between a user's known-for profile and her content, geo-spatial and social influence.",10.1145/2959100.2959146,https://doi.org/10.1145/2959100.2959146,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Discovering What You're Known For: A Contextual Poisson Factorization Approach,"Lu, Haokai and Caverlee, James and Niu, Wei",inproceedings,10.1145/2959100.2959146,
10.1145/2959100.2959148,10.1145/2959100.2959148,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","distrust, trust inference, trust network, trust propagation and aggregation, trust-aware social recommender",8,301–308,Proceedings of the 10th ACM Conference on Recommender Systems,"Social recommendation takes advantage of the influence of social relationships in decision making and the ready availability of social data through social networking systems. Trust relationships in particular can be exploited in such systems for rating prediction and recommendation, which has been shown to have the potential for improving the quality of the recommender and alleviating the issue of data sparsity, cold start, and adversarial attacks. An appropriate trust inference mechanism is necessary in extending the knowledge base of trust opinions and tackling the issue of limited trust information due to connection sparsity of social networks. In this work, we offer a new solution to trust inference in social networks to provide a better knowledge base for trust-aware recommender systems. We propose using a semiring framework as a nonlinear way to combine trust evidences for inferring trust, where trust relationship is model as 2-D vector containing both trust and certainty information. The trust propagation and aggregation rules, as the building blocks of our trust inference scheme, are based upon the properties of trust relationships. In our approach, both trust and distrust (i.e., positive and negative trust) are considered, and opinion conflict resolution is supported. We evaluate the proposed approach on real-world datasets, and show that our trust inference framework has high accuracy, and is capable of handling trust relationship in large networks. The inferred trust relationships can enlarge the knowledge base for trust information and improve the quality of trust-aware recommendation.",10.1145/2959100.2959148,https://doi.org/10.1145/2959100.2959148,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,STAR: Semiring Trust Inference for Trust-Aware Social Recommenders,"Gao, Peixin and Miao, Hui and Baras, John S. and Golbeck, Jennifer",inproceedings,10.1145/2959100.2959148,
10.1145/2959100.2959149,10.1145/2959100.2959149,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","submodular function, recommender systems, diverse recommendation, diverse ranking, coverage",8,15–22,Proceedings of the 10th ACM Conference on Recommender Systems,"We consider the problem of generating diverse, personalized recommendations such that a small set of recommended items covers a broad range of the user's interests. We represent items in a similarity graph, and we formulate the relevance/diversity trade-off as finding a small set of unrated items that best covers a subset of items positively rated by the user. In contrast to previous approaches, our method does not rely on an explicit trade-off between a relevance objective and a diversity objective, as the estimations of relevance and diversity are implicit in the coverage criterion. We show on several benchmark datasets that our approach compares favorably to the state-of-the-art diversification methods according to various relevance and diversity measures.",10.1145/2959100.2959149,https://doi.org/10.1145/2959100.2959149,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,A Coverage-Based Approach to Recommendation Diversity On Similarity Graph,"Puthiya Parambath, Shameem A. and Usunier, Nicolas and Grandvalet, Yves",inproceedings,10.1145/2959100.2959149,
10.1145/2959100.2959165,10.1145/2959100.2959165,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","collaborative filtering, contexual information, deep learning, document modeling, neural network' context-aware recommendation, recommender system",8,233–240,Proceedings of the 10th ACM Conference on Recommender Systems,"Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.",10.1145/2959100.2959165,https://doi.org/10.1145/2959100.2959165,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Convolutional Matrix Factorization for Document Context-Aware Recommendation,"Kim, Donghyun and Park, Chanyoung and Oh, Jinoh and Lee, Sungyoung and Yu, Hwanjo",inproceedings,10.1145/2959100.2959165,
10.1145/2959100.2959170,10.1145/2959100.2959170,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","cold-start, collaborative filtering, explicit feedback, recommender systems, tensor factorization",8,91–98,Proceedings of the 10th ACM Conference on Recommender Systems,"Conventional collaborative filtering techniques treat a top-n recommendations problem as a task of generating a list of the most relevant items. This formulation, however, disregards an opposite -- avoiding recommendations with completely irrelevant items. Due to that bias, standard algorithms, as well as commonly used evaluation metrics, become insensitive to negative feedback. In order to resolve this problem we propose to treat user feedback as a categorical variable and model it with users and items in a ternary way. We employ a third-order tensor factorization technique and implement a higher order folding-in method to support online recommendations. The method is equally sensitive to entire spectrum of user ratings and is able to accurately predict relevant items even from a negative only feedback. Our method may partially eliminate the need for complicated rating elicitation process as it provides means for personalized recommendations from the very beginning of an interaction with a recommender system. We also propose a modification of standard metrics which helps to reveal unwanted biases and account for sensitivity to a negative feedback. Our model achieves state-of-the-art quality in standard recommendation tasks while significantly outperforming other methods in the cold-start ""no-positive-feedback"" scenarios.",10.1145/2959100.2959170,https://doi.org/10.1145/2959100.2959170,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Fifty Shades of Ratings: How to Benefit from a Negative Feedback in Top-N Recommendations Tasks,"Frolov, Evgeny and Oseledets, Ivan",inproceedings,10.1145/2959100.2959170,
10.1145/2959100.2959178,10.1145/2959100.2959178,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","determinantal point processes, mcmc inference, recommender systems",8,349–356,Proceedings of the 10th ACM Conference on Recommender Systems,"Determinantal point processes (DPPs) are an emerging model for encoding probabilities over subsets, such as shopping baskets, selected from a ground set, such as an item catalog. They have recently proved to be appealing models for a number of machine learning tasks, including product recommendation. DPPs are parametrized by a positive semi-definite kernel matrix. Prior work has shown that using a low-rank factorization of this kernel provides scalability improvements that open the door to training on large-scale datasets and computing online recommendations, both of which are infeasible with standard DPP models that use a full-rank kernel. A low-rank DPP model can be trained using an optimization-based method, such as stochastic gradient ascent, to find a point estimate of the kernel parameters, which can be performed efficiently on large-scale datasets. However, this approach requires careful tuning of regularization parameters to prevent overfitting and provide good predictive performance, which can be computationally expensive. In this paper we present a Bayesian method for learning a low-rank factorization of this kernel, which provides automatic control of regularization. We show that our Bayesian low-rank DPP model can be trained efficiently using stochastic gradient Hamiltonian Monte Carlo (SGHMC). Our Bayesian model generally provides better predictive performance on several real-world product recommendation datasets than optimization-based low-rank DPP models trained using stochastic gradient ascent, and better performance than several state-of-the art recommendation methods in many cases.",10.1145/2959100.2959178,https://doi.org/10.1145/2959100.2959178,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Bayesian Low-Rank Determinantal Point Processes,"Gartrell, Mike and Paquet, Ulrich and Koenigstein, Noam",inproceedings,10.1145/2959100.2959178,
10.1145/2959100.2959182,10.1145/2959100.2959182,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","matrix factorization, item embedding, implicit feedback, collaborative filtering",8,59–66,Proceedings of the 10th ACM Conference on Recommender Systems,"Matrix factorization (MF) models and their extensions are standard in modern recommender systems. MF models decompose the observed user-item interaction matrix into user and item latent factors. In this paper, we propose a co-factorization model, CoFactor, which jointly decomposes the user-item interaction matrix and the item-item co-occurrence matrix with shared item latent factors. For each pair of items, the co-occurrence matrix encodes the number of users that have consumed both items. CoFactor is inspired by the recent success of word embedding models (e.g., word2vec) which can be interpreted as factorizing the word co-occurrence matrix. We show that this model significantly improves the performance over MF models on several datasets with little additional computational overhead. We provide qualitative results that explain how CoFactor improves the quality of the inferred factors and characterize the circumstances where it provides the most significant improvements.",10.1145/2959100.2959182,https://doi.org/10.1145/2959100.2959182,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Factorization Meets the Item Embedding: Regularizing Matrix Factorization with Item Co-occurrence,"Liang, Dawen and Altosaar, Jaan and Charlin, Laurent and Blei, David M.",inproceedings,10.1145/2959100.2959182,
10.1145/2959100.2959185,10.1145/2959100.2959185,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","collaborative filtering, local models, slim, top-n recommendation",8,67–74,Proceedings of the 10th ACM Conference on Recommender Systems,"Item-based approaches based on SLIM (Sparse LInear Methods) have demonstrated very good performance for top-N recommendation; however they only estimate a single model for all the users. This work is based on the intuition that not all users behave in the same way -- instead there exist subsets of like-minded users. By using different item-item models for these user subsets, we can capture differences in their preferences and this can lead to improved performance for top-N recommendations. In this work, we extend SLIM by combining global and local SLIM models. We present a method that computes the prediction scores as a user-specific combination of the predictions derived by a global and local item-item models. We present an approach in which the global model, the local models, their user-specific combination, and the assignment of users to the local models are jointly optimized to improve the top-N recommendation performance. Our experiments show that the proposed method improves upon the standard SLIM model and outperforms competing top-N recommendation approaches.",10.1145/2959100.2959185,https://doi.org/10.1145/2959100.2959185,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Local Item-Item Models For Top-N Recommendation,"Christakopoulou, Evangelia and Karypis, George",inproceedings,10.1145/2959100.2959185,
10.1145/2959100.2959186,10.1145/2959100.2959186,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","foundations of recommender systems, recommendation goals and purposes",4,7–10,Proceedings of the 10th ACM Conference on Recommender Systems,"The purpose of recommenders is often summarized as ""help the users find relevant items"", and the predominant operationalization of this goal has been to focus on the ability to numerically estimate the users' preferences for unseen items or to provide users with item lists ranked in accordance to the estimated preferences. This dominant, albeit narrow, view of the recommendation problem has been tremendously helpful in advancing research in different ways, e.g., through the establishment of standardized evaluation procedures and metrics. In reality, recommender systems can serve a variety of purposes from the point of view of both consumers and providers. Most of the purposes, however, are significantly underexplored, even though many of them are arguably more aligned with the real-world expectations for recommenders than our current predominant paradigm. Therefore, it is important to revisit our conceptualizations of the potential goals of recommenders and their operationalization as research problems. In this paper, we discuss a framework of recommendation goals and purposes and highlight possible future directions and challenges related to the operationalization of such alternative problem formulations.",10.1145/2959100.2959186,https://doi.org/10.1145/2959100.2959186,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Recommendations with a Purpose,"Jannach, Dietmar and Adomavicius, Gediminas",inproceedings,10.1145/2959100.2959186,
10.1145/2959100.2959194,10.1145/2959100.2959194,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","machine learning, recommender systems",1,433,Proceedings of the 10th ACM Conference on Recommender Systems,"In 2006, Netflix announced a $1M prize competition to advance recommendation algorithms. The recommendation problem was simplified as the accuracy in predicting a user rating measured by the Root Mean Squared Error. While that formulation helped get the attention of the research community, it put the focus on the wrong approach and metric while leaving many important factors out. In this tutorial we will describe the advances in Recommender Systems in the last 10 years from an industry perspective based on the instructors' personal experience at companies like Quora, LinkedIn, Netflix, or Yahoo! We will do so in the form of different lessons learned through the years.Some of those lessons will describe the different components of modern recommender systems such as: personalized ranking, similarity, explanations, context-awareness, or multi-armed bandits. Others will also review the usage of novel algorithmic approaches such as Factorization Machines, Restricted Boltzmann Machines, SimRank, Deep Neural Networks, or Listwise Learning-to-rank. Others will dive into details of the importance of gathering the right data or using the correct optimization metric.But, most importantly, we will give many examples of prototypical industrial-scale recommender systems with special focus on those unsolved challenges that should define the future of the recommender systems area.",10.1145/2959100.2959194,https://doi.org/10.1145/2959100.2959194,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Tutorial: Lessons Learned from Building Real-life Recommender Systems,"Amatriain, Xavier and Agarwal, Deepak",inproceedings,10.1145/2959100.2959194,
10.1145/2959100.2959197,10.1145/2959100.2959197,RecSys.bib,1,['RecSys.bib'],8,RecSys '16,"Boston, Massachusetts, USA","algorithms, group recommendation, research challenges",2,427–428,Proceedings of the 10th ACM Conference on Recommender Systems,"Group recommender systems provide suggestions in contexts in which people operate in groups. The goal of this tutorial is to provide the RecSys audience with an overview on group recommendation. We will first formally introduce the problem of producing recommendations to groups, then present a survey based on the tasks performed by these systems. We will also analyze challenging topics like their evaluation, and present emerging aspects and techniques in this area. The tutorial will end with a summary that highlights open issues and research challenges.",10.1145/2959100.2959197,https://doi.org/10.1145/2959100.2959197,"New York, NY, USA",Association for Computing Machinery,9781450340359,2016,Group Recommender Systems,"Boratto, Ludovico",inproceedings,10.1145/2959100.2959197,
10.1145/2983323.2983347,10.1145/2983323.2983347,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","user response learning, real-time bidding, ctr estimation, bid optimization",10,679–688,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"Learning and predicting user responses, such as clicks and conversions, are crucial for many Internet-based businesses including web search, e-commerce, and online advertising. Typically, a user response model is established by optimizing the prediction accuracy, e.g., minimizing the error between the prediction and the ground truth user response. However, in many practical cases, predicting user responses is only part of a rather larger predictive or optimization task, where on one hand, the accuracy of a user response prediction determines the final (expected) utility to be optimized, but on the other hand, its learning may also be influenced from the follow-up stochastic process. It is, thus, of great interest to optimize the entire process as a whole rather than treat them independently or sequentially. In this paper, we take real-time display advertising as an example, where the predicted user's ad click-through rate (CTR) is employed to calculate a bid for an ad impression in the second price auction. We reformulate a common logistic regression CTR model by putting it back into its subsequent bidding context: rather than minimizing the prediction error, the model parameters are learned directly by optimizing campaign profit. The gradient update resulted from our formulations naturally fine-tunes the cases where the market competition is high, leading to a more cost-effective bidding. Our experiments demonstrate that, while maintaining comparable CTR prediction accuracy, our proposed user response learning leads to campaign profit gains as much as 78.2% for offline test and 25.5% for online A/B test over strong baselines.",10.1145/2983323.2983347,https://doi.org/10.1145/2983323.2983347,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,User Response Learning for Directly Optimizing Campaign Performance in Display Advertising,"Ren, Kan and Zhang, Weinan and Rong, Yifei and Zhang, Haifeng and Yu, Yong and Wang, Jun",inproceedings,10.1145/2983323.2983347,
10.1145/2983323.2983364,10.1145/2983323.2983364,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","parameter server, latent factor models, large scale recommender systems, factorization machines, collaborative filtering",10,1583–1592,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"Factorization Machines (FM) have been recognized as an effective learning paradigm for incorporating complex relations to improve item recommendation in recommender systems. However, one open issue of FM lies in its factorized representation (latent factors) for each feature in the observed feature space, a characteristic often resulting in a large parameter space. Therefore, training FM (in other words, learning a large number of parameters in FM) is a computationally expensive task. Our work targets to improve the scalability of FM by building it in a distributed environment. We propose a new system framework that integrates Parameter Server (PS) with the Map/Reduce (MR) framework. In addition to the data parallelism achieved via MR, our framework particularly benefits from PS for model parallelism, a critical characteristic for learning with a large number of parameters in FM. We further address two specific challenges in our system, namely, communication cost and parameter update collision. Through both offline and online experiments on recommendation tasks, we demonstrate that the proposed system framework succeeds in scaling up FM for very large datasets, while it also maintains competitive performance on recommendation quality compared to alternative baselines.",10.1145/2983323.2983364,https://doi.org/10.1145/2983323.2983364,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,Scaling Factorization Machines with Parameter Server,"Zhong, Erheng and Shi, Yue and Liu, Nathan and Rajan, Suju",inproceedings,10.1145/2983323.2983364,
10.1145/2983323.2983674,10.1145/2983323.2983674,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","user generated content, latent variable model, derivative creation",6,2239–2244,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"Many amateur creators now create derivative works and put them on the web. Although there are several factors that inspire the creation of derivative works, such factors cannot usually be observed on the web. In this paper, we propose a model for inferring latent factors from sequences of derivative work posting events. We assume a sequence to be a stochastic process incorporating the following three factors: (1) the original work's attractiveness, (2) the original work's popularity, and (3) the derivative work's popularity. To characterize content popularity, we use content ranking data and incorporate rank-biased popularity based on the creators' browsing behavior. Our main contributions are three-fold: (1) to the best of our knowledge, this is the first study modeling derivative creation activity, (2) by using a real-world dataset of music-related derivative work creation to evaluate our model, we showed the effectiveness of adopting all three factors to model derivative creation activity and onsidering creators' browsing behavior, and (3) we carried out qualitative experiments and showed that our model is useful in analyzing derivative creation activity in terms of category characteristics, temporal development of factors that trigger derivative work posting events, etc.",10.1145/2983323.2983674,https://doi.org/10.1145/2983323.2983674,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,Why Did You Cover That Song? Modeling N-th Order Derivative Creation with Content Popularity,"Tsukuda, Kosetsu and Hamasaki, Masahiro and Goto, Masataka",inproceedings,10.1145/2983323.2983674,
10.1145/2983323.2983740,10.1145/2983323.2983740,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","vandalism, trust, knowledge base, data quality",10,327–336,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"Wikidata is the new, large-scale knowledge base of the Wikimedia Foundation. Its knowledge is increasingly used within Wikipedia itself and various other kinds of information systems, imposing high demands on its integrity. Wikidata can be edited by anyone and, unfortunately, it frequently gets vandalized, exposing all information systems using it to the risk of spreading vandalized and falsified information. In this paper, we present a new machine learning-based approach to detect vandalism in Wikidata. We propose a set of 47 features that exploit both content and context information, and we report on 4 classifiers of increasing effectiveness tailored to this learning task. Our approach is evaluated on the recently published Wikidata Vandalism Corpus WDVC-2015 and it achieves an area under curve value of the receiver operating characteristic, ROC-AUC, of 0.991. It significantly outperforms the state of the art represented by the rule-based Wikidata Abuse Filter (0.865 ROC-AUC) and a prototypical vandalism detector recently introduced by Wikimedia within the Objective Revision Evaluation Service (0.859 ROC-AUC).",10.1145/2983323.2983740,https://doi.org/10.1145/2983323.2983740,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,Vandalism Detection in Wikidata,"Heindorf, Stefan and Potthast, Martin and Stein, Benno and Engels, Gregor",inproceedings,10.1145/2983323.2983740,
10.1145/2983323.2983758,10.1145/2983323.2983758,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","top-n recommendation, prfm, pairwise ranking, lambdafm, factorization machines, context-aware",10,227–236,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"State-of-the-art item recommendation algorithms, which apply Factorization Machines (FM) as a scoring function and pairwise ranking loss as a trainer (PRFM for short), have been recently investigated for the implicit feedback based context-aware recommendation problem (IFCAR). However, good recommenders particularly emphasize on the accuracy near the top of the ranked list, and typical pairwise loss functions might not match well with such a requirement. In this paper, we demonstrate, both theoretically and empirically, PRFM models usually lead to non-optimal item recommendation results due to such a mismatch. Inspired by the success of LambdaRank, we introduce Lambda Factorization Machines (LambdaFM), which is particularly intended for optimizing ranking performance for IFCAR. We also point out that the original lambda function suffers from the issue of expensive computational complexity in such settings due to a large amount of unobserved feedback. Hence, instead of directly adopting the original lambda strategy, we create three effective lambda surrogates by conducting a theoretical analysis for lambda from the top-N optimization perspective. Further, we prove that the proposed lambda surrogates are generic and applicable to a large set of pairwise ranking loss functions. Experimental results demonstrate LambdaFM significantly outperforms state-of-the-art algorithms on three real-world datasets in terms of four standard ranking measures.",10.1145/2983323.2983758,https://doi.org/10.1145/2983323.2983758,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,LambdaFM: Learning Optimal Ranking with Factorization Machines Using Lambda Surrogates,"Yuan, Fajie and Guo, Guibing and Jose, Joemon M. and Chen, Long and Yu, Haitao and Zhang, Weinan",inproceedings,10.1145/2983323.2983758,
10.1145/2983323.2983809,10.1145/2983323.2983809,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","retweet prediction, deep neural network, attention mechanism",10,75–84,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"On Twitter-like social media sites, the re-posting statuses or tweets of other users are usually considered to be the key mechanism for spreading information. How to predict whether a tweet will be retweeted by a user has received increasing attention in recent years. Previous methods studied the problem using various linguistic features, personal information of users, and many other manually constructed features to achieve the task. Usually, feature engineering is a laborious task, we require to obtain the external sources and they are difficult or not always available. Recently, deep learning methods have been used in the industry and research community for their ability to learn optimal features automatically and in many tasks, deep learning methods can achieve state-of-the art performance, such as natural language processing, computer vision, image classification and so on. In this work, we proposed a novel attention-based deep neural network to incorporate contextual and social information for this task. We used embeddings to represent the user, the user's attention interests, the author and tweet respectively. To train and evaluate the proposed methods, we also constructed a large dataset collected from Twitter. Experimental results showed that the proposed method could achieve better results than the previous state-of-the-art methods.",10.1145/2983323.2983809,https://doi.org/10.1145/2983323.2983809,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,Retweet Prediction with Attention-based Deep Neural Network,"Zhang, Qi and Gong, Yeyun and Wu, Jindou and Huang, Haoran and Huang, Xuanjing",inproceedings,10.1145/2983323.2983809,
10.1145/2983323.2983812,10.1145/2983323.2983812,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","cascade prediction., information diffusion, self-exciting point process, social media",10,1069–1078,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"Predicting popularity, or the total volume of information outbreaks, is an important subproblem for understanding collective behavior in networks. Each of the two main types of recent approaches to the problem, feature-driven and generative models, have desired qualities and clear limitations. This paper bridges the gap between these solutions with a new hybrid approach and a new performance benchmark. We model each social cascade with a marked Hawkes self-exciting point process, and estimate the content virality, memory decay, and user influence. We then learn a predictive layer for popularity prediction using a collection of cascade history. To our surprise, Hawkes process with a predictive overlay outperform recent feature-driven and generative approaches on existing tweet data [44] and a new public benchmark on news tweets. We also found that a basic set of user features and event time summary statistics performs competitively in both classification and regression tasks, and that adding point process information to the feature set further improves predictions. From these observations, we argue that future work on popularity prediction should compare across feature-driven and generative modeling approaches in both classification and regression tasks.",10.1145/2983323.2983812,https://doi.org/10.1145/2983323.2983812,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,Feature Driven and Point Process Approaches for Popularity Prediction,"Mishra, Swapnil and Rizoiu, Marian-Andrei and Xie, Lexing",inproceedings,10.1145/2983323.2983812,
10.1145/2983323.2983839,10.1145/2983323.2983839,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","social relationship, recommendation systems, learning to rank, collaborative ranking",10,1393–1402,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"With the advent of learning to rank methods, relevant studies showed that Collaborative Ranking (CR) models can produce accurate ranked lists in the top-N recommendation problem. However, in practice several real-world problems decrease their ranking performance, such as the sparsity and cold-start problems, which often occur in recommendation systems for inactive or new users. In this study, to account for the fact that the selections of social friends can improve the recommendation accuracy, we propose a joint CR model based on the users' social relationships. We propose two different CR strategies based on the notions of Social Reverse Height and Social Height, which consider how well the relevant and irrelevant items of users and their social friends have been ranked at the top of the list, respectively. We focus on the top of the list mainly because users see the top-N recommendations in real-world applications, and not the whole ranked list. Furthermore, we formulate a joint objective function to consider both CR strategies, and propose an alternating minimization algorithm to learn our joint CR model. Our experiments on benchmark datasets show that our proposed joint CR model outperforms other state-of-the-art models that either consider social relationships or focus on the ranking performance at the top of the list.",10.1145/2983323.2983839,https://doi.org/10.1145/2983323.2983839,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,Joint Collaborative Ranking with Social Relationships in Top-N Recommendation,"Rafailidis, Dimitrios and Crestani, Fabio",inproceedings,10.1145/2983323.2983839,
10.1145/2983323.2983868,10.1145/2983323.2983868,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","survival theory, self-excited hawkes process, popularity dynamics, periodicity, microblogs, influence",4,1897–1900,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"Modeling and predicting the popularity dynamics of individual user generated items on online social networks has important implications in a wide range of areas. The challenge of this problem comes from the inequality of the popularity of content and the numerous complex factors. Existing works mainly focus on exploring relevant factors for prediction and fitting the time series of popularity dynamics into certain class of functions, while ignoring the underlying arrival process of attentions. Also, the exogenous effect of user activity variation on the platform has been neglected. In this paper, we propose a probabilistic model using an influence-based self-excited Hawkes process (ISEHP) to characterize the process through which individual microblogs gain their popularity. This model explicitly captures three ingredients: the intrinsic attractiveness of a microblog with exponential time decay, the user-specific triggering effect of each forwardings based on the endogenous influence among users, and the exogenous effect from the platform. We validate the ISEHP model by applying it on Sina Weibo, the most popular microblogging network in China. Experimental results demonstrate that our proposed model consistently outperforms existing prediction models.",10.1145/2983323.2983868,https://doi.org/10.1145/2983323.2983868,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,Modeling and Predicting Popularity Dynamics via an Influence-based Self-Excited Hawkes Process,"Bao, Peng",inproceedings,10.1145/2983323.2983868,
10.1145/2983323.2983889,10.1145/2983323.2983889,CIKM.bib,1,['CIKM.bib'],8,CIKM '16,"Indianapolis, Indiana, USA","word embeddings, venue recommendation, matrix factorisation",4,1981–1984,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,"Venue recommendation is an important capability of Location-Based Social Networks such as Yelp and Foursquare. Matrix Factorisation (MF) is a collaborative filtering-based approach that can effectively recommend venues that are relevant to the users' preferences, by training upon either implicit or explicit feedbacks (e.g. check-ins or venue ratings) that these users express about venues. However, MF suffers in that users may only have rated very few venues. To alleviate this problem, recent literature have leveraged additional sources of evidence, e.g. using users' social friendships to reduce the complexity of - or regularise - the MF model, or identifying similar venues based on their comments. This paper argues for a combined regularisation model, where the venues suggested for a user are influenced by friends with similar tastes (as defined by their comments). We propose a MF regularisation technique that seamlessly incorporates both social network information and textual comments, by exploiting word embeddings to estimate a semantic similarity of friends based on their explicit textual feedback, to regularise the complexity of the factorised model. Experiments on a large existing dataset demonstrate that our proposed regularisation model is promising, and can enhance the prediction accuracy of several state-of-the-art matrix factorisation-based approaches.",10.1145/2983323.2983889,https://doi.org/10.1145/2983323.2983889,"New York, NY, USA",Association for Computing Machinery,9781450340731,2016,Regularising Factorised Models for Venue Recommendation using Friends and their Comments,"Manotumruksa, Jarana and Macdonald, Craig and Ounis, Iadh",inproceedings,10.1145/2983323.2983889,
10.1145/2987538.2987545,10.1145/2987538.2987545,RecSys.bib,1,['RecSys.bib'],7,RecSys Challenge '16,"Boston, Massachusetts, USA","LSI, ensemble, recsys challenge 2016, top-n recommendation, word2vec",4,,Proceedings of the Recommender Systems Challenge,"In this paper, we present an ensemble method for job recommendation to ACM RecSys Challenge 2016. Given a user, the goal of a job recommendation system is to predict those job postings that are likely to be relevant to the user1.Firstly, we analyze the train dataset and find several interesting patterns. Secondly, we describe our solution, which is an ensemble of two filters, combining the merits of traditional collaborative filtering and content-based filtering. Our approach finally achieved a score of 1632828.82, ranked at the 10th place on the public leaderboard.",10.1145/2987538.2987545,https://doi.org/10.1145/2987538.2987545,"New York, NY, USA",Association for Computing Machinery,9781450348010,2016,An ensemble method for job recommender systems,"Zhang, Chenrui and Cheng, Xueqi",inproceedings,10.1145/2987538.2987545,2
10.1145/2987538.2987547,10.1145/2987538.2987547,RecSys.bib,1,['RecSys.bib'],7,RecSys Challenge '16,"Boston, Massachusetts, USA","information retrieval, learning to rank, recommendation systems",5,,Proceedings of the Recommender Systems Challenge,"In this paper we describe the system built by the Jobandtalent Recommendation Team to compete in the RecSys Challenge 2016. The task consisted in predicting future interactions between Users and Items within the XING platform. The data provided by XING consists of users, items, plus interactions, and impressions of items showed to those users. We decided to apply a Learning to Rank approach to find the best combination of relevance features. We finally achieved the 11th position.",10.1145/2987538.2987547,https://doi.org/10.1145/2987538.2987547,"New York, NY, USA",Association for Computing Machinery,9781450348010,2016,Jobandtalent at RecSys Challenge 2016,"Honrado, Jose Ignacio and Huarte, Oscar and Jimenez, Cesar and Ortega, Sebastian and Perez-Aguera, Jose R. and Perez-Iglesias, Joaquin and Polo, Alvaro and Rodriguez, Gabriel",inproceedings,10.1145/2987538.2987547,3
10.1145/2987538.2987549,10.1145/2987538.2987549,RecSys.bib,1,['RecSys.bib'],7,RecSys Challenge '16,"Boston, Massachusetts, USA","collaborative filtering, job recommendation challenge, top-n recommendation",4,,Proceedings of the Recommender Systems Challenge,"In this paper we present our method used in the RecSys '16 Challenge.In particular, we propose a general collaborative filtering framework where many predictors can be cast. The framework is able to incorporate information about the content but in a collaborative fashion. Using this framework we instantiate a set of different predictors that consider different aspects of the dataset provided for the challenge. In order to merge all these aspects together, we also provide a method able to linearly combine the predictors. This method learns the weights of the predictors by solving a quadratic optimization problem.In the experimental section we show the performance using different predictors combinations. Results highlight the fact that the combination always outperforms the single predictor.",10.1145/2987538.2987549,https://doi.org/10.1145/2987538.2987549,"New York, NY, USA",Association for Computing Machinery,9781450348010,2016,A preliminary study on a recommender system for the job recommendation challenge,"Polato, Mirko and Aiolli, Fabio",inproceedings,10.1145/2987538.2987549,1
10.1145/3018661.3018665,10.1145/3018661.3018665,WSDM.bib,1,['WSDM.bib'],8,WSDM '17,"Cambridge, United Kingdom","convolutional neural networks, deep learning, rating prediction, recommender systems",10,425–434,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,"A large amount of information exists in reviews written by users. This source of information has been ignored by most of the current recommender systems while it can potentially alleviate the sparsity problem and improve the quality of recommendations. In this paper, we present a deep model to learn item properties and user behaviors jointly from review text. The proposed model, named Deep Cooperative Neural Networks (DeepCoNN), consists of two parallel neural networks coupled in the last layers. One of the networks focuses on learning user behaviors exploiting reviews written by the user, and the other one learns item properties from the reviews written for the item. A shared layer is introduced on the top to couple these two networks together. The shared layer enables latent factors learned for users and items to interact with each other in a manner similar to factorization machine techniques. Experimental results demonstrate that DeepCoNN significantly outperforms all baseline recommender systems on a variety of datasets.",10.1145/3018661.3018665,https://doi.org/10.1145/3018661.3018665,"New York, NY, USA",Association for Computing Machinery,9781450346757,2017,Joint Deep Modeling of Users and Items Using Reviews for Recommendation,"Zheng, Lei and Noroozi, Vahid and Yu, Philip S.",inproceedings,10.1145/3018661.3018665,
10.1145/3018661.3018686,10.1145/3018661.3018686,WSDM.bib,1,['WSDM.bib'],8,WSDM '17,"Cambridge, United Kingdom","recommender systems, topic modeling, trusted social relations, user comment analysis",10,485–494,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,"A recommendation is called explainable if it not only predicts a numerical rating for an item, but also generates explanations for users' preferences. Most existing methods for explainable recommendation apply topic models to analyze user reviews to provide descriptions along with the recommendations they produce. So far, such methods have neglected user opinions and influences from social relations as a source of information for recommendations, even though these are known to improve the rating prediction.In this paper, we propose a latent variable model, called social collaborative viewpoint regression (sCVR), for predicting item ratings based on user opinions and social relations. To this end, we use so-called viewpoints, represented as tuples of a concept, topic, and a sentiment label from both user reviews and trusted social relations. In addition, such viewpoints can be used as explanations. We apply a Gibbs EM sampler to infer posterior distributions of sCVR. Experiments conducted on three large benchmark datasets show the effectiveness of our proposed method for predicting item ratings and for generating explanations.",10.1145/3018661.3018686,https://doi.org/10.1145/3018661.3018686,"New York, NY, USA",Association for Computing Machinery,9781450346757,2017,Social Collaborative Viewpoint Regression with Explainable Recommendations,"Ren, Zhaochun and Liang, Shangsong and Li, Piji and Wang, Shuaiqiang and de Rijke, Maarten",inproceedings,10.1145/3018661.3018686,
10.1145/3018661.3018689,10.1145/3018661.3018689,WSDM.bib,1,['WSDM.bib'],8,WSDM '17,"Cambridge, United Kingdom","recommender systems, recurrent neural networks",9,495–503,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,"Recommender systems traditionally assume that user profiles and movie attributes are static. Temporal dynamics are purely reactive, that is, they are inferred after they are observed, e.g. after a user's taste has changed or based on hand-engineered temporal bias corrections for movies. We propose Recurrent Recommender Networks (RRN) that are able to predict future behavioral trajectories. This is achieved by endowing both users and movies with a Long Short-Term Memory (LSTM) autoregressive model that captures dynamics, in addition to a more traditional low-rank factorization. On multiple real-world datasets, our model offers excellent prediction accuracy and it is very compact, since we need not learn latent state but rather just the state transition function.",10.1145/3018661.3018689,https://doi.org/10.1145/3018661.3018689,"New York, NY, USA",Association for Computing Machinery,9781450346757,2017,Recurrent Recommender Networks,"Wu, Chao-Yuan and Ahmed, Amr and Beutel, Alex and Smola, Alexander J. and Jing, How",inproceedings,10.1145/3018661.3018689,
10.1145/3018661.3018696,10.1145/3018661.3018696,WSDM.bib,1,['WSDM.bib'],8,WSDM '17,"Cambridge, United Kingdom","barter, collaborative filtering, exchange, matrix factorization, reciprocity, social dynamics, swap, temporal dynamics",10,505–514,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,"Bartering is a timeless practice that is becoming increasingly popular on the Web. Recommending trades for an online bartering platform shares many similarities with traditional approaches to recommendation, in particular the need to model the preferences of users and the properties of the items they consume. However, there are several aspects that make bartering problems interesting and challenging, specifically the fact that users are both suppliers and consumers, and that the trading environment is highly dynamic. Thus, a successful model of bartering requires us to understand not just users' preferences, but also the social dynamics of who trades with whom, and the temporal dynamics of when trades occur.We propose new models for bartering-based recommendation, for which we introduce three novel datasets from online bartering platforms. Surprisingly, we find that existing methods (based on matching algorithms) perform poorly on real-world platforms, as they rely on idealized assumptions that are not supported by real bartering data. We develop approaches based on Matrix Factorization in order to model the reciprocal interest between users and each other's items. We also find that the social ties between members have a strong influence, as does the time at which they trade, therefore we extend our model to be socially- and temporally-aware. We evaluate our approach on trades covering books, video games, and beers, where we obtain promising empirical performance compared to existing techniques.",10.1145/3018661.3018696,https://doi.org/10.1145/3018661.3018696,"New York, NY, USA",Association for Computing Machinery,9781450346757,2017,Bartering Books to Beers: A Recommender System for Exchange Platforms,"Rappaz, J\'{e}r\'{e}mie and Vladarean, Maria-Luiza and McAuley, Julian and Catasta, Michele",inproceedings,10.1145/3018661.3018696,
10.1145/3018661.3018701,10.1145/3018661.3018701,WSDM.bib,1,['WSDM.bib'],8,WSDM '17,"Cambridge, United Kingdom","demand-side platform, display advertising, real-time bidding, risk-aware bidding strategy, value at risk",10,581–590,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,"In this paper, we deal with the uncertainty of bidding for display advertising. Similar to the financial market trading, real-time bidding (RTB) based display advertising employs an auction mechanism to automate the impression level media buying; and running a campaign is no different than an investment of acquiring new customers in return for obtaining additional converted sales. Thus, how to optimally bid on an ad impression to drive the profit and return-on-investment becomes essential. However, the large randomness of the user behaviors and the cost uncertainty caused by the auction competition may result in a significant risk from the campaign performance estimation. In this paper, we explicitly model the uncertainty of user click-through rate estimation and auction competition to capture the risk. We borrow an idea from finance and derive the value at risk for each ad display opportunity. Our formulation results in two risk-aware bidding strategies that penalize risky ad impressions and focus more on the ones with higher expected return and lower risk. The empirical study on real-world data demonstrates the effectiveness of our proposed risk-aware bidding strategies: yielding profit gains of 15.4% in offline experiments and up to 17.5% in an online A/B test on a commercial RTB platform over the widely applied bidding strategies.",10.1145/3018661.3018701,https://doi.org/10.1145/3018661.3018701,"New York, NY, USA",Association for Computing Machinery,9781450346757,2017,Managing Risk of Bidding in Display Advertising,"Zhang, Haifeng and Zhang, Weinan and Rong, Yifei and Ren, Kan and Li, Wenxin and Wang, Jun",inproceedings,10.1145/3018661.3018701,
10.1145/3018661.3018702,10.1145/3018661.3018702,WSDM.bib,1,['WSDM.bib'],8,WSDM '17,"Cambridge, United Kingdom","bid optimization, display ads, reinforcement learning",10,661–670,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,"The majority of online display ads are served through real-time bidding (RTB) --- each ad display impression is auctioned off in real-time when it is just being generated from a user visit. To place an ad automatically and optimally, it is critical for advertisers to devise a learning algorithm to cleverly bid an ad impression in real-time. Most previous works consider the bid decision as a static optimization problem of either treating the value of each impression independently or setting a bid price to each segment of ad volume. However, the bidding for a given ad campaign would repeatedly happen during its life span before the budget runs out. As such, each bid is strategically correlated by the constrained budget and the overall effectiveness of the campaign (e.g., the rewards from generated clicks), which is only observed after the campaign has completed. Thus, it is of great interest to devise an optimal bidding strategy sequentially so that the campaign budget can be dynamically allocated across all the available impressions on the basis of both the immediate and future rewards. In this paper, we formulate the bid decision process as a reinforcement learning problem, where the state space is represented by the auction information and the campaign's real-time parameters, while an action is the bid price to set. By modeling the state transition via auction competition, we build a Markov Decision Process framework for learning the optimal bidding policy to optimize the advertising performance in the dynamic real-time bidding environment. Furthermore, the scalability problem from the large real-world auction volume and campaign budget is well handled by state value approximation using neural networks. The empirical study on two large-scale real-world datasets and the live A/B testing on a commercial platform have demonstrated the superior performance and high efficiency compared to state-of-the-art methods.",10.1145/3018661.3018702,https://doi.org/10.1145/3018661.3018702,"New York, NY, USA",Association for Computing Machinery,9781450346757,2017,Real-Time Bidding by Reinforcement Learning in Display Advertising,"Cai, Han and Ren, Kan and Zhang, Weinan and Malialis, Kleanthis and Wang, Jun and Yu, Yong and Guo, Defeng",inproceedings,10.1145/3018661.3018702,
10.1145/3018661.3018716,10.1145/3018661.3018716,WSDM.bib,1,['WSDM.bib'],8,WSDM '17,"Cambridge, United Kingdom","multi-task, multi-view, tensor factorization",9,701–709,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,"Many real-world problems, such as web image analysis, document categorization and product recommendation, often exhibit dual-heterogeneity: heterogeneous features obtained in multiple views, and multiple tasks might be related to each other through one or more shared views. To address these Multi-Task Multi-View (MTMV) problems, we propose a tensor-based framework for learning the predictive multilinear structure from the full-order feature interactions within the heterogeneous data. The usage of tensor structure is to strengthen and capture the complex relationships between multiple tasks with multiple views. We further develop efficient multilinear factorization machines (MFMs) that can learn the task-specific feature map and the task-view shared multilinear structures, without physically building the tensor. In the proposed method, a joint factorization is applied to the full-order interactions such that the consensus representation can be learned. In this manner, it can deal with the partially incomplete data without difficulty as the learning procedure does not simply rely on any particular view. Furthermore, the complexity of MFMs is linear in the number of parameters, which makes MFMs suitable to large-scale real-world problems. Extensive experiments on four real-world datasets demonstrate that the proposed method significantly outperforms several state-of-the-art methods in a wide variety of MTMV problems.",10.1145/3018661.3018716,https://doi.org/10.1145/3018661.3018716,"New York, NY, USA",Association for Computing Machinery,9781450346757,2017,Multilinear Factorization Machines for Multi-Task Multi-View Learning,"Lu, Chun-Ta and He, Lifang and Shao, Weixiang and Cao, Bokai and Yu, Philip S.",inproceedings,10.1145/3018661.3018716,
10.1145/3018661.3022759,10.1145/3018661.3022759,WSDM.bib,1,['WSDM.bib'],8,WSDM '17,"Cambridge, United Kingdom","predictive modeling, social network analysis, web mining",2,821–822,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,"The first international workshop on Mining Actionable Insights from Social Networks (MAISoN'17) is to be held on February 10, 2017; co-located with the Tenth ACM International Web Search and Data Mining (WSDM) Conference in Cambridge, UK. MAISoN'17 aims at bringing together researchers and participants from different disciplines such as computer science, big data mining, machine learning, social network analysis and other related areas in order to identify challenging problems and share ideas, algorithms, and technologies for mining actionable insight from social network data. We organized a workshop program that includes the presentation of eight peer-reviewed papers and keynote talks, which foster discussions around state-of-the-art in social network mining and will hopefully lead to future collaborations and exchanges.",10.1145/3018661.3022759,https://doi.org/10.1145/3018661.3022759,"New York, NY, USA",Association for Computing Machinery,9781450346757,2017,Mining Actionable Insights from Social Networksat WSDM 2017,"Ensan, Faezeh and Noorian, Zeinab and Bagheri, Ebrahim",inproceedings,10.1145/3018661.3022759,
10.1145/3038912.3052556,10.1145/3038912.3052556,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","user behavior modeling, strong and weak ties, social recommendation, personalization",10,1601–1610,Proceedings of the 26th International Conference on World Wide Web,"Recent years have seen a surge of research on social recommendation techniques for improving recommender systems due to the growing influence of social networks to our daily life. The intuition of social recommendation is that users tend to show affinities with items favored by their social ties due to social influence. Despite the extensive studies, no existing work has attempted to distinguish and learn the personalized preferences between strong and weak ties, two important terms widely used in social sciences, for each individual in social recommendation. In this paper, we first highlight the importance of different types of ties in social relations originated from social sciences, and then propose anovel social recommendation method based on a new Probabilistic Matrix Factorization model that incorporates the distinction of strong and weak ties for improving recommendation performance. The proposed method is capable of simultaneously classifying different types of social ties in a social network w.r.t. optimal recommendation accuracy, and learning a personalized tie type preference for each user in addition to other parameters. We conduct extensive experiments on four real-world datasets by comparing our method with state-of-the-art approaches, and find encouraging results that validate the efficacy of the proposed method in exploiting the personalized preferences of strong and weak ties for social recommendation.",10.1145/3038912.3052556,https://doi.org/10.1145/3038912.3052556,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,Learning Personalized Preference of Strong and Weak Ties for Social Recommendation,"Wang, Xin and Hoi, Steven C.H. and Ester, Martin and Bu, Jiajun and Chen, Chun",inproceedings,10.1145/3038912.3052556,
10.1145/3038912.3052569,10.1145/3038912.3052569,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","neural networks, matrix factorization, implicit feedback, deep learning, collaborative filtering",10,173–182,Proceedings of the 26th International Conference on World Wide Web,"In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback.Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items.By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.",10.1145/3038912.3052569,https://doi.org/10.1145/3038912.3052569,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,Neural Collaborative Filtering,"He, Xiangnan and Liao, Lizi and Zhang, Hanwang and Nie, Liqiang and Hu, Xia and Chua, Tat-Seng",inproceedings,10.1145/3038912.3052569,
10.1145/3038912.3052581,10.1145/3038912.3052581,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","product embedding, online shopping, collaborative filtering",10,1113–1122,Proceedings of the 26th International Conference on World Wide Web,"For online product recommendation engines, learning high-quality product embedding that captures various aspects of the product is critical to improving the accuracy of user rating prediction. In recent research, in conjunction with user feedback, the appearance of a product as side information has been shown to be helpful for learning product embedding. However, since a product has a variety of aspects such as functionality and specifications, taking into account only its appearance as side information does not suffice to accurately learn its embedding. In this paper, we propose a matrix co-factorization method that leverages information hidden in the so-called ""also-viewed"" products, i.e., a list of products that has also been viewed by users who have viewed a target product. ""Also-viewed"" products reflect various aspects of a given product that have been overlooked by visually-aware recommendation methods proposed in past research. Experiments on multiple real-world datasets demonstrate that our proposed method outperforms state-of-the-art baselines in terms of user rating prediction. We also perform classification on the product embedding learned by our method, and compare it with a state-of-the-art baseline to demonstrate the superiority of our method in generating high-quality product embedding that better represents the product.",10.1145/3038912.3052581,https://doi.org/10.1145/3038912.3052581,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,"Do ""Also-Viewed"" Products Help User Rating Prediction?","Park, Chanyoung and Kim, Donghyun and Oh, Jinoh and Yu, Hwanjo",inproceedings,10.1145/3038912.3052581,
10.1145/3038912.3052585,10.1145/3038912.3052585,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","structural svm, recommender systems, diversity, collaborative filtering",10,183–192,Proceedings of the 26th International Conference on World Wide Web,"In this study, we investigate diversified recommendation problem by supervised learning, seeking significant improvement in diversity while maintaining accuracy. In particular, we regard each user as a training instance, and heuristically choose a subset of accurate and diverse items as ground-truth for each user. We then represent each user or item as a vector resulted from the factorization of the user-item rating matrix. In our paper, we try to discover a factorization for matching the following supervised learning task. In doing this, we define two coupled optimization problems, parameterized matrix factorization and structural learning, to formulate our task. And we propose a diversified collaborative filtering algorithm (DCF) to solve the coupled problems. We also introduce a new pairwise accuracy metric and a normalized topic coverage diversity metric to measure the performance of accuracy and diversity respectively. Extensive experiments on benchmark datasets show the performance gains of DCF in comparison with the state-of-the-art algorithms.",10.1145/3038912.3052585,https://doi.org/10.1145/3038912.3052585,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,Learning to Recommend Accurate and Diverse Items,"Cheng, Peizhe and Wang, Shuaiqiang and Ma, Jun and Sun, Jiankai and Xiong, Hui",inproceedings,10.1145/3038912.3052585,
10.1145/3038912.3052605,10.1145/3038912.3052605,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","twitter, tf-idf, temporal dynamics, recommender systems, hashtags, hashtag usage recency, hashtag reuse prediction, hashtag recommendation, bll equation, act-r",10,1401–1410,Proceedings of the 26th International Conference on World Wide Web,"Hashtags have become a powerful tool in social platforms such as Twitter to categorize and search for content, and to spread short messages across members of the social network. In this paper, we study temporal hashtag usage practices in Twitter with the aim of designing a cognitive-inspired hashtag recommendation algorithm we call BLLi,s. Our main idea is to incorporate the effect of time on (i) individual hashtag reuse (i.e., reusing own hashtags), and (ii) social hashtag reuse (i.e., reusing hashtags, which has been previously used by a followee) into a predictive model. For this, we turn to the Base-Level Learning (BLL) equation from the cognitive architecture ACT-R, which accounts for the time-dependent decay of item exposure in human memory. We validate BLLI,S using two crawled Twitter datasets in two evaluation scenarios. Firstly, only temporal usage patterns of past hashtag assignments are utilized and secondly, these patterns are combined with a content-based analysis of the current tweet. In both evaluation scenarios, we find not only that temporal effects play an important role for both individual and social hashtag reuse but also that our BLLI,S approach provides significantly better prediction accuracy and ranking results than current state-of-the-art hashtag recommendation methods.",10.1145/3038912.3052605,https://doi.org/10.1145/3038912.3052605,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,Temporal Effects on Hashtag Reuse in Twitter: A Cognitive-Inspired Hashtag Recommendation Approach,"Kowald, Dominik and Pujari, Subhash Chandra and Lex, Elisabeth",inproceedings,10.1145/3038912.3052605,
10.1145/3038912.3052626,10.1145/3038912.3052626,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","tensor decomposition, graph clustering, content prediction",9,725–733,Proceedings of the 26th International Conference on World Wide Web,"Predicting the popularity of online content in social networks is important in many applications, ranging from ad campaign design, web content caching and prefetching, to web-search result ranking. Earlier studies target this problem by learning models that either generalize behaviors of the entire network population or capture behaviors of each individual user. In this paper, we claim that a novel approach based on group-level popularity is necessary and more practical, given that users naturally organize themselves into clusters and that users within a cluster react to online content in a uniform manner. We develop a novel framework by first grouping users into cohesive clusters, and then adopt tensor decomposition to make predictions. In order to minimize the impact of noisy data and be more flexible in capturing changes in users' interests, our framework exploits both the network topology and interaction among users in learning a robust user clustering. The PARAFAC tensor decomposition is adapted to work with hierarchical constraint over user groups, and we show that optimizing this constrained function via gradient descent achieves faster convergence and leads to more stable solutions. Extensive experimental results over two social networks demonstrate that our framework is scalable, finds meaningful user groups, and significantly outperforms eight baseline methods in terms of prediction accuracy.",10.1145/3038912.3052626,https://doi.org/10.1145/3038912.3052626,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,GPOP: Scalable Group-level Popularity Prediction for Online Content in Social Networks,"Hoang, Minh X. and Dang, Xuan-Hong and Wu, Xiang and Yan, Zhenyu and Singh, Ambuj K.",inproceedings,10.1145/3038912.3052626,
10.1145/3038912.3052627,10.1145/3038912.3052627,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","streaming, recommender system, online learning, data stream., continuous time",9,381–389,Proceedings of the 26th International Conference on World Wide Web,"The increasing popularity of real-world recommender systems produces data continuously and rapidly, and it becomes more realistic to study recommender systems under streaming scenarios. Data streams present distinct properties such as temporally ordered, continuous and high-velocity, which poses tremendous challenges to traditional recommender systems. In this paper, we investigate the problem of recommendation with stream inputs. In particular, we provide a principled framework termed sRec, which provides explicit continuous-time random process models of the creation of users and topics, and of the evolution of their interests. A variational Bayesian approach called recursive meanfield approximation is proposed, which permits computationally efficient instantaneous on-line inference. Experimental results on several real-world datasets demonstrate the advantages of our sRec over other state-of-the-arts.",10.1145/3038912.3052627,https://doi.org/10.1145/3038912.3052627,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,Streaming Recommender Systems,"Chang, Shiyu and Zhang, Yang and Tang, Jiliang and Yin, Dawei and Chang, Yi and Hasegawa-Johnson, Mark A. and Huang, Thomas S.",inproceedings,10.1145/3038912.3052627,
10.1145/3038912.3052650,10.1145/3038912.3052650,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","self-exciting processes, popularity modeling, popularity forecasting, item virality, hawkes intensity process",10,735–744,Proceedings of the 26th International Conference on World Wide Web,"Modeling and predicting the popularity of online content is a significant problem for the practice of information dissemination, advertising, and consumption. Recent work analyzing massive datasets advances our understanding of popularity, but one major gap remains: To precisely quantify the relationship between the popularity of an online item and the external promotions it receives. This work supplies the missing link between exogenous inputs from public social media platforms, such as Twitter, and endogenous responses within the content platform, such as YouTube. We develop a novel mathematical model, the Hawkes intensity process, which can explain the complex popularity history of each video according to its type of content, network of diffusion, and sensitivity to promotion. Our model supplies a prototypical description of videos, called an endo-exo map. This map explains popularity as the result of an extrinsic factor -- the amount of promotions from the outside world that the video receives, acting upon two intrinsic factors -- sensitivity to promotion, and inherent virality. We use this model to forecast future popularity given promotions on a large 5-months feed of the most-tweeted videos, and found it to lower the average error by 28.6% from approaches based on popularity history. Finally, we can identify videos that have a high potential to become viral, as well as those for which promotions will have hardly any effect.",10.1145/3038912.3052650,https://doi.org/10.1145/3038912.3052650,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,Expecting to be HIP: Hawkes Intensity Processes for Social Media Popularity,"Rizoiu, Marian-Andrei and Xie, Lexing and Sanner, Scott and Cebrian, Manuel and Yu, Honglin and Van Hentenryck, Pascal",inproceedings,10.1145/3038912.3052650,
10.1145/3038912.3052668,10.1145/3038912.3052668,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","recommender systems, numerical and categorical features, matrix factorization, low-dimensional embedding, large cardinality, gradient boosting, decision trees",9,1311–1319,Proceedings of the 26th International Conference on World Wide Web,"Latent factor models and decision tree based models are widely used in tasks of prediction, ranking and recommendation. Latent factor models have the advantage of interpreting categorical features by a low-dimensional representation, while such an interpretation does not naturally fit numerical features. In contrast, decision tree based models enjoy the advantage of capturing the nonlinear interactions of numerical features, while their capability of handling categorical features is limited by the cardinality of those features. Since in real-world applications we usually have both abundant numerical features and categorical features with large cardinality (e.g. geolocations, IDs, tags etc.), we design a new model, called GB-CENT, which leverages latent factor embedding and tree components to achieve the merits of both while avoiding their demerits. With two real-world data sets, we demonstrate that GB-CENT can effectively (i.e. fast and accurately) achieve better accuracy than state-of-the-art matrix factorization, decision tree based models and their ensemble.",10.1145/3038912.3052668,https://doi.org/10.1145/3038912.3052668,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,GB-CENT: Gradient Boosted Categorical Embedding and Numerical Trees,"Zhao, Qian and Shi, Yue and Hong, Liangjie",inproceedings,10.1145/3038912.3052668,
10.1145/3038912.3052680,10.1145/3038912.3052680,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","unpredictability, social influence, ranking policies, position bias, mathew effect, experimental study, cultural markets, ""rich get richer"" effect",10,745–754,Proceedings of the 26th International Conference on World Wide Web,"Unpredictability is often portrayed as an undesirable outcome of social influence in cultural markets. Unpredictability stems from the ""rich get richer"" effect, whereby small fluctuations in the market share or popularity of products are amplified over time by social influence. In this paper, we report results of an experimental study that shows that unpredictability is not an inherent property of social influence. We investigate strategies for creating markets in which the popularity of products is better-and more predictably-aligned with their underlying quality. For our study, we created a cultural market of science stories and conducted randomized experiments on different policies for presenting the stories to study participants. Specifically, we varied how the stories were ranked, and whether or not participants were shown the ratings these stories received from others. We present a policy that leverages social influence and product positioning to help distinguish the product's market share (popularity) from underlying quality. Highlighting products with the highest estimated quality reduces the ""rich get richer"" effect highlighting popular products. We show that this policy allows us to more robustly and predictably identify high quality products and promote blockbusters. The policy can be used to create more efficient online cultural markets with a better allocation of resources to products.",10.1145/3038912.3052680,https://doi.org/10.1145/3038912.3052680,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,Taming the Unpredictability of Cultural Markets with Social Influence,"Abeliuk, Andr\'{e}s and Berbeglia, Gerardo and Van Hentenryck, Pascal and Hogg, Tad and Lerman, Kristina",inproceedings,10.1145/3038912.3052680,
10.1145/3038912.3052684,10.1145/3038912.3052684,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","social media, reddit, multimodal, language modeling, image processing",10,927–936,Proceedings of the 26th International Conference on World Wide Web,"The content of today's social media is becoming more and more rich, increasingly mixing text, images, videos, and audio. It is an intriguing research question to model the interplay between these different modes in attracting user attention and engagement. But in order to pursue this study of multimodal content, we must also account for context: timing effects, community preferences, and social factors (e.g., which authors are already popular) also affect the amount of feedback and reaction that social-media posts receive. In this work, we separate out the influence of these non-content factors in several ways. First, we focus on ranking pairs of submissions posted to the same community in quick succession, e.g., within 30 seconds; this framing encourages models to focus on time-agnostic and community-specific content features. Within that setting, we determine the relative performance of author vs. content features. We find that victory usually belongs to ""cats and captions,"" as visual and textual features together tend to outperform identity-based features. Moreover, our experiments show that when considered in isolation, simple unigram text features and deep neural network visual features yield the highest accuracy individually, and that the combination of the two modalities generally leads to the best accuracies overall.",10.1145/3038912.3052684,https://doi.org/10.1145/3038912.3052684,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,Cats and Captions vs. Creators and the Clock: Comparing Multimodal Content to Context in Predicting Relative Popularity,"Hessel, Jack and Lee, Lillian and Mimno, David",inproceedings,10.1145/3038912.3052684,
10.1145/3038912.3052694,10.1145/3038912.3052694,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","recommender systems, matrix factorization, implicit feedback, factorization machine, coordinate descent",10,1341–1350,Proceedings of the 26th International Conference on World Wide Web,"In recent years, interest in recommender research has shifted from explicit feedback towards implicit feedback data. A diversity of complex models has been proposed for a wide variety of applications. Despite this, learning from implicit feedback is still computationally challenging. So far, most work relies on stochastic gradient descent (SGD) solvers which are easy to derive, but in practice challenging to apply, especially for tasks with many items. For the simple matrix factorization model, an efficient coordinate descent (CD) solver has been previously proposed. However, efficient CD approaches have not been derived for more complex models.In this paper, we provide a new framework for deriving efficient CD algorithms for complex recommender models. We identify and introduce the property of k-separable models. We show that k-separability is a sufficient property to allow efficient optimization of implicit recommender problems with CD. We illustrate this framework on a variety of state-of-the-art models including factorization machines and Tucker decomposition. To summarize, our work provides the theory and building blocks to derive efficient implicit CD algorithms for complex recommender models.",10.1145/3038912.3052694,https://doi.org/10.1145/3038912.3052694,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,A Generic Coordinate Descent Framework for Learning from Implicit Feedback,"Bayer, Immanuel and He, Xiangnan and Kanagal, Bhargav and Rendle, Steffen",inproceedings,10.1145/3038912.3052694,
10.1145/3038912.3052705,10.1145/3038912.3052705,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17,"Perth, Australia","web applications, time series prediction, online petitions",10,755–764,Proceedings of the 26th International Conference on World Wide Web,"Applying classical time-series analysis techniques to online content is challenging, as web data tends to have data quality issues and is often incomplete, noisy, or poorly aligned. In this paper, we tackle the problem of predicting the evolution of a time series of user activity on the web in a manner that is both accurate and interpretable, using related time series to produce a more accurate prediction. We test our methods in the context of predicting signatures for online petitions using data from thousands of petitions posted on The Petition Site - one of the largest platforms of its kind. We observe that the success of these petitions is driven by a number of factors, including promotion through social media channels and on the front page of the petitions platform. We propose an interpretable model that incorporates seasonality, aging effects, self-excitation, and external effects. The interpretability of the model is important for understanding the elements that drives the activity of an online content. We show through an extensive empirical evaluation that our model is significantly better at predicting the outcome of a petition than state-of-the-art techniques.",10.1145/3038912.3052705,https://doi.org/10.1145/3038912.3052705,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349130,2017,Predicting the Success of Online Petitions Leveraging Multidimensional Time-Series,"Proskurnia, Julia and Grabowicz, Przemyslaw and Kobayashi, Ryota and Castillo, Carlos and Cudr\'{e}-Mauroux, Philippe and Aberer, Karl",inproceedings,10.1145/3038912.3052705,
10.1145/3041021.3051148,10.1145/3041021.3051148,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","recommender systems, matrix approximation, low-rank, clustering",9,1395–1403,Proceedings of the 26th International Conference on World Wide Web Companion,"Matrix factorization is widely used in personalized recommender systems, text mining, and computer vision. A general assumption to construct matrix approximation is that the original matrix is of global low rank, while Joonseok Lee et al. proposed that many real matrices may be not globally low rank, and thus a locally low-rank matrix approximation method has been proposed.[11] However, this kind of matrix approximation method still leaves some important issues unsolved, for example, the randomly selecting anchor nodes. In this paper, we study the problem of the selection of anchor nodes to enhance locally low-rank matrix approximation. We propose a new model for local low-rank matrix approximation which selects anchor-points using a heuristic method. Our experiments indicate that the proposed method outperforms many state-of-the-art recommendation methods. Moreover, the proposed method can significantly improve algorithm efficiency, and it is easy to parallelize. These traits make it potential for large scale real-world recommender systems.",10.1145/3041021.3051148,https://doi.org/10.1145/3041021.3051148,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,Local Low-Rank Matrix Approximation with Preference Selection of Anchor Points,"Zhang, Menghao and Hu, Binbin and Shi, Chuan and Wang, Bai",inproceedings,10.1145/3041021.3051148,
10.1145/3041021.3051149,10.1145/3041021.3051149,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","nash equilibrium, item group recommendation, group recommender system, game theory",7,1405–1411,Proceedings of the 26th International Conference on World Wide Web Companion,"In this paper, we focus on recommending an item set to multiple users. Group recommender systems are designed to deal with the issue of recommending items for a user group. However, in some scenarios such as gift set promotion (different items are packed together as a gift set), album promotion, we need to focus on consumers' preference to multiple items rather than to some specific item. To deal with this issue, we pioneer a Nash equilibrium based Item Group Recommendation approach (NIGR). Specifically, we evaluate each consumer's preference to an item group in two perspectives, interest part from the customer herself and social affection from her friends. Then, we model the recommending process as a game to achieve Nash equilibrium. Finally, we demonstrate the effectiveness of our approach with extensive experiments.",10.1145/3041021.3051149,https://doi.org/10.1145/3041021.3051149,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,Item Group Recommendation: A Method Based on Game Theory,"Zhang, Limeng and Zhou, Rui and Jiang, Haixin and Wang, Hua and Zhang, Yanchun",inproceedings,10.1145/3041021.3051149,
10.1145/3041021.3051153,10.1145/3041021.3051153,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","social recommendation techniques, social networks, recommender systems, matrix factorization",9,1343–1351,Proceedings of the 26th International Conference on World Wide Web Companion,"Recommendation plays an increasingly important role in our daily lives. Recommender systems automatically suggest items to users that might be interesting for them. Recent studies illustrate that incorporating social trust in Matrix Factorization methods demonstrably improves accuracy of rating prediction. Such approaches mainly use the trust scores explicitly expressed by users. However, it is often challenging to have users provide explicit trust scores of each other. There exist quite a few works, which propose Trust Metrics to compute and predict trust scores between users based on their interactions. In this paper, first we present how social relation can be extracted from users' ratings to items by describing Hellinger distance between users in recommender systems. Then, we propose to incorporate the predicted trust scores into social matrix factorization models. By analyzing social relation extraction from three well-known real-world datasets, which both: trust and recommendation data available, we conclude that using the implicit social relation in social recommendation techniques has almost the same performance compared to the actual trust scores explicitly expressed by users. Hence, we build our method, called Hell-TrustSVD, on top of the state-of-the-art social recommendation technique to incorporate both the extracted implicit social relations and ratings given by users on the prediction of items for an active user. To the best of our knowledge, this is the first work to extend TrustSVD with extracted social trust information. The experimental results support the idea of employing implicit trust into matrix factorization whenever explicit trust is not available, can perform much better than the state-of-the-art approaches in user rating prediction.",10.1145/3041021.3051153,https://doi.org/10.1145/3041021.3051153,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,Extracting Implicit Social Relation for Social Recommendation Techniques in User Rating Prediction,"Taheri, Seyed Mohammad and Mahyar, Hamidreza and Firouzi, Mohammad and Ghalebi K., Elahe and Grosu, Radu and Movaghar, Ali",inproceedings,10.1145/3041021.3051153,
10.1145/3041021.3053064,10.1145/3041021.3053064,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","trend analysis, computer science, bibliographic databases",6,1245–1250,Proceedings of the 26th International Conference on World Wide Web Companion,"Research in Computer Science (CS) evolves rapidly in a dynamic fashion. New research area may emerge and attract researchers, while older areas may have lesser interest from researchers. Studying how trends evolve in CS can be interesting from several dimensions. Furthermore, it can be used to craft research agendas. In this paper, we present trend analysis on research area in CS. We also look at citation trend analysis. Our analysis is performed using the Microsoft Academic Graph dataset. We propose the FoS score to measure the level of interest in any particular research area or topic. We apply the FoS score to investigate general publication trends, citation trends, evolution of research areas, and relation between research areas in CS.",10.1145/3041021.3053064,https://doi.org/10.1145/3041021.3053064,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,Analysing Trends in Computer Science Research: A Preliminary Study Using The Microsoft Academic Graph,"Effendy, Suhendry and Yap, Roland H.C.",inproceedings,10.1145/3041021.3053064,
10.1145/3041021.3053901,10.1145/3041021.3053901,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","user generated content sites, social features, prediction, graph model",7,1477–1483,Proceedings of the 26th International Conference on World Wide Web Companion,"YouTube-like User Generated Content (UGC) sites are nowadays entertaining over a billion people. Resource provision is essential for these giant UGC sites as they allow users to request videos from a potentially unlimited selection in an asynchronous fashion. Still, the UGC sites are seeking to create new viewing patterns and social interactions that would engage and attract more users and complicate the already rigorous resource provision problem. In this paper, we seek to combine these two tasks by leveraging social features to provide the reference for resource provision.To this end, we conduct an extensive measurement and analysis of BiliBili, a YouTube-like UGC site with enhanced social features including user following, chat replay, and virtual money donation. Based on datasets that capture the complete view of BiliBili---containing over 2 million videos and over 28 million users---we characterize its video repository and user activities, we demonstrate the positive reinforcement between on-line social behavior and upload behavior, we propose graph models that reveal user relationships and high-level social structures, and we successfully apply our findings to build machine-learnt classifiers to identify videos that will need priority in resource provision.",10.1145/3041021.3053901,https://doi.org/10.1145/3041021.3053901,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,An Analysis on a YouTube-like UGC site with Enhanced Social Features,"Jia, Adele Lu and Shen, Siqi and Chen, Shengling and Li, Dongsheng and Iosup, Alexandru",inproceedings,10.1145/3041021.3053901,
10.1145/3041021.3054139,10.1145/3041021.3054139,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","web stores, user review, sentiment analysis, mobile apps, machine learning, decision-making",9,109–117,Proceedings of the 26th International Conference on World Wide Web Companion,"This paper proposes an approach to evaluate mobile applications which complements the information provided by the number of stars and downloads in app stores. The goal is to provide novel information to assist users in the decision-making process regarding the choice of applications. In this sense, we conducted experiments to verify the relationship between the number of stars and the content of review comments. Results indicated that there is information in reviews not properly represented by stars. Thus, we present a sentiment rating generated automatically by aggregating opinions reported in the reviews related to each application. We evaluated this new rating using 26,996 reviews related to six applications present on the Google Play Store. The obtained results allow us to demonstrate that: (1) it is possible and feasible to generate a sentiment rating automatically and (2) the rating is useful for web stores of mobile applications to improve their mechanisms of ranking and recommendation as well as to assist users and developers to evaluate the quality and/or acceptance of the offered mobile applications.",10.1145/3041021.3054139,https://doi.org/10.1145/3041021.3054139,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,Beyond the Stars: Towards a Novel Sentiment Rating to Evaluate Applications in Web Stores of Mobile Apps,"Rodrigues, Phillipe and Silva, Ismael Santana and Barbosa, Gl\'{\i}via Ang\'{e}lica Rodigues and Coutinho, Fl\'{a}vio Roberto dos Santos and Mour\~{a}o, Fernando",inproceedings,10.1145/3041021.3054139,
10.1145/3041021.3054242,10.1145/3041021.3054242,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","social media, popularity prediction, information cascades",2,765–766,Proceedings of the 26th International Conference on World Wide Web Companion,"Predicting the popularity of online content is highly valuable in many applications and has been studied for several years. However, existing models either work in population level---all messages are assumed to follow similar popularity dynamics, lacking flexibility to capture the intrinsic complexity of popularity dynamics, or work in individual level---the popularity dynamics of messages are independent of each other, failing to leverage other messages to improve prediction accuracy. In this paper, we propose a divide and conquer framework for popularity prediction. We first divide messages into groups, anticipating each group of messages follow similar popularity dynamics, and then, we train a group-specific model for the messages of each group. Experiments demonstrate that group-specific models improve the population-level models by about 30% and outperform state-of-the-art individual-level model.",10.1145/3041021.3054242,https://doi.org/10.1145/3041021.3054242,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,Predicting the Popularity of Online Content with Group-specific Models,"Cao, Qi and Shen, Huawei and Gao, Hao and Gao, Jinhua and Cheng, Xueqi",inproceedings,10.1145/3041021.3054242,
10.1145/3041021.3054255,10.1145/3041021.3054255,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","information propagation, bot characterisation, bot activity analysis",2,781–782,Proceedings of the 26th International Conference on World Wide Web Companion,"The WWW has seen massive growth in population of automated programs (bots) for a variety of exploits on online social networks (OSNs). In this paper we extend on our previous work to study the affects of bots on Twitter. By setting up a bot account on Twitter and conducting analysis on a click logs dataset from our web server, we show that despite bots being in smaller numbers, they exercise a profound impact on content popularity and activity on Twitter.",10.1145/3041021.3054255,https://doi.org/10.1145/3041021.3054255,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,Do Bots impact Twitter activity?,"Gilani, Zafar and Farahbakhsh, Reza and Crowcroft, Jon",inproceedings,10.1145/3041021.3054255,
10.1145/3041021.3054762,10.1145/3041021.3054762,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","social media, media bias, data-driven journalism",6,1521–1526,Proceedings of the 26th International Conference on World Wide Web Companion,"A recent disclosure of a presidential scandal and the following development of subsequent events have been a major news topic in South Korea. We conducted a data-driven study to examine public reactions to the scandal and their effect on the Korean media landscape. Our analysis is based on 59,224 news articles published by five popular newsrooms that received a total of 47,906,770 Likes on Facebook. The data reveal notable changes in media ranks throughout the scandal, where a relatively young TV news network outgrew its audience over other half-a-century old established newspapers in less than a month. Topical similarity of news headlines also remained high over an extended period of time, despite the varying political stance of each newsroom. The topical similarity further shows a gradual divergence, indicating re-positioning of media stance takes place over time. Implications of these findings and suggestions for future directions are discussed based on data analysis of this extraordinary event.",10.1145/3041021.3054762,https://doi.org/10.1145/3041021.3054762,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,Changing News Media Landscape in South Korea,"Lim, Hongjun and Chung, Choongho and Kim, Jihee and Kim, Juho and Moon, Sue and Cha, Meeyoung",inproceedings,10.1145/3041021.3054762,
10.1145/3041021.3055166,10.1145/3041021.3055166,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '17 Companion,"Perth, Australia","time series analysis, prediction, email",9,495–503,Proceedings of the 26th International Conference on World Wide Web Companion,"According to recent estimates, about 90% of consumer received emails are machine-generated. Such messages include shopping receipts, promotional campaigns, newsletters, booking confirmations, etc. Most such messages are created by populating a fixed template with a small amount of personalized information, such as name, salutation, reservation numbers, dates, etc. Web mail providers (Gmail, Hotmail, Yahoo) are leveraging the structured nature of such emails to extract salient information and use it to improve the user experience: e.g. by automatically entering reservation data into a user calendar, or by sending alerts about upcoming shipments. To facilitate these extraction tasks it is helpful to classify templates according to their category, e.g. restaurant reservations or bill reminders, since each category triggers a particular user experience.Recent research has focused on discovering the causal thread of templates, e.g. inferring that a shopping order is usually followed by a shipping confirmation, an airline booking is followed by a confirmation and then by a ""ready to check in"" message, etc. Gamzu et al. took this idea one step further by implementing a method to predict the template category of future emails for a given user based on previously received templates. The motivation is that predicting future emails has a wide range of potential applications, including better user experiences (e.g. warning users of items ordered but not shipped), targeted advertising (e.g. users that recently made a flight reservation may be interested in hotel reservations), and spam classification (a message that is part of a legitimate causal thread is unlikely to be spam).The gist of the Gamzu et al. approach is modeling the problem as a Markov chain, where the nodes are templates or temporal events (e.g. the first day of the month). This paper expands on their work by investigating the use of neural networks for predicting the category of emails that will arrive during a fixed-sized time window in the future. We consider two types of neural networks: multi-layer perceptrons (MLP), a type of feedforward neural network; and long short-term memory (LSTM), a type of recurrent neural network. For each type of neural network, we explore the effects of varying their configuration (e.g. number of layers or number of neurons) and hyper-parameters (e.g. drop-out ratio). We find that the prediction accuracy of neural networks vastly outperforms the Markov chain approach, and that LSTMs perform slightly better than MLPs. We offer some qualitative interpretation of our findings and identify some promising future directions.",10.1145/3041021.3055166,https://doi.org/10.1145/3041021.3055166,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450349147,2017,Email Category Prediction,"Zhang, Aston and Garcia-Pueyo, Lluis and Wendt, James B. and Najork, Marc and Broder, Andrei",inproceedings,10.1145/3041021.3055166,
10.1145/3097983.3098008,10.1145/3097983.3098008,KDD.bib,1,['KDD.bib'],8,KDD '17,"Halifax, NS, Canada","collaborative filtering, content-based filtering, discrete hashing, recommendation",10,325–334,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Precisely recommending relevant items from massive candidates to a large number of users is an indispensable yet computationally expensive task in many online platforms (e.g., Amazon.com and Netflix.com). A promising way is to project users and items into a Hamming space and then recommend items via Hamming distance. However, previous studies didn't address the cold-start challenges and couldn't make the best use of preference data like implicit feedback. To fill this gap, we propose a Discrete Content-aware Matrix Factorization (DCMF) model, 1) to derive compact yet informative binary codes at the presence of user/item content information; 2) to support the classification task based on a local upper bound of logit loss; 3) to introduce an interaction regularization for dealing with the sparsity issue. We further develop an efficient discrete optimization algorithm for parameter learning. Based on extensive experiments on three real-world datasets, we show that DCFM outperforms the state-of-the-arts on both regression and classification tasks.",10.1145/3097983.3098008,https://doi.org/10.1145/3097983.3098008,"New York, NY, USA",Association for Computing Machinery,9781450348874,2017,Discrete Content-aware Matrix Factorization,"Lian, Defu and Liu, Rui and Ge, Yong and Zheng, Kai and Xie, Xing and Cao, Longbing",inproceedings,10.1145/3097983.3098008,
10.1145/3097983.3098048,10.1145/3097983.3098048,KDD.bib,1,['KDD.bib'],8,KDD '17,"Halifax, NS, Canada","applied machine learning, neural networks, private data",9,1643–1651,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Google Drive is a cloud storage and collaboration service used by hundreds of millions of users around the world. Quick Access is a new feature in Google Drive that surfaces the most relevant documents when a user visits the home screen. Our metrics show that users locate their documents in half the time with this feature compared to previous approaches. The development of Quick Access illustrates many general challenges and constraints associated with practical machine learning such as protecting user privacy, working with data services that are not designed with machine learning in mind, and evolving product definitions. We believe that the lessons learned from this experience will be useful to practitioners tackling a wide range of applied machine learning problems.",10.1145/3097983.3098048,https://doi.org/10.1145/3097983.3098048,"New York, NY, USA",Association for Computing Machinery,9781450348874,2017,Quick Access: Building a Smart Experience for Google Drive,"Tata, Sandeep and Popescul, Alexandrin and Najork, Marc and Colagrosso, Mike and Gibbons, Julian and Green, Alan and Mah, Alexandre and Smith, Michael and Garg, Divanshu and Meyer, Cayden and Kan, Reuben",inproceedings,10.1145/3097983.3098048,
10.1145/3097983.3098063,10.1145/3097983.3098063,KDD.bib,1,['KDD.bib'],8,KDD '17,"Halifax, NS, Canada","collaborative filtering, factorization machine, heterogeneous information networks, recommendation system",10,635–644,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Heterogeneous Information Network (HIN) is a natural and general representation of data in modern large commercial recommender systems which involve heterogeneous types of data. HIN based recommenders face two problems: how to represent the high-level semantics of recommendations and how to fuse the heterogeneous information to make recommendations. In this paper, we solve the two problems by first introducing the concept of meta-graph to HIN-based recommendation, and then solving the information fusion problem with a ""matrix factorization (MF) + factorization machine (FM)"" approach. For the similarities generated by each meta-graph, we perform standard MF to generate latent features for both users and items. With different meta-graph based features, we propose to use FM with Group lasso (FMG) to automatically learn from the observed ratings to effectively select useful meta-graph based features. Experimental results on two real-world datasets, Amazon and Yelp, show the effectiveness of our approach compared to state-of-the-art FM and other HIN-based recommendation algorithms.",10.1145/3097983.3098063,https://doi.org/10.1145/3097983.3098063,"New York, NY, USA",Association for Computing Machinery,9781450348874,2017,Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks,"Zhao, Huan and Yao, Quanming and Li, Jianda and Song, Yangqiu and Lee, Dik Lun",inproceedings,10.1145/3097983.3098063,
10.1145/3097983.3098071,10.1145/3097983.3098071,KDD.bib,1,['KDD.bib'],8,KDD '17,"Halifax, NS, Canada","collaborative ranking, large-scale, recommendation systems",10,515–524,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"In this paper, we consider the Collaborative Ranking (CR) problem for recommendation systems. Given a set of pairwise preferences between items for each user, collaborative ranking can be used to rank un-rated items for each user, and this ranking can be naturally used for recommendation. It is observed that collaborative ranking algorithms usually achieve better performance since they directly minimize the ranking loss; however, they are rarely used in practice due to the poor scalability. All the existing CR algorithms have time complexity at least O(|Ω|r) per iteration, where r is the target rank and |Ω| is number of pairs which grows quadratically with number of ratings per user. For example, the Netflix data contains totally 20 billion rating pairs, and at this scale all the current algorithms have to work with significant subsampling, resulting in poor prediction on testing data.In this paper, we propose a new collaborative ranking algorithm called Primal-CR that reduces the time complexity to O(|Ω|+d1 |d2 r), where d1 is number of users and |d2 is the averaged number of items rated by a user. Note that d1 |d2 is strictly smaller and often much smaller than |Ω|.Furthermore, by exploiting the fact that most data is in the form of numerical ratings instead of pairwise comparisons, we propose Primal-CR++ with O(d1|d2 (r+ log |d2)) time complexity. Both algorithms have better theoretical time complexity than existing approaches and also outperform existing approaches in terms of NDCG and pairwise error on real data sets. To the best of our knowledge, this is the first collaborative ranking algorithm capable of working on the full Netflix dataset using all the 20 billion rating pairs, and this leads to a model with much better recommendation compared with previous models trained on subsamples. Finally, compared with classical matrix factorization algorithm which also requires O(d1d2r) time, our algorithm has almost the same efficiency while making much better recommendations since we consider the ranking loss.",10.1145/3097983.3098071,https://doi.org/10.1145/3097983.3098071,"New York, NY, USA",Association for Computing Machinery,9781450348874,2017,Large-scale Collaborative Ranking in Near-Linear Time,"Wu, Liwei and Hsieh, Cho-Jui and Sharpnack, James",inproceedings,10.1145/3097983.3098071,
10.1145/3097983.3098089,10.1145/3097983.3098089,KDD.bib,1,['KDD.bib'],8,KDD '17,"Halifax, NS, Canada","computational advertisement, large scale, local graph algorithm, user action prediction",9,2091–2099,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"User behavior modeling is essential in computational advertisement, which builds users' profiles by tracking their online behaviors and then delivers the relevant ads according to each user's interests and needs. Accurate models will lead to higher targeting accuracy and thus improved advertising performance. Intuitively, similar users tend to have similar behaviors towards the displayed ads (e.g., impression, click, conversion). However, to the best of our knowledge, there is not much previous work that explicitly investigates such similarities of various types of user behaviors, and incorporates them into ad response targeting and prediction, largely due to the prohibitive scale of the problem.To bridge this gap, in this paper, we use bipartite graphs to represent historical user behaviors, which consist of both user nodes and advertiser campaign nodes, as well as edges reflecting various types of user-campaign interactions in the past. Based on this representation, we study random-walk-based local algorithms for user behavior modeling and action prediction, whose computational complexity depends only on the size of the output cluster, rather than the entire graph. Our goal is to improve action prediction by leveraging historical user-user, campaign-campaign, and user-campaign interactions. In particular, we propose the bipartite graphs AdvUserGraph accompanied with the ADNI algorithm. ADNI extends the NIBBLE algorithm to AdvUserGraph, and it is able to find the local cluster consisting of interested users towards a specific advertiser campaign. We also propose two extensions of ADNI with improved efficiencies. The performance of the proposed algorithms is demonstrated on both synthetic data and a world leading Demand Side Platform (DSP), showing that they are able to discriminate extremely rare events in terms of their action propensity.",10.1145/3097983.3098089,https://doi.org/10.1145/3097983.3098089,"New York, NY, USA",Association for Computing Machinery,9781450348874,2017,Local Algorithm for User Action Prediction Towards Display Ads,"Yang, Hongxia and Zhu, Yada and He, Jingrui",inproceedings,10.1145/3097983.3098089,
10.1145/3097983.3098091,10.1145/3097983.3098091,KDD.bib,1,['KDD.bib'],8,KDD '17,"Halifax, NS, Canada","monotone transformation, optimal transformation, regression analysis, spline, variable selection",9,857–865,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"We develop a novel method called SParse Optimal Transformations (SPOT) to simultaneously select important variables and explore relationships between the response and predictor variables in high dimensional nonparametric regression analysis. Not only are the optimal transformations identified by SPOT interpretable, they can also be used for response prediction. We further show that SPOT achieves consistency in both variable selection and parameter estimation. Numerical experiments and real data applications demonstrate that SPOT outperforms other existing methods and can serve as an effective tool in practice.",10.1145/3097983.3098091,https://doi.org/10.1145/3097983.3098091,"New York, NY, USA",Association for Computing Machinery,9781450348874,2017,SPOT: Sparse Optimal Transformations for High Dimensional Variable Selection and Exploratory Regression Analysis,"Huang, Qiming and Zhu, Michael",inproceedings,10.1145/3097983.3098091,
10.1145/3097983.3098104,10.1145/3097983.3098104,KDD.bib,1,['KDD.bib'],8,KDD '17,"Halifax, NS, Canada","cost-benefit analysis, targeted promotions and discounts, temporal point processes, transaction data",9,1923–1931,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Time-limited promotions that exploit consumers' sense of urgency to boost sales account for billions of dollars in consumer spending each year. However, it is challenging to discover the right timing and duration of a promotion to increase its chances of being redeemed. In this work, we consider the problem of delivering time-limited discount coupons, where we partner with a large national bank functioning as a commission-based third-party coupon provider. Specifically, we use large-scale anonymized transaction records to model consumer spending and forecast future purchases, based on which we generate data-driven, personalized coupons. Our proposed model RUSH! (1) predicts {both the time and category} of the next event; (2) captures correlations between purchases in different categories (such as shopping triggering dining purchases); (3) incorporates temporal dynamics of purchase behavior (such as increased spending on weekends); (4) is composed of additive factors that are easily interpretable; and finally (5) scales linearly to millions of transactions. We design a cost-benefit framework that facilitates systematic evaluation in terms of our application, and show that RUSH! provides higher expected value than various baselines that do not jointly model time and category information.",10.1145/3097983.3098104,https://doi.org/10.1145/3097983.3098104,"New York, NY, USA",Association for Computing Machinery,9781450348874,2017,RUSH! Targeted Time-limited Coupons via Purchase Forecasts,"Manzoor, Emaad and Akoglu, Leman",inproceedings,10.1145/3097983.3098104,
10.1145/3097983.3098170,10.1145/3097983.3098170,KDD.bib,1,['KDD.bib'],8,KDD '17,"Halifax, NS, Canada","aspects of user experience, recommender systems, sentiment analysis, user experience, user reviews, user-controlled aspects",9,717–725,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"In this paper, we propose a recommendation technique that not only can recommend items of interest to the user as traditional recommendation systems do but also specific aspects of consumption of the items to further enhance the user experience with those items. For example, it can recommend the user to go to a specific restaurant (item) and also order some specific foods there, e.g., seafood (an aspect of consumption). Our method is called Sentiment Utility Logistic Model (SULM). As its name suggests, SULM uses sentiment analysis of user reviews. It first predicts the sentiment that the user may have about the item based on what he/she might express about the aspects of the item and then identifies the most valuable aspects of the user's potential experience with that item. Furthermore, the method can recommend items together with those most important aspects over which the user has control and can potentially select them, such as the time to go to a restaurant, e.g. lunch vs. dinner, and what to order there, e.g., seafood. We tested the proposed method on three applications (restaurant, hotel, and beauty &amp; spa) and experimentally showed that those users who followed our recommendations of the most valuable aspects while consuming the items, had better experiences, as defined by the overall rating.",10.1145/3097983.3098170,https://doi.org/10.1145/3097983.3098170,"New York, NY, USA",Association for Computing Machinery,9781450348874,2017,Aspect Based Recommendations: Recommending Items with the Most Valuable Aspects Based on User Reviews,"Bauman, Konstantin and Liu, Bing and Tuzhilin, Alexander",inproceedings,10.1145/3097983.3098170,
10.1145/3097983.3098202,10.1145/3097983.3098202,KDD.bib,1,['KDD.bib'],8,KDD '17,"Halifax, NS, Canada","collaborative filtering, neural networks, sampling strategies",10,767–776,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Recent advances in neural networks have inspired people to design hybrid recommendation algorithms that can incorporate both (1) user-item interaction information and (2) content information including image, audio, and text. Despite their promising results, neural network-based recommendation algorithms pose extensive computational costs, making it challenging to scale and improve upon. In this paper, we propose a general neural network-based recommendation framework, which subsumes several existing state-of-the-art recommendation algorithms, and address the efficiency issue by investigating sampling strategies in the stochastic gradient descent training for the framework. We tackle this issue by first establishing a connection between the loss functions and the user-item interaction bipartite graph, where the loss function terms are defined on links while major computation burdens are located at nodes. We call this type of loss functions ""graph-based"" loss functions, for which varied mini-batch sampling strategies can have different computational costs. Based on the insight, three novel sampling strategies are proposed, which can significantly improve the training efficiency of the proposed framework (up to $times 30$ times speedup in our experiments), as well as improving the recommendation performance. Theoretical analysis is also provided for both the computational cost and the convergence. We believe the study of sampling strategies have further implications on general graph-based loss functions, and would also enable more research under the neural network-based recommendation framework.",10.1145/3097983.3098202,https://doi.org/10.1145/3097983.3098202,"New York, NY, USA",Association for Computing Machinery,9781450348874,2017,On Sampling Strategies for Neural Network-based Collaborative Filtering,"Chen, Ting and Sun, Yizhou and Shi, Yue and Hong, Liangjie",inproceedings,10.1145/3097983.3098202,
10.1145/3109859.3109865,10.1145/3109859.3109865,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","context-aware recommender systems, context-driven recommender system, review-mining, topic modeling",5,426–430,Proceedings of the Eleventh ACM Conference on Recommender Systems,"In this work we present Rich-Context, a context-driven recommender system that extracts contextual information using topic modeling without the need to define keywords. Our system uses the mined context to produce recommendations. We propose a methodology to measure the quality of context topic models along with a novel way to represent context that allows it to be used as side-information in a recommendation engine. Results show that Rich-Context makes more accurate predictions than five well-established recommendation algorithms.",10.1145/3109859.3109865,https://doi.org/10.1145/3109859.3109865,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Unsupervised Context-Driven Recommendations Based On User Reviews,"Pe\~{n}a, Francisco J.",inproceedings,10.1145/3109859.3109865,
10.1145/3109859.3109866,10.1145/3109859.3109866,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","reinforcement learning, recommendation system, multi-armed bandits, information discovery, exploration exploitation trade-off",5,431–435,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Recommender Systems (RS) help users discover interesting products by means of relevant proactive suggestions. To accomplish this, RS must learn about user's unknown/unclear tastes, and constantly adapt to the dynamic nature of their environment. In this research, I focus on the notion that RS are faced with an optimization problem when generating recommendations: exploit the known user model, or explore other preferences the user might have. My PhD work aims to define the role of exploitation and exploration in RS, and proposes mechanisms that would allow to balance and control this trade-off. In this extended abstract I present the motivation, related work and research plan that guide the project.",10.1145/3109859.3109866,https://doi.org/10.1145/3109859.3109866,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,The Exploration-Exploitation Trade-off in Interactive Recommender Systems,"Barraza-Urbina, Andrea",inproceedings,10.1145/3109859.3109866,
10.1145/3109859.3109872,10.1145/3109859.3109872,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","session-based recommendation, nearest-neighbors, deep learning",5,306–310,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Deep learning methods have led to substantial progress in various application fields of AI, and in recent years a number of proposals were made to improve recommender systems with artificial neural networks. For the problem of making session-based recommendations, i.e., for recommending the next item in an anonymous session, Hidasi et al.~recently investigated the application of recurrent neural networks with Gated Recurrent Units (GRU4REC). Assessing the true effectiveness of such novel approaches based only on what is reported in the literature is however difficult when no standard evaluation protocols are applied and when the strength of the baselines used in the performance comparison is not clear. In this work we show based on a comprehensive empirical evaluation that a heuristics-based nearest neighbor (kNN) scheme for sessions outperforms GRU4REC in the large majority of the tested configurations and datasets. Neighborhood sampling and efficient in-memory data structures ensure the scalability of the kNN method. The best results in the end were often achieved when we combine the kNN approach with GRU4REC, which shows that RNNs can leverage sequential signals in the data that cannot be detected by the co-occurrence-based kNN method.",10.1145/3109859.3109872,https://doi.org/10.1145/3109859.3109872,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,When Recurrent Neural Networks meet the Neighborhood for Session-Based Recommendation,"Jannach, Dietmar and Ludewig, Malte",inproceedings,10.1145/3109859.3109872,
10.1145/3109859.3109877,10.1145/3109859.3109877,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","sequential recommendations, recurrent neural networks, recommender systems, neural networks, deep learning",9,152–160,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Recurrent Neural Networks are powerful tools for modeling sequences. They are flexibly extensible and can incorporate various kinds of information including temporal order. These properties make them well suited for generating sequential recommendations. In this paper, we extend Recurrent Neural Networks by considering unique characteristics of the Recommender Systems domain. One of these characteristics is the explicit notion of the user recommendations are specifically generated for. We show how individual users can be represented in addition to sequences of consumed items in a new type of Gated Recurrent Unit to effectively produce personalized next item recommendations. Offline experiments on two real-world datasets indicate that our extensions clearly improve objective performance when compared to state-of-the-art recommender algorithms and to a conventional Recurrent Neural Network.",10.1145/3109859.3109877,https://doi.org/10.1145/3109859.3109877,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Sequential User-based Recurrent Neural Network Recommendations,"Donkers, Tim and Loepp, Benedikt and Ziegler, J\""{u}rgen",inproceedings,10.1145/3109859.3109877,
10.1145/3109859.3109878,10.1145/3109859.3109878,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","deep learning, deep non-linear transformative neural nets, recommender systems",9,288–296,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Recently, deep learning methods have been shown to improve the performance of recommender systems over traditional methods, especially when review text is available. For example, a recent model, DeepCoNN, uses neural nets to learn one latent representation for the text of all reviews written by a target user, and a second latent representation for the text of all reviews for a target item, and then combines these latent representations to obtain state-of-the-art performance on recommendation tasks. We show that (unsurprisingly) much of the predictive value of review text comes from reviews of the target user for the target item. We then introduce a way in which this information can be used in recommendation, even when the target user's review for the target item is not available. Our model, called TransNets, extends the DeepCoNN model by introducing an additional latent layer representing the target user-target item pair. We then regularize this layer, at training time, to be similar to another latent representation of the target user's review of the target item. We show that TransNets and extensions of it improve substantially over the previous state-of-the-art.",10.1145/3109859.3109878,https://doi.org/10.1145/3109859.3109878,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,TransNets: Learning to Transform for Recommendation,"Catherine, Rose and Cohen, William",inproceedings,10.1145/3109859.3109878,
10.1145/3109859.3109879,10.1145/3109859.3109879,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","social relationships, learning to rank, collaborative filtering",9,5–13,Proceedings of the Eleventh ACM Conference on Recommender Systems,"The sparsity of users' preferences can significantly degrade the quality of recommendations in the collaborative filtering strategy. To account for the fact that the selections of social friends and foes may improve the recommendation accuracy, we propose a learning to rank model that exploits users' trust and distrust relationships. Our learning to rank model focusses on the performance at the top of the list, with the recommended items that end-users will actually see. In our model, we try to push the relevant items of users and their friends at the top of the list, while ranking low those of their foes. Furthermore, we propose a weighting strategy to capture the correlations of users' preferences with friends' trust and foes' distrust degrees in two intermediate trust- and distrust-preference user latent spaces, respectively. Our experiments on the Epinions dataset show that the proposed learning to rank model significantly outperforms other state-of-the-art methods in the presence of sparsity in users' preferences and when a part of trust and distrust relationships is not available. Furthermore, we demonstrate the crucial role of our weighting strategy in our model, to balance well the influences of friends and foes on users' preferences.",10.1145/3109859.3109879,https://doi.org/10.1145/3109859.3109879,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Learning to Rank with Trust and Distrust in Recommender Systems,"Rafailidis, Dimitrios and Crestani, Fabio",inproceedings,10.1145/3109859.3109879,
10.1145/3109859.3109881,10.1145/3109859.3109881,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","privacy, item-based collaborative filtering, distributed computing",9,89–97,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Recommender systems have become extremely common in recent years, and are utilized in a variety of domains such as movies, music, news, products, restaurants, etc. While a typical recommender system bases its recommendations solely on users' preference data collected by the system itself, the quality of recommendations can significantly be improved if several recommender systems (or vendors) share their data. However, such data sharing poses significant privacy and security challenges, both to the vendors and the users. In this paper we propose secure protocols for distributed item-based Collaborative Filtering. Our protocols allow to compute both the predicted ratings of items and their predicted rankings, without compromising privacy nor predictions' accuracy. Unlike previous solutions in which the secure protocols are executed solely by the vendors, our protocols assume the existence of a mediator that performs intermediate computations on encrypted data supplied by the vendors. Such a mediated setting is advantageous over the non-mediated one since it enables each vendor to communicate solely with the mediator. This yields reduced communication costs and it allows each vendor to issue recommendations to its clients without being dependent on the availability and willingness of the other vendors to collaborate.",10.1145/3109859.3109881,https://doi.org/10.1145/3109859.3109881,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Secure Multi-Party Protocols for Item-Based Collaborative Filtering,"Shmueli, Erez and Tassa, Tamir",inproceedings,10.1145/3109859.3109881,
10.1145/3109859.3109882,10.1145/3109859.3109882,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","recommender systems, relation, sequential behavior, translation",9,161–169,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Modeling the complex interactions between users and items as well as amongst items themselves is at the core of designing successful recommender systems. One classical setting is predicting users' personalized sequential behavior (or 'next-item' recommendation), where the challenges mainly lie in modeling 'third-order' interactions between a user, her previously visited item(s), and the next item to consume. Existing methods typically decompose these higher-order interactions into a combination of pairwise relationships, by way of which user preferences (user-item interactions) and sequential patterns (item-item interactions) are captured by separate components. In this paper, we propose a unified method, TransRec, to model such third-order relationships for large-scale sequential prediction. Methodologically, we embed items into a 'transition space' where users are modeled as translation vectors operating on item sequences. Empirically, this approach outperforms the state-of-the-art on a wide spectrum of real-world datasets. Data and code are available at https://sites.google.com/a/eng.ucsd.edu/ruining-he/.",10.1145/3109859.3109882,https://doi.org/10.1145/3109859.3109882,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Translation-based Recommendation,"He, Ruining and Kang, Wang-Cheng and McAuley, Julian",inproceedings,10.1145/3109859.3109882,
10.1145/3109859.3109890,10.1145/3109859.3109890,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","attention model, convolutional neural network, deep learning for recommender systems",9,297–305,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Recently, many e-commerce websites have encouraged their users to rate shopping items and write review texts. This review information has been very useful for understanding user preferences and item properties, as well as enhancing the capability to make personalized recommendations of these websites. In this paper, we propose to model user preferences and item properties using convolutional neural networks (CNNs) with dual local and global attention, motivated by the superiority of CNNs to extract complex features. By using aggregated review texts from a user and aggregated review text for an item, our model can learn the unique features (embedding) of each user and each item. These features are then used to predict ratings. We train these user and item networks jointly which enable the interaction between users and items in a similar way as matrix factorization. The local attention provides us insight on a user's preferences or an item's properties. The global attention helps CNNs focus on the semantic meaning of the whole review text. Thus, the combined local and global attentions enable an interpretable and better-learned representation of users and items. We validate the proposed models by testing on popular review datasets in Yelp and Amazon and compare the results with matrix factorization (MF), the hidden factor and topical (HFT) model, and the recently proposed convolutional matrix factorization (ConvMF+). Our proposed CNNs with dual attention model outperforms HFT and ConvMF+ in terms of mean square errors (MSE). In addition, we compare the user/item embeddings learned from these models for classification and recommendation. These results also confirm the superior quality of user/item embeddings learned from our model.",10.1145/3109859.3109890,https://doi.org/10.1145/3109859.3109890,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Interpretable Convolutional Neural Networks with Dual Local and Global Attention for Review Rating Prediction,"Seo, Sungyong and Huang, Jing and Yang, Hao and Liu, Yan",inproceedings,10.1145/3109859.3109890,
10.1145/3109859.3109898,10.1145/3109859.3109898,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","distribution-paradigm, human uncertainty, magic barrier, noise, point-paradigm, ranking error, rmse",9,56–64,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Recommender systems nowadays have many applications and are of great economic benefit. Hence, it is imperative for success-oriented companies to compare various of such systems and select the better one for their purposes. To this end, various metrics of predictive accuracy are commonly used, such as the Root Mean Square Error (RMSE), or precision and recall. All these metrics more or less measure how well a recommender system can predict human behaviour. Unfortunately, human behaviour is always associated with some degree of uncertainty, making the evaluation difficult, since it is not clear whether a deviation is system-induced or just originates from the natural variability of human decision making. At this point, some authors speculated that we may be reaching some Magic Barrier where this variability prevents us from getting much more accurate [12, 13, 24]. In this article, we will extend the existing theory of the Magic Barrier [24] into a new probabilistic but a yet pragmatic model. In particular, we will use methods from metrology and physics to develop easy-to-handle quantities for computation to describe the Magic Barrier for different accuracy metrics and provide suggestions for common application. This discussion is substantiated by comprehensive experiments with real users and large-scale simulations on a high-performance cluster.",10.1145/3109859.3109898,https://doi.org/10.1145/3109859.3109898,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,The Magic Barrier Revisited: Accessing Natural Limitations of Recommender Assessment,"Jasberg, Kevin and Sizov, Sergej",inproceedings,10.1145/3109859.3109898,
10.1145/3109859.3109903,10.1145/3109859.3109903,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","audience retrieval, collaborative filtering, recommendations",9,170–178,Proceedings of the Eleventh ACM Conference on Recommender Systems,"The recommendation challenge can be posed as the problem of predicting either item ratings or item rankings. The latter approach has proven more effective. Pairwise learning-to-rank techniques have been relatively successful. Hence, they are popularly used for learning recommender model parameters such as those in collaborative filtering (CF) models. The model parameters are learned by optimizing close smooth approximations of the non-smooth information retrieval (IR) metrics such as Mean Area Under ROC curve (AUC).Targeted campaigns are an alternative to item recommendations for increasing conversion. The user ranking task is referred to as audience retrieval. It is used in targeted campaigns to rank push campaign recipients based on their potential to convert. In this work, we consider the task of efficiently learning a ranking model that provides item recommendations and user rankings simultaneously. We adopt pairwise learning for this task. We refer to our approach as multi-objective pairwise ranking (MPR).We describe our approach and use experiments to evaluate its performance.",10.1145/3109859.3109903,https://doi.org/10.1145/3109859.3109903,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,MPR: Multi-Objective Pairwise Ranking,"Otunba, Rasaq and Rufai, Raimi A. and Lin, Jessica",inproceedings,10.1145/3109859.3109903,
10.1145/3109859.3109905,10.1145/3109859.3109905,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","sentiment analysis, recommender systems, opinion mining",5,321–325,Proceedings of the Eleventh ACM Conference on Recommender Systems,"In this paper we propose a multi-criteria recommender system based on collaborative filtering (CF) techniques, which exploits the information conveyed by users' reviews to provide a multi-faceted representation of users' interests.To this end, we exploited a framework for opinion mining and sentiment analysis, which automatically extracts relevant aspects and sentiment scores from users' reviews. As an example, in a restaurant recommendation scenario, the aspects may regard food quality, service, position, athmosphere of the place and so on. Such a multi-faceted representation of the user is used to feed a multi-criteria CF algorithm which predicts user interest in a particular item and provides her with recommendations.In the experimental session we evaluated the performance of the algorithm against several state-of-the-art baselines; Results confirmed the insight behind this work, since our approach was able to overcome both single-criteria recommendation algorithms as well as more sophisticated techniques based on matrix factorization.",10.1145/3109859.3109905,https://doi.org/10.1145/3109859.3109905,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,A Multi-criteria Recommender System Exploiting Aspect-based Sentiment Analysis of Users' Reviews,"Musto, Cataldo and de Gemmis, Marco and Semeraro, Giovanni and Lops, Pasquale",inproceedings,10.1145/3109859.3109905,
10.1145/3109859.3109911,10.1145/3109859.3109911,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","mnar, matrix factorization, folding, evaluation metric, collaborative filtering",9,201–209,Proceedings of the Eleventh ACM Conference on Recommender Systems,"In recommender systems based on low-rank factorization of a partially observed user-item matrix, a common phenomenon that plagues many otherwise effective models is the interleaving of good and spurious recommendations in the top-K results. A single spurious recommendation can dramatically impact the perceived quality of a recommender system. Spurious recommendations do not result in serendipitous discoveries but rather cognitive dissonance. In this work, we investigate folding, a major contributing factor to spurious recommendations. Folding refers to the unintentional overlap of disparate groups of users and items in the low-rank embedding vector space, induced by improper handling of missing data. We formally define a metric that quantifies the severity of folding in a trained system, to assist in diagnosing its potential to make inappropriate recommendations. The folding metric complements existing information retrieval metrics that focus on the number of good recommendations and their ranks but ignore the impact of undesired recommendations. We motivate the folding metric definition on synthetic data and evaluate its effectiveness on both synthetic and real world datasets. In studying the relationship between the folding metric and other characteristics of recommender systems, we observe that optimizing for goodness metrics can lead to high folding and thus more spurious recommendations.",10.1145/3109859.3109911,https://doi.org/10.1145/3109859.3109911,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Folding: Why Good Models Sometimes Make Spurious Recommendations,"Xin, Doris and Mayoraz, Nicolas and Pham, Hubert and Lakshmanan, Karthik and Anderson, John R.",inproceedings,10.1145/3109859.3109911,
10.1145/3109859.3109912,10.1145/3109859.3109912,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","coverage, learning to rank, long-tail, recommendation evaluation, recommender systems",5,42–46,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Many recommendation algorithms suffer from popularity bias in their output: popular items are recommended frequently and less popular ones rarely, if at all. However, less popular, long-tail items are precisely those that are often desirable recommendations. In this paper, we introduce a flexible regularization-based framework to enhance the long-tail coverage of recommendation lists in a learning-to-rank algorithm. We show that regularization provides a tunable mechanism for controlling the trade-off between accuracy and coverage. Moreover, the experimental results using two data sets show that it is possible to improve coverage of long tail items without substantial loss of ranking performance.",10.1145/3109859.3109912,https://doi.org/10.1145/3109859.3109912,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Controlling Popularity Bias in Learning-to-Rank Recommendation,"Abdollahpouri, Himan and Burke, Robin and Mobasher, Bamshad",inproceedings,10.1145/3109859.3109912,
10.1145/3109859.3109913,10.1145/3109859.3109913,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","recommender systems, matrix factorization, latent factor models, interpretable models, explanations",5,79–83,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Accurate model-based Collaborative Filtering (CF) approaches, such as Matrix Factorization (MF), tend to be black-box machine learning models that lack interpretability and do not provide a straightforward explanation for their outputs. Yet explanations have been shown to improve the transparency of a recommender system by justifying recommendations, and this in turn can enhance the user's trust in the recommendations. Hence, one main challenge in designing a recommender system is mitigating the trade-off between an explainable technique with moderate prediction accuracy and a more accurate technique with no explainable recommendations. In this paper, we focus on factorization models and further assume the absence of any additional data source, such as item content or user attributes. We propose an explainability constrained MF technique that computes the top-n recommendation list from items that are explainable. Experimental results show that our method is effective in generating accurate and explainable recommendations.",10.1145/3109859.3109913,https://doi.org/10.1145/3109859.3109913,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Using Explainability for Constrained Matrix Factorization,"Abdollahi, Behnoush and Nasraoui, Olfa",inproceedings,10.1145/3109859.3109913,
10.1145/3109859.3109916,10.1145/3109859.3109916,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","positive and negative recommendations, matrix factorization, diverse recommendations, collaborative filtering",9,215–223,Proceedings of the Eleventh ACM Conference on Recommender Systems,"In most existing recommender systems, implicit or explicit interactions are treated as positive links and all unknown interactions are treated as negative links. The goal is to suggest new links that will be perceived as positive by users. However, as signed social networks and newer content services become common, it is important to distinguish between positive and negative preferences. Even in existing applications, the cost of a negative recommendation could be high when people are looking for new jobs, friends, or places to live.In this work, we develop novel probabilistic latent factor models to recommend positive links and compare them with existing methods on five different openly available datasets. Our models are able to produce better ranking lists and are effective in the task of ranking positive links at the top, with fewer negative links (flops). Moreover, we find that modeling signed social networks and user preferences this way has the advantage of increasing the diversity of recommendations. We also investigate the effect of regularization on the quality of recommendations, a matter that has not received enough attention in the literature. We find that regularization parameter heavily affects the quality of recommendations in terms of both accuracy and diversity.",10.1145/3109859.3109916,https://doi.org/10.1145/3109859.3109916,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,"Fewer Flops at the Top: Accuracy, Diversity, and Regularization in Two-Class Collaborative Filtering","Paudel, Bibek and Haas, Thilo and Bernstein, Abraham",inproceedings,10.1145/3109859.3109916,
10.1145/3109859.3109937,10.1145/3109859.3109937,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","concept drift, open source recommender systems, ranking prediction by online learning, streaming, temporal evaluation",2,400–401,Proceedings of the Eleventh ACM Conference on Recommender Systems,"Recommender systems have to serve in online environments that can be non-stationary. Traditional recommender algorithms may periodically rebuild their models, but they cannot adjust to quick changes in trends caused by timely information. In contrast, online learning models can adopt to temporal effects, hence they may overcome the effect of concept drift.In our tutorial, we present open source systems capable of updating their models on the fly after each event: Apache Spark, Apache Flink and Alpenglow, a C++ based Python recommender framework. Participants of the tutorial will be able to experiment with all the three systems by using interactive Jupyter and Zeppelin Notebooks. Our final objective is to compare and then blend batch and online methods to build models providing high quality top-k recommendation in non-stationary environments.",10.1145/3109859.3109937,https://doi.org/10.1145/3109859.3109937,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Tutorial on Open Source Online Learning Recommenders,"P\'{a}lovics, R\'{o}bert and Kelen, Domokos and Bencz\'{u}r, Andr\'{a}s A.",inproceedings,10.1145/3109859.3109937,
10.1145/3109859.3109952,10.1145/3109859.3109952,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","concept drift, recommender systems, recurrent neural networks, temporal aspects, temporal sequences, time-aware recommendations",2,368–369,Proceedings of the Eleventh ACM Conference on Recommender Systems,"The workshop focus is on considering temporal aspects for recommender systems in general, regardless of the specific domain and application, trying to develop a holistic approach for dealing with temporal aspects in recommender systems, like personal assistants, news, tourism, health care, TV, e-commerce, social networks and so on.",10.1145/3109859.3109952,https://doi.org/10.1145/3109859.3109952,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,The 1st International Workshop on Temporal Reasoning in Recommender Systems,"Bielikova, Maria and Bogina, Veronika and Kuflik, Tsvi and Sasson, Roy",inproceedings,10.1145/3109859.3109952,
10.1145/3109859.3109982,10.1145/3109859.3109982,RecSys.bib,1,['RecSys.bib'],8,RecSys '17,"Como, Italy","evaluation, r, recommendation algorithms, visualization",2,362–363,Proceedings of the Eleventh ACM Conference on Recommender Systems,"rrecsys is a novel library in R for developing and assessing recommendation algorithms. In this demo, we extend rrecsys with functions for visual analytics of recommendation performance, that is one of the strong capabilities of the R environment. In particular, we show how the library can be used to depict dataset characteristics, train and test recommendation algorithms and to visually assess, for instance, their capability to exploit long-tail items for making correct predictions.",10.1145/3109859.3109982,https://doi.org/10.1145/3109859.3109982,"New York, NY, USA",Association for Computing Machinery,9781450346528,2017,Visual Analysis of Recommendation Performance,"\c{C}oba, Ludovik and Symeonidis, Panagiotis and Zanker, Markus",inproceedings,10.1145/3109859.3109982,
10.1145/3110025.3110071,10.1145/3110025.3110071,KDD.bib,1,['KDD.bib'],8,ASONAM '17,"Sydney, Australia","Cascade Volume Predictions, cascade entropy measures, maximal predictability, social media cascades",6,109–114,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"Predicting cascade volumes in social media communication is an important topic in furthering the use of social media for viral marketing, impact of political campaigns and in home-land security. Several techniques have been reported in the literature to estimate the cascade volumes. These algorithms use a variety of information such as Content, Structural and Temporal features, depending on their availability. Due to the spread of information infused into the algorithms the prediction accuracy has been shown in the literature to be different for different algorithms.Entropy based measures that are tailored for the differing situations of information availability have been successfully applied in the prediction scenarios in many fields including network traffic, human mobility and radio spectrum state dynamics as well as in atmospheric science. In this paper we adopt a multitude of entropy based measures for quantifying the predictability of cascade volumes in online social media communications. The limit derived from the entropy measures discussed in this paper has also been used to explain the difference in accuracies of some of the algorithms for cascade volume predictions reported in the literature. For the purpose of illustration and to demonstrate the utility of the entropy based predictability limits we have used two data sets, the MemeTracker dataset and Twitter Hashtags dataset. The results obtained in this paper demonstrate clearly the utility of entropy based measures for quantifying the predictability in online social media cascades. We have also shown that temporal relevancy is a dominant contributing factor in cascade predictability and how additional features such as the knowledge of a small number of large media sites and blogs can have significant influence on the prediction performance.",10.1145/3110025.3110071,https://doi.org/10.1145/3110025.3110071,"New York, NY, USA",Association for Computing Machinery,9781450349932,2017,On Quantifying Predictability in Online Social Media Cascades Using Entropy,"Kolli, Naimisha and Balakrishnan, N. and Ramakrishnan, K. R.",inproceedings,10.1145/3110025.3110071,
10.1145/3110025.3110075,10.1145/3110025.3110075,KDD.bib,1,['KDD.bib'],7,ASONAM '17,"Sydney, Australia",,8,497–504,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"Many adult content websites incorporate social networking features. Although these are popular, they raise significant challenges, including the potential for users to ""catfish"", i.e., to create fake profiles to deceive other users. This paper takes an initial step towards automated catfish detection. We explore the characteristics of the different age and gender groups, identifying a number of distinctions. Through this, we train models based on user profiles and comments, via the ground truth of specially verified profiles. When applying our models for age and gender estimation to unverified profiles, 38% of profiles are classified as lying about their age, and 25% are predicted to be lying about their gender. The results suggest that women have a greater propensity to catfish than men. Our preliminary work has notable implications on operators of such online social networks, as well as users who may worry about interacting with catfishes.",10.1145/3110025.3110075,https://doi.org/10.1145/3110025.3110075,"New York, NY, USA",Association for Computing Machinery,9781450349932,2017,Fake it till you make it: Fishing for Catfishes,"Magdy, Walid and Elkhatib, Yehia and Tyson, Gareth and Joglekar, Sagar and Sastry, Nishanth",inproceedings,10.1145/3110025.3110075,
10.1145/3110025.3110083,10.1145/3110025.3110083,KDD.bib,1,['KDD.bib'],7,ASONAM '17,"Sydney, Australia",,8,95–102,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"Research in analysis of microblogging platforms is experiencing a renewed surge with a large number of works applying representation learning models for applications like sentiment analysis, semantic textual similarity computation, hashtag prediction, etc. Although the performance of the representation learning models has been better than the traditional baselines for such tasks, little is known about the elementary properties of a tweet encoded within these representations, or why particular representations work better for certain tasks. Our work presented here constitutes the first step in opening the black-box of vector embeddings for tweets.Traditional feature engineering methods for high-level applications have exploited various elementary properties of tweets. We believe that a tweet representation is effective for an application because it meticulously encodes the application-specific elementary properties of tweets. To understand the elementary properties encoded in a tweet representation, we evaluate the representations on the accuracy to which they can model each of those properties such as tweet length, presence of particular words, hashtags, mentions, capitalization, etc.Our systematic extensive study of nine supervised and four unsupervised tweet representations against most popular eight textual and five social elementary properties reveal that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors (STV) best encode the textual and social properties of tweets respectively. FastText is the best model for low resource settings, providing very little degradation with reduction in embedding size. Finally, we draw interesting insights by correlating the model performance obtained for elementary property prediction tasks with the high-level downstream applications.",10.1145/3110025.3110083,https://doi.org/10.1145/3110025.3110083,"New York, NY, USA",Association for Computing Machinery,9781450349932,2017,Interpretation of Semantic Tweet Representations,"Ganesh, J. and Gupta, Manish and Varma, Vasudeva",inproceedings,10.1145/3110025.3110083,
10.1145/3110025.3110090,10.1145/3110025.3110090,KDD.bib,1,['KDD.bib'],8,ASONAM '17,"Sydney, Australia","behavioural analysis, bot characterisation, content propagation, social network analysis",6,349–354,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"Recent research has shown a substantial active presence of bots in online social networks (OSNs). In this paper we utilise our previous work (Stweeler) to comparatively analyse the usage and impact of bots and humans on Twitter, one of the largest OSNs in the world. We collect a large-scale Twitter dataset and define various metrics based on tweet metadata. Using a human annotation task we assign 'bot' and 'human' ground-truth labels to the dataset, and compare the annotations against an online bot detection tool for evaluation. We then ask a series of questions to discern important behavioural characteristics of bots and humans using metrics within and among four popularity groups. From the comparative analysis we draw differences and interesting similarities between the two entities, thus paving the way for reliable classification of bots, and studying automated political infiltration and advertisement campaigns.",10.1145/3110025.3110090,https://doi.org/10.1145/3110025.3110090,"New York, NY, USA",Association for Computing Machinery,9781450349932,2017,Of Bots and Humans (on Twitter),"Gilani, Zafar and Farahbakhsh, Reza and Tyson, Gareth and Wang, Liang and Crowcroft, Jon",inproceedings,10.1145/3110025.3110090,
10.1145/3110025.3110091,10.1145/3110025.3110091,KDD.bib,1,['KDD.bib'],8,ASONAM '17,"Sydney, Australia","account classification, automated agents, bot detection, social network analysis",8,489–496,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"Online social networks (OSNs) have seen a remarkable rise in the presence of surreptitious automated accounts. Massive human user-base and business-supportive operating model of social networks (such as Twitter) facilitates the creation of automated agents. In this paper we outline a systematic methodology and train a classifier to categorise Twitter accounts into 'automated' and 'human' users. To improve classification accuracy we employ a set of novel steps. First, we divide the dataset into four popularity bands to compensate for differences in types of accounts. Second, we create a large ground truth dataset using human annotations and extract relevant features from raw tweets. To judge accuracy of the procedure we calculate agreement among human annotators as well as with a bot detection research tool. We then apply a Random Forests classifier that achieves an accuracy close to human agreement. Finally, as a concluding step we perform tests to measure the efficacy of our results.",10.1145/3110025.3110091,https://doi.org/10.1145/3110025.3110091,"New York, NY, USA",Association for Computing Machinery,9781450349932,2017,Classification of Twitter Accounts into Automated Agents and Human Users,"Gilani, Zafar and Kochmar, Ekaterina and Crowcroft, Jon",inproceedings,10.1145/3110025.3110091,
10.1145/3110025.3110107,10.1145/3110025.3110107,KDD.bib,1,['KDD.bib'],7,ASONAM '17,"Sydney, Australia",,8,195–202,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"Online social media provide a platform for rapid network propagation of information at an unprecedented scale. In this paper, we study the evolution of information cascades in Twitter using a point process model of user activity. Twitter is rich with heterogenous information on users and network structure. We develop several Hawkes process models considering various properties of Twitter including conversational structure, users' connections and general features of users including the textual information, and show how they are helpful in modeling the social network activity. Evaluation on Twitter data sets shows that incorporating richer properties improves the performance in predicting future activity of users and memes.",10.1145/3110025.3110107,https://doi.org/10.1145/3110025.3110107,"New York, NY, USA",Association for Computing Machinery,9781450349932,2017,Longitudinal Modeling of Social Media with Hawkes Process Based on Users and Networks,"Srijith, P. K. and Lukasik, Michal and Bontcheva, Kalina and Cohn, Trevor",inproceedings,10.1145/3110025.3110107,
10.1145/3110025.3110126,10.1145/3110025.3110126,KDD.bib,1,['KDD.bib'],7,ASONAM '17,"Sydney, Australia",,8,525–532,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"What tweet features are associated with higher effectiveness in tweets? Through the mining of 122 million engagements of 2.5 million original tweets, we present a systematic review of tweet time, entities, composition, and user account features. We show that the relationship between various features and tweeting effectiveness is non-linear; for example, tweets that use a few hashtags have higher effectiveness than using no or too many hashtags. This research closely relates to various industrial applications that are based on tweet features, including the analysis of advertising campaigns, the prediction of user engagement, the extraction of signals for automated trading, etc.",10.1145/3110025.3110126,https://doi.org/10.1145/3110025.3110126,"New York, NY, USA",Association for Computing Machinery,9781450349932,2017,Mining Features Associated with Effective Tweets,"Xu, Jian and Chawla, Nitesh V.",inproceedings,10.1145/3110025.3110126,
10.1145/3110025.3110144,10.1145/3110025.3110144,KDD.bib,1,['KDD.bib'],7,ASONAM '17,"Sydney, Australia",,8,401–408,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"Existing collaborative ranking based recommender systems tend to perform best when there is enough observed ratings for each user, and the observed data is uniformly sampled at random. However, when the observed ratings are extremely sparse (e.g. in the case of cold-start item where no rating data is available), and are not sampled uniformly at random, existing ranking methods fail to effectively leverage side information to transduct the knowledge from existing ratings to unobserved ones. We propose a semi-supervised collaborative ranking model, dubbed S2COR, to improve the quality of cold-start item recommendation. S2COR mitigates the sparsity issue by leveraging side information about both observed and missing ratings by collaboratively learning the ranking model. This enables it to deal with the case of data missing not at random, but to also effectively incorporate the available side information in transduction. We experimentally evaluated our proposed algorithm on a number of challenging real-world datasets and compared our results against state-of-the-art models for cold-start recommendation. We show significantly higher quality recommendations with our algorithm when compared to other state-of-the-art methods.",10.1145/3110025.3110144,https://doi.org/10.1145/3110025.3110144,"New York, NY, USA",Association for Computing Machinery,9781450349932,2017,Semi-supervised Collaborative Ranking with Push at the Top,"Forsati, Rana and Barjasteh, Iman and Esfahanian, Abdol-Hossein",inproceedings,10.1145/3110025.3110144,
10.1145/3110025.3116192,10.1145/3110025.3116192,KDD.bib,1,['KDD.bib'],8,ASONAM '17,"Sydney, Australia","Information diffusion, feature selection, online social networks, retweet, sentiment analysis",8,836–843,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"Reposting is the basic and key behavior for information diffusion in online social networks. It would be beneficial to understand the influence factors of reposting behavior and predict future reposting status, which could be practically applied in breaking news detection, marketing, social media researches and so on. Existing reposting analytics and prediction approaches mainly focus on factors related to the original information content and the social influence of the information publishers. However, online information diffuses by viral cascades instead of single-source broadcast in social network, which means some reposting behavior actually occurs in information propagators rather than the original publishers. In some social networks, users are allowed to comment when they repost, which represents their views and attitudes to the information they propagate. In this paper, we evaluate how emotional tendencies of information propagators influence future reposting. We first propose a modified sentiment analysis method and present emotional analysis on the user-generated content in online diffusion. Experiments are conducted with a real-world dataset and the results indicate the effectiveness of our fine-grained emotional features in reposting prediction.",10.1145/3110025.3116192,https://doi.org/10.1145/3110025.3116192,"New York, NY, USA",Association for Computing Machinery,9781450349932,2017,Propagator or Influencer? A Data-driven Approach for Evaluating Emotional Effect in Online Information Diffusion,"Yang, Jun and Wang, Zhaoguo and Di, Fangchun and Chen, Liyue and Yi, Chengqi and Xue, Yibo and Li, Jun",inproceedings,10.1145/3110025.3116192,
10.1145/312129.312230,10.1145/312129.312230,KDD.bib,1,['KDD.bib'],6,KDD '99,"San Diego, California, USA",,12,201–212,Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,10.1145/312129.312230,https://doi.org/10.1145/312129.312230,"New York, NY, USA",Association for Computing Machinery,1581131437,1999,Horting hatches an egg: a new graph-theoretic approach to collaborative filtering,"Aggarwal, Charu C. and Wolf, Joel L. and Wu, Kun-Lung and Yu, Philip S.",inproceedings,10.1145/312129.312230,
10.1145/3124791.3124794,10.1145/3124791.3124794,RecSys.bib,1,['RecSys.bib'],7,RecSys Challenge '17,"Como, Italy","recsys challenge 2017, recommendation systems, job recommendations, content-based filtering, cold start",6,,Proceedings of the Recommender Systems Challenge 2017,"The 2017 ACM RecSys Challenge focuses on the problem of job recommendations on XING in a cold-start scenario. In this paper we describe our solution as well as some practical lessons learned from the competition. We model this task as a binary classification problem. Negative candidate selection is the first key phase in our solution. We design a negative sampling strategy which performs significantly better than taking users' deleted or unclicked items as negative candidates. We then extract comprehensive features to model the relationship between a user-job candidate, including the direct profile similarity between the user and the job, and the profile similarity between the user's historical interested jobs and the target job. To make the whole pipeline scalable and easy to deploy online, we decide to use a single boosting tree model as the final discriminative model, instead of using a stacking ensemble of multiple models. Overall our model ranked 5th on the challenge leaderboard, and our last model has remained in 2nd place during the last two online weeks. We have open-sourced our implementation on https://github.com/Leavingseason/RecsysChallenge2017.",10.1145/3124791.3124794,https://doi.org/10.1145/3124791.3124794,"New York, NY, USA",Association for Computing Machinery,9781450353915,2017,Practical Lessons for Job Recommendations in the Cold-Start Scenario,"Lian, Jianxun and Zhang, Fuzheng and Hou, Min and Wang, Hongwei and Xie, Xing and Sun, Guangzhong",inproceedings,10.1145/3124791.3124794,4
10.1145/3132847.3132853,10.1145/3132847.3132853,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","word2vec, transfer learning, text representation, noise contrastive estimation, article recommendation",9,1099–1107,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Programmatic display advertising, which enables advertisers to make real-time decisions on individual ad display opportunities so as to achieve a precise audience marketing, has become a key technique for online advertising. However, the constrained budget setting still restricts unlimited ad impressions. As a result, a smart strategy for ad impression selection is necessary for the advertisers to maximize positive user responses such as clicks or conversions, under the constraints of both ad volume and campaign budget. In this paper, we borrow in the idea of top-N ranking and filtering techniques from information retrieval and propose an effective ad impression volume ranking method for each ad campaign, followed by a sequential selection strategy considering the remaining ad volume and budget, to smoothly deliver the volume filtering while maximizing campaign efficiency. The extensive experiments on two benchmarking datasets and a commercial ad platform demonstrate large performance superiority of our proposed solution over traditional methods, especially under tight budgets.",10.1145/3132847.3132853,https://doi.org/10.1145/3132847.3132853,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Volume Ranking and Sequential Selection in Programmatic Display Advertising,"Song, Yuxuan and Ren, Kan and Cai, Han and Zhang, Weinan and Yu, Yong",inproceedings,10.1145/3132847.3132853,
10.1145/3132847.3132892,10.1145/3132847.3132892,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","top-n recommendation, representation learning, recommender systems, heterogeneous information processing",10,1449–1458,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"The Web has accumulated a rich source of information, such as text, image, rating, etc, which represent different aspects of user preferences. However, the heterogeneous nature of this information makes it difficult for recommender systems to leverage in a unified framework to boost the performance. Recently, the rapid development of representation learning techniques provides an approach to this problem. By translating the various information sources into a unified representation space, it becomes possible to integrate heterogeneous information for informed recommendation.  In this work, we propose a Joint Representation Learning (JRL) framework for top-N recommendation. In this framework, each type of information source (review text, product image, numerical rating, etc) is adopted to learn the corresponding user and item representations based on available (deep) representation learning architectures. Representations from different sources are integrated with an extra layer to obtain the joint representations for users and items. In the end, both the per-source and the joint representations are trained as a whole using pair-wise learning to rank for top-N recommendation. We analyze how information propagates among different information sources in a gradient-descent learning paradigm, based on which we further propose an extendable version of the JRL framework (eJRL), which is rigorously extendable to new information sources to avoid model re-training in practice. By representing users and items into embeddings offline, and using a simple vector multiplication for ranking score calculation online, our framework also has the advantage of fast online prediction compared with other deep learning approaches to recommendation that learn a complex prediction network for online calculation.",10.1145/3132847.3132892,https://doi.org/10.1145/3132847.3132892,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Joint Representation Learning for Top-N Recommendation with Heterogeneous Information Sources,"Zhang, Yongfeng and Ai, Qingyao and Chen, Xu and Croft, W. Bruce",inproceedings,10.1145/3132847.3132892,
10.1145/3132847.3132911,10.1145/3132847.3132911,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","social network, recommender system, implicit feedback",10,337–346,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"User feedback in the form of movie-watching history, item ratings, or product consumption is very helpful in training recommender systems. However, relatively few interactions between items and users can be observed. Instances of missing user--item entries are caused by the user not seeing the item (although the actual preference to the item could still be positive) or the user seeing the item but not liking it. Separating these two cases enables missing interactions to be modeled with finer granularity, and thus reflects user preferences more accurately. However, most previous studies on the modeling of missing instances have not fully considered the case where the user has not seen the item. Social connections are known to be helpful for modeling users' potential preferences more extensively, although a similar visibility problem exists in accurately identifying social relationships. That is, when two users are unaware of each other's existence, they have no opportunity to connect. In this paper, we propose a novel user preference model for recommender systems that considers the visibility of both items and social relationships. Furthermore, the two kinds of information are coordinated in a unified model inspired by the idea of transfer learning. Extensive experiments have been conducted on three real-world datasets in comparison with five state-of-the-art approaches. The encouraging performance of the proposed system verifies the effectiveness of social knowledge transfer and the modeling of both item and social visibilities.",10.1145/3132847.3132911,https://doi.org/10.1145/3132847.3132911,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Learning and Transferring Social and Item Visibilities for Personalized Recommendation,"Xiao, Lin and Min, Zhang and Yongfeng, Zhang and Yiqun, Liu and Shaoping, Ma",inproceedings,10.1145/3132847.3132911,
10.1145/3132847.3132923,10.1145/3132847.3132923,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","popularity dynamics, poisson process, interdisciplinary citations, diffusion process, affinity",10,477–486,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Information items draw collective attention across a heterogeneous social system, leading to great disparities of popularity. Unveiling underlying diffusion processes is very challenging, since a social system consists of time-evolving subgroups interacting and exerting disproportionate influences on an individual item's popularity. In this study, we propose the Affinity Poisson Process model (APP) which models popularity dynamics, by incorporating (1) affinities between subgroups, (2) heterogeneous preferential attachment, and (3) subgroup-level time decay. As a case study, we apply our proposed model to scholarly publications in computer science. Our model outperforms the state of the art approach in predicting citation volumes of individual papers. More importantly, the proposed model enables us to uncover popularity dynamics driven by intra- and inter-subgroup interactions, which has been neglected in prior work. We expect that our model can afford interpretable insights on the attention economy in terms of affinity and aging effect.",10.1145/3132847.3132923,https://doi.org/10.1145/3132847.3132923,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Modeling Affinity based Popularity Dynamics,"Kim, Minkyoung and McFarland, Daniel A. and Leskovec, Jure",inproceedings,10.1145/3132847.3132923,
10.1145/3132847.3132941,10.1145/3132847.3132941,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","probabilistic model, pre-training strategy, bayesian personalized ranking deep neural network",10,1479–1488,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Friendship is the cornerstone to build a social network. In online social networks, statistics show that the leading reason for user to create a new friendship is due to recommendation. Thus the accuracy of recommendation matters. In this paper, we propose a Bayesian Personalized Ranking Deep Neural Network (BayDNN) model for friend recommendation in social networks. With BayDNN, we achieve significant improvement on two public datasets: Epinions and Slashdot. For example, on Epinions dataset, BayDNN significantly outperforms the state-of-the-art algorithms, with a 5% improvement on NDCG over the best baseline. The advantages of the proposed BayDNN mainly come from its underlying convolutional neural network (CNN), which offers a mechanism to extract latent deep structural feature representations of the complicated network data, and a novel Bayesian personalized ranking idea, which precisely captures the users' personal bias based on the extracted deep features. To get good parameter estimation for the neural network, we present a fine-tuned pre-training strategy for the proposed BayDNN model based on Poisson and Bernoulli probabilistic models.",10.1145/3132847.3132941,https://doi.org/10.1145/3132847.3132941,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,BayDNN: Friend Recommendation with Bayesian Personalized Ranking Deep Neural Network,"Ding, Daizong and Zhang, Mi and Li, Shao-Yuan and Tang, Jie and Chen, Xiaotie and Zhou, Zhi-Hua",inproceedings,10.1145/3132847.3132941,
10.1145/3132847.3132972,10.1145/3132847.3132972,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","variational autoencoders, recommender systems, generative adversarial networks, deep learning, collaborative filtering",10,1139–1148,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Recommender systems offer critical services in the age of mass information. A good recommender system selects a certain item for a specific user by recognizing why the user might like the item. This awareness implies that the system should model the background of the items and the users. This background modeling for recommendation is tackled through the various models of collaborative filtering with auxiliary information. This paper presents variational approaches for collaborative filtering to deal with auxiliary information. The proposed methods encompass variational autoencoders through augmenting structures to model the auxiliary information and to model the implicit user feedback. This augmentation includes the ladder network and the generative adversarial network to extract the low-dimensional representations influenced by the auxiliary information. These two augmentations are the first trial in the venue of the variational autoencoders, and we demonstrate their significant improvement on the performances in the applications of the collaborative filtering.",10.1145/3132847.3132972,https://doi.org/10.1145/3132847.3132972,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Augmented Variational Autoencoders for Collaborative Filtering with Auxiliary Information,"Lee, Wonsung and Song, Kyungwoo and Moon, Il-Chul",inproceedings,10.1145/3132847.3132972,
10.1145/3132847.3132973,10.1145/3132847.3132973,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","popularity prediction, interpretable factors, information cascade, hawkes process, end-to-end deep learning",10,1149–1158,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Online social media remarkably facilitates the production and delivery of information, intensifying the competition among vast information for users' attention and highlighting the importance of predicting the popularity of information. Existing approaches for popularity prediction fall into two paradigms: feature-based approaches and generative approaches. Feature-based approaches extract various features (e.g., user, content, structural, and temporal features), and predict the future popularity of information by training a regression/classification model. Their predictive performance heavily depends on the quality of hand-crafted features. In contrast, generative approaches devote to characterizing and modeling the process that a piece of information accrues attentions, offering us high ease to understand the underlying mechanisms governing the popularity dynamics of information cascades. But they have less desirable predictive power since they are not optimized for popularity prediction. In this paper, we propose DeepHawkes to combat the defects of existing methods, leveraging end-to-end deep learning to make an analogy to interpretable factors of Hawkes process --- a widely-used generative process to model information cascade. DeepHawkes inherits the high interpretability of Hawkes process and possesses the high predictive power of deep learning methods, bridging the gap between prediction and understanding of information cascades. We verify the effectiveness of DeepHawkes by applying it to predict retweet cascades of Sina Weibo and citation cascades of a longitudinal citation dataset. Experimental results demonstrate that DeepHawkes outperforms both feature-based and generative approaches.",10.1145/3132847.3132973,https://doi.org/10.1145/3132847.3132973,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,DeepHawkes: Bridging the Gap between Prediction and Understanding of Information Cascades,"Cao, Qi and Shen, Huawei and Cen, Keting and Ouyang, Wentao and Cheng, Xueqi",inproceedings,10.1145/3132847.3132973,
10.1145/3132847.3132976,10.1145/3132847.3132976,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","recommendation, matrix factorization, cross-network, anchor links",10,1409–1418,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Anchor links connect information entities, such as entities of movies or products, across networks from different sources, and thus information in these networks can be transferred directly via anchor links. Therefore, anchor links have great value to many cross-network applications, such as cross-network social link prediction and cross-network recommendation. In this paper, we focus on studying the recommendation problem that can provide ratings of items or services. To address the problem, we propose a Cross-network Collaborative Matrix Factorization (CCMF) recommendation framework based on broad learning setting, which can effectively integrate multi-source information and alleviate the sparse information problem in each individual network. Based on item anchor links CCMF can fuse item similarity information and item latent information across networks from different sources. And different from most of the traditional works, CCMF can make multi-source recommendation tasks collaborate together via the information transfer based on the broad learning setting. During the transfer process, a novel cross-network similarity transfer method is applied to keep the consistency of item similarities between two different networks, and a domain adaptation matrix is used to overcome the domain difference problem. We conduct experiments to compare the proposed CCMF method with both classic and state-of-the-art recommendation techniques. The experimental results illustrate that CCMF outperforms other methods in different experimental circumstances, and has great advantages on dealing with different data sparse problems.",10.1145/3132847.3132976,https://doi.org/10.1145/3132847.3132976,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Broad Learning based Multi-Source Collaborative Recommendation,"Zhu, Junxing and Zhang, Jiawei and He, Lifang and Wu, Quanyuan and Zhou, Bin and Zhang, Chenwei and Yu, Philip S.",inproceedings,10.1145/3132847.3132976,
10.1145/3132847.3132985,10.1145/3132847.3132985,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","social correlation, negative sampling criterion, geographical influences",10,1469–1478,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Recommending a ranked list of interesting venues to users based on their preferences has become a key functionality in Location-Based Social Networks (LBSNs) such as Yelp and Gowalla. Bayesian Personalised Ranking (BPR) is a popular pairwise recommendation technique that is used to generate the ranked list of venues of interest to a user, by leveraging the user's implicit feedback such as their check-ins as instances of positive feedback, while randomly sampling other venues as negative instances. To alleviate the sparsity that affects the usefulness of recommendations by BPR for users with few check-ins, various approaches have been proposed in the literature to incorporate additional sources of information such as the social links between users, the textual content of comments, as well as the geographical location of the venues. However, such approaches can only readily leverage one source of additional information for negative sampling. Instead, we propose a novel Personalised Ranking Framework with Multiple sampling Criteria (PRFMC) that leverages both geographical influence and social correlation to enhance the effectiveness of BPR. In particular, we apply a multi-centre Gaussian model and a power-law distribution method, to capture geographical influence and social correlation when sampling negative venues, respectively. Finally, we conduct comprehensive experiments using three large-scale datasets from the Yelp, Gowalla and Brightkite LBSNs. The experimental results demonstrate the effectiveness of fusing both geographical influence and social correlation in our proposed PRFMC framework and its superiority in comparison to BPR-based and other similar ranking approaches. Indeed, our PRFMC approach attains a 37% improvement in MRR over a recently proposed approach that identifies negative venues only from social links.",10.1145/3132847.3132985,https://doi.org/10.1145/3132847.3132985,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,A Personalised Ranking Framework with Multiple Sampling Criteria for Venue Recommendation,"Manotumruksa, Jarana and Macdonald, Craig and Ounis, Iadh",inproceedings,10.1145/3132847.3132985,
10.1145/3132847.3132997,10.1145/3132847.3132997,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","youtube, time series analysis, social media, regression model, popularity prediction",10,467–476,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Online content popularity prediction provides substantial value to a broad range of applications in the end-to-end social media systems, from network resource allocation to targeted advertising. While using historical popularity can predict the near-term popularity with a reasonable accuracy, the bursty nature of online content popularity evolution makes it difficult to capture the correlation between historical data and future data in the long term. Although various existing efforts have been made toward long-term prediction, they need to accumulate a long enough historical data before the prediction and their model assumptions cannot be applied to the complex YouTube networks with inherent unpredictability.In this paper, we aim to achieve fast prediction of long-term video popularity in the complex YouTube networks. We propose LARM, a lifetime aware regression model, representing the first work that leverages content lifetime to compensate the insufficiency of historical data without assumptions of network structure. The proposed LARM is empowered by a lifetime metric that is both predictable via early-accessible features and adaptable to different observation intervals, as well as a set of specialized regression models to handle different classes of videos with different lifetime. We validate LARM on two YouTube data sets with hourly and daily observation intervals. Experimental results indicate that LARM outperforms several non-trivial baselines from the literature by up to 20% and 18% of prediction error reduction in the two data sets.",10.1145/3132847.3132997,https://doi.org/10.1145/3132847.3132997,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,LARM: A Lifetime Aware Regression Model for Predicting YouTube Video Popularity,"Ma, Changsha and Yan, Zhisheng and Chen, Chang Wen",inproceedings,10.1145/3132847.3132997,
10.1145/3132847.3133005,10.1145/3132847.3133005,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","user-item interaction, recurrent neural network, feature-based recommendation, attention model",10,1459–1468,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Capturing the temporal dynamics of user preferences over items is important for recommendation. Existing methods mainly assume that all time steps in user-item interaction history are equally relevant to recommendation, which however does not apply in real-world scenarios where user-item interactions can often happen accidentally. More importantly, they learn user and item dynamics separately, thus failing to capture their joint effects on user-item interactions. To better model user and item dynamics, we present the Interacting Attention-gated Recurrent Network (IARN) which adopts the attention model to measure the relevance of each time step. In particular, we propose a novel attention scheme to learn the attention scores of user and item history in an interacting way, thus to account for the dependencies between user and item dynamics in shaping user-item interactions. By doing so, IARN can selectively memorize different time steps of a user's history when predicting her preferences over different items. Our model can therefore provide meaningful interpretations for recommendation results, which could be further enhanced by auxiliary features. Extensive validation on real-world datasets shows that IARN consistently outperforms state-of-the-art methods.",10.1145/3132847.3133005,https://doi.org/10.1145/3132847.3133005,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Interacting Attention-gated Recurrent Networks for Recommendation,"Pei, Wenjie and Yang, Jie and Sun, Zhu and Zhang, Jie and Bozzon, Alessandro and Tax, David M.J.",inproceedings,10.1145/3132847.3133005,
10.1145/3132847.3133034,10.1145/3132847.3133034,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","user propensity, recommendation systems, point-of-interest recommendation, latent factor recommendation, capacity constraints",10,1439–1448,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"In many recommendation settings, the candidate items for recommendation are associated with a maximum capacity, i.e., number of seats in a Point-of-Interest (POI) or number of item copies in the inventory. However, despite the prevalence of the capacity constraint in the recommendation process, the existing recommendation methods are not designed to optimize for respecting such a constraint. Towards closing this gap, we propose Recommendation with Capacity Constraints -- a framework that optimizes for both recommendation accuracy and expected item usage that respects the capacity constraints. We show how to apply our method to three state-of-the-art latent factor recommendation models: probabilistic matrix factorization (PMF), bayesian personalized ranking (BPR) for item recommendation, and geographical matrix factorization (GeoMF) for POI recommendation. Our experiments indicate that our framework is effective for providing good recommendations while taking the limited resources into consideration. Interestingly, our methods are shown in some cases to further improve the top-N recommendation quality of the respective unconstrained models.",10.1145/3132847.3133034,https://doi.org/10.1145/3132847.3133034,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Recommendation with Capacity Constraints,"Christakopoulou, Konstantina and Kawale, Jaya and Banerjee, Arindam",inproceedings,10.1145/3132847.3133034,
10.1145/3132847.3133036,10.1145/3132847.3133036,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","static preferences, dynamic preferences, deep recurrent collaborative filtering framework",10,1429–1438,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Venue recommendation is an important application for Location-Based Social Networks (LBSNs), such as Yelp, and has been extensively studied in recent years. Matrix Factorisation (MF) is a popular Collaborative Filtering (CF) technique that can suggest relevant venues to users based on an assumption that similar users are likely to visit similar venues. In recent years, deep neural networks have been successfully applied to tasks such as speech recognition, computer vision and natural language processing. Building upon this momentum, various approaches for recommendation have been proposed in the literature to enhance the effectiveness of MF-based approaches by exploiting neural network models such as: word embeddings to incorporate auxiliary information (e.g. textual content of comments); and Recurrent Neural Networks (RNN) to capture sequential properties of observed user-venue interactions. However, such approaches rely on the traditional inner product of the latent factors of users and venues to capture the concept of collaborative filtering, which may not be sufficient to capture the complex structure of user-venue interactions. In this paper, we propose a Deep Recurrent Collaborative Filtering framework (DRCF) with a pairwise ranking function that aims to capture user-venue interactions in a CF manner from sequences of observed feedback by leveraging Multi-Layer Perception and Recurrent Neural Network architectures. Our proposed framework consists of two components: namely Generalised Recurrent Matrix Factorisation (GRMF) and Multi-Level Recurrent Perceptron (MLRP) models. In particular, GRMF and MLRP learn to model complex structures of user-venue interactions using element-wise and dot products as well as the concatenation of latent factors. In addition, we propose a novel sequence-based negative sampling approach that accounts for the sequential properties of observed feedback and geographical location of venues to enhance the quality of venue suggestions, as well as alleviate the cold-start users problem. Experiments on three large checkin and rating datasets show the effectiveness of our proposed framework by outperforming various state-of-the-art approaches.",10.1145/3132847.3133036,https://doi.org/10.1145/3132847.3133036,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,A Deep Recurrent Collaborative Filtering Framework for Venue Recommendation,"Manotumruksa, Jarana and Macdonald, Craig and Ounis, Iadh",inproceedings,10.1145/3132847.3133036,
10.1145/3132847.3133057,10.1145/3132847.3133057,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","matrix/tensor completion, low-rank modeling, group algebra, context-aware recommendation",4,2415–2418,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"The incorporation of contextual information is an important part of context-aware recommendation. Many context-aware recommendation systems adopt tensor completion to include contextual information. However, the symmetries between dimensions of a tensor induce an unreasonable assumption that users, items and contexts should be treated equally in recommender systems. In this paper, we address this by using matrices over finite abelian group algebra (AGA) to model context-aware interactions between users and items. Specifically, we formulate context-aware recommendation as a low-rank matrix completion problem over AGA (MC-AGA) and derive a new algorithm using the inexact augmented Lagrange multiplier method. We then test MC-AGA on two real-world datasets: one containing implicit feedback and one with explicit feedback. Experiment results show that MC-AGA outperforms not only existing tensor completion algorithms but also recommendation systems with other context-aware representations.",10.1145/3132847.3133057,https://doi.org/10.1145/3132847.3133057,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Low-Rank Matrix Completion over Finite Abelian Group Algebras for Context-Aware Recommendation,"Yu, Chia-An and Chan, Tak-Shing and Yang, Yi-Hsuan",inproceedings,10.1145/3132847.3133057,
10.1145/3132847.3133066,10.1145/3132847.3133066,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","user reviews, text embedding, ranking, co-occurrence network",4,2011–2014,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"This paper attempts to conduct analysis for one certain type of user reviews; that is, the reviews on a super-entity (e.g., restaurant) involve descriptions for many sub-entities (e.g., dishes). To deal with such analysis, we propose a text embedding framework for ranking sub-entities from user reviews of a given super-entity. Experiments on two real-world datasets show that our method outperforms three baselines by a statistically significant amount. Intriguing cases from the experiments are discussed in the paper.",10.1145/3132847.3133066,https://doi.org/10.1145/3132847.3133066,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Text Embedding for Sub-Entity Ranking from User Reviews,"Chao, Chih-Yu and Chu, Yi-Fan and Yang, Hsiu-Wei and Wang, Chuan-Ju and Tsai, Ming-Feng",inproceedings,10.1145/3132847.3133066,
10.1145/3132847.3133083,10.1145/3132847.3133083,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","recommender systems, neighborhood information, deep neural network",4,1979–1982,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Recently, deep neural networks have been widely applied to recommender systems. A representative work is to utilize deep learning for modeling complex user-item interactions. However, similar to traditional latent factor models by factorizing user-item interactions, they tend to be ineffective to capture localized information. Localized information, such as neighborhood, is important to recommender systems in complementing the user-item interaction data. Based on this consideration, we propose a novel Neighborhood-based Neural Collaborative Filtering model (NNCF). To the best of our knowledge, it is the first time that the neighborhood information is integrated into the neural collaborative filtering methods. Extensive experiments on three real-world datasets demonstrate the effectiveness of our model for the implicit recommendation task.",10.1145/3132847.3133083,https://doi.org/10.1145/3132847.3133083,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,A Neural Collaborative Filtering Model with Interaction-based Neighborhood,"Bai, Ting and Wen, Ji-Rong and Zhang, Jun and Zhao, Wayne Xin",inproceedings,10.1145/3132847.3133083,
10.1145/3132847.3133128,10.1145/3132847.3133128,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","topic model, social collaborative filtering, collaborative deep learning, cold-start recommendation, autoencoder",4,2231–2234,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Personalized recommendation of items frequently faces scenarios where we have sparse observations on users' adoption of items. In the literature, there are two promising directions. One is to connect sparse items through similarity in content. The other is to connect sparse users through similarity in social relations. We seek to integrate both types of information, in addition to the adoption information, within a single integrated model. Our proposed method models item content via a topic model, and user communities via an autoencoder model, while bridging a user's community-based preference to her topic-based preference. Experiments on public real-life data showcase the utility of the model, particularly when there is significant compatibility between communities and topics.",10.1145/3132847.3133128,https://doi.org/10.1145/3132847.3133128,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Collaborative Topic Regression with Denoising AutoEncoder for Content and Community Co-Representation,"Nguyen, Trong T. and Lauw, Hady W.",inproceedings,10.1145/3132847.3133128,
10.1145/3132847.3133130,10.1145/3132847.3133130,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","subspace clustering, group recommendation, fault tolerance",4,2047–2050,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Fault-tolerant group recommendation systems based on subspace clustering successfully alleviate high-dimensionality and sparsity problems. However, the cost of recommendation grows exponentially with the size of dataset. To address this issue, we model the fault-tolerant subspace clustering problem as a search problem on graphs and present an algorithm, GraphRec, based on the concept of α-\ss{}-core. Moreover, we propose two variants of our approach that use indexes to improve query latency. Our experiments on different datasets demonstrate that our methods are extremely fast compared to the state-of-the-art.",10.1145/3132847.3133130,https://doi.org/10.1145/3132847.3133130,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Efficient Fault-Tolerant Group Recommendation Using alpha-beta-core,"Ding, Danhao and Li, Hui and Huang, Zhipeng and Mamoulis, Nikos",inproceedings,10.1145/3132847.3133130,
10.1145/3132847.3133137,10.1145/3132847.3133137,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","recipe popularity prediction, recipe features, multi-modal fusion",4,2279–2282,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Predicting the popularity of user-created recipes has great potential to be adopted in several applications on recipe-sharing websites. To ensure timely prediction when a recipe is uploaded, a prediction model needs to be trained based on the recipe's content features (i.e., its visual and semantic features). This paper presents a novel approach to predicting recipe popularity using deep visual-semantic fusion. We first pre-train a deep model that predicts the popularity of recipes based on each single modality. We insert additional layers to the two models and concatenate their activations. Finally, we train a network comprising fully connected (FC) layers on the fused features to learn more powerful features, which are used for training a regressor. Based on experiments conducted on more than 150K recipes collected from the Cookpad website, we present a comprehensive comparison with several baselines to verify the effectiveness of our method. The best practice for the proposed method is also described.",10.1145/3132847.3133137,https://doi.org/10.1145/3132847.3133137,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,Recipe Popularity Prediction with Deep Visual-Semantic Fusion,"Sanjo, Satoshi and Katsurai, Marie",inproceedings,10.1145/3132847.3133137,
10.1145/3132847.3133158,10.1145/3132847.3133158,CIKM.bib,1,['CIKM.bib'],8,CIKM '17,"Singapore, Singapore","denoising autoencoders, data imputation, collaborative filtering",4,2143–2146,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"In recent years, while deep neural networks have shown impressive performance to solve various recognition and classification problems, collaborative filtering (CF) received relatively little attention to utilize deep neural networks. Because of inherent data sparsity, it remains a challenging problem for deep neural networks. In this paper, we propose a new CF model, namely the imputation-boosted denoising autoencoder (IDAE), for top-N recommendation. Specifically, IDAE consists of two steps: imputing positive values and learning with imputed values. First, it infers and imputes positive user feedback from missing values. Then, the correlation between items is learned by using the denoising autoencoder (DAE) with imputed values. Unlike the existing DAE that randomly corrupts the input, the key characteristic of IDAE is that original user values are taken as the input, and imputed values are reflected as the corrupted output. Our experimental results demonstrate that IDAE significantly outperforms state-of-the-art CF algorithms using autoencoders (by up to 5%) on the MovieLens datasets.",10.1145/3132847.3133158,https://doi.org/10.1145/3132847.3133158,"New York, NY, USA",Association for Computing Machinery,9781450349185,2017,IDAE: Imputation-boosted Denoising Autoencoder for Collaborative Filtering,"Lee, Jae-woong and Lee, Jongwuk",inproceedings,10.1145/3132847.3133158,
10.1145/3159652.3159673,10.1145/3159652.3159673,WSDM.bib,1,['WSDM.bib'],8,WSDM '18,"Marina Del Rey, CA, USA","collaborative filtering, data sketching, privacy preservation, user-based top-n recommneder",9,10–18,Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining,"This paper evaluates two algorithms, BLIP and JLT, for creating differentially private data sketches of user profiles, in terms of their ability to protect a kNN collaborative filtering algorithm from an inference attack by third-parties. The transformed user profiles are employed in a user-based top-N collaborative filtering system. For the first time, a theoretical analysis of the BLIP is carried out, to derive expressions that relate its parameters to its performance. This allows the two techniques to be fairly compared. The impact of deploying these approaches on the utility of the system---its ability to make good recommendations, and on its privacy level---the ability of third-parties to make inferences about the underlying user preferences, is examined. An active inference attack is evaluated, that consists of the injection of a number of tailored sybil profiles into the system database. User profile data of targeted users is then inferred from the recommendations made to the sybils. Although the differentially private sketches are designed to allow the transformed user profiles to be published without compromising privacy, the attack we examine does not use such information and depends only on some pre-existing knowledge of some user preferences as well as the neighbourhood size of the kNN algorithm. Our analysis therefore assesses in practical terms a relatively weak privacy attack, which is extremely simple to apply in systems that allow low-cost generation of sybils. We find that, for a given differential privacy level, the BLIP injects less noise into the system, but for a given level of noise, the JLT offers a more compact representation.",10.1145/3159652.3159673,https://doi.org/10.1145/3159652.3159673,"New York, NY, USA",Association for Computing Machinery,9781450355810,2018,Performance Analysis of a Privacy Constrained kNN Recommendation Using Data Sketches,"Afsharinejad, Armita and Hurley, Neil",inproceedings,10.1145/3159652.3159673,
10.1145/3159652.3159681,10.1145/3159652.3159681,WSDM.bib,1,['WSDM.bib'],8,WSDM '18,"Marina Del Rey, CA, USA","adaptable, extensible, framework, modular, recommendation",9,664–672,Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining,"With the increasing demand for deeper understanding of users» preferences, recommender systems have gone beyond simple user-item filtering and are increasingly sophisticated, comprised of multiple components for analyzing and fusing diverse information. Unfortunately, existing frameworks do not adequately support extensibility and adaptability and consequently pose significant challenges to rapid, iterative, and systematic, experimentation. In this work, we propose OpenRec, an open and modular Python framework that supports extensible and adaptable research in recommender systems. Each recommender is modeled as a computational graph that consists of a structured ensemble of reusable modules connected through a set of well-defined interfaces. We present the architecture of OpenRec and demonstrate that OpenRec provides adaptability, modularity and reusability while maintaining training efficiency and recommendation accuracy. Our case study illustrates how OpenRec can support an efficient design process to prototype and benchmark alternative approaches with inter-changeable modules and enable development and evaluation of new algorithms.",10.1145/3159652.3159681,https://doi.org/10.1145/3159652.3159681,"New York, NY, USA",Association for Computing Machinery,9781450355810,2018,OpenRec: A Modular Framework for Extensible and Adaptable Recommendation Algorithms,"Yang, Longqi and Bagdasaryan, Eugene and Gruenstein, Joshua and Hsieh, Cheng-Kang and Estrin, Deborah",inproceedings,10.1145/3159652.3159681,
10.1145/3159652.3159705,10.1145/3159652.3159705,WSDM.bib,1,['WSDM.bib'],8,WSDM '18,"Marina Del Rey, CA, USA","diffusion path prediction, online social networks, recurrent neural networks",9,252–260,Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining,"Content popularity prediction has been extensively studied due to its importance and interest for both users and hosts of social media sites like Facebook, Instagram, Twitter, and Pinterest. However, existing work mainly focuses on modeling popularity using a single metric such as the total number of likes or shares. In this work, we propose Diffusion-LSTM, a memory-based deep recurrent network that learns to recursively predict the entire diffusion path of an image through a social network. By combining user social features and image features, and encoding the diffusion path taken thus far with an explicit memory cell, our model predicts the diffusion path of an image more accurately compared to alternate baselines that either encode only image or social features, or lack memory. By mapping individual users to user prototypes, our model can generalize to new users not seen during training. Finally, we demonstrate our model»s capability of generating diffusion trees, and show that the generated trees closely resemble ground-truth trees.",10.1145/3159652.3159705,https://doi.org/10.1145/3159652.3159705,"New York, NY, USA",Association for Computing Machinery,9781450355810,2018,Who Will Share My Image? Predicting the Content Diffusion Path in Online Social Networks,"Hu, Wenjian and Singh, Krishna Kumar and Xiao, Fanyi and Han, Jinyoung and Chuah, Chen-Nee and Lee, Yong Jae",inproceedings,10.1145/3159652.3159705,
10.1145/3159652.3159723,10.1145/3159652.3159723,WSDM.bib,1,['WSDM.bib'],8,WSDM '18,"Marina Del Rey, CA, USA","collaborative filtering, matrix factorization, ordinal regression",9,243–251,Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining,"Accurately predicting user preferences/ratings over items are crucial for many Internet applications, e.g., recommender systems, online advertising. In current main-stream algorithms regarding the rating prediction problem, discrete rating scores are often viewed as either numerical values or(nominal) categorical labels. Practically, viewing user rating scores as numerical values or categorical labels cannot precisely reflect the exact degree of user preferences. It is expected that for each user, the quantitative distance/scale between any pair of adjacent rating scores could be different.  In this paper, we propose a new ordinal regression approach. We view ordered preference scores in an additive way, where we are able to model users» internal rating patterns. Specifically, we model and learn the quantitative distances/scales between any pair of adjacent rating scores. In this way, we can generate a mapping from users» assigned discrete rating scores to the exact magnitude/degree of user preferences for items. In the application of rating prediction, we combine our newly proposed ordinal regression method with matrix factorization, forming a new ordinal matrix factorization method. Through extensive experiments on benchmark datasets, we show that our method significantly outperforms existing ordinal methods, as well as other popular collaborative filtering methods in terms of the rating prediction accuracy.",10.1145/3159652.3159723,https://doi.org/10.1145/3159652.3159723,"New York, NY, USA",Association for Computing Machinery,9781450355810,2018,Collaborative Filtering via Additive Ordinal Regression,"Hu, Jun and Li, Ping",inproceedings,10.1145/3159652.3159723,
10.1145/3178876.3185994,10.1145/3178876.3185994,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","reinforcement learning, news recommendation, deep Q-Learning",10,167–176,Proceedings of the 2018 World Wide Web Conference,"In this paper, we propose a novel Deep Reinforcement Learning framework for news recommendation. Online personalized news recommendation is a highly challenging problem due to the dynamic nature of news features and user preferences. Although some online recommendation models have been proposed to address the dynamic nature of news recommendation, these methods have three major issues. First, they only try to model current reward (e.g., Click Through Rate). Second, very few studies consider to use user feedback other than click / no click labels (e.g., how frequent user returns) to help improve recommendation. Third, these methods tend to keep recommending similar news to users, which may cause users to get bored. Therefore, to address the aforementioned challenges, we propose a Deep Q-Learning based recommendation framework, which can model future reward explicitly. We further consider user return pattern as a supplement to click / no click label in order to capture more user feedback information. In addition, an effective exploration strategy is incorporated to find new attractive news for users. Extensive experiments are conducted on the offline dataset and online production environment of a commercial news recommendation application and have shown the superior performance of our methods.",10.1145/3178876.3185994,https://doi.org/10.1145/3178876.3185994,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,DRN: A Deep Reinforcement Learning Framework for News Recommendation,"Zheng, Guanjie and Zhang, Fuzheng and Zheng, Zihan and Xiang, Yang and Yuan, Nicholas Jing and Xie, Xing and Li, Zhenhui",inproceedings,10.1145/3178876.3185994,
10.1145/3178876.3186013,10.1145/3178876.3186013,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","online conversations, deep learning, conversation prediction",10,1145–1154,Proceedings of the 2018 World Wide Web Conference,"How to improve the quality of conversations in online communities has attracted considerable attention recently. Having engaged, civil, and reactive online conversations has a critical effect on the social life of Internet users. In this study, we are particularly interested in identifying a post in a multi-party conversation that is unlikely to be further replied to, which therefore kills that thread of the conversation. For this purpose, we propose a deep learning model called the ConverNet. ConverNet is attractive due to its capability of modeling the internal structure of a long conversation and its appropriate encoding of the contextual information of the conversation, through effective integration of attention mechanisms. Empirical experiments on real-world datasets demonstrate the effectiveness of the proposed model. For the widely concerned topic, our analysis also offers implications for how to improve the quality and user experience of online conversations, or how to engage users in a conversation with a chatbot.",10.1145/3178876.3186013,https://doi.org/10.1145/3178876.3186013,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Find the Conversation Killers: A Predictive Study of Thread-ending Posts,"Jiao, Yunhao and Li, Cheng and Wu, Fei and Mei, Qiaozhu",inproceedings,10.1145/3178876.3186013,
10.1145/3178876.3186026,10.1145/3178876.3186026,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","social image popularity, multi-modal analysis, attention network",10,1277–1286,Proceedings of the 2018 World Wide Web Conference,"Popularity prediction for the growing social images has opened unprecedented opportunities for wide commercial applications, such as precision advertising and recommender system. While a few studies have explored this significant task, little research has addressed its unstructured properties of both visual and textual modalities, and further considered to learn effective representation from multi-modalities for popularity prediction. To this end, we propose a model named User-guided Hierarchical Attention Network (UHAN) with two novel user-guided attention mechanisms to hierarchically attend both visual and textual modalities. It is capable of not only learning effective representation for each modality, but also fusing them to obtain an integrated multi-modal representation under the guidance of user embedding. As no benchmark dataset exists, we extend a publicly available social image dataset by adding the descriptions of images. The comprehensive experiments have demonstrated the rationality of our proposed UHAN and its better performance than several strong alternatives.",10.1145/3178876.3186026,https://doi.org/10.1145/3178876.3186026,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,User-guided Hierarchical Attention Network for Multi-modal Social Image Popularity Prediction,"Zhang, Wei and Wang, Wen and Wang, Jun and Zha, Hongyuan",inproceedings,10.1145/3178876.3186026,
10.1145/3178876.3186064,10.1145/3178876.3186064,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","university ranking, popularity prediction, partial-order hypergraph, hypergraph, graph-based learning",10,1523–1532,Proceedings of the 2018 World Wide Web Conference,"Graph-based learning methods explicitly consider the relations between two entities (i.e., vertices) for learning the prediction function. They have been widely used in semi-supervised learning, manifold ranking, and clustering, among other tasks. Enhancing the expressiveness of simple graphs, hypergraphs formulate an edge as a link to multiple vertices, so as to model the higher-order relations among entities. For example, hyperedges in a hypergraph can be used to encode the similarity among vertices. To the best of our knowledge, all existing hypergraph structures represent the hyperedge as an unordered set of vertices, without considering the possible ordering relationship among vertices. In real-world data, ordering relations commonly exist, such as in graded categorical features (e.g., users» ratings on movies) and numerical features (e.g., monthly income of customers). When constructing a hypergraph, ignoring such ordering relations among entities will lead to severe information loss, resulting in suboptimal performance of the subsequent learning algorithms. In this work, we address the inherent limitation of existing hypergraphs by proposing a new data structure named Partial-Order Hypergraph, which specifically injects the partially ordering relations among vertices into a hyperedge. We develop regularization-based learning theories for partial-order hypergraphs, generalizing conventional hypergraph learning by incorporating logical rules that encode the partial-order relations. We apply our proposed method to two applications: university ranking from Web data and popularity prediction of online content. Extensive experiments demonstrate the superiority of our proposed partial-order hypergraphs, which consistently improve over conventional hypergraph methods.",10.1145/3178876.3186064,https://doi.org/10.1145/3178876.3186064,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Learning on Partial-Order Hypergraphs,"Feng, Fuli and He, Xiangnan and Liu, Yiqun and Nie, Liqiang and Chua, Tat-Seng",inproceedings,10.1145/3178876.3186064,
10.1145/3178876.3186070,10.1145/3178876.3186070,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","review usefulness, recommender systems, neural attention network, explainable recommendation",10,1583–1592,Proceedings of the 2018 World Wide Web Conference,"Reviews information is dominant for users to make online purchasing decisions in e-commerces. However, the usefulness of reviews is varied. We argue that less-useful reviews hurt model's performance, and are also less meaningful for user's reference. While some existing models utilize reviews for improving the performance of recommender systems, few of them consider the usefulness of reviews for recommendation quality. In this paper, we introduce a novel attention mechanism to explore the usefulness of reviews, and propose a Neural Attentional Regression model with Review-level Explanations (NARRE) for recommendation. Specifically, NARRE can not only predict precise ratings, but also learn the usefulness of each review simultaneously. Therefore, the highly-useful reviews are obtained which provide review-level explanations to help users make better and faster decisions. Extensive experiments on benchmark datasets of Amazon and Yelp on different domains show that the proposed NARRE model consistently outperforms the state-of-the-art recommendation approaches, including PMF, NMF, SVD++, HFT, and DeepCoNN in terms of rating prediction, by the proposed attention model that takes review usefulness into consideration. Furthermore, the selected reviews are shown to be effective when taking existing review-usefulness ratings in the system as ground truth. Besides, crowd-sourcing based evaluations reveal that in most cases, NARRE achieves equal or even better performances than system's usefulness rating method in selecting reviews. And it is flexible to offer great help on the dominant cases in real e-commerce scenarios when the ratings on review-usefulness are not available in the system.",10.1145/3178876.3186070,https://doi.org/10.1145/3178876.3186070,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Neural Attentional Rating Regression with Review-level Explanations,"Chen, Chong and Zhang, Min and Liu, Yiqun and Ma, Shaoping",inproceedings,10.1145/3178876.3186070,
10.1145/3178876.3186075,10.1145/3178876.3186075,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","online learning, online convex optimization, online conditional gradient, factorization machine",10,1633–1642,Proceedings of the 2018 World Wide Web Conference,"Factorization Machine (FM) is a supervised learning approach with a powerful capability of feature engineering. It yields state-of-the-art performances in various batch learning tasks where all the training data is made available prior to the training. However, in real-world applications where the data arrives sequentially in a streaming manner, the high cost of re-training with batch learning algorithms has posed formidable challenges in the online learning scenario. The initial challenge is that no prior formulations of FM could directly fulfill the requirements in Online Convex Optimization (OCO) -- the paramount framework for online learning algorithm design. To address this aforementioned challenge, we invent a new convexification scheme leading to a Compact Convexified FM (CCFM) that seamlessly meets the requirements in OCO. However for learning Compact Convexified FM (CCFM) in the online learning settings, most existing algorithms suffer from expensive projection operations. To address this subsequent challenge, we follow the general projection-free algorithmic framework of Online Conditional Gradient and propose an Online Compact Convex Factorization Machine (OCCFM) algorithm that eschews the projection operation with efficient linear optimization steps. In support of the proposed OCCFM in terms of its theoretical foundation, we prove that the developed algorithm achieves a sub-linear regret bound. To evaluate the empirical performance of OCCFM, we conduct extensive experiments on 6 real-world datasets for online regression and online classification tasks. The experimental results show that OCCFM outperforms the state-of-art online learning methods for FM.",10.1145/3178876.3186075,https://doi.org/10.1145/3178876.3186075,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Online Compact Convexified Factorization Machine,"Lin, Xiao and Zhang, Wenpeng and Zhang, Min and Zhu, Wenwu and Pei, Jian and Zhao, Peilin and Huang, Junzhou",inproceedings,10.1145/3178876.3186075,
10.1145/3178876.3186079,10.1145/3178876.3186079,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","spam detection, online shopping, crowdsourcing manipulation",10,1673–1682,Proceedings of the 2018 World Wide Web Conference,"""Add to Favorites"" is a popular function in online shopping sites which helps users to make a record of potentially interesting items for future purchases. It is usually regarded as a type of explicit feedback signal for item popularity and therefore also adopted as a ranking signal by many shopping search engines. With the increasing usage of crowdsourcing platforms, some malicious online sellers also organize crowdturfing activities to increase the numbers of ""Add to Favorites"" for their items. By this means, they expect the items to gain higher positions in search ranking lists and therefore boost sales. This kind of newly-appeared malicious activity proposes challenges to traditional search spam detection efforts because it involves the participation of many crowd workers who are normal online shopping users in most of the times, and these activities are composed of a series of behaviors including search, browse, click and add to favorites. To shed light on this research question, we are among the first to investigate this particular spamming activity by looking into both the task organization information in crowdsourcing platforms and the user behavior information from online shopping sites. With a comprehensive analysis of some ground truth spamming activities from the perspective of behavior, user and item, we propose a factor graph based model to identify this kind of spamming activity. Experimental results based on data collected in practical shopping search environment show that our model helps detect malicious ""Add to Favorites"" activities effectively.",10.1145/3178876.3186079,https://doi.org/10.1145/3178876.3186079,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,"Detecting Crowdturfing ""Add to Favorites"" Activities in Online Shopping","Su, Ning and Liu, Yiqun and Li, Zhao and Liu, Yuli and Zhang, Min and Ma, Shaoping",inproceedings,10.1145/3178876.3186079,
10.1145/3178876.3186108,10.1145/3178876.3186108,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","temporal point processes, epidemic models, diffusions in finite population, diffusion size prediction",10,419–428,Proceedings of the 2018 World Wide Web Conference,"Among the statistical tools for online information diffusion modeling, both epidemic models and Hawkes point processes are popular choices. The former originate from epidemiology, and consider information as a viral contagion which spreads into a population of online users. The latter have roots in geophysics and finance, view individual actions as discrete events in continuous time, and modulate the rate of events according to the self-exciting nature of event sequences. Here, we establish a novel connection between these two frameworks. Namely, the rate of events in an extended Hawkes model is identical to the rate of new infections in the Susceptible-Infected-Recovered (SIR) model after marginalizing out recovery events -- which are unobserved in a Hawkes process. This result paves the way to apply tools developed for SIR to Hawkes, and vice versa. It also leads to HawkesN, a generalization of the Hawkes model which accounts for a finite population size. Finally, we derive the distribution of cascade sizes for HawkesN, inspired by methods in stochastic SIR. Such distributions provide nuanced explanations to the general unpredictability of popularity: the distribution for diffusion cascade sizes tends to have two modes, one corresponding to large cascade sizes and another one around zero.",10.1145/3178876.3186108,https://doi.org/10.1145/3178876.3186108,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,SIR-Hawkes: Linking Epidemic Models and Hawkes Processes to Model Diffusions in Finite Populations,"Rizoiu, Marian-Andrei and Mishra, Swapnil and Kong, Quyu and Carman, Mark and Xie, Lexing",inproceedings,10.1145/3178876.3186108,
10.1145/3178876.3186145,10.1145/3178876.3186145,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","topic model, review-aware, recommendation, matrix factorization, aspect-aware",10,639–648,Proceedings of the 2018 World Wide Web Conference,"Although latent factor models (e.g., matrix factorization) achieve good accuracy in rating prediction, they suffer from several problems including cold-start, non-transparency, and suboptimal recommendation for local users or items. In this paper, we employ textual review information with ratings to tackle these limitations. Firstly, we apply a proposed aspect-aware topic model (ATM) on the review text to model user preferences and item features from different aspects, and estimate the aspect importance of a user towards an item. The aspect importance is then integrated into a novel aspect-aware latent factor model (ALFM), which learns user's and item's latent factors based on ratings. In particular, ALFM introduces a weighted matrix to associate those latent factors with the same set of aspects discovered by ATM, such that the latent factors could be used to estimate aspect ratings. Finally, the overall rating is computed via a linear combination of the aspect ratings, which are weighted by the corresponding aspect importance. To this end, our model could alleviate the data sparsity problem and gain good interpretability for recommendation. Besides, an aspect rating is weighted by an aspect importance, which is dependent on the targeted user's preferences and targeted item's features. Therefore, it is expected that the proposed method can model a user's preferences on an item more accurately for each user-item pair locally. Comprehensive experimental studies have been conducted on 19 datasets from Amazon and Yelp 2017 Challenge dataset. Results show that our method achieves significant improvement compared with strong baseline methods, especially for users with only few ratings. Moreover, our model could interpret the recommendation results in depth.",10.1145/3178876.3186145,https://doi.org/10.1145/3178876.3186145,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Aspect-Aware Latent Factor Model: Rating Prediction with Ratings and Reviews,"Cheng, Zhiyong and Ding, Ying and Zhu, Lei and Kankanhalli, Mohan",inproceedings,10.1145/3178876.3186145,
10.1145/3178876.3186146,10.1145/3178876.3186146,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","tensor factorization, side information, dynamic collaborative filtering, clothing recommendation, aesthetic features",10,649–658,Proceedings of the 2018 World Wide Web Conference,"Recently, product images have gained increasing attention in clothing recommendation since the visual appearance of clothing products has a significant impact on consumers» decision. Most existing methods rely on conventional features to represent an image, such as the visual features extracted by convolutional neural networks (CNN features) and the scale-invariant feature transform algorithm (SIFT features), color histograms, and so on. Nevertheless, one important type of features, the aesthetic features, is seldom considered. It plays a vital role in clothing recommendation since a users» decision depends largely on whether the clothing is in line with her aesthetics, however the conventional image features cannot portray this directly. To bridge this gap, we propose to introduce the aesthetic information, which is highly relevant with user preference, into clothing recommender systems. To achieve this, we first present the aesthetic features extracted by a pre-trained neural network, which is a brain-inspired deep structure trained for the aesthetic assessment task. Considering that the aesthetic preference varies significantly from user to user and by time, we then propose a new tensor factorization model to incorporate the aesthetic features in a personalized manner. We conduct extensive experiments on real-world datasets, which demonstrate that our approach can capture the aesthetic preference of users and significantly outperform several state-of-the-art recommendation methods.",10.1145/3178876.3186146,https://doi.org/10.1145/3178876.3186146,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Aesthetic-based Clothing Recommendation,"Yu, Wenhui and Zhang, Huidi and He, Xiangnan and Chen, Xu and Xiong, Li and Qin, Zheng",inproceedings,10.1145/3178876.3186146,
10.1145/3178876.3186148,10.1145/3178876.3186148,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","robust optimization, response prediction, interval uncertainty, field aware factorization machines, factorization machines, computational advertising",10,669–678,Proceedings of the 2018 World Wide Web Conference,"Factorization machines (FMs) are a state-of-the-art model class for user response prediction in the computational advertising domain. Rapid growth of internet and mobile device usage has given rise to multiple customer touchpoints. This coupled with factors like high cookie churn rate results in a fragmented view of user activity at the advertiser»s end. Current literature assumes procured user signals as the absolute truth, which is contested by the absence of deterministic identity linkage across a user's multiple avatars. In this work, we characterize the data uncertainty using Robust Optimization (RO) paradigm to design approaches that are immune against perturbations. We propose two novel algorithms: robust factorization machine (RFM) and its field-aware variant (RFFM), under interval uncertainty. These formulations are generic and can find applicability in any classification setting under noise. We provide a distributed and scalable Spark implementation using parallel stochastic gradient descent. In the experiments conducted on three real-world datasets, the robust counterparts outperform the baselines significantly under perturbed settings. Our experimental findings reveal interesting connections between choice of uncertainty set and the noise-proofness of resulting models.",10.1145/3178876.3186148,https://doi.org/10.1145/3178876.3186148,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Robust Factorization Machines for User Response Prediction,"Punjabi, Surabhi and Bhatt, Priyanka",inproceedings,10.1145/3178876.3186148,
10.1145/3178876.3186153,10.1145/3178876.3186153,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","zero-inflated poisson, repeat consumption, explore-exploit, consumption rate modeling",10,719–728,Proceedings of the 2018 World Wide Web Conference,"In this paper we address the problem of building user models that can predict the rate at which individuals consume items from a finite set, including items they have consumed in the past and items that are new. This combination of repeat and new item consumption is common in applications such as listening to music, visiting web sites, and purchasing products. We use zero-inflated Poisson (ZIP) regression models as the basis for our modeling approach, leading to a general framework for modeling user-item consumption rates over time. We show that these models are more flexible in capturing user behavior than alternatives such as well-known latent factor models based on matrix factorization. We compare the performance of ZIP regression and latent factor models on three different data sets involving music, restaurant reviews, and social media. The ZIP regression models are systematically more accurate across all three data sets and across different prediction metrics.",10.1145/3178876.3186153,https://doi.org/10.1145/3178876.3186153,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Prediction of Sparse User-Item Consumption Rates with Zero-Inflated Poisson Regression,"Lichman, Moshe and Smyth, Padhraic",inproceedings,10.1145/3178876.3186153,
10.1145/3178876.3186155,10.1145/3178876.3186155,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","matrix approximation, collaborative filtering",11,741–751,Proceedings of the 2018 World Wide Web Conference,"Gradient-based learning methods such as stochastic gradient descent are widely used in matrix approximation-based collaborative filtering algorithms to train recommendation models based on observed user-item ratings. One major difficulty in existing gradient-based learning methods is determining proper learning rates, since model convergence would be inaccurate or very slow if the learning rate is too large or too small, respectively. This paper proposes AdaError, an adaptive learning rate method for matrix approximation-based collaborative filtering. AdaError eliminates the need of manually tuning the learning rates by adaptively adjusting the learning rates based on the noisiness level of user-item ratings, using smaller learning rates for noisy ratings so as to reduce their impact on the learned models. Our theoretical and empirical analysis shows that AdaError can improve the generalization performance of the learned models. Experimental studies on the MovieLens and Netflix datasets also demonstrate that AdaError outperforms state-of-the-art adaptive learning rate methods in matrix approximation-based collaborative filtering. Furthermore, by applying AdaError to the standard matrix approximation method, we can achieve statistically significant improvements over state-of-the-art collaborative filtering methods in both rating prediction accuracy and top-N recommendation accuracy.",10.1145/3178876.3186155,https://doi.org/10.1145/3178876.3186155,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,AdaError: An Adaptive Learning Rate Method for Matrix Approximation-based Collaborative Filtering,"Li, Dongsheng and Chen, Chao and Lv, Qin and Gu, Hansu and Lu, Tun and Shang, Li and Gu, Ning and Chu, Stephen M.",inproceedings,10.1145/3178876.3186155,
10.1145/3178876.3186158,10.1145/3178876.3186158,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","user modeling, recommender systems, natural language processing, deep learning, collaborative filtering",10,773–782,Proceedings of the 2018 World Wide Web Conference,"Collaborative filtering (CF) is a common recommendation approach that relies on user-item ratings. However, the natural sparsity of user-item rating data can be problematic in many domains and settings, limiting the ability to generate accurate predictions and effective recommendations. Moreover, in some CF approaches latent features are often used to represent users and items, which can lead to a lack of recommendation transparency and explainability. User-generated, customer reviews are now commonplace on many websites, providing users with an opportunity to convey their experiences and opinions of products and services. As such, these reviews have the potential to serve as a useful source of recommendation data, through capturing valuable sentiment information about particular product features. In this paper, we present a novel deep learning recommendation model, which co-learns user and item information from ratings and customer reviews, by optimizing matrix factorization and an attention-based GRU network. Using real-world datasets we show a significant improvement in recommendation performance, compared to a variety of alternatives. Furthermore, the approach is useful when it comes to assigning intuitive meanings to latent features to improve the transparency and explainability of recommender systems.",10.1145/3178876.3186158,https://doi.org/10.1145/3178876.3186158,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Coevolutionary Recommendation Model: Mutual Learning between Ratings and Reviews,"Lu, Yichao and Dong, Ruihai and Smyth, Barry",inproceedings,10.1145/3178876.3186158,
10.1145/3178876.3186165,10.1145/3178876.3186165,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","reinforcement learning, multi-agent learning, learning to rank, joint optimization",10,1939–1948,Proceedings of the 2018 World Wide Web Conference,"Ranking is a fundamental and widely studied problem in scenarios such as search, advertising, and recommendation. However, joint optimization for multi-scenario ranking, which aims to improve the overall performance of several ranking strategies in different scenarios, is rather untouched. Separately optimizing each individual strategy has two limitations. The first one is lack of collaboration between scenarios meaning that each strategy maximizes its own objective but ignores the goals of other strategies, leading to a sub-optimal overall performance. The second limitation is the inability of modeling the correlation between scenarios meaning that independent optimization in one scenario only uses its own user data but ignores the context in other scenarios. In this paper, we formulate multi-scenario ranking as a fully cooperative, partially observable, multi-agent sequential decision problem. We propose a novel model named Multi-Agent Recurrent Deterministic Policy Gradient (MA-RDPG) which has a communication component for passing messages, several private actors (agents) for making actions for ranking, and a centralized critic for evaluating the overall performance of the co-working actors. Each scenario is treated as an agent (actor). Agents collaborate with each other by sharing a global action-value function (the critic) and passing messages that encodes historical information across scenarios. The model is evaluated with online settings on a large E-commerce platform. Results show that the proposed model exhibits significant improvements against baselines in terms of the overall performance.",10.1145/3178876.3186165,https://doi.org/10.1145/3178876.3186165,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356398,2018,Learning to Collaborate: Multi-Scenario Ranking via Multi-Agent Reinforcement Learning,"Feng, Jun and Li, Heng and Huang, Minlie and Liu, Shichen and Ou, Wenwu and Wang, Zhirong and Zhu, Xiaoyan",inproceedings,10.1145/3178876.3186165,
10.1145/3184558.3186584,10.1145/3184558.3186584,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","fine-grained, long short-term memory(lstm), multimodal fusion, video attractiveness",8,671–678,Companion Proceedings of the The Web Conference 2018,"Nowadays, billions of videos are online ready to be viewed and shared. Among an enormous volume of videos, some popular ones are widely viewed by online users while the majority attract little attention. Furthermore, within each video, different segments may attract significantly different numbers of views. This phenomenon leads to a challenging yet important problem, namely fine-grained video attractiveness prediction, which only relies on video contents to forecast video attractiveness at fine-grained levels, specifically video segments of several second length in this paper. However, one major obstacle for such a challenging problem is that no suitable benchmark dataset currently exists. To this end, we construct the first fine-grained video attractiveness dataset (FVAD), which is collected from one of the most popular video websites in the world. In total, the constructed FVAD consists of 1,019 drama episodes with 780.6 hours covering different categories and a wide variety of video contents. Apart from the large amount of videos, hundreds of millions of user behaviors during watching videos are also included, such as view counts, ""fast-forward, ""fast-rewind, and so on, where ""view counts"" reflects the video attractiveness while other engagements capture the interactions between the viewers and videos. First, we demonstrate that video attractiveness and different engagements present different relationships. Second, FVAD provides us an opportunity to study the fine-grained video attractiveness prediction problem. We design different sequential models to perform video attractiveness prediction by relying solely on video contents. The sequential models exploit the multimodal relationships between visual and audio components of the video contents at different levels. Experimental results demonstrate the effectiveness of our proposed sequential models with different visual and audio representations, the necessity of incorporating the two modalities, and the complementary behaviors of the sequential prediction models at different levels.",10.1145/3184558.3186584,https://doi.org/10.1145/3184558.3186584,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356404,2018,Fine-grained Video Attractiveness Prediction Using Multimodal Deep Learning on a Large Real-world Dataset,"Chen, Xinpeng and Chen, Jingyuan and Ma, Lin and Yao, Jian and Liu, Wei and Luo, Jiebo and Zhang, Tong",inproceedings,10.1145/3184558.3186584,
10.1145/3184558.3186956,10.1145/3184558.3186956,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","MLP, RNN, social networks, user modeling",2,115–116,Companion Proceedings of the The Web Conference 2018,"Modeling the evolution of user preferences and item attributes in a dynamic social network is important because it is the basis for many applications, including recommendation systems and user behavior analysis. This study introduces a comprehensive general neural framework with several optimal strategies to jointly model the evolution of user preferences and item attributes in dynamic social networks. Preliminary experimental results conducted on real-world datasets demonstrate that our model performs better than the state-of-the-art methods.",10.1145/3184558.3186956,https://doi.org/10.1145/3184558.3186956,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356404,2018,Deep Modeling of the Evolution of User Preferences and Item Attributes in Dynamic Social Networks,"Wu, Peizhi and Tu, Yi and Yang, Zhenglu and Jatowt, Adam and Odagaki, Masato",inproceedings,10.1145/3184558.3186956,
10.1145/3184558.3186972,10.1145/3184558.3186972,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","channel comparison, identifying future popular videos, interactive visualization, popularity modeling, promotion simulation, video comparison, youtube videos",4,175–178,Companion Proceedings of the The Web Conference 2018,"What makes content go viral Which videos become popular and why others don't Such questions have elicited significant attention from both researchers and industry, particularly in the context of online media. A range of models have been recently proposed to explain and predict popularity; however, there is a short supply of practical tools, accessible for regular users, that leverage these theoretical results. HIPie--an interactive visualization system--is created to fill this gap, by enabling users to reason about the virality and the popularity of online videos. It retrieves the metadata and the past popularity series of Youtube videos, it employs the Hawkes Intensity Process, a state-of-the-art online popularity model for explaining and predicting video popularity, and it presents videos comparatively in a series of interactive plots. This system will help both content consumers and content producers in a range of data-driven inquiries, such as to comparatively analyze videos and channels, to explain and to predict future popularity, to identify viral videos, and to estimate responses to online promotion.",10.1145/3184558.3186972,https://doi.org/10.1145/3184558.3186972,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356404,2018,Will This Video Go Viral: Explaining and Predicting the Popularity of Youtube Videos,"Kong, Quyu and Rizoiu, Marian-Andrei and Wu, Siqi and Xie, Lexing",inproceedings,10.1145/3184558.3186972,
10.1145/3184558.3191531,10.1145/3184558.3191531,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","alt-right, changepoint analysis, hate speech, social networks",8,1007–1014,Companion Proceedings of the The Web Conference 2018,"Over the past few years, a number of new ""fringe"" communities, like 4chan or certain subreddits, have gained traction on the Web at a rapid pace. However, more often than not, little is known about how they evolve or what kind of activities they attract, despite recent research has shown that they influence how false information reaches mainstream communities. This motivates the need to monitor these communities and analyze their impact on the Web's information ecosystem. In August 2016, a new social network called Gab was created as an alternative to Twitter. It positions itself as putting ""people and free speech first"", welcoming users banned or suspended from other social networks. In this paper, we provide, to the best of our knowledge, the first characterization of Gab. We collect and analyze 22M posts produced by 336K users between August 2016 and January 2018, finding that Gab is predominantly used for the dissemination and discussion of news and world events, and that it attracts alt-right users, conspiracy theorists, and other trolls. We also measure the prevalence of hate speech on the platform, finding it to be much higher than Twitter, but lower than 4chan's Politically Incorrect board.",10.1145/3184558.3191531,https://doi.org/10.1145/3184558.3191531,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356404,2018,What is Gab: A Bastion of Free Speech or an Alt-Right Echo Chamber,"Zannettou, Savvas and Bradlyn, Barry and De Cristofaro, Emiliano and Kwak, Haewoon and Sirivianos, Michael and Stringini, Gianluca and Blackburn, Jeremy",inproceedings,10.1145/3184558.3191531,
10.1145/3184558.3191586,10.1145/3184558.3191586,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","concept drift, online recommendation, recommender systems",5,1419–1423,Companion Proceedings of the The Web Conference 2018,"With the explosion of the volume of user-generated data, designing online recommender systems that learn from data streams has become essential. These systems rely on incremental learning that continuously update models as new observations arrive and they should be able to adapt to drifts in real-time. User preferences evolve over time and tracking their evolution is not an easy task. In addition to the low number of observations available per user, the preferences change at different moments and in different ways for each individual. In this paper, we propose a novel approach based on local models to address this problem. Local models are known for their ability to capture diverse preferences among user subsets. Our approach automatically detects the drift of preferences that leads a user to adopt a behavior closer to the users of another subset, and adjusts the models accordingly. Our experiments on real world datasets show promising results and prove the effectiveness of using local models to adapt to changes in user preferences.",10.1145/3184558.3191586,https://doi.org/10.1145/3184558.3191586,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356404,2018,Dynamic Local Models for Online Recommendation,"Al-Ghossein, Marie and Abdessalem, Talel and Barr\'{e}, Anthony",inproceedings,10.1145/3184558.3191586,
10.1145/3184558.3191588,10.1145/3184558.3191588,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","recommender systems, slim, svd",1,1369,Companion Proceedings of the The Web Conference 2018,"Recommender systems are designed to identify the items that a user will like or find useful based on the user's prior preferences and activities. These systems have become ubiquitous and are an essential tool for information filtering and (e-)commerce. Over the years, collaborative filtering, which derive these recommendations by leveraging past activities of groups of users, has emerged as the most prominent approach for solving this problem. This talk will present some of our recent work towards improving the performance of collaborative filtering-based recommender systems and understanding some of their fundamental limitations and characteristics. It will start by analyzing how the ratings that users provide to a set of items relate to their ratings of the set's individual items and, using these insights, will present rating prediction approaches that utilize distant supervision. It will then discuss extensions to approaches based on sparse linear and latent factor models that postulate that users' preferences are a combination of global and local preferences, which are shown to lead to better user modeling and as such improved prediction performance. Finally, the talk will conclude by discussing what can be accurately predicted by latent factor approaches and by analyzing the estimation error of sparse linear and latent factor models and how its characteristics impacts the performance of top N recommendation algorithms.",10.1145/3184558.3191588,https://doi.org/10.1145/3184558.3191588,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356404,2018,"Recent Advances in Recommender Systems: Sets, Local Models, Coverage, and Errors","Karypis, George",inproceedings,10.1145/3184558.3191588,
10.1145/3184558.3191634,10.1145/3184558.3191634,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '18,"Lyon, France","multi-actor network, popularity prediction, temporal point process",6,1737–1742,Companion Proceedings of the The Web Conference 2018,"Predicting the popularity of a discussion topic in an online social network (OSN) or the responses to an online fund-raising campaign is a practical challenge of immense value. Previous work tries to predict the popularity of an online campaign by modeling information diffusion as a homogeneous temporal point process within a network of a single-type of actors. However, real-world information propagation often involved multiple types of actors. In particular, there are the so-called opinion leaders, e.g. online celebrities or influential OSN users with a huge number of followers, who can create a great impact on the visibility and thus the final popularity of an event by simply mentioning it in their tweets or postings. In this paper, we propose MASEP, a Multi-actor Self-exciting Process, to model and predict the popularity of different online campaigns involving multiple types of actors. MASEP combines a self-exciting branching process with a periodical decay process to capture the dynamics and interdependent relationship between opinion leaders and ordinary users during an online campaign. A closed-form expression is derived for the temporal campaign popularity under the MASEP model. Based on this closed-form expression, we can efficiently perform regression against the empirical activity measurements of an online campaign during its early stage to estimate the parameters of the corresponding MASEP model. The final popularity of the campaign can then be predicted. To demonstrate the efficacy of the MASEP-based approach, we apply it to predict the popularity of three types of online campaigns from different large-scale real-world datasets, namely, the total number of posts in retweeting cascades, the overall count of individual hashtags in posting streams, and the final number of sponsors for crowd-funding campaigns. In particular, using the initial 30% of each campaign data trace for training, our approach can achieve absolute prediction error (APE) of 13.25%, 15.7%, and 36.9% respectively for datasets of 3 different types of campaigns. This corresponds to a 26.1% to 63.2% reduction in prediction error when comparing to state-of-the-art approaches including SEISMIC, SpikeM, and STRM.",10.1145/3184558.3191634,https://doi.org/10.1145/3184558.3191634,"Republic and Canton of Geneva, CHE",International World Wide Web Conferences Steering Committee,9781450356404,2018,Temporal Modeling of Information Diffusion using MASEP: Multi-Actor Self-Exciting Processes,"Zhang, Bowen and Lau, Wing Cheong",inproceedings,10.1145/3184558.3191634,
10.1145/3219819.3219821,10.1145/3219819.3219821,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","churn prediction, interpretable model, user clustering",9,914–922,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"As online platforms are striving to get more users, a critical challenge is user churn, which is especially concerning for new users. In this paper, by taking the anonymous large-scale real-world data from Snapchat as an example, we develop ClusChurn , a systematic two-step framework for interpretable new user clustering and churn prediction, based on the intuition that proper user clustering can help understand and predict user churn. Therefore, ClusChurn firstly groups new users into interpretable typical clusters, based on their activities on the platform and ego-network structures. Then we design a novel deep learning pipeline based on LSTM and attention to accurately predict user churn with very limited initial behavior data, by leveraging the correlations among users' multi- dimensional activities and the underlying user types. ClusChurn is also able to predict user types, which enables rapid reactions to different types of user churn. Extensive data analysis and experiments show that ClusChurn provides valuable insight into user behaviors, and achieves state-of-the-art churn prediction performance. The whole framework is deployed as a data analysis pipeline, delivering real-time data analysis and prediction results to multiple relevant teams for business intelligence uses. It is also general enough to be readily adopted by any online systems with user behavior data.",10.1145/3219819.3219821,https://doi.org/10.1145/3219819.3219821,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,I Know You'll Be Back: Interpretable New User Clustering and Churn Prediction on a Mobile Social Application,"Yang, Carl and Shi, Xiaolin and Jie, Luo and Han, Jiawei",inproceedings,10.1145/3219819.3219821,
10.1145/3219819.3219847,10.1145/3219819.3219847,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","bayesian optimization, gaussian processes, online feed ranking, thompson sampling",10,23–32,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Web-based ranking problems involve ordering different kinds of items in a list or grid to be displayed in mediums like a website or a mobile app. In most cases, there are multiple objectives or metrics like clicks, viral actions, job applications, advertising revenue and others that we want to balance. Constructing a serving algorithm that achieves the desired tradeoff among multiple objectives is challenging, especially for more than two objectives. In addition, it is often not possible to estimate such a serving scheme using offline data alone for non-stationary systems with frequent online interventions. We consider a large-scale online application where metrics for multiple objectives are continuously available and can be controlled in a desired fashion by changing certain control parameters in the ranking model. We assume that the desired balance of metrics is known from business considerations. Our approach models the balance criteria as a composite utility function via a Gaussian process over the space of control parameters. We show that obtaining a solution can be equated to finding the maximum of the Gaussian process, practically obtainable via Bayesian optimization. However, implementing such a scheme for large-scale applications is challenging. We provide a novel framework to do so and illustrate its efficacy in the context of LinkedIn Feed. In particular, we show the effectiveness of our method by using both offline simulations as well as promising online A/B testing results. At the time of writing this paper, the method described was fully deployed on the LinkedIn Feed.",10.1145/3219819.3219847,https://doi.org/10.1145/3219819.3219847,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Online Parameter Selection for Web-based Ranking Problems,"Agarwal, Deepak and Basu, Kinjal and Ghosh, Souvik and Xuan, Ying and Yang, Yang and Zhang, Liang",inproceedings,10.1145/3219819.3219847,
10.1145/3219819.3219880,10.1145/3219819.3219880,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","machine learning, notifications, optimization, stream computing",10,283–292,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"In recent years, social media applications (e.g., Facebook, LinkedIn) have created mobile applications (apps) to give their members instant and real-time access from anywhere. To keep members informed and drive timely engagement, these mobile apps send event notifications. However, sending notifications for every possible event would result in too many notifications which would in turn annoy members and create a poor member experience.In this paper, we present our strategy of optimizing notifications to balance various utilities (e.g., engagement, send volume) by formulating the problem using constrained optimization. To guarantee freshness of notifications, we implement the solution in a stream computing system in which we make multi-channel send decisions in near real-time. Through online A/B test results, we show the effectiveness of our proposed approach on tens of millions of members.",10.1145/3219819.3219880,https://doi.org/10.1145/3219819.3219880,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Near Real-time Optimization of Activity-based Notifications,"Gao, Yan and Gupta, Viral and Yan, Jinyun and Shi, Changji and Tao, Zhongen and Xiao, PJ and Wang, Curtis and Yu, Shipeng and Rosales, Romer and Muralidharan, Ajith and Chatterjee, Shaunak",inproceedings,10.1145/3219819.3219880,
10.1145/3219819.3219894,10.1145/3219819.3219894,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","bootstrapping conversations, engaging casual users, interactive recommendation, question and recommendation",10,139–148,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Recommendation systems, prevalent in many applications, aim to surface to users the right content at the right time. Recently, researchers have aspired to develop conversational systems that offer seamless interactions with users, more effectively eliciting user preferences and offering better recommendations. Taking a step towards this goal, this paper explores the two stages of a single round of conversation with a user: which question to ask the user, and how to use their feedback to respond with a more accurate recommendation. Following these two stages, first, we detail an RNN-based model for generating topics a user might be interested in, and then extend a state-of-the-art RNN-based video recommender to incorporate the user's selected topic. We describe our proposed system Q&amp;R, i.e., Question &amp; Recommendation, and the surrogate tasks we utilize to bootstrap data for training our models. We evaluate different components of Q&amp;R on live traffic in various applications within YouTube: User Onboarding, Homepage Recommendation, and Notifications. Our results demonstrate that our approach improves upon state-of-the-art recommendation models, including RNNs, and makes these applications more useful, such as a &gt;1% increase in video notifications opened. Further, our design choices can be useful to practitioners wanting to transition to more conversational recommendation systems.",10.1145/3219819.3219894,https://doi.org/10.1145/3219819.3219894,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Q&amp;R: A Two-Stage Approach toward Interactive Recommendation,"Christakopoulou, Konstantina and Beutel, Alex and Li, Rui and Jain, Sagar and Chi, Ed H.",inproceedings,10.1145/3219819.3219894,
10.1145/3219819.3219965,10.1145/3219819.3219965,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","attention mechanism, deep learning, heterogeneous information network, recommender system",10,1531–1540,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Heterogeneous information network (HIN) has been widely adopted in recommender systems due to its excellence in modeling complex context information. Although existing HIN based recommendation methods have achieved performance improvement to some extent, they have two major shortcomings. First, these models seldom learn an explicit representation for path or meta-path in the recommendation task. Second, they do not consider the mutual effect between the meta-path and the involved user-item pair in an interaction. To address these issues, we develop a novel deep neural network with the co-attention mechanism for leveraging rich meta-path based context for top-N recommendation. We elaborately design a three-way neural interaction model by explicitly incorporating meta-path based context. To construct the meta-path based context, we propose to use a priority based sampling technique to select high-quality path instances. Our model is able to learn effective representations for users, items and meta-path based context for implementing a powerful interaction function. The co-attention mechanism improves the representations for meta-path based con- text, users and items in a mutual enhancement way. Extensive experiments on three real-world datasets have demonstrated the effectiveness of the proposed model. In particular, the proposed model performs well in the cold-start scenario and has potentially good interpretability for the recommendation results.",10.1145/3219819.3219965,https://doi.org/10.1145/3219819.3219965,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Leveraging Meta-path based Context for Top- N Recommendation with A Neural Co-Attention Model,"Hu, Binbin and Shi, Chuan and Zhao, Wayne Xin and Yu, Philip S.",inproceedings,10.1145/3219819.3219965,
10.1145/3219819.3219987,10.1145/3219819.3219987,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","bayesian nonparametric, topic modelling, urban computing, urban function discovery",9,2692–2700,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Urbanization is a global trend that we have all witnessed in the past decades. It brings us both opportunities and challenges. On the one hand, urban system is one of the most sophisticated social-economic systems that is responsible for efficiently providing supplies meeting the demand of residents in various of domains, e.g., dwelling, education, entertainment, healthcare, etc. On the other hand, significant diversity and inequality exist in the development patterns of urban systems, which makes urban data analysis difficult. Different urban regions often exhibit diverse urbanization patterns and provide distinct urban functions, e.g., commercial and residential areas offer significantly different urban functions. It is desired to develop the data analytic capabilities for discovering the underlying cross-domain urbanization patterns, clustering urban regions based on their function similarity and predicting region popularity in specified domains. Previous studies in the urban data analysis area often just focus on individual domains and rarely consider cross-domain urban development patterns hidden in different urban regions. In this paper, we propose the infinite urbanization process (IUP) model for simultaneous urban region function discovery and region popularity prediction. The IUP model is a generative Bayesian nonparametric process that is capable of describing a potentially infinite number of urbanization patterns. It is developed within the supervised topic modelling framework and is supported by a novel hierarchical spatial distance dependent Bayesian nonparametric prior over the spatial region partition space. The empirical study conducted on the real-world datasets shows promising outcome compared with the state-of-the-art techniques.",10.1145/3219819.3219987,https://doi.org/10.1145/3219819.3219987,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Simultaneous Urban Region Function Discovery and Popularity Estimation via an Infinite Urbanization Process Model,"Zhang, Bang and Zhang, Lelin and Guo, Ting and Wang, Yang and Chen, Fang",inproceedings,10.1145/3219819.3219987,
10.1145/3219819.3220004,10.1145/3219819.3220004,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","collaborative filtering, memory networks, streaming recommender systems",9,2467–2475,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"With the increasing popularity of various social media and E-commerce platforms, large volumes of user behaviour data (e.g., user transaction data, rating and review data) are being continually generated at unprecedented and ever-increasing scales. It is more realistic and practical to study recommender systems with inputs of streaming data. User-generated streaming data presents unique properties such as temporally ordered, continuous and high-velocity, which poses tremendous new challenges for the once very successful recommendation techniques. Although a few temporal or sequential recommender models have recently been developed based on recurrent neural models, most of them can only be applied to the session-based recommendation scenario, due to their short-term memories and the limited capability of capturing users' long-term stable interests. In this paper, we propose a streaming recommender model based on neural memory networks with external memories to capture and store both long-term stable interests and short-term dynamic interests in a unified way. An adaptive negative sampling framework based on Generative Adversarial Nets (GAN) is developed to optimize our proposed streaming recommender model, which effectively overcomes the limitations of classical negative sampling approaches and improves both effectiveness and efficiency of the model parameter inference. Extensive experiments have been conducted on two large-scale recommendation datasets, and the experimental results show the superiority of our proposed streaming recommender model in the streaming recommendation scenario.",10.1145/3219819.3220004,https://doi.org/10.1145/3219819.3220004,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Neural Memory Streaming Recommender Networks with Adversarial Training,"Wang, Qinyong and Yin, Hongzhi and Hu, Zhiting and Lian, Defu and Wang, Hao and Huang, Zi",inproceedings,10.1145/3219819.3220004,
10.1145/3219819.3220036,10.1145/3219819.3220036,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","attention network, question answering, relation fact mining, semantic knowledge, visual question answering",10,1880–1889,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Recently, Visual Question Answering (VQA) has emerged as one of the most significant tasks in multimodal learning as it requires understanding both visual and textual modalities. Existing methods mainly rely on extracting image and question features to learn their joint feature embedding via multimodal fusion or attention mechanism. Some recent studies utilize external VQA-independent models to detect candidate entities or attributes in images, which serve as semantic knowledge complementary to the VQA task. However, these candidate entities or attributes might be unrelated to the VQA task and have limited semantic capacities. To better utilize semantic knowledge in images, we propose a novel framework to learn visual relation facts for VQA. Specifically, we build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset via a semantic similarity module, in which each data consists of an image, a corresponding question, a correct answer and a supporting relation fact. A well-defined relation detector is then adopted to predict visual question-related relation facts. We further propose a multi-step attention model composed of visual attention and semantic attention sequentially to extract related visual knowledge and semantic knowledge. We conduct comprehensive experiments on the two benchmark datasets, demonstrating that our model achieves state-of-the-art performance and verifying the benefit of considering visual relation facts.",10.1145/3219819.3220036,https://doi.org/10.1145/3219819.3220036,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering,"Lu, Pan and Ji, Lei and Zhang, Wei and Duan, Nan and Zhou, Ming and Wang, Jianyong",inproceedings,10.1145/3219819.3220036,
10.1145/3219819.3220044,10.1145/3219819.3220044,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","convex online learning, factorization machine, follow-the-regularized-leader, sketching",10,1900–1909,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Factorization Machine (FM) is a supervised machine learning model for feature engineering, which is widely used in many real-world applications. In this paper, we consider the case that the data samples arrive sequentially. The existing convex formulation for online FM has the strong theoretical guarantee and stable performance in practice, but the computational cost is typically expensive when the data is high-dimensional. To address this weakness, we devise a novel online learning algorithm called Sketched Follow-The-Regularizer-Leader (SFTRL). SFTRL presents the parameters of FM implicitly by maintaining low-rank matrices and updates the parameters via sketching. More specifically, we propose Generalized Frequent Directions to approximate indefinite symmetric matrices in a streaming way, making that the sum of historical gradients for FM could be estimated with tighter error bound efficiently. With mild assumptions, we prove that the regret bound of SFTRL is close to that of the standard FTRL. Experimental results show that SFTRL has better prediction quality than the state-of-the-art online FM algorithms in much lower time and space complexities.",10.1145/3219819.3220044,https://doi.org/10.1145/3219819.3220044,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Sketched Follow-The-Regularized-Leader for Online Factorization Machine,"Luo, Luo and Zhang, Wenpeng and Zhang, Zhihua and Zhu, Wenwu and Zhang, Tong and Pei, Jian",inproceedings,10.1145/3219819.3220044,
10.1145/3219819.3220048,10.1145/3219819.3220048,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","attention mechanism, co-attention, conversation modeling, deep learning, information retrieval, intra-attention, learning to rank, neural networks, neural ranking models, qa, question answering",10,2299–2308,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Attention is typically used to select informative sub-phrases that are used for prediction. This paper investigates the novel use of attention as a form of feature augmentation, i.e, casted attention. We propose Multi-Cast Attention Networks (MCAN), a new attention mechanism and general model architecture for a potpourri of ranking tasks in the conversational modeling and question answering domains. Our approach performs a series of soft attention operations, each time casting a scalar feature upon the inner word embeddings. The key idea is to provide a real-valued hint (feature) to a subsequent encoder layer and is targeted at improving the representation learning process. There are several advantages to this design, e.g., it allows an arbitrary number of attention mechanisms to be casted, allowing for multiple attention types (e.g., co-attention, intra-attention) and attention variants (e.g., alignment-pooling, max-pooling, mean-pooling) to be executed simultaneously. This not only eliminates the costly need to tune the nature of the co-attention layer, but also provides greater extents of explainability to practitioners. Via extensive experiments on four well-known benchmark datasets, we show that MCAN achieves state-of-the-art performance. On the Ubuntu Dialogue Corpus, MCAN outperforms existing state-of-the-art models by 9%. MCAN also achieves the best performing score to date on the well-studied TrecQA dataset.",10.1145/3219819.3220048,https://doi.org/10.1145/3219819.3220048,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Multi-Cast Attention Networks,"Tay, Yi and Tuan, Luu Anh and Hui, Siu Cheung",inproceedings,10.1145/3219819.3220048,
10.1145/3219819.3220061,10.1145/3219819.3220061,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","active learning, influence maximization, matrix factorization, opinion maximization, social networks, viral marketing",10,1840–1849,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Influence maximization (IM) targets at maximizing the number of users being aware of a product by finding a set of seed users to expose in a social network. Previous IM models mainly focus on optimizing the spread of product consumption, which assumes that all users are potential customers and more exposures lead to better profit. However, in the real-world scenario, some people may not like the product and may express negative opinions after consuming, which damage the product reputation and harm the long-term profit. Only a portion of users in the social network, called the target user, is the potential customer that likes the product and will spread positive opinion. In this paper, we consider a problem called AcTive Opinion Maximization (ATOM), where the goal is to find a set of seed users to maximize the overall opinion spread toward a target product in a multi-round campaign. Different from previous works, we do not assume the user opinion is known before consumption, but should be derived from user preference data. The ATOM problem has essential applications in viral marketing, such as reputation building and precision advertising. Given its significance, ATOM problem is profoundly challenging due to the hardness of estimating user opinion in a multi-round campaign. Moreover, the process of opinion estimation and influence propagation intertwine with each other, which requires the model to consider the two components collectively. We propose an active learning framework called CONE (aCtive OpinioN Estimator) to address above challenges. Experimental results on two real-world datasets demonstrate that CONE improves the total opinion spread in a social network.",10.1145/3219819.3220061,https://doi.org/10.1145/3219819.3220061,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Active Opinion Maximization in Social Networks,"Liu, Xinyue and Kong, Xiangnan and Yu, Philip S.",inproceedings,10.1145/3219819.3220061,
10.1145/3219819.3220086,10.1145/3219819.3220086,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","attention mechanism, collaborative filtering, deep learning, information retrieval, natural language processing, pointer networks, recommendation, review rating prediction, review-based recommender systems",10,2309–2318,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Many recent state-of-the-art recommender systems such as D-ATT, TransNet and DeepCoNN exploit reviews for representation learning. This paper proposes a new neural architecture for recommendation with reviews. Our model operates on a multi-hierarchical paradigm and is based on the intuition that not all reviews are created equal, i.e., only a selected few are important. The importance, however, should be dynamically inferred depending on the current target. To this end, we propose a review-by-review pointer-based learning scheme that extracts important reviews from user and item reviews and subsequently matches them in a word-by-word fashion. This enables not only the most informative reviews to be utilized for prediction but also a deeper word-level interaction. Our pointer-based method operates with a gumbel-softmax based pointer mechanism that enables the incorporation of discrete vectors within differentiable neural architectures. Our pointer mechanism is co-attentive in nature, learning pointers which are co-dependent on user-item relationships. Finally, we propose a multi-pointer learning scheme that learns to combine multiple views of user-item interactions. We demonstrate the effectiveness of our proposed model via extensive experiments on 24 benchmark datasets from Amazon and Yelp. Empirical results show that our approach significantly outperforms existing state-of-the-art models, with up to 19% and 71% relative improvement when compared to TransNet and DeepCoNN respectively. We study the behavior of our multi-pointer learning mechanism, shedding light on 'evidence aggregation' patterns in review-based recommender systems.",10.1145/3219819.3220086,https://doi.org/10.1145/3219819.3220086,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Multi-Pointer Co-Attention Networks for Recommendation,"Tay, Yi and Luu, Anh Tuan and Hui, Siu Cheung",inproceedings,10.1145/3219819.3220086,
10.1145/3219819.3220112,10.1145/3219819.3220112,KDD.bib,1,['KDD.bib'],8,KDD '18,"London, United Kingdom","clustering, collaborative filtering, latent space models, local models",9,1235–1243,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Users' behaviors are driven by their preferences across various aspects of items they are potentially interested in purchasing, viewing, etc. Latent space approaches model these aspects in the form of latent factors. Although such approaches have been shown to lead to good results, the aspects that are important to different users can vary. In many domains, there may be a set of aspects for which all users care about and a set of aspects that are specific to different subsets of users. To explicitly capture this, we consider models in which there are some latent factors that capture the shared aspects and some user subset specific latent factors that capture the set of aspects that the different subsets of users care about.In particular, we propose two latent space models: rGLSVD and sGLSVD, that combine such a global and user subset specific sets of latent factors. The rGLSVD model assigns the users into different subsets based on their rating patterns and then estimates a global and a set of user subset specific local models whose number of latent dimensions can vary.The sGLSVD model estimates both global and user subset specific local models by keeping the number of latent dimensions the same among these models but optimizes the grouping of the users in order to achieve the best approximation. Our experiments on various real-world datasets show that the proposed approaches significantly outperform state-of-the-art latent space top-N recommendation approaches.",10.1145/3219819.3220112,https://doi.org/10.1145/3219819.3220112,"New York, NY, USA",Association for Computing Machinery,9781450355520,2018,Local Latent Space Models for Top-N Recommendation,"Christakopoulou, Evangelia and Karypis, George",inproceedings,10.1145/3219819.3220112,
10.1145/3240323.3240343,10.1145/3240323.3240343,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","spectrum, recommender systems, collaborative filtering",9,311–319,Proceedings of the 12th ACM Conference on Recommender Systems,"Despite the popularity of Collaborative Filtering (CF), CF-based methods are haunted by the cold-start problem, which has a significantly negative impact on users' experiences with Recommender Systems (RS). In this paper, to overcome the aforementioned drawback, we first formulate the relationships between users and items as a bipartite graph. Then, we propose a new spectral convolution operation directly performing in the spectral domain, where not only the proximity information of a graph but also the connectivity information hidden in the graph are revealed. With the proposed spectral convolution operation, we build a deep recommendation model called Spectral Collaborative Filtering (SpectralCF). Benefiting from the rich information of connectivity existing in the spectral domain, SpectralCF is capable of discovering deep connections between users and items and therefore, alleviates the cold-start problem for CF. To the best of our knowledge, SpectralCF is the first CF-based method directly learning from the spectral domains of user-item bipartite graphs. We apply our method on several standard datasets. It is shown that SpectralCF significantly out-performs state-of-the-art models. Code and data are available at https://github.com/lzheng21/SpectralCF.",10.1145/3240323.3240343,https://doi.org/10.1145/3240323.3240343,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Spectral collaborative filtering,"Zheng, Lei and Lu, Chun-Ta and Jiang, Fei and Zhang, Jiawei and Yu, Philip S.",inproceedings,10.1145/3240323.3240343,
10.1145/3240323.3240347,10.1145/3240323.3240347,RecSys.bib,1,['RecSys.bib'],7,RecSys '18,"Vancouver, British Columbia, Canada",,9,260–268,Proceedings of the 12th ACM Conference on Recommender Systems,"The evaluation of Recommender Systems is still an open issue in the field. Despite its limitations, offline evaluation usually constitutes the first step in assessing recommendation methods due to its reduced costs and high reproducibility. Selecting the appropriate metric is a critical and ranking accuracy usually attracts the most attention nowadays. In this paper, we aim to shed light on the advantages of different ranking metrics which were previously used in Information Retrieval and are now used for assessing top-N recommenders. We propose methodologies for comparing the robustness and the discriminative power of different metrics. On the one hand, we study cut-offs and we find that deeper cut-offs offer greater robustness and discriminative power. On the other hand, we find that precision offers high robustness and Normalised Discounted Cumulative Gain provides the best discriminative power.",10.1145/3240323.3240347,https://doi.org/10.1145/3240323.3240347,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,On the robustness and discriminative power of information retrieval metrics for top-N recommendation,"Valcarce, Daniel and Bellog\'{\i}n, Alejandro and Parapar, Javier and Castells, Pablo",inproceedings,10.1145/3240323.3240347,
10.1145/3240323.3240352,10.1145/3240323.3240352,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","preference elicitation, mixed initiative search and recommendation, cold start problem",9,172–180,Proceedings of the 12th ACM Conference on Recommender Systems,"The new user coldstart problem arises when a recommender system does not yet have any information about a user. A common solution to it is to generate a profile by asking the user to rate a number of items. Which items are selected determines the quality of the recommendations made, and thus has been studied extensively. We propose a new elicitation method to generate a static preference questionnaire (SPQ) that poses relative preference questions to the user. Using a latent factor model, we show that SPQ improves personalized recommendations by choosing a minimal and diverse set of questions. We are the first to rigorously prove which optimization task should be solved to select each question in static questionnaires. Our theoretical results are confirmed by extensive experimentation. We test the performance of SPQ on two real-world datasets, under two experimental conditions: simulated, when users behave according to a latent factor model (LFM), and real, in which only real user judgments are revealed as the system asks questions. We show that SPQ reduces the necessary length of a questionnaire by up to a factor of three compared to state-of-the-art preference elicitation methods. Moreover, solving the right optimization task, SPQ also performs better than baselines with dynamically generated questions.",10.1145/3240323.3240352,https://doi.org/10.1145/3240323.3240352,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Preference elicitation as an optimization problem,"Sepliarskaia, Anna and Kiseleva, Julia and Radlinski, Filip and de Rijke, Maarten",inproceedings,10.1145/3240323.3240352,
10.1145/3240323.3240353,10.1145/3240323.3240353,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","deep learning, gaussian mixture model, recommendation, review-based rating prediction",9,113–121,Proceedings of the 12th ACM Conference on Recommender Systems,"Review has been proven to be an important information in recommendation. Different from the overall user-item rating matrix, it can provide textual information that exhibits why a user likes an item or not. Recently, more and more researchers have paid attention on review-based rating prediction. There are two challenging issues: how to extract representative features to characterize users / items from reviews and how to leverage them for recommendation system. In this paper, we propose a Neural Gaussian Mixture Model (NGMM) for review-based rating prediction task. Among it, the review textual information is used to construct two parallel neural networks for users and items respectively, so that the users' preferences and items' properties can be sufficiently extracted and represented as two latent vectors. A shared layer is introduced on the top to couple these two networks together and model user-item rating based on the features learned from reviews. Specifically, each rating is modeled via a Gaussian mixture model, where each Gaussian component has zero variance, the mean described by the corresponding component in user's latent vector and the weight indicated by the corresponding component in item's latent vector. Extensive experiments are conducted on five real-world Amazon review datasets. The experimental results have demonstrated that our proposed NGMM model achieves the state-of-the-art performance in review-based rating prediction task.",10.1145/3240323.3240353,https://doi.org/10.1145/3240323.3240353,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Neural gaussian mixture model for review-based rating prediction,"Deng, Dong and Jing, Liping and Yu, Jian and Sun, Shaolong and Zhou, Haofei",inproceedings,10.1145/3240323.3240353,
10.1145/3240323.3240354,10.1145/3240323.3240354,RecSys.bib,1,['RecSys.bib'],7,RecSys '18,"Vancouver, British Columbia, Canada",,9,31–39,Proceedings of the 12th ACM Conference on Recommender Systems,"The multi-armed bandit is an important framework for balancing exploration with exploitation in recommendation. Exploitation recommends content (e.g., products, movies, music playlists) with the highest predicted user engagement and has traditionally been the focus of recommender systems. Exploration recommends content with uncertain predicted user engagement for the purpose of gathering more information. The importance of exploration has been recognized in recent years, particularly in settings with new users, new items, non-stationary preferences and attributes. In parallel, explaining recommendations (""recsplanations"") is crucial if users are to understand their recommendations. Existing work has looked at bandits and explanations independently. We provide the first method that combines both in a principled manner. In particular, our method is able to jointly (1) learn which explanations each user responds to; (2) learn the best content to recommend for each user; and (3) balance exploration with exploitation to deal with uncertainty. Experiments with historical log data and tests with live production traffic in a large-scale music recommendation service show a significant improvement in user engagement.",10.1145/3240323.3240354,https://doi.org/10.1145/3240323.3240354,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,"Explore, exploit, and explain: personalizing explainable recommendations with bandits","McInerney, James and Lacker, Benjamin and Hansen, Samantha and Higley, Karl and Bouchard, Hugues and Gruson, Alois and Mehrotra, Rishabh",inproceedings,10.1145/3240323.3240354,
10.1145/3240323.3240357,10.1145/3240323.3240357,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","deep generative models, group formation, group recommendation, novel item recommendation",9,145–153,Proceedings of the 12th ACM Conference on Recommender Systems,"Consider a movie studio aiming to produce a set of new movies for summer release: What types of movies it should produce? Who would the movies appeal to? How many movies should it make? Similar issues are encountered by a variety of organizations, e.g., mobile-phone manufacturers and online magazines, who have to create new (non-existent) items to satisfy groups of users with different preferences. In this paper, we present a joint problem formalization of these interrelated issues, and propose generative methods that address these questions simultaneously. Specifically, we leverage on the latent space obtained by training a deep generative model---the Variational Autoencoder (VAE)---via a loss function that incorporates both rating performance and item reconstruction terms. We use a greedy search algorithm that utilize this learned latent space to jointly obtain K plausible new items, and user groups that would find the items appealing. An evaluation of our methods on a synthetic dataset indicates that our approach is able to generate novel items similar to highly-desirable unobserved items. As case studies on real-world data, we applied our method on the MART abstract art and Movielens Tag Genome datasets, which resulted in promising results: small and diverse sets of novel items.",10.1145/3240323.3240357,https://doi.org/10.1145/3240323.3240357,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Generation meets recommendation: proposing novel items for groups of users,"Vo, Thanh Vinh and Soh, Harold",inproceedings,10.1145/3240323.3240357,
10.1145/3240323.3240365,10.1145/3240323.3240365,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","collaborative filtering, information retrieval, natural language generation, personalization, recommender systems",9,4–12,Proceedings of the 12th ACM Conference on Recommender Systems,"We describe a novel, multi-task recommendation model, which jointly learns to perform rating prediction and recommendation explanation by combining matrix factorization, for rating prediction, and adversarial sequence to sequence learning for explanation generation. The result is evaluated using real-world datasets to demonstrate improved rating prediction performance, compared to state-of-the-art alternatives, while producing effective, personalized explanations.",10.1145/3240323.3240365,https://doi.org/10.1145/3240323.3240365,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Why I like it: multi-task learning for recommendation and explanation,"Lu, Yichao and Dong, Ruihai and Smyth, Barry",inproceedings,10.1145/3240323.3240365,
10.1145/3240323.3240366,10.1145/3240323.3240366,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","decision field theory, decision making, user inaction",9,40–48,Proceedings of the 12th ACM Conference on Recommender Systems,"Temporally, users browse and interact with items in recommender systems. However, for most systems, the majority of the displayed items do not elicit any action from users. In other words, the user-system interaction process includes three aspects: browsing, action, and inaction. Prior recommender systems literature has focused more on actions than on browsing or inaction. In this work, we deployed a field survey in a live movie recommender system to interpret what inaction means from both the user's and the system's perspective, guided by psychological theories of human decision making. We further systematically study factors to infer the reasons of user inaction and demonstrate with offline data sets that this descriptive and predictive inaction model can provide benefits for recommender systems in terms of both action prediction and recommendation timing.",10.1145/3240323.3240366,https://doi.org/10.1145/3240323.3240366,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Interpreting user inaction in recommender systems,"Zhao, Qian and Willemsen, Martijn C. and Adomavicius, Gediminas and Harper, F. Maxwell and Konstan, Joseph A.",inproceedings,10.1145/3240323.3240366,
10.1145/3240323.3240367,10.1145/3240323.3240367,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","recommender systems, multi-task learning, hierarchical softmax, hierarchical classification",9,320–328,Proceedings of the 12th ACM Conference on Recommender Systems,"Many techniques to utilize side information of users and/or items as inputs to recommenders to improve recommendation, especially on cold-start items/users, have been developed over the years. In this work, we test the approach of utilizing item side information, specifically categorical attributes, in the output of recommendation models either through multi-task learning or hierarchical classification. We first demonstrate the efficacy of these approaches for both matrix factorization and neural networks with a medium-size real-word data set. We then show that they improve a neural-network based production model in an industrial-scale recommender system. We demonstrate the robustness of the hierarchical classification approach by introducing noise in building the hierarchy. Lastly, we investigate the generalizability of hierarchical classification on a simulated dataset by building two user models in which we can fully control the generative process of user-item interactions.",10.1145/3240323.3240367,https://doi.org/10.1145/3240323.3240367,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Categorical-attributes-based item classification for recommender systems,"Zhao, Qian and Chen, Jilin and Chen, Minmin and Jain, Sagar and Beutel, Alex and Belletti, Francois and Chi, Ed H.",inproceedings,10.1145/3240323.3240367,
10.1145/3240323.3240370,10.1145/3240323.3240370,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","algorithmic confounding, recommendation systems",9,224–232,Proceedings of the 12th ACM Conference on Recommender Systems,"Recommendation systems are ubiquitous and impact many domains; they have the potential to influence product consumption, individuals' perceptions of the world, and life-altering decisions. These systems are often evaluated or trained with data from users already exposed to algorithmic recommendations; this creates a pernicious feedback loop. Using simulations, we demonstrate how using data confounded in this way homogenizes user behavior without increasing utility.",10.1145/3240323.3240370,https://doi.org/10.1145/3240323.3240370,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,How algorithmic confounding in recommendation systems increases homogeneity and decreases utility,"Chaney, Allison J. B. and Stewart, Brandon M. and Engelhardt, Barbara E.",inproceedings,10.1145/3240323.3240370,
10.1145/3240323.3240372,10.1145/3240323.3240372,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","recommender systems, fairness, diversity, calibration",9,154–162,Proceedings of the 12th ACM Conference on Recommender Systems,"When a user has watched, say, 70 romance movies and 30 action movies, then it is reasonable to expect the personalized list of recommended movies to be comprised of about 70% romance and 30% action movies as well. This important property is known as calibration, and recently received renewed attention in the context of fairness in machine learning. In the recommended list of items, calibration ensures that the various (past) areas of interest of a user are reflected with their corresponding proportions. Calibration is especially important in light of the fact that recommender systems optimized toward accuracy (e.g., ranking metrics) in the usual offline-setting can easily lead to recommendations where the lesser interests of a user get crowded out by the user's main interests-which we show empirically as well as in thought-experiments. This can be prevented by calibrated recommendations. To this end, we outline metrics for quantifying the degree of calibration, as well as a simple yet effective re-ranking algorithm for post-processing the output of recommender systems.",10.1145/3240323.3240372,https://doi.org/10.1145/3240323.3240372,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Calibrated recommendations,"Steck, Harald",inproceedings,10.1145/3240323.3240372,
10.1145/3240323.3240380,10.1145/3240323.3240380,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","cold-start problem, convolution neural network, deep learning, personalization, recommender systems, retail",5,195–199,Proceedings of the 12th ACM Conference on Recommender Systems,"Recommender systems are an important component in the retail industry, but the constantly renewed inventory of many companies makes it difficult to aggregate enough data to fully harness the benefits of such systems. In this paper, we describe a technique that significantly improves the accuracy of the recommendations, validated on a real store transaction history, by performing a time translation that maps out-of-stock items to similar items that are currently in stock using deep features of the products. This greatly reduces the dimension of the item-item interactions matrix while preserving all the dataset entries, which mitigates the sparsity of the dataset, and provides an original solution to the cold-start problem. We also improve the coverage at no accuracy cost by favouring less popular items within a small radius in the feature space while applying the time translation mapping. Finally, by modelling item-item rather that user-item correlations, we are able to update the recommendations for a given user in real-time, without re-training, as the user's history receives new entries.",10.1145/3240323.3240380,https://doi.org/10.1145/3240323.3240380,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Deep inventory time translation to improve recommendations for real-world retail,"Pr\'{e}vost, Bobby and Janssen, Jonathan Laflamme and Camacaro, Jaime R. and Bessega, Carolina",inproceedings,10.1145/3240323.3240380,
10.1145/3240323.3240384,10.1145/3240323.3240384,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","benchmarking, evaluation, news recommendation",5,269–273,Proceedings of the 12th ACM Conference on Recommender Systems,"News is one of the earliest application domains of recommender systems, and recommending items from a virtually endless stream of news is still a relevant problem today. News recommendation is different from other application domains in a variety of ways, e.g., because new items constantly become available for recommendation. To be effective, news recommenders therefore have to continuously consider the latest items in the incoming stream of news in their recommendation models. However, today's public software libraries for algorithm benchmarking mostly do not consider these particularities of the domain. As a result, authors often rely on proprietary protocols, which hampers the comparability of the obtained results. In this paper, we present StreamingRec as a framework for evaluating streaming-based news recommenders in a replicable way. The open-source framework implements a replay-based evaluation protocol that allows algorithms to update the underlying models in real-time when new events are recorded and new articles are available for recommendation. Furthermore, a variety of baseline algorithms for session-based recommendation are part of StreamingRec. For these, we also report a number of performance results for two datasets, which confirm the importance of immediate model updates.",10.1145/3240323.3240384,https://doi.org/10.1145/3240323.3240384,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Streamingrec: a framework for benchmarking stream-based news recommenders,"Jugovac, Michael and Jannach, Dietmar and Karimi, Mozhgan",inproceedings,10.1145/3240323.3240384,
10.1145/3240323.3240390,10.1145/3240323.3240390,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","matrix factorization, recommender systems, social network",5,397–401,Proceedings of the 12th ACM Conference on Recommender Systems,"Data sparsity and cold start are two major problems of collaborative filtering based recommender systems. In many modern Internet applications, we have a social network over the users of recommender systems, from which social information can be utilized to improve the accuracy of recommendation. In this paper, we propose a novel trust-based matrix factorization model. Unlike most existing social recommender systems which use social information in the form of a regularizer on parameters of recommendation algorithms, we utilize the social information to densify the training data set by filling certain missing values (handle the data sparsity problem). In addition, by employing different pseudo rating generating criteria on cold start users and normal users, we can also partially solve the cold start problem effectively. Experiment results on real-world data sets demonstrated the superiority of our method over state-of-art approaches.",10.1145/3240323.3240390,https://doi.org/10.1145/3240323.3240390,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Psrec: social recommendation with pseudo ratings,"Meng, Yitong and Chen, Guangyong and Li, Jiajin and Zhang, Shengyu",inproceedings,10.1145/3240323.3240390,
10.1145/3240323.3240402,10.1145/3240323.3240402,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","collaborative filtering, graph kernel, matrix factorization, projected user and item graph, recommendation",4,437–440,Proceedings of the 12th ACM Conference on Recommender Systems,"Matrix Factorization (MF) techniques have already shown its strong foundation in collaborative filtering (CF), particularly for rating prediction problem. In the basic MF model, the use of additional information such as social network, item tags along with rating has become popular and effective, which results in making the model more complex. However, there are very few studies in recent years, which only use the users rating information for the recommendation. In this paper, we present a new finding on exploiting Projected User and Item Graph in the setting of Kernelized Probabilistic Matrix Factorization (KPMF), which uses different graph kernels from the projected graphs. KPMF works with its latent vector spanning over all users (and items) with Gaussian process priors and tries to capture the covariance structure across users and items from their respective projected graphs. We also explore the ways of building these projected graphs to maximize the prediction accuracy. We implement the model in five real-world datasets and achieve significant performance improvement in terms of RMSE with state-of-the-art MF techniques.",10.1145/3240323.3240402,https://doi.org/10.1145/3240323.3240402,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Kernelized probabilistic matrix factorization for collaborative filtering: exploiting projected user and item graph,"Pal, Bithika and Jenamani, Mamata",inproceedings,10.1145/3240323.3240402,
10.1145/3240323.3240405,10.1145/3240323.3240405,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","adults with autism, game recommendation, social interaction",5,209–213,Proceedings of the 12th ACM Conference on Recommender Systems,"Games play a significant role in modern society, since they affect people of all ages and all walks of life, whether it be socially or mentally, and have direct impacts on adults with autism. Autism spectrum disorders (ASD) are a collection of neurodevelopmental disorders characterized by qualitative impairments in social relatedness and interaction, as well as difficulties in acquiring and using communication and language abilities. Adults with ASD often find it difficult to express and recognize emotions which makes it hard for them to interact with others socially. We have designed new interactive and collaborative games for autistic adults and developed a novel strategy to recommend games to them. Using modern computer vision and graphics techniques, we (i) track the player's speech rate, facial features, eye contact, audio communication, and emotional states, and (ii) foster their collaboration. These games are personalized and recommended to a user based on games interested to the user, besides the complexity of games at different levels according to the deficient level of the emotional understanding and social skills to which the user belongs. The objective of developing and recommending short-head (i.e., familiar) and long-tail (i.e., unfamiliar) games for adults with ASD is to enhance their social interacting skills with peers so that they can live a better life.",10.1145/3240323.3240405,https://doi.org/10.1145/3240323.3240405,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Recommending social-interactive games for adults with autism spectrum disorders (ASD),"Ng, Yiu-Kai and Pera, Maria Soledad",inproceedings,10.1145/3240323.3240405,
10.1145/3240323.3240406,10.1145/3240323.3240406,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","collaborative filtering, recommender systems",4,451–454,Proceedings of the 12th ACM Conference on Recommender Systems,"The two main tasks in the Recommender Systems domain are the ranking and rating prediction tasks. The rating prediction task aims at predicting to what extent a user would like any given item, which would enable to recommend the items with the highest predicted scores. The ranking task on the other hand directly aims at recommending the most valuable items for the user. Several previous approaches proposed learning user and item representations to optimize both tasks simultaneously in a multi-task framework. In this work we propose a novel multi-task framework that exploits the fact that a user does a two-phase decision process - first decides to interact with an item (ranking task) and only afterward to rate it (rating prediction task).We evaluated our framework on two benchmark datasets, on two different configurations and showed its superiority over state-of-the-art methods.",10.1145/3240323.3240406,https://doi.org/10.1145/3240323.3240406,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Rank and rate: multi-task learning for recommender systems,"Hadash, Guy and Shalom, Oren Sar and Osadchy, Rita",inproceedings,10.1145/3240323.3240406,
10.1145/3240323.3240407,10.1145/3240323.3240407,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","visual features, user-study, recommender systems, offline evaluation, multimedia, movies, audio features",5,455–459,Proceedings of the 12th ACM Conference on Recommender Systems,"We propose a multi-modal content-based movie recommender system that replaces human-generated metadata with content descriptions automatically extracted from the visual and audio channels of a video. Content descriptors improve over traditional metadata in terms of both richness (it is possible to extract hundreds of meaningful features covering various modalities) and quality (content features are consistent across different systems and immune to human errors). Our recommender system integrates state-of-the-art aesthetic and deep visual features as well as block-level and i-vector audio features. For fusing the different modalities, we propose a rank aggregation strategy extending the Borda count approach.We evaluate the proposed multi-modal recommender system comprehensively against metadata-based baselines. To this end, we conduct two empirical studies: (i) a system-centric study to measure the offline quality of recommendations in terms of accuracy-related and beyond-accuracy performance measures (novelty, diversity, and coverage), and (ii) a user-centric online experiment, measuring different subjective metrics, including relevance, satisfaction, and diversity. In both studies, we use a dataset of more than 4,000 movie trailers, which makes our approach versatile. Our results shed light on the accuracy and beyond-accuracy performance of audio, visual, and textual features in content-based movie recommender systems.",10.1145/3240323.3240407,https://doi.org/10.1145/3240323.3240407,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Audio-visual encoding of multimedia content for enhancing movie recommendations,"Deldjoo, Yashar and Constantin, Mihai Gabriel and Eghbal-Zadeh, Hamid and Ionescu, Bogdan and Schedl, Markus and Cremonesi, Paolo",inproceedings,10.1145/3240323.3240407,
10.1145/3240323.3240412,10.1145/3240323.3240412,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","collaborative filtering, deep learning, multi-criteria ratings, stacked autoencoders",5,475–479,Proceedings of the 12th ACM Conference on Recommender Systems,"Recommender System (RS) is an essential component of many businesses, especially in e-commerce domain. RS exploits the preference history (rating, purchase, review, etc.) of users in order to provide the recommendations. A user in traditional RS can provide only one rating value about an item. Deep Neural Networks have been used in this single rating system to improve recommendation accuracy in the recent times. However, the single rating systems are inadequate to understand the usersfi preferences about an item. On the other hand, business enterprises such as tourism, e-learning, etc. facilitate users to provide multiple criteria ratings about an item, thus it becomes easier to understand users' preference over single rating system. In this paper, we propose an extended Stacked Autoencoders (a Deep Neural Network technique) to utilize the multi-criteria ratings. The proposed network is designed to learn the relationship between each user's criteria and overall rating efficiently. Experimental results on real world datasets (Yahoo! Movies and TripAdvisor) demonstrate that the proposed approach outperforms state-of-the-art single rating systems and multi-criteria approaches on various performance metrics.",10.1145/3240323.3240412,https://doi.org/10.1145/3240323.3240412,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,User preference learning in multi-criteria recommendations using stacked auto encoders,"Tallapally, Dharahas and Sreepada, Rama Syamala and Patra, Bidyut Kr. and Babu, Korra Sathya",inproceedings,10.1145/3240323.3240412,
10.1145/3240323.3241592,10.1145/3240323.3241592,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","factorization methods, hadoop, hive, spark, top-k item recommendation",2,502–503,Proceedings of the 12th ACM Conference on Recommender Systems,"This study demonstrates a way to build large-scale recommender systems by just writing a series of SQL-like queries. In order to efficiently run recommendation logics on a cluster of computers, we implemented a variety of recommendation algorithms and common recommendation functions (e.g., efficient similarity computation, top-k retrieval, and evaluation measures) asHive user-defined functions (UDFs) in Apache Hivemall. We demonstrate that how Apache Hivemall can easily be used for building a scalable recommendation system with satisfying business requirements such as scalability, latency, and stability.",10.1145/3240323.3241592,https://doi.org/10.1145/3240323.3241592,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Query-based simple and scalable recommender systems with apache hivemall,"Kitazawa, Takuya and Yui, Makoto",inproceedings,10.1145/3240323.3241592,
10.1145/3240323.3241611,10.1145/3240323.3241611,RecSys.bib,1,['RecSys.bib'],8,RecSys '18,"Vancouver, British Columbia, Canada","framework, python, recommender systems",2,494–495,Proceedings of the 12th ACM Conference on Recommender Systems,"This paper presents a polished open-source Python-based recommender framework named Case Recommender, which provides a rich set of components from which developers can construct and evaluate customized recommender systems. It implements well-known and state-of-the-art algorithms in rating prediction and item recommendation scenarios. The main advantage of the Case Recommender is the possibility to integrate clustering and ensemble algorithms with recommendation engines, easing the development of more accurate and efficient approaches.",10.1145/3240323.3241611,https://doi.org/10.1145/3240323.3241611,"New York, NY, USA",Association for Computing Machinery,9781450359016,2018,Case recommender: a flexible and extensible python framework for recommender systems,"da Costa, Arthur and Fressato, Eduardo and Neto, Fernando and Manzato, Marcelo and Campello, Ricardo",inproceedings,10.1145/3240323.3241611,
10.1145/3269206.3269258,10.1145/3269206.3269258,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","word-driven, recommendation, cnns",4,1859–1862,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Recently, convolutional neural networks(CNNs) has been demonstrated to effectively model reviews in recommender systems, due to the learning of contextual features such as surrounding words and word order for reviews. However, CNNs with max-pooling fails to capture the count information of contextual features, since the feature map generated by a convolution filter can only get a max feature value with max-pooling. If the max feature value appears more than once in the feature map, CNNs will lose the count information of the contextual feature. The count information is quite critical for modeling reviews, for example, ten ""a good quality"" is more credible than one ""a good quality"" for representing item properties, and five ""the scenery is"" shows that a user may pay more attention to the scenery than one ""the scenery is"" does. Our model, called WCN-MF, extends CNNs by introducing a new module named Deep Latent Dirichlet Allocation (DLDA) to capture the count information of contextual features. DLDA is inspired by the fact that contextual features consist of words, hence, we can first capture the count information of words, and second generate contextual features with words. By combining DLDA with CNNs, we can get a word-driven and context-aware review representation. Further, we incorporate the review representation with Matrix Factorization for recommendation. Our evaluations on three real- world datasets reveal that our model can significantly outperform the state-of-the-art recommendation models.",10.1145/3269206.3269258,https://doi.org/10.1145/3269206.3269258,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Word-Driven and Context-Aware Review Modeling for Recommendation,"Wang, Qianqian and Li, Si and Chen, Guang",inproceedings,10.1145/3269206.3269258,
10.1145/3269206.3269264,10.1145/3269206.3269264,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","recommender systems, neural collaborative filtering, long-tail phenomenon, adversarial learning",4,1491–1494,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"In recent times, deep neural networks have found success in Collaborative Filtering (CF) based recommendation tasks. By parametrizing latent factor interactions of users and items with neural architectures, they achieve significant gains in scalability and performance over matrix factorization. However, the long-tail phenomenon in recommender performance persists on the massive inventories of online media or retail platforms. Given the diversity of neural architectures and applications, there is a need to develop a generalizable and principled strategy to enhance long-tail item coverage.In this paper, we propose a novel adversarial training strategy to enhance long-tail recommendations for users with Neural CF (NCF) models. The adversary network learns the implicit association structure of entities in the feedback data while the NCF model is simultaneously trained to reproduce these associations and avoid the adversarial penalty, resulting in enhanced long-tail performance. Experimental results show that even without auxiliary data, adversarial training can boost long-tail recall of state-of-the-art NCF models by up to 25%, without trading-off overall performance. We evaluate our approach on two diverse platforms, content tag recommendation in Q&amp;A forums and movie recommendation.",10.1145/3269206.3269264,https://doi.org/10.1145/3269206.3269264,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,An Adversarial Approach to Improve Long-Tail Performance in Neural Collaborative Filtering,"Krishnan, Adit and Sharma, Ashish and Sankar, Aravind and Sundaram, Hari",inproceedings,10.1145/3269206.3269264,
10.1145/3269206.3269307,10.1145/3269206.3269307,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","news recommendation, convolutional neural networks",4,1855–1858,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"An effective news recommendation system should harness the historical information of the user based on her interactions as well as the content of the articles. In this paper we propose a novel deep learning model for news recommendation which utilizes the content of the news articles as well as the sequence in which the articles were read by the user. To model both of these information, which are essentially of different types, we propose a simple yet effective architecture which utilizes a 3-dimensional Convolutional Neural Network which takes the word embeddings of the articles present in the user history as its input. Using such a method endows the model with the capability to automatically learn spatial (features of a particular article) as well as temporal features (features across articles read by a user) which signify the interest of the user. At test time, we use this in combination with a 2-dimensional Convolutional Neural Network for recommending articles to users. On a real-world dataset our method outperformed strong baselines which also model the news recommendation problem using neural networks.",10.1145/3269206.3269307,https://doi.org/10.1145/3269206.3269307,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Weave&amp;Rec: A Word Embedding based 3-D Convolutional Network for News Recommendation,"Khattar, Dhruv and Kumar, Vaibhav and Varma, Vasudeva and Gupta, Manish",inproceedings,10.1145/3269206.3269307,
10.1145/3269206.3269311,10.1145/3269206.3269311,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","recurrent neural networks, news recommendation, matrix factorization",4,1619–1622,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Popular methods for news recommendation which are based on collaborative filtering and content-based filtering have multiple drawbacks. The former method does not account for the sequential nature of news reading and suffers from the problem of cold-start, while the latter, suffers from over-specialization. In order to address these issues for news recommendation we propose a Hybrid Recurrent Attention Machine (HRAM). HRAM consists of two components. The first component utilizes a neural network for matrix factorization. While in the second component, we first learn the distributed representation of each news article. We then use the historical data of the user in a sequential manner and feed it to an attention-based recurrent layer. Finally, we concatenate the outputs from both these components and use further hidden layers in order to make predictions. In this way, we harness the information present in the user reading history and boost it with the information available through collaborative filtering for providing better news recommendations. Extensive experiments over two real-world datasets show that the proposed model provides significant improvement over the state-of-the-art.",10.1145/3269206.3269311,https://doi.org/10.1145/3269206.3269311,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,HRAM: A Hybrid Recurrent Attention Machine for News Recommendation,"Khattar, Dhruv and Kumar, Vaibhav and Varma, Vasudeva and Gupta, Manish",inproceedings,10.1145/3269206.3269311,
10.1145/3269206.3271677,10.1145/3269206.3271677,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","multi-touch attribution, deep learning, conversion attribution, computational advertising, attention mechanism",10,1433–1442,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"In online advertising, the Internet users may be exposed to a sequence of different ad campaigns, i.e., display ads, search, or referrals from multiple channels, before led up to any final sales conversion and transaction. For both campaigners and publishers, it is fundamentally critical to estimate the contribution from ad campaign touch-points during the customer journey (conversion funnel) and assign the right credit to the right ad exposure accordingly. However, the existing research on the multi-touch attribution problem lacks a principled way of utilizing the users' pre-conversion actions (i.e., clicks), and quite often fails to model the sequential patterns among the touch points from a user's behavior data. To make it worse, the current industry practice is merely employing a set of arbitrary rules as the attribution model, e.g., the popular last-touch model assigns 100% credit to the final touch-point regardless of actual attributions. In this paper, we propose a Dual-attention Recurrent Neural Network (DARNN) for the multi-touch attribution problem. It learns the attribution values through an attention mechanism directly from the conversion estimation objective. To achieve this, we utilize sequence-to-sequence prediction for user clicks, and combine both post-view and post-click attribution patterns together for the final conversion estimation. To quantitatively benchmark attribution models, we also propose a novel yet practical attribution evaluation scheme through the proxy of budget allocation (under the estimated attributions) over ad channels. The experimental results on two real datasets demonstrate the significant performance gains of our attribution model against the state of the art.",10.1145/3269206.3271677,https://doi.org/10.1145/3269206.3271677,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Learning Multi-touch Conversion Attribution with Dual-attention Mechanisms for Online Advertising,"Ren, Kan and Fang, Yuchen and Zhang, Weinan and Liu, Shuhao and Li, Jiajun and Zhang, Ya and Yu, Yong and Wang, Jun",inproceedings,10.1145/3269206.3271677,
10.1145/3269206.3271695,10.1145/3269206.3271695,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","user reviews, recommender system, rating prediction, deep learning",10,677–686,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Review-based methods are one of the dominant methods to address the data sparsity problem of recommender system. However, the performance of most existing review-based methods will degrade when the review is also sparse. To this end, we propose a method to exploit user-item p air-dependent features from a uxiliary r eviews written by l ike-minded users (PARL) to address such problem. That is, both the reviews written by the user and the reviews written for the item are incorporated to highlight the useful features covered by the auxiliary reviews. PARL not only alleviates the sparsity problem of reviews but also produce extra informative features to further improve the accuracy of rating prediction. More importantly, it is designed as a plug-and-play model which can be plugged into various deep recommender systems to improve recommendations provided by them. Extensive experiments on five real-world datasets show that PARL achieves better prediction accuracy than other state-of-the-art alternatives. Also, with the exploitation of auxiliary reviews, the performance of PARL is robust on datasets with different characteristics.",10.1145/3269206.3271695,https://doi.org/10.1145/3269206.3271695,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,PARL: Let Strangers Speak Out What You Like,"Wu, Libing and Quan, Cong and Li, Chenliang and Ji, Donghong",inproceedings,10.1145/3269206.3271695,
10.1145/3269206.3271710,10.1145/3269206.3271710,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","neural recommendation model, hybrid recommendation, collaborative filtering, cold-start, cold sampling, attention mechanism",10,127–136,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Nowadays, recommender systems provide essential web services on the Internet. There are mainly two categories of traditional recommendation algorithms: Content-Based (CB) and Collaborative Filtering (CF). CF methods make recommendations mainly according to the historical feedback information. They usually perform better when there is sufficient feedback information but less successful on new users and items, which is called the ""cold-start'' problem. However, CB methods help in this scenario because of using content information. To take both advantages of CF and CB, how to combine them is a challenging issue. To the best of our knowledge, little previous work has been done to solve the problem in one unified recommendation model. In this work, we study how to integrate CF and CB, which utilizes both types of information in model-level but not in result-level and makes recommendations adaptively. A novel attention-based model named Attentional Content&amp;Collaborate Model (ACCM) is proposed. Attention mechanism helps adaptively adjust for each user-item pair from which source information the recommendation is made. Especially, a ""cold sampling'' learning strategy is designed to handle the cold-start problem. Experimental results on two benchmark datasets show that the ACCM performs better on both warm and cold tests compared to the state-of-the-art algorithms.",10.1145/3269206.3271710,https://doi.org/10.1145/3269206.3271710,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Attention-based Adaptive Model to Unify Warm and Cold Starts Recommendation,"Shi, Shaoyun and Zhang, Min and Liu, Yiqun and Ma, Shaoping",inproceedings,10.1145/3269206.3271710,
10.1145/3269206.3271714,10.1145/3269206.3271714,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","popularity prediction, point process, feature driven, event sequence, adversarial model",10,517–526,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"This paper targets a general popularity prediction problem for event sequence, which has recently gained great attention due to its extensive applications in various domains. Feature driven method and point process method are two basic thinking paradigms to tackle the prediction problem, but both of them suffer from limitations. In this paper, we propose PreNets unifying the two thinking paradigms in an adversarial manner. On one side, feature driven model acts like a 'critic' who aims to discriminate the predicted popularity from the real one based on a set of temporal features from the sequence. On the other side, point process model acts like an 'interpreter' who recognizes the dynamic patterns in sequence to generate a predicted popularity that can fool the 'critic'. Through a Wasserstein learning based two-player game, the training loss of the 'critic' guides the 'interpreter' to better exploit the sequence patterns and enhance prediction, while the 'interpreter' pushes the 'critic' to select effective early features that helps discrimination. This mechanism enables the framework to absorb the advantages of both feature driven and point process methods. Empirical results show that PreNets achieves significant MAPE improvement for both Twitter cascade and Amazon review prediction.",10.1145/3269206.3271714,https://doi.org/10.1145/3269206.3271714,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Adversarial Training Model Unifying Feature Driven and Point Process Perspectives for Event Popularity Prediction,"Wu, Qitian and Yang, Chaoqi and Zhang, Hengrui and Gao, Xiaofeng and Weng, Paul and Chen, Guihai",inproceedings,10.1145/3269206.3271714,
10.1145/3269206.3271715,10.1145/3269206.3271715,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","recommender systems, pairwise ranking, neural networks",10,1353–1362,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Recommender systems are aimed at generating a personalized ranked list of items that an end user might be interested in. With the unprecedented success of deep learning in computer vision and speech recognition, recently it has been a hot topic to bridge the gap between recommender systems and deep neural network. And deep learning methods have been shown to achieve state-of-the-art on many recommendation tasks. For example, a recent model, NeuMF, first projects users and items into some shared low-dimensional latent feature space, and then employs neural nets to model the interaction between the user and item latent features to obtain state-of-the-art performance on the recommendation tasks. NeuMF assumes that the non-interacted items are inherent negative and uses negative sampling to relax this assumption. In this paper, we examine an alternative approach which does not assume that the non-interacted items are necessarily negative, just that they are less preferred than interacted items. Specifically, we develop a new classification strategy based on the widely used pairwise ranking assumption. We combine our classification strategy with the recently proposed neural collaborative filtering framework, and propose a general collaborative ranking framework called Neural Network based Collaborative Ranking (NCR). We resort to a neural network architecture to model a user's pairwise preference between items, with the belief that neural network will effectively capture the latent structure of latent factors. The experimental results on two real-world datasets show the superior performance of our models in comparison with several state-of-the-art approaches.",10.1145/3269206.3271715,https://doi.org/10.1145/3269206.3271715,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Neural Collaborative Ranking,"Song, Bo and Yang, Xin and Cao, Yi and Xu, Congfu",inproceedings,10.1145/3269206.3271715,
10.1145/3269206.3271726,10.1145/3269206.3271726,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","temporal point processes, product competition",10,537–546,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Accurate modeling of how the visibility of a piece of information varies across time has a wide variety of applications. For example, in an e-commerce site like Amazon, it can help to identify which product is preferred over others; in Twitter, it can predict which hashtag may go viral against others. Visibility of a piece of information, therefore, indicates the ability of a piece of information to attract the attention of the users, against the rest. Therefore, apart from the individual information diffusion processes, the information visibility dynamics also involves a competition process, where each information diffusion process competes against each other to draw the attention of users. Despite models of individual information diffusion processes abounding in literature, modeling the competition process is left unaddressed. In this paper, we propose Competing Recurrent Point Process (CRPP), a probabilistic deep machinery that unifies the nonlinear generative dynamics of a collection of diffusion processes, and inter-process competition - the two ingredients of visibility dynamics. To design this model, we rely on a recurrent neural network (RNN) guided generative framework, where the recurrent unit captures the joint temporal dynamics of a group of processes. This is aided by a discriminative model which captures the underlying competition process by discriminating among the various processes using several ranking functions. On ten diverse datasets crawled from Amazon and Twitter, CRPP offers a substantial performance boost in predicting item visibility against several baselines, thereby achieving significant accuracy in predicting both the collective diffusion mechanism and the underlying competition processes.",10.1145/3269206.3271726,https://doi.org/10.1145/3269206.3271726,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,CRPP: Competing Recurrent Point Process for Modeling Visibility Dynamics in Information Diffusion,"Saha, Avirup and Samanta, Bidisha and Ganguly, Niloy and De, Abir",inproceedings,10.1145/3269206.3271726,
10.1145/3269206.3271730,10.1145/3269206.3271730,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","user embeddings, recommendation, negative sampling, item embeddings, collaborative filtering",10,687–696,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Following recent successes in exploiting both latent factor and word embedding models in recommendation, we propose a novel Regularized Multi-Embedding (RME) based recommendation model that simultaneously encapsulates the following ideas via decomposition: (1) which items a user likes, (2) which two users co-like the same items, (3) which two items users often co-liked, and (4) which two items users often co-disliked. In experimental validation, the RME outperforms competing state-of-the-art models in both explicit and implicit feedback datasets, significantly improving Recall@5 by 5.9~7.0%, NDCG@20 by 4.3~5.6%, and MAP@10 by 7.9~8.9%. In addition, under the cold-start scenario for users with the lowest number of interactions, against the competing models, the RME outperforms NDCG@5 by 20.2% and 29.4% in MovieLens-10M and MovieLens-20M datasets, respectively. Our datasets and source code are available at: https://github.com/thanhdtran/RME.git.",10.1145/3269206.3271730,https://doi.org/10.1145/3269206.3271730,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Regularizing Matrix Factorization with User and Item Embeddings for Recommendation,"Tran, Thanh and Lee, Kyumin and Liao, Yiming and Lee, Dongwon",inproceedings,10.1145/3269206.3271730,
10.1145/3269206.3271739,10.1145/3269206.3271739,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","recommender systems, preference propagation, knowledge graph",10,417–426,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"To address the sparsity and cold start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve recommendation performance. This paper considers the knowledge graph as the source of side information. To address the limitations of existing embedding-based and path-based methods for knowledge-graph-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the knowledge graph into recommender systems. Similar to actual ripples propagating on the water, RippleNet stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user's potential interests along links in the knowledge graph. The multiple ""ripples"" activated by a user's historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item, which could be used for predicting the final clicking probability. Through extensive experiments on real-world datasets, we demonstrate that RippleNet achieves substantial gains in a variety of scenarios, including movie, book and news recommendation, over several state-of-the-art baselines.",10.1145/3269206.3271739,https://doi.org/10.1145/3269206.3271739,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems,"Wang, Hongwei and Zhang, Fuzheng and Wang, Jialin and Zhao, Miao and Li, Wenjie and Xie, Xing and Guo, Minyi",inproceedings,10.1145/3269206.3271739,
10.1145/3269206.3271742,10.1145/3269206.3271742,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","social recommendation, implicit feedback, graphic model, exposure",10,953–962,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Users' consumption behaviors are affected by both their personal preference and their exposure to items (i.e. whether a user knows the items).Most of the recent works in social recommendation assume that people share similar preference with their socially connected friends. However, this assumption may not hold due to the diversity of social relations, and modeling social influence on users' preference may not be suitable for implicit feedback data (i.e. whether a user has consumed certain items). Since users often share item information with their social relations, it will be less restrictive to model social influence on users' exposure to items. We notice that a user's exposure is affected by the exposure of the other users in his social communities and by the consumption of his connected friends. In this paper, we propose a novel social exposure-based recommendation model SoEXBMF by integrating two kinds of social influence on users' exposure, i.e. social knowledge influence and social consumption influence, into basic EXMF model for better recommendation performance. Furthermore, SoEXBMF uses Bernoulli distribution instead of Gaussian distribution in EXMF to better model the binary implicit feedback data. A variational inference method has been developed for the proposed SoEXBMF model to infer the posterior and make the recommendations. Extensive experiments on three real-world datasets demonstrate the superiority of our method over existing methods in various evaluation metrics.",10.1145/3269206.3271742,https://doi.org/10.1145/3269206.3271742,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Modeling Users' Exposure with Social Knowledge Influence and Consumption Influence for Recommendation,"Chen, Jiawei and Feng, Yan and Ester, Martin and Zhou, Sheng and Chen, Chun and Wang, Can",inproceedings,10.1145/3269206.3271742,
10.1145/3269206.3271743,10.1145/3269206.3271743,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","top-n recommendation, implicit feedback, generative adversarial networks, collaborative filtering",10,137–146,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Generative Adversarial Networks (GAN) have achieved big success in various domains such as image generation, music generation, and natural language generation. In this paper, we propose a novel GAN-based collaborative filtering (CF) framework to provide higher accuracy in recommendation. We first identify a fundamental problem of existing GAN-based methods in CF and highlight it quantitatively via a series of experiments. Next, we suggest a new direction of vector-wise adversarial training to solve the problem and propose our GAN-based CF framework, called CFGAN, based on the direction. We identify a unique challenge that arises when vector-wise adversarial training is employed in CF. We then propose three CF methods realized on top of our CFGAN that are able to address the challenge. Finally, via extensive experiments on real-world datasets, we validate that vector-wise adversarial training employed in CFGAN is really effective to solve the problem of existing GAN-based CF methods. Furthermore, we demonstrate that our proposed CF methods on CFGAN provide recommendation accuracy consistently and universally higher than those of the state-of-the-art recommenders.",10.1145/3269206.3271743,https://doi.org/10.1145/3269206.3271743,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks,"Chae, Dong-Kyu and Kang, Jin-Soo and Kim, Sang-Wook and Lee, Jung-Tae",inproceedings,10.1145/3269206.3271743,
10.1145/3269206.3271759,10.1145/3269206.3271759,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","recommendation, neural network, meta path, heterogeneous information network, attention mechanism",10,833–842,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Heterogeneous Information Network(HIN) has been employed in recommender system to represent heterogeneous types of data, and meta path has been proposed to capture semantic relationship among objects. When applying HIN to the recommendation, there are two problems: how to extract features from meta paths and how to properly fuse these features to further improve recommendations. Some recent work has employed deep neural network to learn user and item representation, and attention mechanism has been explored to integrate information for recommendation. Inspired by these work, in this paper, we propose Heterogeneous Neural Attentive Factorization Machine(HNAFM) to solve above problems. Specifically, we first calculate the commuting matrices based on meta paths and use multilayer perceptrons to learn user and item features. A hierarchical attention mechanism is employed to find the meta path that best describes user's preference and item's property. Comprehensive experiments based on real-world datasets demonstrate that the proposed HNAFM significantly outperforms state-of-the-art rating prediction methods.",10.1145/3269206.3271759,https://doi.org/10.1145/3269206.3271759,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Heterogeneous Neural Attentive Factorization Machine for Rating Prediction,"Chen, Liang and Liu, Yang and Zheng, Zibin and Yu, Philip",inproceedings,10.1145/3269206.3271759,
10.1145/3269206.3271776,10.1145/3269206.3271776,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","product search, personalized agent, memory networks, dialog systems, conversational search, conversational recommendation",10,177–186,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Conversational search and recommendation based on user-system dialogs exhibit major differences from conventional search and recommendation tasks in that 1) the user and system can interact for multiple semantically coherent rounds on a task through natural language dialog, and 2) it becomes possible for the system to understand the user needs or to help users clarify their needs by asking appropriate questions from the users directly. We believe the ability to ask questions so as to actively clarify the user needs is one of the most important advantages of conversational search and recommendation. In this paper, we propose and evaluate a unified conversational search/recommendation framework, in an attempt to make the research problem doable under a standard formalization. Specifically, we propose a System Ask -- User Respond (SAUR) paradigm for conversational search, define the major components of the paradigm, and design a unified implementation of the framework for product search and recommendation in e-commerce. To accomplish this, we propose the Multi-Memory Network (MMN) architecture, which can be trained based on large-scale collections of user reviews in e-commerce. The system is capable of asking aspect-based questions in the right order so as to understand the user needs, while (personalized) search is conducted during the conversation, and results are provided when the system feels confident. Experiments on real-world user purchasing data verified the advantages of conversational search and recommendation against conventional search and recommendation algorithms in terms of standard evaluation measures such as NDCG.",10.1145/3269206.3271776,https://doi.org/10.1145/3269206.3271776,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,"Towards Conversational Search and Recommendation: System Ask, User Respond","Zhang, Yongfeng and Chen, Xu and Ai, Qingyao and Yang, Liu and Croft, W. Bruce",inproceedings,10.1145/3269206.3271776,
10.1145/3269206.3271785,10.1145/3269206.3271785,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","recommendation, personalized ranking, multi-objective learning, collaborative ranking",10,1363–1372,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"This paper proposes to jointly resolve row-wise and column-wise ranking problems when an explicit rating matrix is given. The row-wise ranking problem, also known as personalized ranking, aims to build user-specific models such that the correct order of items (in terms of user preference) is most accurately predicted and then items on the top of ranked list will be recommended to a specific user, while column-wise ranking aims to build item-specific models focusing on targeting users who are most interested in the specific item (for example, for distributing coupons to customers). In recommender systems, ranking-based collaborative filtering (known as collaborative ranking (CR)) algorithms are designed to solve the aforementioned ranking problems. The key part of CR algorithms is to learn effective user and item latent factors which are combined to decide user preference scores over items. In this paper, we demonstrate that by individually solving row-wise or column-wise ranking problems using typical CR algorithms is only able to learn one set of effective (user or item) latent factors. Therefore, we propose to jointly solve row-wise and column-wise ranking problems through a parameter sharing framework which optimizes three objectives together: to accurately predict rating scores, to satisfy the user-specific order constraints on all the rated items, and to satisfy the item-specific order constraints. Our extensive experimental results on popular datasets confirm significant performance gains of our proposed method over state-of-the-art CR approaches in both of row-wise and column-wise ranking tasks.",10.1145/3269206.3271785,https://doi.org/10.1145/3269206.3271785,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Collaborative Multi-objective Ranking,"Hu, Jun and Li, Ping",inproceedings,10.1145/3269206.3271785,
10.1145/3269206.3271786,10.1145/3269206.3271786,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","representation learning, recommender system, grocery shopping, consumer behavior",10,1133–1142,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"We study the problem of representing and recommending products for grocery shopping. We carefully investigate grocery transaction data and observe three important patterns: products within the same basket complement each other in terms of functionality (complementarity); users tend to purchase products that match their preferences (compatibility); and a significant fraction of users repeatedly purchase the same products over time (loyalty). Unlike conventional e-commerce settings, complementarity and loyalty are particularly predominant in the grocery shopping domain. This motivates a new representation learning approach to leverage complementarity and compatibility holistically, as well as a new recommendation approach to explicitly account for users' 'must-buy' purchases in addition to their overall preferences and needs. Doing so not only improves product classification and recommendation performance on both public and proprietary transaction data covering various grocery store types, but also reveals interesting findings about the relationships between preferences, necessity, and loyalty in consumer purchases.",10.1145/3269206.3271786,https://doi.org/10.1145/3269206.3271786,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,"Representing and Recommending Shopping Baskets with Complementarity, Compatibility and Loyalty","Wan, Mengting and Wang, Di and Liu, Jie and Bennett, Paul and McAuley, Julian",inproceedings,10.1145/3269206.3271786,
10.1145/3269206.3271792,10.1145/3269206.3271792,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","next-item recommendation, item relationships",10,1143–1152,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Recommender Systems have proliferated as general-purpose approaches to model a wide variety of consumer interaction data. Specific instances make use of signals ranging from user feedback, item relationships, geographic locality, social influence (etc.). Typically, research proceeds by showing that making use of a specific signal (within a carefully designed model) allows for higher-fidelity recommendations on a particular dataset. Of course, the real situation is more nuanced, in which a combination of many signals may be at play, or favored in different proportion by individual users. Here we seek to develop a framework that is capable of combining such heterogeneous item relationships by simultaneously modeling (a) what modality of recommendation is a user likely to be susceptible to at a particular point in time; and (b) what is the best recommendation from each modality. Our method borrows ideas from mixtures-of-experts approaches as well as knowledge graph embeddings. We find that our approach naturally yields more accurate recommendations than alternatives, while also providing intuitive 'explanations' behind the recommendations it provides.",10.1145/3269206.3271792,https://doi.org/10.1145/3269206.3271792,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Recommendation Through Mixtures of Heterogeneous Item Relationships,"Kang, Wang-Cheng and Wan, Mengting and McAuley, Julian",inproceedings,10.1145/3269206.3271792,
10.1145/3269206.3271810,10.1145/3269206.3271810,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","recommender systems, neural attention, co-attention, aspect-based recommendation",10,147–156,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Textual reviews, which are readily available on many e-commerce and review websites such as Amazon and Yelp, serve as an invaluable source of information for recommender systems. However, not all parts of the reviews are equally important, and the same choice of words may reflect a different meaning based on its context. In this paper, we propose a novel end-to-end Aspect-based Neural Recommender (ANR) to perform aspect-based representation learning for both users and items via an attention-based component. Furthermore, we model the multi-faceted process behind how users rate items by estimating the aspect-level user and item importance by adapting the neural co-attention mechanism. Our proposed model concurrently address several shortcomings of existing recommender systems, and a thorough experimental study on 25 benchmark datasets from Amazon and Yelp shows that ANR significantly outperforms recently proposed state-of-the-art baselines such as DeepCoNN, D-Attn and ALFM.",10.1145/3269206.3271810,https://doi.org/10.1145/3269206.3271810,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,ANR: Aspect-based Neural Recommender,"Chin, Jin Yao and Zhao, Kaiqi and Joty, Shafiq and Cong, Gao",inproceedings,10.1145/3269206.3271810,
10.1145/3269206.3271813,10.1145/3269206.3271813,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","interaction networks, explainable recommendations, context-aware recommendations",10,157–166,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Context-aware Recommendations (CARS) have attracted a lot of attention recently because of the impact of contextual information on user behaviors. Recent state-of-the-art methods represent the relations between users/items and contexts as a tensor, with which it is difficult to distinguish the impacts of different contextual factors and to model complex, non-linear interactions between contexts and users/items. In this paper, we propose a novel neural model, named Attentive Interaction Network (AIN), to enhance CARS through adaptively capturing the interactions between contexts and users/items. Specifically, AIN contains an Interaction-Centric Module to capture the interaction effects of contexts on users/items; a User-Centric Module and an Item-Centric Module to model respectively how the interaction effects influence the user and item representations. The user and item representations under interaction effects are combined to predict the recommendation scores. We further employ effect-level attention mechanism to aggregate multiple interaction effects. Extensive experiments on two rating datasets and one ranking dataset show that the proposed AIN outperforms state-of-the-art CARS methods. In addition, we also find that AIN provides recommendations with better explanation ability with respect to contexts than the existing approaches.",10.1145/3269206.3271813,https://doi.org/10.1145/3269206.3271813,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,An Attentive Interaction Network for Context-aware Recommendations,"Mei, Lei and Ren, Pengjie and Chen, Zhumin and Nie, Liqiang and Ma, Jun and Nie, Jian-Yun",inproceedings,10.1145/3269206.3271813,
10.1145/3269206.3272009,10.1145/3269206.3272009,CIKM.bib,1,['CIKM.bib'],8,CIKM '18,"Torino, Italy","recommendation, matrix factorization, iot rule recommendation, internet of things",9,2037–2045,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"With over 34 billion IoT devices to be installed by 2020, the Internet of Things (IoT) is fundamentally changing our lives. One of the greatest benefits of the IoT is the powerful automations achieved by applying rules to IoT devices. For instance, a rule named ""Make me a cup of coffee when I wake up'' automatically turns on the coffee machine when the sensor in the bedroom detects motion in the morning. With large numbers of possible rules out there, a recommendation system is of great necessity to help users find rules they need. However, little effort has been made to design a model tailored for the IoT rule recommendation, which comes with lots of new challenges compared with traditional recommendation tasks. We not only need to re-define ""users'' and ""items'' in the recommendation task, but also have to consider a new type of entities, devices, and the extra information and constraints brought by them. To handle these challenges, we propose a novel efficient recommendation algorithm, which not only considers the implicit feedback of users on rules, but also takes user-rule-device interactions and the match between rule device requirements and user device possessions into account. In collaboration with Samsung, one of the leading companies in this field, we have designed an IoT rule recommendation framework and evaluated our algorithm on a real-life industry dataset. Experiments show the effectiveness and efficiency of our method.",10.1145/3269206.3272009,https://doi.org/10.1145/3269206.3272009,"New York, NY, USA",Association for Computing Machinery,9781450360142,2018,Device-Aware Rule Recommendation for the Internet of Things,"Wang, Beidou and Guo, Xin and Ester, Martin and Guan, Ziyu and Singh, Bandeep and Zhu, Yu and Bu, Jiajun and Cai, Deng",inproceedings,10.1145/3269206.3272009,
10.1145/3289600.3290977,10.1145/3289600.3290977,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","attention mechanism, autoencoders, content-aware recommendation",9,519–527,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"The rapid growth of Internet services and mobile devices provides an excellent opportunity to satisfy the strong demand for the personalized item or product recommendation. However, with the tremendous increase of users and items, personalized recommender systems still face several challenging problems: (1) the hardness of exploiting sparse implicit feedback; (2) the difficulty of combining heterogeneous data. To cope with these challenges, we propose a gated attentive-autoencoder (GATE) model, which is capable of learning fused hidden representations of items' contents and binary ratings, through a neural gating structure. Based on the fused representations, our model exploits neighboring relations between items to help infer users' preferences. In particular, a word-level and a neighbor-level attention module are integrated with the autoencoder. The word-level attention learns the item hidden representations from items' word sequences, while favoring informative words by assigning larger attention weights. The neighbor-level attention learns the hidden representation of an item's neighborhood by considering its neighbors in a weighted manner. We extensively evaluate our model with several state-of-the-art methods and different validation metrics on four real-world datasets. The experimental results not only demonstrate the effectiveness of our model on top-N recommendation but also provide interpretable results attributed to the attention modules.",10.1145/3289600.3290977,https://doi.org/10.1145/3289600.3290977,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Gated Attentive-Autoencoder for Content-Aware Recommendation,"Ma, Chen and Kang, Peng and Wu, Bin and Wang, Qinglong and Liu, Xue",inproceedings,10.1145/3289600.3290977,
10.1145/3289600.3290982,10.1145/3289600.3290982,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","attention, collaborative filtering, memory networks, recommender systems, social connections",9,177–185,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"Social connections are known to be helpful for modeling users' potential preferences and improving the performance of recommender systems. However, in social-aware recommendations, there are two issues which influence the inference of users' preferences, and haven't been well-studied in most existing methods: First, the preferences of a user may only partially match that of his friends in certain aspects, especially when considering a user with diverse interests. Second, for an individual, the influence strength of his friends might be different, as not all friends are equally helpful for modeling his preferences in the system. To address the above issues, in this paper, we propose a novel Social Attentional Memory Network (SAMN) for social-aware recommendation. Specifically, we first design an attention-based memory module to learn user-friend relation vectors, which can capture the varying aspect attentions that a user share with his different friends. Then we build a friend-level attention component to adaptively select informative friends for user modeling. The two components are fused together to mutually enhance each other and lead to a finer extended model. Experimental results on three publicly available datasets show that the proposed SAMN model consistently and significantly outperforms the state-of-the-art recommendation methods. Furthermore, qualitative studies have been made to explore what the proposed attention-based memory module and friend-level attention have learnt, which provide insights into the model's learning process.",10.1145/3289600.3290982,https://doi.org/10.1145/3289600.3290982,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Social Attentional Memory Network: Modeling Aspect- and Friend-Level Differences in Recommendation,"Chen, Chong and Zhang, Min and Liu, Yiqun and Ma, Shaoping",inproceedings,10.1145/3289600.3290982,
10.1145/3289600.3290993,10.1145/3289600.3290993,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","content modeling, podcast, popularity prediction, spoken word",9,276–284,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"Recent years have witnessed the flourishing of podcasts, a unique type of audio medium. Prior work on podcast content modeling focused on analyzing Automatic Speech Recognition outputs, which ignored vocal, musical, and conversational properties (e.g., energy, humor, and creativity) that uniquely characterize this medium. In this paper, we present an Adversarial Learning-based Podcast Representation (ALPR) that captures non-textual aspects of podcasts. Through extensive experiments on a large-scale podcast dataset (88,728 episodes from 18,433 channels), we show that (1) ALPR significantly outperforms the state-of-the-art features developed for music and speech in predicting theseriousness andenergy of podcasts, and (2) incorporating ALPR significantly improves the performance of topic-based podcast-popularity prediction. Our experiments also reveal factors that correlate with podcast popularity.",10.1145/3289600.3290993,https://doi.org/10.1145/3289600.3290993,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,More Than Just Words: Modeling Non-Textual Characteristics of Podcasts,"Yang, Longqi and Wang, Yu and Dunne, Drew and Sobolev, Michael and Naaman, Mor and Estrin, Deborah",inproceedings,10.1145/3289600.3290993,
10.1145/3289600.3290998,10.1145/3289600.3290998,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","deep learning, temporal interaction learning, tensor factorization",9,537–545,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"Neural collaborative filtering (NCF) and recurrent recommender systems (RRN) have been successful in modeling relational data (user-item interactions). However, they are also limited in their assumption of static or sequential modeling of relational data as they do not account for evolving users' preference over time as well as changes in the underlying factors that drive the change in user-item relationship over time. We address these limitations by proposing a Neural network based Tensor Factorization (NTF) model for predictive tasks on dynamic relational data. The NTF model generalizes conventional tensor factorization from two perspectives: First, it leverages the long short-term memory architecture to characterize the multi-dimensional temporal interactions on relational data. Second, it incorporates the multi-layer perceptron structure for learning the non-linearities between different latent factors. Our extensive experiments demonstrate the significant improvement in both the rating prediction and link prediction tasks on various dynamic relational data by our NTF model over both neural network based factorization models and other traditional methods.",10.1145/3289600.3290998,https://doi.org/10.1145/3289600.3290998,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Neural Tensor Factorization for Temporal Interaction Learning,"Wu, Xian and Shi, Baoxu and Dong, Yuxiao and Huang, Chao and Chawla, Nitesh V.",inproceedings,10.1145/3289600.3290998,
10.1145/3289600.3291019,10.1145/3289600.3291019,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","domain switch, multi-domain user behavior, recurrent neural network, sequence modeling",9,663–671,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"Understanding user behavior and predicting future behavior on the web is critical for providing seamless user experiences as well as increasing revenue of service providers. Recently, thanks to the remarkable success of recurrent neural networks (RNNs), it has been widely used for modeling sequences of user behaviors. However, although sequential behaviors appear across multiple domains in practice, existing RNN-based approaches still focus on the single-domain scenario assuming that sequential behaviors come from only a single domain. Hence, in order to analyze sequential behaviors across multiple domains, they require to separately train multiple RNN models, which fails to jointly model the interplay among sequential behaviors across multiple domains. Consequently, they often suffer from lack of information within each domain. In this paper, we first introduce a practical but overlooked phenomenon in sequential behaviors across multiple domains, i.e.,domain switch where two successive behaviors belong to different domains. Then, we propose aDomain Switch-Aware Holistic Recurrent Neural Network (DS-HRNN) that effectively shares the knowledge extracted from multiple domains by systematically handlingdomain switch for the multi-domain scenario. DS-HRNN jointly models the multi-domain sequential behaviors and accurately predicts the future behaviors in each domain with only a single RNN model. Our extensive evaluations on two real-world datasets demonstrate that DCHRNN outperforms existing RNN-based approaches and non-sequential baselines with significant improvements by up to 14.93% in terms of recall of the future behavior prediction.",10.1145/3289600.3291019,https://doi.org/10.1145/3289600.3291019,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Domain Switch-Aware Holistic Recurrent Neural Network for Modeling Multi-Domain User Behavior,"Kim, Donghyun and Kim, Sungchul and Zhao, Handong and Li, Sheng and Rossi, Ryan A. and Koh, Eunyee",inproceedings,10.1145/3289600.3291019,
10.1145/3289600.3291021,10.1145/3289600.3291021,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","cross-cultural analysis, log analysis, motivation, multi-language, survey, wikipedia",9,618–626,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"As one of the Web's primary multilingual knowledge sources, Wikipedia is read by millions of people across the globe every day. Despite this global readership, little is known about why users read Wikipedia's various language editions. To bridge this gap, we conduct a comparative study by combining a large-scale survey of Wikipedia readers across 14 language editions with a log-based analysis of user activity. We proceed in three steps. First, we analyze the survey results to compare the prevalence of Wikipedia use cases across languages, discovering commonalities, but also substantial differences, among Wikipedia languages with respect to their usage. Second, we match survey responses to the respondents' traces in Wikipedia's server logs to characterize behavioral patterns associated with specific use cases, finding that distinctive patterns consistently mark certain use cases across language editions. Third, we show that certain Wikipedia use cases are more common in countries with certain socio-economic characteristics; e.g., in-depth reading of Wikipedia articles is substantially more common in countries with a low Human Development Index. These findings advance our understanding of reader motivations and behaviors across Wikipedia languages and have implications for Wikipedia editors and developers of Wikipedia and other Web technologies.",10.1145/3289600.3291021,https://doi.org/10.1145/3289600.3291021,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Why the World Reads Wikipedia: Beyond English Speakers,"Lemmerich, Florian and S\'{a}ez-Trumper, Diego and West, Robert and Zia, Leila",inproceedings,10.1145/3289600.3291021,
10.1145/3289600.3291022,10.1145/3289600.3291022,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","aspect modeling, correlated topic model, review mining",9,609–617,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"A user-generated review document is a product between the item's intrinsic properties and the user's perceived composition of those properties. Without properly modeling and decoupling these two factors, one can hardly obtain any accurate user understanding nor item profiling from such user-generated data. In this paper, we study a new text mining problem that aims at differentiating a user's subjective composition of topical content in his/her review document from the entity's intrinsic properties. Motivated by the Item Response Theory (IRT), we model each review document as a user's detailed response to an item, and assume the response is jointly determined by the individuality of the user and the property of the item. We model the text-based response with a generative topic model, in which we characterize the items' properties and users' manifestations of them in a low-dimensional topic space. Via posterior inference, we separate and study these two components over a collection of review documents. Extensive experiments on two large collections of Amazon and Yelp review data verified the effectiveness of the proposed solution: it outperforms the state-of-art topic models with better predictive power in unseen documents, which is directly translated into improved performance in item recommendation and item summarization tasks.",10.1145/3289600.3291022,https://doi.org/10.1145/3289600.3291022,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Learning Personalized Topical Compositions with Item Response Theory,"Lin, Lu and Gong, Lin and Wang, Hongning",inproceedings,10.1145/3289600.3291022,
10.1145/3289600.3291024,10.1145/3289600.3291024,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","local coherence, neural networks, recommendation",9,564–572,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"We propose a new time-dependent predictive model of user-item ratings centered around local coherence -- that is, while both users and items are constantly in flux, within a short-term sequence, the neighborhood of a particular user or item is likely to be coherent. Three unique characteristics of the framework are: (i) it incorporates both implicit and explicit feedbacks by extracting the local coherence hidden in the feedback sequences; (ii) it uses parallel recurrent neural networks to capture the evolution of users and items, resulting in a dual factor recommendation model; and (iii) it combines both coherence-enhanced consistent latent factors and dynamic latent factors to balance short-term changes with long-term trends for improved recommendation. Through experiments on Goodreads and Amazon, we find that the proposed model can outperform state-of-the-art models in predicting users' preferences.",10.1145/3289600.3291024,https://doi.org/10.1145/3289600.3291024,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Recurrent Recommendation with Local Coherence,"Wang, Jianling and Caverlee, James",inproceedings,10.1145/3289600.3291024,
10.1145/3289600.3291598,10.1145/3289600.3291598,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","hawkes processes, information diffusion, recurrent neural networks",2,810–811,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"Understanding and predicting the popularity of online items is an important open problem in social media analysis. Most of the recent work on popularity prediction is either based on learning a variety of features from full network data or using generative processes to model the event time data. We identify two gaps in the current state of the art prediction models. The first is the unexplored connection and comparison between the two aforementioned approaches. In our work, we bridge gap between feature-driven and generative models by modelling social cascade with a marked Hawkes self-exciting point process. We then learn a predictive layer on top for popularity prediction using a collection of cascade history. Secondly, the existing methods typically focus on a single source of external influence, whereas for many types of online content such as YouTube videos or news articles, attention is driven by multiple heterogeneous sources simultaneously - e.g. microblogs or traditional media coverage. We propose a recurrent neural network based model for asynchronous streams that connects multiple streams of different granularity via joint inference. We further design two new measures, one to explain the viral potential of videos, the other to uncover latent influences including seasonal trends. This work provides accurate and explainable popularity predictions, as well as computational tools for content producers and marketers to allocate resources for promotion campaigns.",10.1145/3289600.3291598,https://doi.org/10.1145/3289600.3291598,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Bridging Models for Popularity Prediction on Social Media,"Mishra, Swapnil",inproceedings,10.1145/3289600.3291598,
10.1145/3289600.3291601,10.1145/3289600.3291601,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","epidemic models, hawkes processes, information diffusion",2,818–819,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"Epidemic models and Hawkes point process models are two common model classes for information diffusion. Recent work has revealed the equivalence between the two for information diffusion modeling. This allows tools created for one class of models to be applied to another. However, epidemic models and Hawkes point processes can be connected in more ways. This thesis aims to develop a rich set of mathematical equivalences and extensions, and use them to ask and answer questions in social media and beyond. Specifically, we show our plan of generalizing the equivalence of the two model classes by extending it to Hawkes point process models with arbitrary memory kernels. We then outline a rich set of quantities describing diffusion, including diffusion size and extinction probability, introduced in the fields where the models are originally designed. Lastly, we discuss some novel applications of these quantities in a range of problems such as popularity prediction and popularity intervention.",10.1145/3289600.3291601,https://doi.org/10.1145/3289600.3291601,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Linking Epidemic Models and Hawkes Point Processes for Modeling Information Diffusion,"Kong, Quyu",inproceedings,10.1145/3289600.3291601,
10.1145/3289600.3291604,10.1145/3289600.3291604,WSDM.bib,1,['WSDM.bib'],8,WSDM '19,"Melbourne VIC, Australia","conversational, preference elicitation, recommender system",2,824–825,Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,"Traditionally, recommenders have been based on a single-shot model based on past user actions. Conversational recommenders allow incremental elicitation of user preference by performing user-system dialogue. For example, the systems can ask about user preference toward a feature associated with the items. In such systems, it is important to design an efficient conversation, which minimizes the number of question asked while maximizing the preference information obtained. Therefore, this research is intended to explore possible ways to design a conversational recommender with an efficient preference elicitation. Specifically, it focuses on the order of questions. Also, an idea proposed to suggest answers for each question asked, which can assist users in giving their feedback.",10.1145/3289600.3291604,https://doi.org/10.1145/3289600.3291604,"New York, NY, USA",Association for Computing Machinery,9781450359405,2019,Preference Elicitation Strategy for Conversational Recommender System,"Priyogi, Bilih",inproceedings,10.1145/3289600.3291604,
10.1145/3292500.3330715,10.1145/3292500.3330715,KDD.bib,1,['KDD.bib'],8,KDD '19,"Anchorage, AK, USA","internal cross-promotion, internal promotion, machine learning, optimization",9,2358–2366,Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Most large Internet companies run internal promotions to cross-promote their different products and/or to educate members on how to obtain additional value from the products that they already use. This in turn drives engagement and/or revenue for the company. However, since these internal promotions can distract a member away from the product or page where these are shown, there is a non-zero cannibalization loss incurred for showing these internal promotions. This loss has to be carefully weighed against the gain from showing internal promotions. This can be a complex problem if different internal promotions optimize for different objectives. In that case, it is difficult to compare not just the gain from a conversion through an internal promotion against the loss incurred for showing that internal promotion, but also the gains from conversions through different internal promotions. Hence, we need a principled approach for deciding which internal promotion (if any) to serve to a member in each opportunity to serve an internal promotion. This approach should optimize not just for the net gain to the company, but also for the member's experience. In this paper, we discuss our approach for optimization of internal promotions at LinkedIn. In particular, we present a cost-benefit analysis of showing internal promotions, our formulation of internal promotion optimization as a constrained optimization problem, the architecture of the system for solving the optimization problem and serving internal promotions in real-time, and experimental results from online A/B tests.",10.1145/3292500.3330715,https://doi.org/10.1145/3292500.3330715,"New York, NY, USA",Association for Computing Machinery,9781450362016,2019,Internal Promotion Optimization,"Gupta, Rupesh and Chen, Guangde and Yu, Shipeng",inproceedings,10.1145/3292500.3330715,
10.1145/3292500.3330750,10.1145/3292500.3330750,KDD.bib,1,['KDD.bib'],8,KDD '19,"Anchorage, AK, USA","action graph, app usage pattern, graph neural network, time-series model, user engagement prediction",9,2023–2031,Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"While mobile social apps have become increasingly important in people's daily life, we have limited understanding on what motivates users to engage with these apps. In this paper, we answer the question whether users' in-app activity patterns help inform their future app engagement (e.g., active days in a future time window)? Previous studies on predicting user app engagement mainly focus on various macroscopic features (e.g., time-series of activity frequency), while ignoring fine-grained inter-dependencies between different in-app actions at the microscopic level. Here we propose to formalize individual user's in-app action transition patterns as a temporally evolving action graph, and analyze its characteristics in terms of informing future user engagement. Our analysis suggested that action graphs are able to characterize user behavior patterns and inform future engagement. We derive a number of high-order graph features to capture in-app usage patterns and construct interpretable models for predicting trends of engagement changes and active rates. To further enhance predictive power, we design an end-to-end, multi-channel neural model to encode both temporal action graphs, activity sequences, and other macroscopic features. Experiments on predicting user engagement for 150k Snapchat new users over a 28-day period demonstrate the effectiveness of the proposed prediction models. The analysis and prediction framework is also deployed at Snapchat to deliver real world business insights. Our proposed framework is also general and can be applied to any online platform.",10.1145/3292500.3330750,https://doi.org/10.1145/3292500.3330750,"New York, NY, USA",Association for Computing Machinery,9781450362016,2019,Characterizing and Forecasting User Engagement with In-App Action Graph: A Case Study of Snapchat,"Liu, Yozen and Shi, Xiaolin and Pierce, Lucas and Ren, Xiang",inproceedings,10.1145/3292500.3330750,
10.1145/3292500.3330764,10.1145/3292500.3330764,KDD.bib,1,['KDD.bib'],8,KDD '19,"Anchorage, AK, USA","content creation optimization, feed ranking, machine learning, recommendation system, social network",10,2241–2250,Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Social media platforms bring together content creators and content consumers through recommender systems like newsfeed. The focus of such recommender systems has thus far been primarily on modeling the content consumer preferences and optimizing for their experience. However, it is equally critical to nurture content creation by prioritizing the creators' interests, as quality content forms the seed for sustainable engagement and conversations, bringing in new consumers while retaining existing ones. In this work, we propose a modeling approach to predict how feedback from content consumers incentivizes creators. We then leverage this model to optimize the newsfeed experience for content creators by reshaping the feedback distribution, leading to a more active content ecosystem. Practically, we discuss how we balance the user experience for both consumers and creators, and how we carry out online A/B tests with strong network effects. We present a deployed use case on the LinkedIn newsfeed, where we used this approach to improve content creation significantly without compromising the consumers' experience.",10.1145/3292500.3330764,https://doi.org/10.1145/3292500.3330764,"New York, NY, USA",Association for Computing Machinery,9781450362016,2019,Feedback Shaping: A Modeling Approach to Nurture Content Creation,"Tu, Ye and Lo, Chun and Yuan, Yiping and Chatterjee, Shaunak",inproceedings,10.1145/3292500.3330764,
10.1145/3292500.3330873,10.1145/3292500.3330873,KDD.bib,1,['KDD.bib'],8,KDD '19,"Anchorage, AK, USA","adversarial training, collaborative filtering, data sparsit",9,548–556,Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Collaborative filtering (CF) has become one of the most popular and widely used methods in recommender systems, but its performance degrades sharply for users with rare interaction data. Most existing hybrid CF methods try to incorporate side information such as review texts to alleviate the data sparsity problem. However, the process of exploiting and integrating side information is computationally expensive. Existing hybrid recommendation methods treat each user equally and ignore that the pure CF methods have already achieved both effective and efficient recommendation performance for active users with sufficient interaction records and the little improvement brought by side information to these active users is ignorable. Therefore, they are not cost-effective solutions. One cost-effective idea to bypass this dilemma is to generate sufficient ""real"" interaction data for the inactive users with the help of side information, and then a pure CF method could be performed on this augmented dataset effectively. However, there are three major challenges to implement this idea. Firstly, how to ensure the correctness of the generated interaction data. Secondly, how to combine the data augmentation process and recommendation process into a unified model and train the model end-to-end. Thirdly, how to make the solution generalizable for various side information and recommendation tasks. In light of these challenges, we propose a generic and effective CF model called AugCF that supports a wide variety of recommendation tasks. AugCF is based on Conditional Generative Adversarial Nets that additionally consider the class (like or dislike) as a feature to generate new interaction data, which can be a sufficiently real augmentation to the original dataset. Also, AugCF adopts a novel discriminator loss and Gumbel-Softmax approximation to enable end-to-end training. Finally, extensive experiments are conducted on two large-scale recommendation datasets, and the experimental results show the superiority of our proposed model.",10.1145/3292500.3330873,https://doi.org/10.1145/3292500.3330873,"New York, NY, USA",Association for Computing Machinery,9781450362016,2019,Enhancing Collaborative Filtering with Generative Augmentation,"Wang, Qinyong and Yin, Hongzhi and Wang, Hao and Nguyen, Quoc Viet Hung and Huang, Zi and Cui, Lizhen",inproceedings,10.1145/3292500.3330873,
10.1145/3292500.3330880,10.1145/3292500.3330880,KDD.bib,1,['KDD.bib'],8,KDD '19,"Anchorage, AK, USA","matrix factorization, regularization hyperparameter, top-k recommendation",9,978–986,Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Recommendation models mainly deal with categorical variables, such as user/item ID and attributes. Besides the high-cardinality issue, the interactions among such categorical variables are usually long-tailed, with the head made up of highly frequent values and a long tail of rare ones. This phenomenon results in the data sparsity issue, making it essential to regularize the models to ensure generalization. The common practice is to employ grid search to manually tune regularization hyperparameters based on the validation data. However, it requires non-trivial efforts and large computation resources to search the whole candidate space; even so, it may not lead to the optimal choice, for which different parameters should have different regularization strengths. In this paper, we propose a hyperparameter optimization method, lambdaOpt, which automatically and adaptively enforces regularization during training. Specifically, it updates the regularization coefficients based on the performance of validation data. With lambdaOpt, the notorious tuning of regularization hyperparameters can be avoided; more importantly, it allows fine-grained regularization (i.e. each parameter can have an individualized regularization coefficient), leading to better generalized models. We show how to employ lambdaOpt on matrix factorization, a classical model that is representative of a large family of recommender models. Extensive experiments on two public benchmarks demonstrate the superiority of our method in boosting the performance of top-K recommendation.",10.1145/3292500.3330880,https://doi.org/10.1145/3292500.3330880,"New York, NY, USA",Association for Computing Machinery,9781450362016,2019,λOpt: Learn to Regularize Recommender Models in Finer Levels,"Chen, Yihong and Chen, Bei and He, Xiangnan and Gao, Chen and Li, Yong and Lou, Jian-Guang and Wang, Yue",inproceedings,10.1145/3292500.3330880,
10.1145/3292500.3330906,10.1145/3292500.3330906,KDD.bib,1,['KDD.bib'],8,KDD '19,"Anchorage, AK, USA","attention mechanism, neural factorization machines, neural network, rating prediction, recommender systems",9,344–352,Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Despite the great success of many matrix factorization based collaborative filtering approaches, there is still much space for improvement in recommender system field. One main obstacle is the cold-start and data sparseness problem, requiring better solutions. Recent studies have attempted to integrate review information into rating prediction. However, there are two main problems: (1) most of existing works utilize a static and independent method to extract the latent feature representation of user and item reviews ignoring the correlation between the latent features, which may fail to capture the preference of users comprehensively. (2) there is no effective framework that unifies ratings and reviews. Therefore, we propose a novel d ual a ttention m utual l earning between ratings and reviews for item recommendation, named DAML. Specifically, we utilize local and mutual attention of the convolutional neural network to jointly learn the features of reviews to enhance the interpretability of the proposed DAML model. Then the rating features and review features are integrated into a unified neural network model, and the higher-order nonlinear interaction of features are realized by the neural factorization machines to complete the final rating prediction. Experiments on the five real-world datasets show that DAML achieves significantly better rating prediction accuracy compared to the state-of-the-art methods. Furthermore, the attention mechanism can highlight the relevant information in reviews to increase the interpretability of rating prediction.",10.1145/3292500.3330906,https://doi.org/10.1145/3292500.3330906,"New York, NY, USA",Association for Computing Machinery,9781450362016,2019,DAML: Dual Attention Mutual Learning between Ratings and Reviews for Item Recommendation,"Liu, Donghua and Li, Jing and Du, Bo and Chang, Jun and Gao, Rong",inproceedings,10.1145/3292500.3330906,
10.1145/3292500.3330928,10.1145/3292500.3330928,KDD.bib,1,['KDD.bib'],8,KDD '19,"Anchorage, AK, USA","data mining, healthcare informatics, personalized model",11,1258–1268,Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"In contrast to the one-size-fits-all approach to medicine, precision medicine will allow targeted prescriptions based on the specific profile of the patient thereby avoiding adverse reactions and ineffective but expensive treatments. Longitudinal observational data such as Electronic Health Records (EHRs) have become an emerging data source for personalized medicine. In this paper, we propose a unified computational framework, called PerDREP, to predict the unique response patterns of each individual patient from EHR data. PerDREP models individual responses of each patient to the drug exposure by introducing a linear system to account for patients' heterogeneity, and incorporates a patient similarity graph as a network regularization. We formulate PerDREP as a convex optimization problem and develop an iterative gradient descent method to solve it. In the experiments, we identify the effect of drugs on Glycated hemoglobin test results. The experimental results provide evidence that the proposed method is not only more accurate than state-of-the-art methods, but is also able to automatically cluster patients into multiple coherent groups, thus paving the way for personalized medicine.",10.1145/3292500.3330928,https://doi.org/10.1145/3292500.3330928,"New York, NY, USA",Association for Computing Machinery,9781450362016,2019,PerDREP: Personalized Drug Effectiveness Prediction from Longitudinal Observational Data,"Dey, Sanjoy and Zhang, Ping and Sow, Daby and Ng, Kenney",inproceedings,10.1145/3292500.3330928,
10.1145/3292500.3330952,10.1145/3292500.3330952,KDD.bib,1,['KDD.bib'],8,KDD '19,"Anchorage, AK, USA","basket completion, determinantal point process, tensor",11,1605–1615,Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Interest in determinantal point processes (DPPs) is increasing in machine learning due to their ability to provide an elegant parametric model over combinatorial sets. In particular, the number of required parameters in a DPP grows only quadratically with the size of the ground set (e.g., item catalog), while the number of possible sets of items grows exponentially. Recent work has shown that DPPs can be effective models for product recommendation and basket completion tasks, since they are able to account for both the diversity and quality of items within a set. We present an enhanced DPP model that is specialized for the task of basket completion, the tensorized DPP. We leverage ideas from tensor factorization in order to customize the model for the next-item basket completion task, where the next item is captured in an extra dimension of the model. We evaluate our model on several real-world datasets, and find that the tensorized DPP provides significantly better predictive quality in several settings than a number of state-of-the art models.",10.1145/3292500.3330952,https://doi.org/10.1145/3292500.3330952,"New York, NY, USA",Association for Computing Machinery,9781450362016,2019,Tensorized Determinantal Point Processes for Recommendation,"Warlop, Romain and Mary, J\'{e}r\'{e}mie and Gartrell, Mike",inproceedings,10.1145/3292500.3330952,
10.1145/3292500.3330959,10.1145/3292500.3330959,KDD.bib,1,['KDD.bib'],8,KDD '19,"Anchorage, AK, USA","information dissemination, semi-supervised learning, sequential prediction model, sequential recommendation",11,447–457,Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Sequential recommendation and information dissemination are two traditional problems for sequential information retrieval. The common goal of the two problems is to predict future user-item interactions based on past observed interactions. The difference is that the former deals with users' histories of clicked items, while the latter focuses on items' histories of infected users.In this paper, we take a fresh view and propose dual sequential prediction models that unify these two thinking paradigms. One user-centered model takes a user's historical sequence of interactions as input, captures the user's dynamic states, and approximates the conditional probability of the next interaction for a given item based on the user's past clicking logs. By contrast, one item-centered model leverages an item's history, captures the item's dynamic states, and approximates the conditional probability of the next interaction for a given user based on the item's past infection records. To take advantage of the dual information, we design a new training mechanism which lets the two models play a game with each other and use the predicted score from the opponent to design a feedback signal to guide the training. We show that the dual models can better distinguish false negative samples and true negative samples compared with single sequential recommendation or information dissemination models. Experiments on four real-world datasets demonstrate the superiority of proposed model over some strong baselines as well as the effectiveness of dual training mechanism between two models.",10.1145/3292500.3330959,https://doi.org/10.1145/3292500.3330959,"New York, NY, USA",Association for Computing Machinery,9781450362016,2019,Dual Sequential Prediction Models Linking Sequential Recommendation and Information Dissemination,"Wu, Qitian and Gao, Yirui and Gao, Xiaofeng and Weng, Paul and Chen, Guihai",inproceedings,10.1145/3292500.3330959,
10.1145/3298689.3346950,10.1145/3298689.3346950,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","context-aware systems, interactional context, preference evolution, sequence-aware systems",5,591–595,Proceedings of the 13th ACM Conference on Recommender Systems,"Customer decision making process is not invariant. Actual circumstances have a great influence on user's preference adjustments, therefore an absence of incorporating contextual information leads to sub-optimal prediction performance. A popular approach in recommender systems is to treat a context as a set of identifiable and observable attributes while assuming their full separability from an activity. In contrast, we believe that the context emerges from the activity and its change can be perceived and possibly predicted by using mined patterns of its evolution on multiple levels, starting at individual sessions. This paper presents concepts, ideas and motivation for our PhD research project.",10.1145/3298689.3346950,https://doi.org/10.1145/3298689.3346950,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,User's activity driven short-term context inference,"Rac, Miroslav",inproceedings,10.1145/3298689.3346950,
10.1145/3298689.3346957,10.1145/3298689.3346957,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","bidirectional encoder representations from transformer (BERT), convolutional neural networks (CNN), deep learning, embedding, generative adversarial networks (GAN), knowledge graph, long short-term memory (LSTM), multi-task learning, recommender system, recurrent neural networks (RNN)",2,584–585,Proceedings of the 13th ACM Conference on Recommender Systems,"Deep Learning has shown significant results in Computer Vision, Natural Language Processing, Speech and recommender systems. Promising techniques include Embedding, Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN) and its variant Long Short-Term Memory (LSTM and Bi-directional LSTMs), Attention, Autoencoders, Generative Adversarial Networks (GAN) and Bidirectional Encoder Representations from Transformer (BERT).Multi-task learning (MTL) has led to successes in many applications of machine learning. We are proposing a tutorial for applying MTL for recommendation, improving recommendation and providing explanation. We cover few recent and diverse techniques which will be used for hands-on session.We believe that a self-contained tutorial giving good conceptual understanding of MTL technique with sufficient mathematical background along with actual code will be of immense help to RecSys participants.",10.1145/3298689.3346957,https://doi.org/10.1145/3298689.3346957,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Concept to code: deep learning for multitask recommendation,"Sonie, Omprakash",inproceedings,10.1145/3298689.3346957,
10.1145/3298689.3346993,10.1145/3298689.3346993,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","ranking, combination, RFDSA",8,12–19,Proceedings of the 13th ACM Conference on Recommender Systems,"As a task of high importance for recommender systems, we consider the problem of learning the convex combination of ranking algorithms by online machine learning. In the case of two base rankers, we show that the exponentially weighted combination achieves near optimal performance. However, the number of required points to be evaluated may be prohibitive with more base models in a real application. We propose a gradient based stochastic optimization algorithm that uses finite differences. Our new algorithm achieves similar empirical performance for two base rankers, while scaling well with an increased number of models. In our experiments with five real-world recommendation data sets, we show that the combination offers significant improvement over previously known stochastic optimization techniques. Our algorithm is the first effective stochastic optimization method for combining ranked recommendation lists by online machine learning.",10.1145/3298689.3346993,https://doi.org/10.1145/3298689.3346993,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Online ranking combination,"Frig\'{o}, Erzs\'{e}bet and Kocsis, Levente",inproceedings,10.1145/3298689.3346993,
10.1145/3298689.3346999,10.1145/3298689.3346999,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","collaborative filtering, graph embedding, non-linear factorization machines, recommender systems",8,314–321,Proceedings of the 13th ACM Conference on Recommender Systems,"In very sparse recommender data sets, attributes of users such as age, gender and home location and attributes of items such as, in the case of movies, genre, release year, and director can improve the recommendation accuracy, especially for users and items that have few ratings. While most recommendation models can be extended to take attributes of users and items into account, their architectures usually become more complicated. While attributes for items are often easy to be provided, attributes for users are often scarce for reasons of privacy or simply because they are not relevant to the operational process at hand. In this paper, we address these two problems for attribute-aware recommender systems by proposing a simple model that co-embeds users and items into a joint latent space in a similar way as a vanilla matrix factorization, but with non-linear latent features construction that seamlessly can ingest user or item attributes or both (GraphRec). To address the second problem, scarce attributes, the proposed model treats the user-item relation as a bipartite graph and constructs generic user and item attributes via the Laplacian of the user-item co-occurrence graph that requires no further external side information but the mere rating matrix. In experiments on three recommender datasets, we show that GraphRec significantly outperforms existing state-of-the-art attribute-aware and content-aware recommender systems even without using any side information.",10.1145/3298689.3346999,https://doi.org/10.1145/3298689.3346999,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Attribute-aware non-linear co-embeddings of graph features,"Rashed, Ahmed and Grabocka, Josif and Schmidt-Thieme, Lars",inproceedings,10.1145/3298689.3346999,
10.1145/3298689.3347009,10.1145/3298689.3347009,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","conversational recommendation, critiquing, deep learning",9,137–145,Proceedings of the 13th ACM Conference on Recommender Systems,"Critiquing is a method for conversational recommendation that adapts recommendations in response to user preference feedback regarding item attributes. Historical critiquing methods were largely based on constraint- and utility-based methods for modifying recommendations w.r.t. these critiqued attributes. In this paper, we revisit the critiquing approach from the lens of deep learning based recommendation methods and language-based interaction. Concretely, we propose an end-to-end deep learning framework with two variants that extend the Neural Collaborative Filtering architecture with explanation and critiquing components. These architectures not only predict personalized keyphrases for a user and item but also embed language-based feedback in the latent space that in turn modulates subsequent critiqued recommendations. We evaluate the proposed framework on two recommendation datasets containing user reviews. Empirical results show that our modified NCF approach not only provides a strong baseline recommender and high-quality personalized item keyphrase suggestions, but that it also properly suppresses items predicted to have a critiqued keyphrase. In summary, this paper provides a first step to unify deep recommendation and language-based feedback in what we hope to be a rich space for future research in deep critiquing for conversational recommendation.",10.1145/3298689.3347009,https://doi.org/10.1145/3298689.3347009,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Deep language-based critiquing for recommender systems,"Wu, Ga and Luo, Kai and Sanner, Scott and Soh, Harold",inproceedings,10.1145/3298689.3347009,
10.1145/3298689.3347010,10.1145/3298689.3347010,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","discriminative power, parameter tuning, recommender systems",5,447–451,Proceedings of the 13th ACM Conference on Recommender Systems,"Hyper-parameters tuning is a crucial task to make a model perform at its best. However, despite the well-established methodologies, some aspects of the tuning remain unexplored. As an example, it may affect not just accuracy but also novelty as well as it may depend on the adopted dataset. Moreover, sometimes it could be sufficient to concentrate on a single parameter only (or a few of them) instead of their overall set. In this paper we report on our investigation on hyper-parameters tuning by performing an extensive 10-Folds Cross-Validation on MovieLens and Amazon Movies for three well-known baselines: User-kNN, Item-kNN, BPR-MF. We adopted a grid search strategy considering approximately 15 values for each parameter, and we then evaluated each combination of parameters in terms of accuracy and novelty. We investigated the discriminative power of nDCG, Precision, Recall, MRR, EFD, EPC, and, finally, we analyzed the role of parameters on model evaluation for Cross-Validation.",10.1145/3298689.3347010,https://doi.org/10.1145/3298689.3347010,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,On the discriminative power of hyper-parameters in cross-validation and how to choose them,"Anelli, Vito Walter and Di Noia, Tommaso and Di Sciascio, Eugenio and Pomo, Claudio and Ragone, Azzurra",inproceedings,10.1145/3298689.3347010,
10.1145/3298689.3347011,10.1145/3298689.3347011,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","neural networks, random walk, recommender systems, recurrent neural network, social network, social recommendation",9,305–313,Proceedings of the 13th ACM Conference on Recommender Systems,"Recommender systems are crucial to alleviate the information overload problem in online worlds. Most of the modern recommender systems capture users' preference towards items via their interactions based on collaborative filtering techniques. In addition to the user-item interactions, social networks can also provide useful information to understand users' preference as suggested by the social theories such as homophily and influence. Recently, deep neural networks have been utilized for social recommendations, which facilitate both the user-item interactions and the social network information. However, most of these models cannot take full advantage of the social network information. They only use information from direct neighbors, but distant neighbors can also provide helpful information. Meanwhile, most of these models treat neighbors' information equally without considering the specific recommendations. However, for a specific recommendation case, the information relevant to the specific item would be helpful. Besides, most of these models do not explicitly capture the neighbor's opinions to items for social recommendations, while different opinions could affect the user differently. In this paper, to address the aforementioned challenges, we propose DSCF, a Deep Social Collaborative Filtering framework, which can exploit the social relations with various aspects for recommender systems. Comprehensive experiments on two-real world datasets show the effectiveness of the proposed framework.",10.1145/3298689.3347011,https://doi.org/10.1145/3298689.3347011,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Deep social collaborative filtering,"Fan, Wenqi and Ma, Yao and Yin, Dawei and Wang, Jianping and Tang, Jiliang and Li, Qing",inproceedings,10.1145/3298689.3347011,
10.1145/3298689.3347017,10.1145/3298689.3347017,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","nearest-neighbours, incremental algorithms, distributed algorithms",9,251–259,Proceedings of the 13th ACM Conference on Recommender Systems,"The problem of computing all pairwise similarities in a large collection of vectors is a well-known and common data mining task. As the number and dimensionality of these vectors keeps increasing, however, currently existing approaches are often unable to meet the strict efficiency requirements imposed by the environments they need to perform in. Real-time neighbourhood-based collaborative filtering (CF) is one example of such an environment in which performance is critical.In this work, we present a novel algorithm for efficient and exact similarity computation between sparse, high-dimensional vectors. Our approach exploits the sparsity that is inherent to implicit feedback data-streams, entailing significant gains compared to other methods. Furthermore, as our model learns incrementally, it is naturally suited for dynamic real-time CF environments. We propose a MapReduce-inspired parallellisation procedure along with our method, and show how even more speed-up can be achieved. Additionally, in many real-world systems, many items are actually not recommendable at any given time, due to recency, stock, seasonality, or enforced business rules. We exploit this fact to further improve the computational efficiency of our approach. Experimental evaluation on both real-world and publicly available datasets shows that our approach scales up to millions of processed user-item interactions per second, and well advances the state-of-the-art.",10.1145/3298689.3347017,https://doi.org/10.1145/3298689.3347017,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Efficient similarity computation for collaborative filtering in dynamic environments,"Jeunen, Olivier and Verstrepen, Koen and Goethals, Bart",inproceedings,10.1145/3298689.3347017,
10.1145/3298689.3347028,10.1145/3298689.3347028,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","time-aware recommendations, convolutional neural networks, context-aware recommender systems, collective embedding",9,201–209,Proceedings of the 13th ACM Conference on Recommender Systems,"Context-aware recommender systems consider contextual features as additional information to predict user's preferences. For example, the recommendations could be based on time, location, or the company of other people. Among the contextual information, time became an important feature because user preferences tend to change over time or be similar in the near future. Researchers have proposed different models to incorporate time into their recommender system, however, the current models are not able to capture specific temporal patterns. To address the limitation observed in previous works, we propose Collective embedding for Neural Context-Aware Recommender Systems (CoNCARS). The proposed solution jointly model the item, user and time embeddings to capture temporal patterns. Then, CoNCARS use the outer product to model the user-item-time correlations between dimensions of the embedding space. The hidden features feed our Convolutional Neural Networks (CNNs) to learn the non-linearities between the different features. Finally, we combine the output from our CNNs in the fusion layer and then predict the user's preference score. We conduct extensive experiments on real-world datasets, demonstrating CoNCARS improves the top-N item recommendation task and outperform the state-of-the-art recommendation methods.",10.1145/3298689.3347028,https://doi.org/10.1145/3298689.3347028,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Collective embedding for neural context-aware recommender systems,"Costa, Felipe Soares da and Dolog, Peter",inproceedings,10.1145/3298689.3347028,
10.1145/3298689.3347035,10.1145/3298689.3347035,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","decentralised matrix factorisation, matrix factorisation, privacy aware, rating prediction",5,457–461,Proceedings of the 13th ACM Conference on Recommender Systems,"Conventional approaches to matrix factorisation (MF) typically rely on a centralised collection of user data for building a MF model. This approach introduces an increased risk when it comes to user privacy. In this short paper we propose an alternative, user-centric, privacy enhanced, decentralised approach to MF. Our method pushes the computation of the recommendation model to the user's device, and eliminates the need to exchange sensitive personal information; instead only the loss gradients of local (device-based) MF models need to be shared. Moreover, users can select the amount and type of information to be shared, for enhanced privacy. We demonstrate the effectiveness of this approach by considering different levels of user privacy in comparison with state-of-the-art alternatives.",10.1145/3298689.3347035,https://doi.org/10.1145/3298689.3347035,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,PDMFRec: a decentralised matrix factorisation with tunable user-centric privacy,"Duriakova, Erika and Tragos, Elias Z. and Smyth, Barry and Hurley, Neil and Pe\~{n}a, Francisco J. and Symeonidis, Panagiotis and Geraci, James and Lawlor, Aonghus",inproceedings,10.1145/3298689.3347035,
10.1145/3298689.3347037,10.1145/3298689.3347037,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","collaborative filtering, content recommendation, implicit feedback, user modeling",9,278–286,Proceedings of the 13th ACM Conference on Recommender Systems,"Implicit feedback (e.g., clicks) is widely used in content recommendations. However, clicks only reflect user preferences according to their first impressions. They do not capture the extent to which users continue to engage with the content. Our analysis shows that more than half of the clicks on music and short videos are followed by skips from two real-world datasets. In this paper, we leverage post-click feedback, e.g. skips and completions, to improve the training and evaluation of content recommenders. Specifically, we experiment with existing collaborative filtering algorithms and find that they perform poorly against post-click-aware ranking metrics. Based on these insights, we develop a generic probabilistic framework to fuse click and post-click signals. We show how our framework can be applied to improve pointwise and pairwise recommendation models. Our approach is shown to outperform existing methods by 18.3% and 2.5% respectively in terms of Area Under the Curve (AUC) on the short-video and music dataset. We discuss the effectiveness of our approach across content domains and trade-offs in weighting various user feedback signals.",10.1145/3298689.3347037,https://doi.org/10.1145/3298689.3347037,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Leveraging post-click feedback for content recommendations,"Wen, Hongyi and Yang, Longqi and Estrin, Deborah",inproceedings,10.1145/3298689.3347037,
10.1145/3298689.3347044,10.1145/3298689.3347044,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","variational methods, recommendations, continuous implicit data",9,287–295,Proceedings of the 13th ACM Conference on Recommender Systems,"Maximizing sales and revenue is an important goal of online commercial retailers. Recommender systems are designed to maximize users' click or purchase probability, but often disregard users' eventual satisfaction with purchased items. As result, such systems promote items with high appeal at the selling stage (e.g. an eyecatching presentation) over items that would yield more satisfaction to users in the long run. This work presents a novel unified model that considers both goals and can be tuned to balance between them according to the needs of the business scenario.We propose a multi-task probabilistic matrix factorization model with a dual task objective: predicting binary purchase/no purchase variables combined with predicting continuous satisfaction scores. Model parameters are optimized using Variational Bayes which allows learning a posterior distribution over model parameters. This model allows making predictions that balance the two goals of maximizing the probability for an immediate purchase and maximizing user satisfaction and engagement down the line. These goals lie at the heart of most commercial recommendation scenarios and enabling their balance has the potential to improve value for millions of users worldwide. Finally, we present experimental evaluation on different types of consumer retail datasets that demonstrate the benefits of the model over popular baselines on a number of well-known ranking metrics.",10.1145/3298689.3347044,https://doi.org/10.1145/3298689.3347044,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,When actions speak louder than clicks: a combined model of purchase probability and long-term customer satisfaction,"Lavee, Gal and Koenigstein, Noam and Barkan, Oren",inproceedings,10.1145/3298689.3347044,
10.1145/3298689.3347045,10.1145/3298689.3347045,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","intent-aware, diversity, calibration",9,151–159,Proceedings of the 13th ACM Conference on Recommender Systems,"Calibrated and intent-aware recommendation are recent approaches to recommendation that have apparent similarities. Both try, to a certain extent, to cover the user's interests, as revealed by her user profile. In this paper, we compare them in detail. On two datasets, we show the extent to which intent-aware recommendations are calibrated and the extent to which calibrated recommendations are diverse. We consider two ways of defining a user's interests, one based on item features, the other based on subprofiles of the user's profile. We find that defining interests in terms of subprofiles results in highest precision and the best relevance/diversity trade-off. Along the way, we define a new version of calibrated recommendation and three new evaluation metrics.",10.1145/3298689.3347045,https://doi.org/10.1145/3298689.3347045,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,A comparison of calibrated and intent-aware recommendations,"Kaya, Mesut and Bridge, Derek",inproceedings,10.1145/3298689.3347045,
10.1145/3298689.3347051,10.1145/3298689.3347051,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","Bayesian personalized ranking, asymmetric pairwise preference assumption, one-class collaborative filtering",5,373–377,Proceedings of the 13th ACM Conference on Recommender Systems,"In this paper, we propose a novel preference assumption for modeling users' one-class feedback such as ""thumb up"" in an important recommendation problem called one-class collaborative filtering (OCCF). Specifically, we address a fundamental limitation of a recent symmetric pairwise preference assumption and propose a novel and first asymmetric one, which is able to make the preferences of different users more comparable. With the proposed asymmetric pairwise preference assumption, we further design a novel recommendation algorithm called asymmetric Bayesian personalized ranking (ABPR). Extensive empirical studies on two large and public datasets show that our ABPR performs significantly better than several state-of-the-art recommendation methods with either pointwise preference assumption or pairwise preference assumption.",10.1145/3298689.3347051,https://doi.org/10.1145/3298689.3347051,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Asymmetric Bayesian personalized ranking for one-class collaborative filtering,"Ouyang, Shan and Li, Lin and Pan, Weike and Ming, Zhong",inproceedings,10.1145/3298689.3347051,
10.1145/3298689.3347055,10.1145/3298689.3347055,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","top-n recommendation, matrix factorization, hybrid recommenders, collaborative filtering, cold start, PureSVD",9,331–339,Proceedings of the 13th ACM Conference on Recommender Systems,"We propose a new hybrid algorithm that allows incorporating both user and item side information within the standard collaborative filtering technique. One of its key features is that it naturally extends a simple PureSVD approach and inherits its unique advantages, such as highly efficient Lanczos-based optimization procedure, simplified hyper-parameter tuning and a quick folding-in computation for generating recommendations instantly even in highly dynamic online environments. The algorithm utilizes a generalized formulation of the singular value decomposition, which adds flexibility to the solution and allows imposing the desired structure on its latent space. Conveniently, the resulting model also admits an efficient and straightforward solution for the cold start scenario. We evaluate our approach on a diverse set of datasets and show its superiority over similar classes of hybrid models.",10.1145/3298689.3347055,https://doi.org/10.1145/3298689.3347055,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,HybridSVD: when collaborative information is not enough,"Frolov, Evgeny and Oseledets, Ivan",inproceedings,10.1145/3298689.3347055,
10.1145/3298689.3347058,10.1145/3298689.3347058,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","reproducibility, recommender systems, evaluation, deep learning",9,101–109,Proceedings of the 13th ACM Conference on Recommender Systems,"Deep learning techniques have become the method of choice for researchers working on algorithmic aspects of recommender systems. With the strongly increased interest in machine learning in general, it has, as a result, become difficult to keep track of what represents the state-of-the-art at the moment, e.g., for top-n recommendation tasks. At the same time, several recent publications point out problems in today's research practice in applied machine learning, e.g., in terms of the reproducibility of the results or the choice of the baselines when proposing new models.In this work, we report the results of a systematic analysis of algorithmic proposals for top-n recommendation tasks. Specifically, we considered 18 algorithms that were presented at top-level research conferences in the last years. Only 7 of them could be reproduced with reasonable effort. For these methods, it however turned out that 6 of them can often be outperformed with comparably simple heuristic methods, e.g., based on nearest-neighbor or graph-based techniques. The remaining one clearly outperformed the baselines but did not consistently outperform a well-tuned non-neural linear ranking method. Overall, our work sheds light on a number of potential problems in today's machine learning scholarship and calls for improved scientific practices in this area.",10.1145/3298689.3347058,https://doi.org/10.1145/3298689.3347058,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Are we really making much progress? A worrying analysis of recent neural recommendation approaches,"Ferrari Dacrema, Maurizio and Cremonesi, Paolo and Jannach, Dietmar",inproceedings,10.1145/3298689.3347058,
10.1145/3298689.3347061,10.1145/3298689.3347061,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","collaborative filtering, recommender systems, user reviews",5,353–357,Proceedings of the 13th ACM Conference on Recommender Systems,"User generated reviews is a highly informative source of information, that has recently gained lots of attention in the recommender systems community. In this work we propose a generative latent variable model that explains both observed ratings and textual reviews. This latent variable model allows to combine any traditional collaborative filtering method, together with any deep learning architecture for text processing. Experimental results on four benchmark datasets demonstrate its superiority comparing to all baseline recommender systems. Furthermore, a running time analysis shows that this approach is in order of magnitude faster that relevant baselines. Moreover, underlying our solution there is a general framework that may be further explored.",10.1145/3298689.3347061,https://doi.org/10.1145/3298689.3347061,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,A generative model for review-based recommendations,"Shalom, Oren Sar and Uziel, Guy and Kantor, Amir",inproceedings,10.1145/3298689.3347061,
10.1145/3298689.3347069,10.1145/3298689.3347069,RecSys.bib,1,['RecSys.bib'],8,RecSys '19,"Copenhagen, Denmark","counterfactual evaluation, implicit feedback, offline evaluation",5,596–600,Proceedings of the 13th ACM Conference on Recommender Systems,"Recommender systems are typically evaluated in an offline setting. A subset of the available user-item interactions is sampled to serve as test set, and some model trained on the remaining data points is then evaluated on its performance to predict which interactions were left out. Alternatively, in an online evaluation setting, multiple versions of the system are deployed and various metrics for those systems are recorded. Systems that score better on these metrics, are then typically preferred. Online evaluation is effective, but inefficient for a number of reasons. Offline evaluation is much more efficient, but current methodologies often fail to accurately predict online performance. In this work, we identify three ways to improve and extend current work on offline evaluation methodologies. More specifically, we believe there is much room for improvement in temporal evaluation, off-policy evaluation, and moving beyond using just clicks to evaluate performance.",10.1145/3298689.3347069,https://doi.org/10.1145/3298689.3347069,"New York, NY, USA",Association for Computing Machinery,9781450362436,2019,Revisiting offline evaluation for implicit-feedback recommender systems,"Jeunen, Olivier",inproceedings,10.1145/3298689.3347069,
10.1145/3308558.3313404,10.1145/3308558.3313404,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Reinforcement Learning, Recommender Systems, Economics of Data Science",7,3123–3129,The World Wide Web Conference,"Existing recommendation algorithms mostly focus on optimizing traditional recommendation measures, such as the accuracy of rating prediction in terms of RMSE or the quality of top-k recommendation lists in terms of precision, recall, MAP, etc. However, an important expectation for commercial recommendation systems is to improve the final revenue/profit of the system. Traditional recommendation targets such as rating prediction and top-k recommendation are not directly related to this goal. In this work, we blend the fundamental concepts in online advertising and micro-economics into personalized recommendation for profit maximization. Specifically, we propose value-aware recommendation based on reinforcement learning, which directly optimizes the economic value of candidate items to generate the recommendation list. In particular, we generalize the basic concept of click conversion rate (CVR) in computational advertising into the conversation rate of an arbitrary user action (XVR) in E-commerce, where the user actions can be clicking, adding to cart, adding to wishlist, etc. In this way, each type of user action is mapped to its monetized economic value. Economic values of different user actions are further integrated as the reward of a ranking list, and reinforcement learning is used to optimize the recommendation list for the maximum total value. Experimental results in both offline benchmarks and online commercial systems verified the improved performance of our framework, in terms of both traditional top-k ranking tasks and the economic profits of the system.",10.1145/3308558.3313404,https://doi.org/10.1145/3308558.3313404,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Value-aware Recommendation based on Reinforcement Profit Maximization,"Pei, Changhua and Yang, Xinru and Cui, Qing and Lin, Xiao and Sun, Fei and Jiang, Peng and Ou, Wenwu and Zhang, Yongfeng",inproceedings,10.1145/3308558.3313404,
10.1145/3308558.3313406,10.1145/3308558.3313406,TheWebConf.bib,1,['TheWebConf.bib'],7,WWW '19,"San Francisco, CA, USA",,12,1759–1770,The World Wide Web Conference,"Request latency is a critical metric in determining the usability of web services. The latency of a request includes service time - the time when the request is being actively serviced - and waiting time - the time when the request is waiting to be served. Most existing works aim to reduce request latency by focusing on reducing the mean service time (that is, shortening the critical path). In this paper, we explore an alternative approach to reducing latency - using variability as a guiding principle when designing web services. By tracking the service time variability of the request as it traverses across software layers within the user and kernel space of the web server, we identify the most critical stages of request processing. We then determine control knobs in the OS and application, such as thread scheduling and request batching, that regulate the variability in these stages, and demonstrate that tuning these specific knobs can significantly improve end-to-end request latency. Our experimental results with Memcached and Apache web server under different request rates, including real-world traces, show that this alternative approach can reduce mean and tail latency by 30-50%.",10.1145/3308558.3313406,https://doi.org/10.1145/3308558.3313406,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Using Variability as a Guiding Principle to Reduce Latency in Web Applications via OS Profiling,"Suresh, Amoghavarsha and Gandhi, Anshul",inproceedings,10.1145/3308558.3313406,
10.1145/3308558.3313440,10.1145/3308558.3313440,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Q&amp;A communities, Hawkes processes, Excitation effects",12,1634–1645,The World Wide Web Conference,"In this paper, we quantify the impact of self- and cross-excitation on the temporal development of user activity in Stack Exchange Question &amp; Answer (Q&amp;A) communities. We study differences in user excitation between growing and declining Stack Exchange communities, and between those dedicated to STEM and humanities topics by leveraging Hawkes processes. We find that growing communities exhibit early stage, high cross-excitation by a small core of power users reacting to the community as a whole, and strong long-term self-excitation in general and cross-excitation by casual users in particular, suggesting community openness towards less active users. Further, we observe that communities in the humanities exhibit long-term power user cross-excitation, whereas in STEM communities activity is more evenly distributed towards casual user self-excitation. We validate our findings via permutation tests and quantify the impact of these excitation effects with a range of prediction experiments. Our work enables researchers to quantitatively assess the evolution and activity potential of Q&amp;A communities.",10.1145/3308558.3313440,https://doi.org/10.1145/3308558.3313440,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Self- and Cross-Excitation in Stack Exchange Question &amp; Answer Communities,"Santos, Tiago and Walk, Simon and Kern, Roman and Strohmaier, Markus and Helic, Denis",inproceedings,10.1145/3308558.3313440,
10.1145/3308558.3313449,10.1145/3308558.3313449,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Social Recommendation, Social Influence, Review Community, Generative Model, Content Analysis",11,1310–1320,The World Wide Web Conference,"Social influence plays a vital role in shaping a user's behavior in online communities dealing with items of fine taste like movies, food, and beer. For online recommendation, this implies that users' preferences and ratings are influenced due to other individuals. Given only time-stamped reviews of users, can we find out who-influences-whom, and characteristics of the underlying influence network? Can we use this network to improve recommendation? While prior works in social-aware recommendation have leveraged social interaction by considering the observed social network of users, many communities like Amazon, Beeradvocate, and Ratebeer do not have explicit user-user links. Therefore, we propose GhostLink, an unsupervised probabilistic graphical model, to automatically learn the latent influence network underlying a review community - given only the temporal traces (timestamps) of users' posts and their content. Based on extensive experiments with four real-world datasets with 13 million reviews, we show that GhostLink improves item recommendation by around 23% over state-of-the-art methods that do not consider this influence. As additional use-cases, we show that GhostLink can be used to differentiate between users' latent preferences and influenced ones, as well as to detect influential users based on the learned influence graph.",10.1145/3308558.3313449,https://doi.org/10.1145/3308558.3313449,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,GhostLink: Latent Network Inference for Influence-aware Recommendation,"Mukherjee, Subhabrata and Guennemann, Stephan",inproceedings,10.1145/3308558.3313449,
10.1145/3308558.3313453,10.1145/3308558.3313453,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Urban Dynamics, Mobility, Hidden Markov Model",7,3363–3369,The World Wide Web Conference,"Modeling people's activities in the urban space is a crucial socio-economic task but extremely challenging due to the deficiency of suitable methods. To model the temporal dynamics of human activities concisely and specifically, we present State-sharing Hidden Markov Model (SSHMM). First, it extracts the urban states from the whole city, which captures the volume of population flows as well as the frequency of each type of Point of Interests (PoIs) visited. Second, it characterizes the urban dynamics of each urban region as the state transition on the shared-states, which reveals distinct daily rhythms of urban activities. We evaluate our method via a large-scale real-life mobility dataset and results demonstrate that SSHMM learns semantics-rich urban dynamics, which are highly correlated with the functions of the region. Besides, it recovers the urban dynamics in different time slots with an error of 0.0793, which outperforms the general HMM by 54.2%.",10.1145/3308558.3313453,https://doi.org/10.1145/3308558.3313453,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Understanding Urban Dynamics via State-sharing Hidden Markov Model,"Xia, Tong and Yu, Yue and Xu, Fengli and Sun, Funing and Guo, Diansheng and Jin, Depeng and Li, Yong",inproceedings,10.1145/3308558.3313453,
10.1145/3308558.3313463,10.1145/3308558.3313463,TheWebConf.bib,1,['TheWebConf.bib'],7,WWW '19,"San Francisco, CA, USA",,11,1864–1874,The World Wide Web Conference,"Key to recommender systems is learning user preferences, which are expressed through various modalities. In online reviews, for instance, this manifests in numerical rating, textual content, as well as visual images. In this work, we hypothesize that modelling these modalities jointly would result in a more holistic representation of a review towards more accurate recommendations. Therefore, we propose Multimodal Review Generation (MRG), a neural approach that simultaneously models a rating prediction component and a review text generation component. We hypothesize that the shared user and item representations would augment the rating prediction with richer information from review text, while sensitizing the generated review text to sentiment features based on user and item of interest. Moreover, when review photos are available, visual features could inform the review text generation further. Comprehensive experiments on real-life datasets from several major US cities show that the proposed model outperforms comparable multimodal baselines, while an ablation analysis establishes the relative contributions of the respective components of the joint model.",10.1145/3308558.3313463,https://doi.org/10.1145/3308558.3313463,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Multimodal Review Generation for Recommender Systems,"Truong, Quoc-Tuan and Lauw, Hady",inproceedings,10.1145/3308558.3313463,
10.1145/3308558.3313473,10.1145/3308558.3313473,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Variational Inference, Recommender System, Graphical Model",11,995–1005,The World Wide Web Conference,"Many e-commerce platforms today allow users to give their rating scores and reviews on items as well as to establish social relationships with other users. As a result, such platforms accumulate heterogeneous data including numeric scores, short textual reviews, and social relationships. However, many recommender systems only consider historical user feedbacks in modeling user preferences. More specifically, most existing recommendation approaches only use rating scores but ignore reviews and social relationships in the user-generated data. In this paper, we propose TSNPF-a latent factor model to effectively capture user preferences and item features. Employing Poisson factorization, TSNPF fully exploits the wealth of information in rating scores, review text and social relationships altogether. It extracts topics of items and users from the review text and makes use of similarities between user pairs with social relationships, which results in a comprehensive understanding of user preferences. Experimental results on real-world datasets demonstrate that our TSNPF approach is highly effective at recommending items to users.",10.1145/3308558.3313473,https://doi.org/10.1145/3308558.3313473,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,"Exploiting Ratings, Reviews and Relationships for Item Recommendations in Topic Based Social Networks","Li, Pengfei and Lu, Hua and Zheng, Gang and Zheng, Qian and Yang, Long and Pan, Gang",inproceedings,10.1145/3308558.3313473,
10.1145/3308558.3313478,10.1145/3308558.3313478,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","spectral feature, pairwise learning to rank, latent community, latent category., Collaborative filtering",11,2247–2257,The World Wide Web Conference,"To enhance the performance of the recommender system, side information is extensively explored with various features (e.g., visual features and textual features). However, there are some demerits of side information: (1) the extra data is not always available in all recommendation tasks; (2) it is only for items, there is seldom high-level feature describing users. To address these gaps, we introduce the spectral features extracted from two hypergraph structures of the purchase records. Spectral features describe the similarity of users/items in the graph space, which is critical for recommendation. We leverage spectral features to model the users' preference and items' properties by incorporating them into a Matrix Factorization (MF) model. In addition to modeling, we also use spectral features to optimize. Bayesian Personalized Ranking (BPR) is extensively leveraged to optimize models in implicit feedback data. However, in BPR, all missing values are regarded as negative samples equally while many of them are indeed unseen positive ones. We enrich the positive samples by calculating the similarity among users/items by the spectral features. The key ideas are: (1) similar users shall have similar preference on the same item; (2) a user shall have similar perception on similar items. Extensive experiments on two real-world datasets demonstrate the usefulness of the spectral features and the effectiveness of our spectrum-enhanced pairwise optimization. Our models outperform several state-of-the-art models significantly.",10.1145/3308558.3313478,https://doi.org/10.1145/3308558.3313478,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Spectrum-enhanced Pairwise Learning to Rank,"Yu, Wenhui and Qin, Zheng",inproceedings,10.1145/3308558.3313478,
10.1145/3308558.3313488,10.1145/3308558.3313488,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Social Recommendation, Social Network, Recommender Systems, Neural Networks, Graph Neural Networks",10,417–426,The World Wide Web Conference,"In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key. However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the user-user social graph and the user-item graph). To address the three aforementioned challenges simultaneously, in this paper, we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec, which coherently models two graphs and heterogeneous strengths. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework GraphRec.",10.1145/3308558.3313488,https://doi.org/10.1145/3308558.3313488,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Graph Neural Networks for Social Recommendation,"Fan, Wenqi and Ma, Yao and Li, Qing and He, Yuan and Zhao, Eric and Tang, Jiliang and Yin, Dawei",inproceedings,10.1145/3308558.3313488,
10.1145/3308558.3313496,10.1145/3308558.3313496,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Rating Prediction, Persona Modeling, Adversarial Variational Auto-Encoders., Abstractive Tips Generation",11,1006–1016,The World Wide Web Conference,"Tips, as a compacted and concise form of reviews, were paid less attention by researchers. In this paper, we investigate the task of tips generation by considering the “persona” information which captures the intrinsic language style of the users or the different characteristics of the product items. In order to exploit the persona information, we propose a framework based on adversarial variational auto-encoders (aVAE) for persona modeling from the historical tips and reviews of users and items. The latent variables from aVAE are regarded as persona embeddings. Besides representing persona using the latent embeddings, we design a persona memory for storing the persona related words for users and items. Pointer Network is used to retrieve persona wordings from the memory when generating tips. Moreover, the persona embeddings are used as latent factors by a rating prediction component to predict the sentiment of a user over an item. Finally, the persona embeddings and the sentiment information are incorporated into a recurrent neural networks based tips generation component. Extensive experimental results are reported and discussed to elaborate the peculiarities of our framework.",10.1145/3308558.3313496,https://doi.org/10.1145/3308558.3313496,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Persona-Aware Tips Generation?,"Li, Piji and Wang, Zihao and Bing, Lidong and Lam, Wai",inproceedings,10.1145/3308558.3313496,
10.1145/3308558.3313543,10.1145/3308558.3313543,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Recommender Systems, Deep Learning, Collaborative Filtering",8,2822–2829,The World Wide Web Conference,"Collaborative Filtering (CF) is the key technique for recommender systems. CF exploits user-item behavior interactions (e.g., clicks) only and hence suffers from the data sparsity issue. One research thread is to integrate auxiliary information such as product reviews and news titles, leading to hybrid filtering methods. Another thread is to transfer knowledge from source domains such as improving the movie recommendation with the knowledge from the book domain, leading to transfer learning methods. In real-world applications, a user registers for multiple services across websites. Thus it motivates us to exploit both auxiliary and source information for recommendation in this paper. To achieve this, we propose a Transfer Meeting Hybrid (TMH) model for cross-domain recommendation with unstructured text. The proposed TMH model attentively extracts useful content from unstructured text via a memory network and selectively transfers knowledge from a source domain via a transfer network. On two real-world datasets, TMH shows better performance in terms of three ranking metrics by comparing with various baselines. We conduct thorough analyses to understand how the text content and transferred knowledge help the proposed model.",10.1145/3308558.3313543,https://doi.org/10.1145/3308558.3313543,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Transfer Meets Hybrid: A Synthetic Approach for Cross-Domain Collaborative Filtering with Text,"Hu, Guangneng and Zhang, Yu and Yang, Qiang",inproceedings,10.1145/3308558.3313543,
10.1145/3308558.3313582,10.1145/3308558.3313582,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Social recommendation, Sampling, Implicit feedback",12,228–239,The World Wide Web Conference,"Recommendation from implicit feedback is a highly challenging task due to the lack of reliable negative feedback data. Only positive feedback are observed and the unobserved feedback can be attributed to two reasons: unknow or dislike. Existing methods address this challenge by treating all the un-observed data as negative (dislike) but downweight the confidence of these data. However, this treatment causes two problems: (1) Confidence weights of the unobserved data are usually assigned manually, which lack flexible and may create empirical bias in evaluating user's preference. (2) To handle massive volume of the unobserved feedback data, most of the existing methods rely on stochastic inference and data sampling strategies. However, since users are only aware of a very small fraction of items in a large dataset, it is difficult for existing samplers to select informative training instances in which the user really dislikes the item rather than does not know it. To address the above two problems, we propose a new recommendation method SamWalker that leverages social information to infer data confidence and guide the sampling process. By modeling data confidence with a social context-aware function, SamWalker can adaptively specify different weights to different data based on users' social contexts. Further, a personalized random-walk-based sampling strategy is developed to adaptively draw informative training instances, which can speed up gradient estimation and reduce sampling variance. Extensive experiments on three real-world datasets demonstrate the superiority of the proposed SamWalker method and its sampling strategy.",10.1145/3308558.3313582,https://doi.org/10.1145/3308558.3313582,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,SamWalker: Social Recommendation with Informative Sampling Strategy,"Chen, Jiawei and Wang, Can and Zhou, Sheng and Shi, Qihao and Feng, Yan and Chen, Chun",inproceedings,10.1145/3308558.3313582,
10.1145/3308558.3313585,10.1145/3308558.3313585,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","top-N recommendation, dual representation, Implicit feedback",11,863–873,The World Wide Web Conference,"Implicit user feedback is a fundamental dataset for personalized recommendation models. Because of its inherent characteristics of sparse one-class values, it is challenging to uncover meaningful user/item representations. In this paper, we propose dual neural personalized ranking (DualNPR), which fully exploits both user- and item-side pairwise rankings in a unified manner. The key novelties of the proposed model are three-fold: (1) DualNPR discovers mutual correlation among users and items by utilizing both user- and item-side pairwise rankings, alleviating the data sparsity problem. We stress that, unlike existing models that require extra information, DualNPR naturally augments both user- and item-side pairwise rankings from a user-item interaction matrix. (2) DualNPR is built upon deep matrix factorization to capture the variability of user/item representations. In particular, it chooses raw user/item vectors as an input and learns latent user/item representations effectively. (3) DualNPR employs a dynamic negative sampling method using an exponential function, further improving the accuracy of top-N recommendation. In experimental results over three benchmark datasets, DualNPR outperforms baseline models by 21.9-86.7% in hit rate, 14.5-105.8% in normalized discounted cumulative gain, and 5.1-23.3% in the area under the ROC curve.",10.1145/3308558.3313585,https://doi.org/10.1145/3308558.3313585,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Dual Neural Personalized Ranking,"Kim, Seunghyeon and Lee, Jongwuk and Shim, Hyunjung",inproceedings,10.1145/3308558.3313585,
10.1145/3308558.3313672,10.1145/3308558.3313672,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","XGBoost, Search ranking, Personalization, Nonlinear personalized models, GLMix models",7,3116–3122,The World Wide Web Conference,"Talent Search systems aim to recommend potential candidates who are a good match to the hiring needs of a recruiter expressed in terms of the recruiter's search query or job posting. Past work in this domain has focused on linear and nonlinear models which lack preference personalization in the user-level due to being trained only with globally collected recruiter activity data. In this paper, we propose an entity-personalized Talent Search model which utilizes a combination of generalized linear mixed (GLMix) models and gradient boosted decision tree (GBDT) models, and provides personalized talent recommendations using nonlinear tree interaction features generated by the GBDT. We also present the offline and online system architecture for the productionization of this hybrid model approach in our Talent Search systems. Finally, we provide offline and online experiment results benchmarking our entity-personalized model with tree interaction features, which demonstrate significant improvements in our precision metrics compared to globally trained non-personalized models.",10.1145/3308558.3313672,https://doi.org/10.1145/3308558.3313672,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Entity Personalized Talent Search Models with Tree Interaction Features,"Ozcaglar, Cagri and Geyik, Sahin and Schmitz, Brian and Sharma, Prakhar and Shelkovnykov, Alex and Ma, Yiming and Buchanan, Erik",inproceedings,10.1145/3308558.3313672,
10.1145/3308558.3313695,10.1145/3308558.3313695,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Path Aggregation, Neural Networks, Edge Learning",11,15–25,The World Wide Web Conference,"Graph edges, along with their labels, can represent information of fundamental importance, such as links between web pages, friendship between users, the rating given by users to other users or items, and much more. We introduce LEAP, a trainable, general framework for predicting the presence and properties of edges on the basis of the local structure, topology, and labels of the graph. The LEAP framework is based on the exploration and machine-learning aggregation of the paths connecting nodes in a graph. We provide several methods for performing the aggregation phase by training path aggregators, and we demonstrate the flexibility and generality of the framework by applying it to the prediction of links and user ratings in social networks. We validate the LEAP framework on two problems: link prediction, and user rating prediction. On eight large datasets, among which the arXiv collaboration network, the Yeast protein-protein interaction, and the US airlines routes network, we show that the link prediction performance of LEAP is at least as good as the current state of the art methods, such as SEAL and WLNM. Next, we consider the problem of predicting user ratings on other users: this problem is known as the edge-weight prediction problem in weighted signed networks (WSN). On Bitcoin networks, and Wikipedia RfA, we show that LEAP performs consistently better than the Fairness &amp; Goodness based regression models, varying the amount of training edges between 10 to 90%. These examples demonstrate that LEAP, in spite of its generality, can match or best the performance of approaches that have been especially crafted to solve very specific edge prediction problems.",10.1145/3308558.3313695,https://doi.org/10.1145/3308558.3313695,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Learning Edge Properties in Graphs from Path Aggregations,"Agrawal, Rakshit and de Alfaro, Luca",inproceedings,10.1145/3308558.3313695,
10.1145/3308558.3313721,10.1145/3308558.3313721,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","topic modeling, news media, multi-level regression, fake news",12,139–150,The World Wide Web Conference,"The spread of content produced by fake news publishers was one of the most discussed characteristics of the 2016 U.S. Presidential Election. Yet, little is known about the prevalence and focus of such content, how its prevalence changed over time, and how this prevalence related to important election dynamics. In this paper, we address these questions using tweets that mention the two presidential candidates sampled at the daily level, the news content mentioned in such tweets, and open-ended responses from nationally representative telephone interviews. The results of our analysis highlight various important lessons for news consumers and journalists. We find that (i.) traditional news producers outperformed fake news producers in aggregate, (ii.) the prevalence of content produced by fake news publishers increased over the course of the campaign-particularly among tweets that mentioned Clinton, and (iii.) changes in such prevalence were closely following changes in net Clinton favorability. Turning to content, we (iv.) identify similarities and differences in agenda setting by fake and traditional news media and show that (v.) information individuals most commonly reported to having read, seen or heard about the candidates was more closely aligned with content produced by fake news outlets than traditional news outlets, in particular for information Republican voters retained about Clinton. We also model fake-ness of retained information as a function of demographics characteristics. Implications for platform owners, news consumers, and journalists are discussed.",10.1145/3308558.3313721,https://doi.org/10.1145/3308558.3313721,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,What happened? The Spread of Fake News Publisher Content During the 2016 U.S. Presidential Election,"Budak, Ceren",inproceedings,10.1145/3308558.3313721,
10.1145/3308558.3313725,10.1145/3308558.3313725,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Risk Attitude, Recommendation Systems, Personalization, Marginal Utility per Dollar, Computational Economics",7,2757–2763,The World Wide Web Conference,"Understanding the economic nature of consumer decisions in e-Commerce is important to personalized recommendation systems. Established economic theories claim that informed consumers always attempt to maximize their utility by choosing the items of the largest marginal utility per dollar (MUD) within their budgets. For example, gaining 5 dollars of extra benefit by spending 10 dollars makes a consumer much more satisfied than having the same amount of extra benefit by spending 20 dollars, although the second product may have higher absolute utility value. Meanwhile, making purchases online may be risky decisions that could cause dissatisfaction. For example, people may give low ratings towards purchased items that they thought they would like when placing the order. Therefore, the design of recommender systems should also take users' risk attitudes into consideration to better learn consumer behaviors. Motivated by the first consideration, in this paper, we propose a learning algorithm to maximize marginal utility per dollar for recommendations. With the second, economic theory shows that rational people can be arbitrarily close to risk neutral when stakes are arbitrarily small, and this is generally applicable to consumer online purchase behaviors because most people spend a small portion of their total wealth for a single purchase. To integrate this theory with machine learning, we propose to augment MUD optimization with approximate risk-neural constraint to generate personalized recommendations. Experiments on real-world e-Commerce datasets show that our approach is able to achieve better performance than many classical recommendation methods, in terms of both traditional recommendation measures such as precision and recall, as well as economic measures such as MUD.",10.1145/3308558.3313725,https://doi.org/10.1145/3308558.3313725,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Maximizing Marginal Utility per Dollar for Economic Recommendation,"Ge, Yingqiang and Xu, Shuyuan and Liu, Shuchang and Geng, Shijie and Fu, Zuohui and Zhang, Yongfeng",inproceedings,10.1145/3308558.3313725,
10.1145/3308558.3313727,10.1145/3308558.3313727,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","regret analysis, recommender systems, Non-stationary bandits",11,2080–2090,The World Wide Web Conference,"Recommender systems have to handle a highly non-stationary environment, due to users' fast changing interests over time. Traditional solutions have to periodically rebuild their models, despite high computational cost. But this still cannot empower them to automatically adjust to abrupt changes in trends caused by timely information. It is important to note that the changes of reward distributions caused by a non-stationary environment can also be context dependent. When the change is orthogonal to the given context, previously maintained models should be reused for better recommendation prediction. In this work, we focus on contextual bandit algorithms for making adaptive recommendations. We capitalize on the unique context-dependent property of reward changes to conquer the challenging non-stationary environment for model update. In particular, we maintain a dynamic ensemble of contextual bandit models, where each bandit model's reward estimation quality is monitored regarding given context and possible environment changes. Only the admissible models to the current environment will be used for recommendation. We provide a rigorous upper regret bound analysis of our proposed algorithm. Extensive empirical evaluations on both synthetic and three real-world datasets confirmed the algorithm's advantage against existing non-stationary solutions that simply create new models whenever an environment change is detected.",10.1145/3308558.3313727,https://doi.org/10.1145/3308558.3313727,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Dynamic Ensemble of Contextual Bandits to Satisfy Users' Changing Interests,"Wu, Qingyun and Wang, Huazheng and Li, Yanen and Wang, Hongning",inproceedings,10.1145/3308558.3313727,
10.1145/3308558.3313733,10.1145/3308558.3313733,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Implicit Feedback, Generative Adversarial Networks, Deep learning, Cross-network Recommendations, Collaborative Filtering",7,3144–3150,The World Wide Web Conference,"A major drawback of cross-network recommender solutions is that they can only be applied to users that are overlapped across networks. Thus, the non-overlapped users, which form the majority of users are ignored. As a solution, we propose CnGAN, a novel multi-task learning based, encoder-GAN-recommender architecture. The proposed model synthetically generates source network user preferences for non-overlapped users by learning the mapping from target to source network preference manifolds. The resultant user preferences are used in a Siamese network based neural recommender architecture. Furthermore, we propose a novel user-based pairwise loss function for recommendations using implicit interactions to better guide the generation process in the multi-task learning environment. We illustrate our solution by generating user preferences on the Twitter source network for recommendations on the YouTube target network. Extensive experiments show that the generated preferences can be used to improve recommendations for non-overlapped users. The resultant recommendations achieve superior performance compared to the state-of-the-art cross-network recommender solutions in terms of accuracy, novelty and diversity.",10.1145/3308558.3313733,https://doi.org/10.1145/3308558.3313733,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,CnGAN: Generative Adversarial Networks for Cross-network user preference generation for non-overlapped users,"Perera, Dilruk and Zimmermann, Roger",inproceedings,10.1145/3308558.3313733,
10.1145/3308558.3313736,10.1145/3308558.3313736,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Recommender systems, Matrix factorization, Matrix completion, Collaborative filtering",7,3223–3229,The World Wide Web Conference,"Recommender systems are widely used to recommend the most appealing items to users. These recommendations can be generated by applying collaborative filtering methods. The low-rank matrix completion method is the state-of-the-art collaborative filtering method. In this work, we show that the skewed distribution of ratings in the user-item rating matrix of real-world datasets affects the accuracy of matrix-completion-based approaches. Also, we show that the number of ratings that an item or a user has positively correlates with the ability of low-rank matrix-completion-based approaches to predict the ratings for the item or the user accurately. Furthermore, we use these insights to develop four matrix completion-based approaches, i.e., Frequency Adaptive Rating Prediction (FARP), Truncated Matrix Factorization (TMF), Truncated Matrix Factorization with Dropout (TMF + Dropout) and Inverse Frequency Weighted Matrix Factorization (IFWMF), that outperforms traditional matrix-completion-based approaches for the users and the items with few ratings in the user-item rating matrix.",10.1145/3308558.3313736,https://doi.org/10.1145/3308558.3313736,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Adaptive matrix completion for the users and the items in tail,"Sharma, Mohit and Karypis, George",inproceedings,10.1145/3308558.3313736,
10.1145/3308558.3313739,10.1145/3308558.3313739,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","Viusal Compatibility, Image Representation, Fashion Recommendation",7,3434–3440,The World Wide Web Conference,"With the increasing of online shopping services, fashion recommendation plays an important role in daily online shopping scenes. A lot of recommender systems have been developed with visual information. However, few works take into account compatibility relationship when they are generating recommendations. The challenge is that fashion concept is often subtle and subjective for different customers. In this paper, we propose a fashion compatibility knowledge learning method that incorporates visual compatibility relationships as well as style information. We also propose a fashion recommendation method with domain adaptation strategy to alleviate the distribution gap between the items in target domain and the items of external compatible outfits. Our results indicate that the proposed method is capable of learning visual compatibility knowledge and outperforms all the baselines.",10.1145/3308558.3313739,https://doi.org/10.1145/3308558.3313739,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,Enhancing Fashion Recommendation with Visual Compatibility Relationship,"Yin, Ruiping and Li, Kan and Lu, Jie and Zhang, Guangquan",inproceedings,10.1145/3308558.3313739,
10.1145/3308558.3313745,10.1145/3308558.3313745,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, CA, USA","social recommender systems, recommendation systems, influence propagation",7,2778–2784,The World Wide Web Conference,"Social recommendations have been a very intriguing domain for researchers in the past decade. The main premise is that the social network of a user can be leveraged to enhance the rating-based recommendation process. This has been achieved in various ways, and under different assumptions about the network characteristics, structure, and availability of other information (such as trust, content, etc.) In this work, we create neighborhoods of influence leveraging only the social graph structure. These are in turn introduced in the recommendation process both as a pre-processing step and as a social regularization factor of the matrix factorization algorithm. Our experimental evaluation using real-life datasets demonstrates the effectiveness of the proposed technique.",10.1145/3308558.3313745,https://doi.org/10.1145/3308558.3313745,"New York, NY, USA",Association for Computing Machinery,9781450366748,2019,With a Little Help from My Friends (and Their Friends): Influence Neighborhoods for Social Recommendations,"Gulati, Avni and Eirinaki, Magdalini",inproceedings,10.1145/3308558.3313745,
10.1145/3308560.3316702,10.1145/3308560.3316702,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, USA","user generated video systems, User donation, User Generated Content (UGC)",8,1055–1062,Companion Proceedings of The 2019 World Wide Web Conference,"User generated video systems like YouTube and Twitch.tv have been a major internet phenomenon. They have attracted a vast user base with their many and varied contents provided by their users, and a series of social features tailored for online viewing. In hoping for building a more lively community and encouraging the content creators to share more, recently many such systems have introduced crowdsourcing mechanisms wherein creators get tangible rewards through user donations. User donation is a very special form of user relationships. It influences user engagement in the community, and has a great impact on the success of these systems. However, user donations and donation relationships remain trade secrets for most enterprises and to date are still unexplored. It is not clear at what scale are the donations or how users donate in these systems. In this work, we attempt to fill this gap. We obtain and provide a publicly available dataset on user donations in BiliBili, a popular user generated video system in China with 76.4 million average monthly active users. Based on detailed information on over 5 million videos, over 700 thousand content creators, and over 1.5 million user donations, we quantitatively reveal the characteristics of user donations, we examine their correlations with the upload behavior and content popularity of the creators, and we adopt machine-learned classifiers to accurately predict the creators who will receive donations and who will donate in the future.",10.1145/3308560.3316702,https://doi.org/10.1145/3308560.3316702,"New York, NY, USA",Association for Computing Machinery,9781450366755,2019,User Donations in a User Generated Video System,"Lu Jia, Adele and Shen, Xiaoxue and Shen, Siqi and Fu, Yongquan and Peng, Liwen",inproceedings,10.1145/3308560.3316702,
10.1145/3308560.3316706,10.1145/3308560.3316706,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, USA","mining and learning, cryptocurrency, Social media",4,1051–1054,Companion Proceedings of The 2019 World Wide Web Conference,"The ability to track and monitor relevant and important news in real-time is of crucial interest in multiple industrial sectors. In this work, we focus on cryptocurrency news, which recently became of emerging interest to the general and financial audience. In order to track popular news in real-time, we (i) match news from the web with tweets from social media, (ii) track their intraday tweet activity and (iii) explore different machine learning models for predicting the number of article mentions on Twitter after its publication. We compare several machine learning models, such as linear extrapolation, linear and random forest autoregressive models, and a sequence-to-sequence neural network.",10.1145/3308560.3316706,https://doi.org/10.1145/3308560.3316706,"New York, NY, USA",Association for Computing Machinery,9781450366755,2019,Sensing Social Media Signals for Cryptocurrency News,"Beck, Johannes and Huang, Roberta and Lindner, David and Guo, Tian and Ce, Zhang and Helbing, Dirk and Antulov-Fantulin, Nino",inproceedings,10.1145/3308560.3316706,
10.1145/3308560.3317080,10.1145/3308560.3317080,TheWebConf.bib,1,['TheWebConf.bib'],7,WWW '19,"San Francisco, USA",,5,1106–1110,Companion Proceedings of The 2019 World Wide Web Conference,"Crowdsourcing systems increasingly rely on users to provide more subjective ground truth for intelligent systems - e.g. ratings, aspect of quality and perspectives on how expensive or lively a place feels, etc. We focus on the ubiquitous implementation of online user ordinal voting (e.g 1-5, 1 star-4 stars) on some aspect of an entity, to extract a relative truth, measured by a selected metric such as vote plurality or mean. We argue that this methodology can aggregate results that yield little information to the end user. In particular, ordinal user rankings often converge to a indistinguishable rating. This is demonstrated by the trend in certain cities for the majority of restaurants to all have a 4 star rating. Similarly, the rating of an establishment can be significantly affected by a few users [10]. User bias in voting is not spam, but rather a preference that can be harnessed to provide more information to users. We explore notions of both global skew and user bias. Leveraging these bias and preference concepts, the paper suggests explicit models for better personalization and more informative ratings.",10.1145/3308560.3317080,https://doi.org/10.1145/3308560.3317080,"New York, NY, USA",Association for Computing Machinery,9781450366755,2019,Discovering User Bias in Ordinal Voting Systems,"Lees, Alyssa and Welty, Chris",inproceedings,10.1145/3308560.3317080,
10.1145/3308560.3317303,10.1145/3308560.3317303,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, USA","Recommender Systems (RSs), Propensity, Matrix Factorization, Active Learning (AL)",7,645–651,Companion Proceedings of The 2019 World Wide Web Conference,"Recommender Systems (RSs) are widely used to help online users discover products, books, news, music, movies, courses, restaurants, etc. Because a traditional recommendation strategy always shows the most relevant items (thus with highest predicted rating), traditional RS’s are expected to make popular items become even more popular and non-popular items become even less popular which in turn further divides the haves (popular) from the have-nots (unpopular). Therefore, a major problem with RSs is that they may introduce biases affecting the exposure of items, thus creating a popularity divide of items during the feedback loop that occurs with users, and this may lead the RS to make increasingly biased recommendations over time. In this paper, we view the RS environment as a chain of events that are the result of interactions between users and the RS. Based on that, we propose several debiasing algorithms during this chain of events, and evaluate how these algorithms impact the predictive behavior of the RS, as well as trends in the popularity distribution of items over time. We also propose a novel blind-spot-aware matrix factorization (MF) algorithm to debias the RS. Results show that propensity matrix factorization achieved a certain level of debiasing of the RS while active learning combined with the propensity MF achieved a higher debiasing effect on recommendations.",10.1145/3308560.3317303,https://doi.org/10.1145/3308560.3317303,"New York, NY, USA",Association for Computing Machinery,9781450366755,2019,Debiasing the Human-Recommender System Feedback Loop in Collaborative Filtering,"Sun, Wenlong and Khenissi, Sami and Nasraoui, Olfa and Shafto, Patrick",inproceedings,10.1145/3308560.3317303,
10.1145/3308560.3317598,10.1145/3308560.3317598,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '19,"San Francisco, USA","social media, politics, memes, media governance, media, journalism, hacking, ethics, Trolling",6,523–528,Companion Proceedings of The 2019 World Wide Web Conference,"In this paper, we analogize the practice of trolling to the practice of hacking. Just as hacking often involves the discovery and exploitation of vulnerabilities in a computer security landscape, trolling frequently involves the discovery and exploitation of vulnerabilities in a media or attention landscape to amplify messages and direct attention. Also like with hacking, we consider the possibility for a range of trolling personas: from black hat trolls who push an agenda that is clearly counter to the interests of the target, to gray hat trolls who exploit vulnerabilities to draw critical attention to unaddressed issues, and white hat trolls who could help proactively disclose vulnerabilities so that attack surface can be reduced. We discuss a variety of trolling techniques from dogpiling to sockpuppetry and also a range of possible interventions.",10.1145/3308560.3317598,https://doi.org/10.1145/3308560.3317598,"New York, NY, USA",Association for Computing Machinery,9781450366755,2019,"Black Hat Trolling, White Hat Trolling, and Hacking the Attention Landscape","Matthews, Jeanna and Goerzen, Matt",inproceedings,10.1145/3308560.3317598,
10.1145/3326937.3341250,10.1145/3326937.3341250,KDD.bib,1,['KDD.bib'],7,DLP-KDD '19,"Anchorage, Alaska","collaborative filtering, convolutional neural networks, local taylor approximation",4,,Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data,"Collaborative filtering (CF) is an extensively studied topic in Recommender System. Recent approaches use the statistical framework based on local Taylor approximations to unify both user based and item based CF algorithms and improve the performance of estimating unknown ratings. In this paper, we propose a new Machine Learning approach based on Convolutional Neural Networks to exploit complex latent user-item relations, using features extracted from the neighborhood of unknown rating via local approximations. Experimental results on two benchmark data sets demonstrate the effectiveness of the proposed approach via comparing to state-of-the-art methods.",10.1145/3326937.3341250,https://doi.org/10.1145/3326937.3341250,"New York, NY, USA",Association for Computing Machinery,9781450367837,2019,Collaborative filtering via learning characteristics of neighborhood based on convolutional neural networks,"Jia, Yugang and Wang, Xin and Zhang, Jinting",inproceedings,10.1145/3326937.3341250,1
10.1145/3326937.3341251,10.1145/3326937.3341251,KDD.bib,1,['KDD.bib'],6,DLP-KDD '19,"Anchorage, Alaska",,8,,Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data,"This paper presents a method of pairwise multi-layer networks for multi-field categorical data, which widely exists with various applications such as web search, recommender systems, social link prediction, and computational advertising. The success of non-linear models, e.g., factorization machines, boosted trees, has proved the potential of exploring the interactions among inter-field discrete categories. Inspired by Word2Vec, the distributed representation for natural language, we propose a PMLN (Pairwise Multi-Layer Nets) model to learn the distributed representation for multi-field categorical data. In PMLN, a low-dimensional continuous vector is automatically learned for each category in each field. The interactions among inter-field categories are explored by different neural gates and the most informative ones are selected by pooling layers. Such combined categories can be further explored by performing more gate interactions with another category and then selected by additional pooling operations. In our experiments, with the exploration of the interactions between pairwise categories over layers, the model outperforms state-of-the-art models in a supervised learning task, i.e., ad click prediction, while capturing the most significant interactions from the data in an unsupervised fashion.",10.1145/3326937.3341251,https://doi.org/10.1145/3326937.3341251,"New York, NY, USA",Association for Computing Machinery,9781450367837,2019,Pairwise multi-layer nets for learning distributed representation of multi-field categorical data,"Wen, Ying and Chen, Tianyao and Wang, Jun and Zhang, Weinan",inproceedings,10.1145/3326937.3341251,2
10.1145/3336191.3371774,10.1145/3336191.3371774,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","personalization, recommender systems, sparse linear model",9,555–563,Proceedings of the 13th International Conference on Web Search and Data Mining,"The Sparse Linear Method (SLIM) is a well-established approach for top-N recommendations. This article proposes several improvements that are enabled by the Alternating Directions Method of Multipliers (ADMM), a well-known optimization method with many application areas. First, we show that optimizing the original SLIM-objective by ADMM results in an approach where the training time is independent of the number of users in the training data, and hence trivially scales to large numbers of users. Second, the flexibility of ADMM allows us to switch on and off the various constraints and regularization terms in the original SLIM-objective, in order to empirically assess their contributions to ranking accuracy on given data. Third, we also propose two extensions to the original SLIM training-objective in order to improve recommendation accuracy further without increasing the computational cost. In our experiments on three well-known data-sets, we first compare to the original SLIM-implementation and find that not only ADMM reduces training time considerably, but also achieves an improvement in recommendation accuracy due to better optimization. We then compare to various state-of-the-art approaches and observe up to 25% improvement in recommendation accuracy in our experiments. Finally, we evaluate the importance of sparsity and the non-negativity constraint in the original SLIM-objective with sub-sampling experiments that simulate scenarios of cold-starting and large catalog sizes compared to relatively small user base, which often occur in practice.",10.1145/3336191.3371774,https://doi.org/10.1145/3336191.3371774,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,ADMM SLIM: Sparse Recommendations for Many Users,"Steck, Harald and Dimakopoulou, Maria and Riabov, Nickolai and Jebara, Tony",inproceedings,10.1145/3336191.3371774,
10.1145/3336191.3371783,10.1145/3336191.3371783,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","implicit feedback, inverse propensity weighting, matrix factorization., missing-not-at-random, positive-unlabeled learning",9,501–509,Proceedings of the 13th International Conference on Web Search and Data Mining,"Recommender systems widely use implicit feedback such as click data because of its general availability. Although the presence of clicks signals the users' preference to some extent, the lack of such clicks does not necessarily indicate a negative response from the users, as it is possible that the users were not exposed to the items (positive-unlabeled problem). This leads to a difficulty in predicting the users' preferences from implicit feedback. Previous studies addressed the positive-unlabeled problem by uniformly upweighting the loss for the positive feedback data or estimating the confidence of each data having relevance information via the EM-algorithm. However, these methods failed to address the missing-not-at-random problem in which popular or frequently recommended items are more likely to be clicked than other items even if a user does not have a considerable interest in them. To overcome these limitations, we first define an ideal loss function to be optimized to realize recommendations that maximize the relevance and propose an unbiased estimator for the ideal loss. Subsequently, we analyze the variance of the proposed unbiased estimator and further propose a clipped estimator that includes the unbiased estimator as a special case. We demonstrate that the clipped estimator is expected to improve the performance of the recommender system, by considering the bias-variance trade-off. We conduct semi-synthetic and real-world experiments and demonstrate that the proposed method largely outperforms the baselines. In particular, the proposed method works better for less popular items that are less frequently observed in the training data. The findings indicate that the proposed method can better achieve the objective of recommending items with the highest relevance.",10.1145/3336191.3371783,https://doi.org/10.1145/3336191.3371783,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Unbiased Recommender Learning from Missing-Not-At-Random Implicit Feedback,"Saito, Yuta and Yaginuma, Suguru and Nishino, Yuta and Sakata, Hayato and Nakata, Kazuhide",inproceedings,10.1145/3336191.3371783,
10.1145/3336191.3371790,10.1145/3336191.3371790,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","differentiable path-based model, explainable recommendation, knowledge distillation",9,735–743,Proceedings of the 13th International Conference on Web Search and Data Mining,"Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) have been prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide interpretable recommendation reasons.",10.1145/3336191.3371790,https://doi.org/10.1145/3336191.3371790,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation,"Zhang, Yuan and Xu, Xiaoran and Zhou, Hanning and Zhang, Yan",inproceedings,10.1145/3336191.3371790,
10.1145/3336191.3371810,10.1145/3336191.3371810,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","latent representation, polarization, rating distribution, recommendation system",9,762–770,Proceedings of the 13th International Conference on Web Search and Data Mining,"The importance of the distribution of ratings on recommender systems (RS) is well-recognized. And yet, recommendation approaches based on latent factor models and recently introduced neural variants (e.g., NCF) optimize for the head of these distributions, potentially leading to large estimation errors for tail ratings. These errors in tail ratings that are far from the mean predicted rating fall out of a uni-modal assumption underlying these popular models, as we show in this paper. We propose to improve the estimation of tail ratings by extending traditional single latent representations (e.g., an item is represented by a single latent vector) with new multi-latent representations for better modeling these tail ratings. We show how to incorporate these multi-latent representations in an end-to-end neural prediction model that is designed to better reflect the underlying ratings distributions of items. Through experiments over six datasets, we find the proposed model leads to a significant improvement in RMSE versus a suite of benchmark methods. We also find that the predictions for the most polarized items are improved by more than 15%.",10.1145/3336191.3371810,https://doi.org/10.1145/3336191.3371810,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Improving the Estimation of Tail Ratings in Recommender System with Multi-Latent Representations,"Zhao, Xing and Zhu, Ziwei and Zhang, Yin and Caverlee, James",inproceedings,10.1145/3336191.3371810,
10.1145/3336191.3371811,10.1145/3336191.3371811,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","attention, autoencoder, deep learning, diffusion, social network",9,510–518,Proceedings of the 13th International Conference on Web Search and Data Mining,"Recent years have witnessed tremendous interest in understanding and predicting information spread on social media platforms such as Twitter, Facebook, etc. Existing diffusion prediction methods primarily exploit the sequential order of influenced users by projecting diffusion cascades onto their local social neighborhoods. However, this fails to capture global social structures that do not explicitly manifest in any of the cascades, resulting in poor performance for inactive users with limited historical activities.  In this paper, we present a novel variational autoencoder framework (Inf-VAE) to jointly embed homophily and influence through proximity-preserving social and position-encoded temporal latent variables. To model social homophily, Inf-VAE utilizes powerful graph neural network architectures to learn social variables that selectively exploit the social connections of users. Given a sequence of seed user activations, Inf-VAE uses a novel expressive co-attentive fusion network that jointly attends over their social and temporal variables to predict the set of all influenced users. Our experimental results on multiple real-world social network datasets, including Digg, Weibo, and Stack-Exchanges demonstrate significant gains (22% MAP@10) for Inf-VAE over state-of-the-art diffusion prediction models; we achieve massive gains for users with sparse activities, and users who lack direct social neighbors in seed sets.",10.1145/3336191.3371811,https://doi.org/10.1145/3336191.3371811,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Inf-VAE: A Variational Autoencoder Framework to Integrate Homophily and Influence in Diffusion Prediction,"Sankar, Aravind and Zhang, Xinyang and Krishnan, Adit and Han, Jiawei",inproceedings,10.1145/3336191.3371811,
10.1145/3336191.3371821,10.1145/3336191.3371821,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","epidemic models, hawkes processes, information diffusion",9,286–294,Proceedings of the 13th International Conference on Web Search and Data Mining,"Epidemic models and self-exciting processes are two types of models used to describe diffusion phenomena online and offline. These models were originally developed in different scientific communities, and their commonalities are under-explored. This work establishes, for the first time, a general connection between the two model classes via three new mathematical components. The first is a generalized version of stochastic Susceptible-Infected-Recovered (SIR) model with arbitrary recovery time distributions; the second is the relationship between the (latent and arbitrary) recovery time distribution, recovery hazard function, and the infection kernel of self-exciting processes; the third includes methods for simulating, fitting, evaluating and predicting the generalized process. On three large Twitter diffusion datasets, we conduct goodness-of-fit tests and holdout log-likelihood evaluation of self-exciting processes with three infection kernels --- exponential, power-law and Tsallis Q-exponential. We show that the modeling performance of the infection kernels varies with respect to the temporal structures of diffusions, and also with respect to user behavior, such as the likelihood of being bots. We further improve the prediction of popularity by combining two models that are identified as complementary by the goodness-of-fit tests.",10.1145/3336191.3371821,https://doi.org/10.1145/3336191.3371821,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Modeling Information Cascades with Self-exciting Processes via Generalized Epidemic Models,"Kong, Quyu and Rizoiu, Marian-Andrei and Xie, Lexing",inproceedings,10.1145/3336191.3371821,
10.1145/3336191.3371826,10.1145/3336191.3371826,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","graph neural networks, key opinion leaders, recommendation",9,636–644,Proceedings of the 13th International Conference on Web Search and Data Mining,"Recommendation systems typically rely on the interactions between a crowd of ordinary users and items, ignoring the fact that many real-world communities are notably influenced by a small group of key opinion leaders, whose feedback on items wields outsize influence. With important positions in the community (e.g. have a large number of followers), their elite opinions are able to diffuse to the community and further impact what items we buy, what media we consume, and how we interact with online platforms. Hence, this paper investigates how to develop a novel recommendation system by explicitly capturing the influence from key opinion leaders to the whole community. Centering around opinion elicitation and diffusion, we propose an end-to-end Graph-based neural model - GoRec. Specifically, to preserve the multi-relations between key opinion leaders and items, GoRec elicits the opinions from key opinion leaders with a translation-based embedding method. Moreover, GoRec adopts the idea of Graph Neural Networks to model the elite opinion diffusion process for improved recommendation. Through experiments on Goodreads and Epinions, the proposed model outperforms state-of-the-art approaches by 10.75% and 9.28% on average in Top-K item recommendation.",10.1145/3336191.3371826,https://doi.org/10.1145/3336191.3371826,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Key Opinion Leaders in Recommendation Systems: Opinion Elicitation and Diffusion,"Wang, Jianling and Ding, Kaize and Zhu, Ziwei and Zhang, Yin and Caverlee, James",inproceedings,10.1145/3336191.3371826,
10.1145/3336191.3371834,10.1145/3336191.3371834,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","cascading effect, graph neural networks, network-aware, popularity prediction",9,70–78,Proceedings of the 13th International Conference on Web Search and Data Mining,"Predicting the popularity of online content on social platforms is an important task for both researchers and practitioners. Previous methods mainly leverage demographics, temporal and structural patterns of early adopters for popularity prediction. However, most existing methods are less effective to precisely capture the cascading effect in information diffusion, in which early adopters try to activate potential users along the underlying network. In this paper, we consider the problem of network-aware popularity prediction, leveraging both early adopters and social networks for popularity prediction. We propose to capture the cascading effect explicitly, modeling the activation state of a target user given the activation state and influence of his/her neighbors. To achieve this goal, we propose a novel method, namely CoupledGNN, which uses two coupled graph neural networks to capture the interplay between node activation states and the spread of influence. By stacking graph neural network layers, our proposed method naturally captures the cascading effect along the network in a successive manner. Experiments conducted on both synthetic and real-world Sina Weibo datasets demonstrate that our method significantly outperforms the state-of-the-art methods for popularity prediction.",10.1145/3336191.3371834,https://doi.org/10.1145/3336191.3371834,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Popularity Prediction on Social Platforms with Coupled Graph Neural Networks,"Cao, Qi and Shen, Huawei and Gao, Jinhua and Wei, Bingzheng and Cheng, Xueqi",inproceedings,10.1145/3336191.3371834,
10.1145/3336191.3371855,10.1145/3336191.3371855,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","machine learning fairness, marketing bias, recommender systems",9,618–626,Proceedings of the 13th International Conference on Web Search and Data Mining,"Modern collaborative filtering algorithms seek to provide personalized product recommendations by uncovering patterns in consumer-product interactions. However, these interactions can be biased by how the product is marketed, for example due to the selection of a particular human model in a product image. These correlations may result in the underrepresentation of particular niche markets in the interaction data; for example, a female user who would potentially like motorcycle products may be less likely to interact with them if they are promoted using stereotypically 'male' images.In this paper, we first investigate this correlation between users' interaction feedback and products' marketing images on two real-world e-commerce datasets. We further examine the response of several standard collaborative filtering algorithms to the distribution of consumer-product market segments in the input interaction data, revealing that marketing strategy can be a source of bias for modern recommender systems. In order to protect recommendation performance on underrepresented market segments, we develop a framework to address this potential marketing bias. Quantitative results demonstrate that the proposed approach significantly improves the recommendation fairness across different market segments, with a negligible loss (or better) recommendation accuracy.",10.1145/3336191.3371855,https://doi.org/10.1145/3336191.3371855,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Addressing Marketing Bias in Product Recommendations,"Wan, Mengting and Ni, Jianmo and Misra, Rishabh and McAuley, Julian",inproceedings,10.1145/3336191.3371855,
10.1145/3336191.3372182,10.1145/3336191.3372182,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","heterogeneous networks, network embedding, personalization",2,927–928,Proceedings of the 13th International Conference on Web Search and Data Mining,"Complex systems in different disciplines are usually modeled as heterogeneous networks. Different from homogeneous networks or attributed networks, heterogeneous networks are associated with complexity in heterogeneous structure or heterogeneous content or both. The abundant information in heterogeneous networks provide opportunities yet pose challenges for researchers and practitioners to develop customized machine learning solutions for solving different problems in complex systems. We are motivated to do significant work for learning from heterogeneous networks. In this paper, we first introduce the motivation and background of this research. Later, we present our current work which include a series of proposed methods and applications. These methods will be introduced in the perspectives of personalization in web-based systems and heterogeneous network embedding. In the end, we raise several research directions as future agenda.",10.1145/3336191.3372182,https://doi.org/10.1145/3336191.3372182,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Learning from Heterogeneous Networks: Methods and Applications,"Zhang, Chuxu",inproceedings,10.1145/3336191.3372182,
10.1145/3336191.3372183,10.1145/3336191.3372183,WSDM.bib,1,['WSDM.bib'],8,WSDM '20,"Houston, TX, USA","hybrid utility, recommender system, unexpectedness",2,923–924,Proceedings of the 13th International Conference on Web Search and Data Mining,"Unexpectedness constitutes an important factor for recommender system to improve user satisfaction and avoid filter bubble issues. In this proposal, we propose to provide unexpected recommendations using the hybrid utility function as a mixture of estimated ratings, unexpectedness, relevance and annoyance. We plan to conduct extensive experiments to validate the superiority of the proposed method.",10.1145/3336191.3372183,https://doi.org/10.1145/3336191.3372183,"New York, NY, USA",Association for Computing Machinery,9781450368223,2020,Hybrid Utility Function for Unexpected Recommendations,"Li, Pan",inproceedings,10.1145/3336191.3372183,
10.1145/3340531.3411861,10.1145/3340531.3411861,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","self-exciting processes, reshare cascades, online information diffusion, dual mixture processes, Hawkes processes",10,645–654,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"It is well-known that online behavior is long-tailed, with most cascaded actions being short and a few being very long. A prominent drawback in generative models for online events is the inability to describe unpopular items well. This work addresses these shortcomings by proposing dual mixture self-exciting processes to jointly learn from groups of cascades. We first start from the observation that maximum likelihood estimates for content virality and influence decay are separable in a Hawkes process. Next, our proposed model, which leverages a Borel mixture model and a kernel mixture model, jointly models the unfolding of a heterogeneous set of cascades. When applied to cascades of the same online items, the model directly characterizes their spread dynamics and supplies interpretable quantities, such as content virality and content influence decay, as well as methods for predicting the final content popularities. On two retweet cascade datasets --- one relating to YouTube videos and the second relating to controversial news articles --- we show that our models capture the differences between online items at the granularity of items, publishers and categories. In particular, we are able to distinguish between far-right, conspiracy, controversial and reputable online news articles based on how they diffuse through social media, achieving an F1 score of 0.945. On holdout datasets, we show that the dual mixture model provides, for reshare diffusion cascades especially unpopular ones, better generalization performance and, for online items, accurate item popularity predictions.",10.1145/3340531.3411861,https://doi.org/10.1145/3340531.3411861,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Describing and Predicting Online Items with Reshare Cascades via Dual Mixture Self-exciting Processes,"Kong, Quyu and Rizoiu, Marian-Andrei and Xie, Lexing",inproceedings,10.1145/3340531.3411861,
10.1145/3340531.3411884,10.1145/3340531.3411884,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","shilling attack, recommender systems, generative adversarial network",10,855–864,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Recommendation Systems (RS) have become an essential part of many online services. Due to its pivotal role in guiding customers towards purchasing, there is a natural motivation for unscrupulous parties to spoof RS for profits. In this paper, we study the shilling attack: a subsistent and profitable attack where an adversarial party injects a number of user profiles to promote or demote a target item. Conventional shilling attack models are based on simple heuristics that can be easily detected, or directly adopt adversarial attack methods without a special design for RS. Moreover, the study on the attack impact on deep learning based RS is missing in the literature, making the effects of shilling attack against real RS doubtful. We present a novel Augmented Shilling Attack framework (AUSH) and implement it with the idea of Generative Adversarial Network. AUSH is capable of tailoring attacks against RS according to budget and complex attack goals, such as targeting a specific user group. We experimentally show that the attack impact of AUSH is noticeable on a wide range of RS including both classic and modern deep learning based RS, while it is virtually undetectable by the state-of-the-art attack detection model.",10.1145/3340531.3411884,https://doi.org/10.1145/3340531.3411884,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Attacking Recommender Systems with Augmented User Profiles,"Lin, Chen and Chen, Si and Li, Hui and Xiao, Yanghua and Li, Lianyun and Yang, Qian",inproceedings,10.1145/3340531.3411884,
10.1145/3340531.3411904,10.1145/3340531.3411904,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","review-driven answer generation, question answering, opinion mining, e-commerce",10,255–264,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Product-related question answering (QA) is an important but challenging task in E-Commerce. It leads to a great demand on automatic review-driven QA, which aims at providing instant responses towards user-posted questions based on diverse product reviews. Nevertheless, the rich information about personal opinions in product reviews, which is essential to answer those product-specific questions, is underutilized in current generation-based review-driven QA studies. There are two main challenges when exploiting the opinion information from the reviews to facilitate the opinion-aware answer generation: (i) jointly modeling opinionated and interrelated information between the question and reviews to capture important information for answer generation, (ii) aggregating diverse opinion information to uncover the common opinion towards the given question. In this paper, we tackle opinion-aware answer generation by jointly learning answer generation and opinion mining tasks with a unified model. Two kinds of opinion fusion strategies, namely, static and dynamic fusion, are proposed to distill and aggregate important opinion information learned from the opinion mining task into the answer generation process. Then a multi-view pointer-generator network is employed to generate opinion-aware answers for a given product-related question. Experimental results show that our method achieves superior performance in real-world E-Commerce QA datasets, and effectively generate opinionated and informative answers.",10.1145/3340531.3411904,https://doi.org/10.1145/3340531.3411904,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Opinion-aware Answer Generation for Review-driven Question Answering in E-Commerce,"Deng, Yang and Zhang, Wenxuan and Lam, Wai",inproceedings,10.1145/3340531.3411904,
10.1145/3340531.3411917,10.1145/3340531.3411917,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","item recommendation, generative adversarial networks, deep learning, convolutional neural networks",10,1773–1782,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Adversarial examples can be detrimental to a recommender,leading to a surging enthusiasm for applying adversarial learning to improve recommendation performance, e.g. raising model robustness, alleviating data sparsity, generating initial profiles for cold-start users or items, etc. Most existing adversarial example generation methods fall within three categories: attacking the user-item interactions or auxiliary contents, adding perturbations in latent space, sampling the latent space according to certain distribution. In this work, we focus on the semantic-rich user-item interactions in a recommender system and propose a novel generative adversarial network (GAN) named Convolutional Generative Collaborative Filtering (Conv-GCF). We develop an effective perturbation mechanism (adversarial noise layer) for convolutional neural networks (CNN), based on which we design a generator with residual blocks to synthesize user-item interactions. We empirically demonstrate that on Conv-GCF, the adversarial noise layer is superior to the conventional noise-adding approach. Moreover, we propose two types of discriminators: one using Bayes Personalized Ranking (BPR) and the other with binary classification. On four public datasets, we show that our approach achieves the state-of-the-art top-n recommendation performance among competitive baselines.",10.1145/3340531.3411917,https://doi.org/10.1145/3340531.3411917,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Exploring Missing Interactions: A Convolutional Generative Adversarial Network for Collaborative Filtering,"Yuan, Feng and Yao, Lina and Benatallah, Boualem",inproceedings,10.1145/3340531.3411917,
10.1145/3340531.3411927,10.1145/3340531.3411927,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","representation learning, recommendation, graph neural network, collaborative tagging",10,155–164,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Tag-aware recommender systems (TRS) utilize rich tagging records to better depict user portraits and item features. Recently, many efforts have been done to improve TRS with neural networks. However, these solutions rustically rely on the tag-based features for recommendation, which is insufficient to ease the sparsity, ambiguity and redundancy issues introduced by tags, thus hindering the recommendation performance. In this paper, we propose a novel tag-aware recommendation model named Tag Graph Convolutional Network (TGCN), which leverages the contextual semantics of multi-hop neighbors in the user-tag-item graph to alleviate the above issues. Specifically, TGCN first employs type-aware neighbor sampling and aggregation operation to learn the type-specific neighborhood representations. Then we leverage attention mechanism to discriminate the importance of different node types and creatively employ Convolutional Neural Network (CNN) as type-level aggregator to perform vertical and horizontal convolutions for modeling multi-granular feature interactions. Besides, a TransTag regularization function is proposed to accurately identify user's substantive preference. Extensive experiments on three public datasets and a real industrial dataset show that TGCN significantly outperforms state-of-the-art baselines for tag-aware top-N recommendation.",10.1145/3340531.3411927,https://doi.org/10.1145/3340531.3411927,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,TGCN: Tag Graph Convolutional Network for Tag-Aware Recommendation,"Chen, Bo and Guo, Wei and Tang, Ruiming and Xin, Xin and Ding, Yue and He, Xiuqiang and Wang, Dong",inproceedings,10.1145/3340531.3411927,
10.1145/3340531.3411933,10.1145/3340531.3411933,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","thread recommendation, recommender systems, online health community, neural network, latent dirichlet allocation, discussion forum",10,765–774,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Online health communities (OHCs) provide a popular channel for users to seek information, suggestions and support during their medical treatment and recovery processes. To help users find relevant information easily, we present CLIR, an effective system for recommending relevant discussion threads to users in OHCs. We identify that thread content and user interests can be categorized in two dimensions: topics and concepts. CLIR leverages Latent Dirichlet Allocation model to summarize the topic dimension and uses Convolutional Neural Network to encode the concept dimension. It then builds a thread neural network to capture thread characteristics and builds a user neural network to capture user interests by integrating these two dimensions and their interactions. Finally, it matches the target thread's characteristics with candidate users' interests to make recommendations. Experimental evaluation with multiple OHC datasets demonstrates the performance advantage of CLIR over the state-of-the-art recommender systems on various evaluation metrics.",10.1145/3340531.3411933,https://doi.org/10.1145/3340531.3411933,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,A Topic and Concept Integrated Model for Thread Recommendation in Online Health Communities,"Li, Mingda and Gao, Weiting and Chen, Yi",inproceedings,10.1145/3340531.3411933,
10.1145/3340531.3411939,10.1145/3340531.3411939,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","sequence modeling, review-based recommendation, review-aware graph attention network, multi-view representation learning",10,395–404,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Existing review-based recommendation models mainly learn long- term user and item representations from a set of reviews. Due to the ignorance of rich side information of reviews, these models suffer from two drawbacks: 1) they fail to capture short-term changes of user preferences and item features reflected in reviews and 2) they cannot accurately model high-order user-item collaborative signals from reviews. To overcome these limitations, we propose a multi-view approach named Set-Sequence-Graph (SSG), to augment existing single-view (i.e., view of set) methods by introducing two additional views of exploiting reviews: sequence and graph. In particular, with reviews organized in forms of set, sequence, and graph respectively, we design a three-way encoder architecture that jointly captures long-term (set), short-term (sequence), and collaborative (graph) features of users and items for recommendation. For the sequence encoder, we propose a short-term priority attention network that explicitly takes the order and personalized time intervals of reviews into consideration. For the graph encoder, we design a novel review-aware graph attention network to model high-order multi-aspect relations in the user-item graph. To combat the potential redundancy in captured features, our fusion module employs a cross-view decorrelation mechanism to encourage diverse representations from multiple views for integration. Experiments on public datasets demonstrate that SSG significantly outperforms state-of-the-art methods.",10.1145/3340531.3411939,https://doi.org/10.1145/3340531.3411939,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Set-Sequence-Graph: A Multi-View Approach Towards Exploiting Reviews for Recommendation,"Gao, Jingyue and Lin, Yang and Wang, Yasha and Wang, Xiting and Yang, Zhao and He, Yuanduo and Chu, Xu",inproceedings,10.1145/3340531.3411939,
10.1145/3340531.3411952,10.1145/3340531.3411952,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","sequential recommendation, recurrent neural network, information dissemination, e-commerce recommendation, attention",10,785–794,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"For better user satisfaction and business effectiveness, Click-Through Rate (CTR) prediction is one of the most important tasks in E-commerce. It is often the case that users' interests different from their past routines may emerge or impressions such as promotional items may burst in a very short period. In essence, such changes relate to item evolution problem, which has not been investigated by previous studies. The state-of-the-art methods in the sequential recommendation, which use simple user behaviors, are incapable of modeling these changes sufficiently. It is because, in the user behaviors, outdated interests may exist and the popularity of an item over time is not well represented. To address these limitations, we introduce time-aware item behaviors for addressing the recommendation of emerging preference. The time-aware item behavior for an item is a set of users who interact with this item with timestamps. The rich interaction information of users for an item may help to model its evolution. In this work, we propose a CTR prediction model TIEN based on the time-aware item behavior. In TIEN, by leveraging the interaction time intervals, information of similar users in a short time interval helps identify the emerging user interest of the target user. By using the sequential time intervals, the item's popularity over time can be captured in evolutionary item dynamics. Noisy users who interact with items accidentally are further eliminated thus learning robust personalized item dynamics. To the best of our knowledge, this is the first study to the item evolution problem for E-commerce CTR prediction. We conduct extensive experiments on five real-world CTR prediction datasets. The results show that the TIEN model consistently achieves remarkable improvements to the state-of-the-art methods.",10.1145/3340531.3411952,https://doi.org/10.1145/3340531.3411952,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Deep Time-Aware Item Evolution Network for Click-Through Rate Prediction,"Li, Xiang and Wang, Chao and Tong, Bin and Tan, Jiwei and Zeng, Xiaoyi and Zhuang, Tao",inproceedings,10.1145/3340531.3411952,
10.1145/3340531.3411969,10.1145/3340531.3411969,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","textual information, recommender systems, preference ranking",10,215–224,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Textual data is common and informative auxiliary information for recommender systems. Most prior art utilizes text for rating prediction, but rare work connects it to top-recommendation. Moreover, although advanced recommendation models capable of incorporating auxiliary information have been developed, none of these are specifically designed to model textual information, yielding a limited usage scenario for typical user-to-item recommendation. In this work, we present a framework of text-aware preference ranking (TPR) for top- recommendation, in which we comprehensively model the joint association of user-item interaction and relations between items and associated text. Using the TPR framework, we construct a joint likelihood function that explicitly describes two ranking structures: 1) item preference ranking (IPR) and 2) word relatedness ranking (WRR), where the former captures the item preference of each user and the latter captures the word relatedness of each item. As these two explicit structures are by nature mutually dependent, we propose TPR-OPT, a simple yet effective learning criterion that additionally includes implicit structures, such as relatedness between items and relatedness between words for each user for model optimization. Such a design not only successfully describes the joint association among users, words, and text comprehensively but also naturally yields powerful representations that are suitable for a range of recommendation tasks, including user-to-item, item-to-item, and user-to-word recommendation, as well as item-to-word reconstruction. In this paper, extensive experiments have been conducted on eight recommendation datasets, the results of which demonstrate that by including textual information from item descriptions, the proposed TPR model consistently outperforms state-of-the-art baselines on various recommendation tasks.",10.1145/3340531.3411969,https://doi.org/10.1145/3340531.3411969,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,TPR: Text-aware Preference Ranking for Recommender Systems,"Chuang, Yu-Neng and Chen, Chih-Ming and Wang, Chuan-Ju and Tsai, Ming-Feng and Fang, Yuan and Lim, Ee-Peng",inproceedings,10.1145/3340531.3411969,
10.1145/3340531.3411978,10.1145/3340531.3411978,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","weakly supervised binary classification, review helpfulness classification, recommendation, negative confidence",10,1565–1574,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"The incompleteness of positive labels and the presence of many unlabelled instances are common problems in binary classification applications such as in review helpfulness classification. Various studies from the classification literature consider all unlabelled instances as negative examples. However, a classification model that learns to classify binary instances with incomplete positive labels while assuming all unlabelled data to be negative examples will often generate a biased classifier. In this work, we propose a novel Negative Confidence-aware Weakly Supervised approach (NCWS), which customises a binary classification loss function by discriminating the unlabelled examples with different negative confidences during the classifier's training. NCWS allows to effectively, unbiasedly identify and separate positive and negative instances after its integration into various binary classifiers from the literature, including SVM, CNN and BERT-based classifiers. We use the review helpfulness classification as a test case for examining the effectiveness of our NCWS approach. We thoroughly evaluate NCWS by using three different datasets, namely one from Yelp (venue reviews), and two from Amazon (Kindle and Electronics reviews). Our results show that NCWS outperforms strong baselines from the literature including an existing SVM-based approach (i.e. SVM-P), the positive and unlabelled learning-based approach (i.e. C-PU) and the positive confidence-based approach (i.e. P-conf) in addressing the classifier's bias problem. Moreover, we further examine the effectiveness of NCWS by using its classified helpful reviews in a state-of-the-art review-based venue recommendation model (i.e. DeepCoNN) and demonstrate the benefits of using NCWS in enhancing venue recommendation effectiveness in comparison to the baselines.",10.1145/3340531.3411978,https://doi.org/10.1145/3340531.3411978,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Negative Confidence-Aware Weakly Supervised Binary Classification for Effective Review Helpfulness Classification,"Wang, Xi and Ounis, Iadh and Macdonald, Craig",inproceedings,10.1145/3340531.3411978,
10.1145/3340531.3411992,10.1145/3340531.3411992,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","recommender systems, neural template explanation, natural language generation, explainable recommendation",10,755–764,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Personalized recommender systems are important to assist user decision-making in the era of information overload. Meanwhile, explanations of the recommendations further help users to better understand the recommended items so as to make informed choices, which gives rise to the importance of explainable recommendation research. Textual sentence-based explanation has been an important form of explanations for recommender systems due to its advantage in communicating rich information to users. However, current approaches to generating sentence explanations are either limited to predefined sentence templates, which restricts the sentence expressiveness, or opt for free-style sentence generation, which makes it difficult for sentence quality control. In an attempt to benefit both sentence expressiveness and quality, we propose a Neural Template (NETE) explanation generation framework, which brings the best of both worlds by learning sentence templates from data and generating template-controlled sentences that comment about specific features. Experimental results on real-world datasets show that NETE consistently outperforms state-of-the-art explanation generation approaches in terms of sentence quality and expressiveness. Further analysis on case study also shows the advantages of NETE on generating diverse and controllable explanations.",10.1145/3340531.3411992,https://doi.org/10.1145/3340531.3411992,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Generate Neural Template Explanations for Recommendation,"Li, Lei and Zhang, Yongfeng and Chen, Li",inproceedings,10.1145/3340531.3411992,
10.1145/3340531.3411993,10.1145/3340531.3411993,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","recommendation systems, psychological bias, probability weight function, expected utility, economic recommendation",10,1695–1704,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Different from shopping at retail stores, consumers on e-commerce platforms usually cannot touch or try products before purchasing, which means that they have to make decisions when they are uncertain about the outcome (e.g., satisfaction level) of purchasing a product. To study people's preferences with regard to choices that have uncertain outcomes, economics researchers have proposed the hypothesis of Expected Utility (EU) that models the subject value associated with an individual's choice as the statistical expectations of that individual's valuations of the outcomes of this choice. Despite its success in studies of game theory and decision theory, the effectiveness of EU, however, is mostly unknown in e-commerce recommendation systems. Previous research on e-commerce recommendation interprets the utility of purchase decisions either as a function of the consumed quantity of the product or as the gain of sellers/buyers in the monetary sense. As most consumers just purchase one unit of a product at a time and most alternatives have similar prices, such modeling of purchase utility is likely to be inaccurate in practice. In this paper, we interpret purchase utility as the satisfaction level a consumer gets from a product and propose a recommendation framework using EU to model consumers' behavioral patterns. We assume that consumer estimates the expected utilities of all the alternatives and choose products with maximum expected utility for each purchase. To deal with the potential psychological biases of each consumer, we introduce the usage of Probability Weight Function (PWF) and design our algorithm based on Weighted Expected Utility (WEU). Empirical study on real-world e-commerce datasets shows that our proposed ranking-based recommendation framework achieves statistically significant improvement against both classical Collaborative Filtering/Latent Factor Models and state-of-the-art deep models in top-K recommendation.",10.1145/3340531.3411993,https://doi.org/10.1145/3340531.3411993,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,E-commerce Recommendation with Weighted Expected Utility,"Xu, Zhichao and Han, Yi and Zhang, Yongfeng and Ai, Qingyao",inproceedings,10.1145/3340531.3411993,
10.1145/3340531.3411996,10.1145/3340531.3411996,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","heterogeneous information network, graph neural network, disentangled representation learning, collaborative filtering",10,1605–1614,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Heterogeneous information network has been widely used to alleviate sparsity and cold start problems in recommender systems since it can model rich context information in user-item interactions. Graph neural network is able to encode this rich context information through propagation on the graph. However, existing heterogeneous graph neural networks neglect entanglement of the latent factors stemming from different aspects. Moreover, meta paths in existing approaches are simplified as connecting paths or side information between node pairs, overlooking the rich semantic information in the paths. In this paper, we propose a novel disentangled heterogeneous graph attention network DisenHAN for top-N recommendation, which learns disentangled user/item representations from different aspects in a heterogeneous information network. In particular, we use meta relations to decompose high-order connectivity between node pairs and propose a disentangled embedding propagation layer which can iteratively identify the major aspect of meta relations. Our model aggregates corresponding aspect features from each meta relation for the target user/item. With different layers of embedding propagation, DisenHAN is able to explicitly capture the collaborative filtering effect semantically. Extensive experiments on three real-world datasets show that DisenHAN consistently outperforms state-of-the-art approaches. We further demonstrate the effectiveness and interpretability of the learned disentangled representations via insightful case studies and visualization.",10.1145/3340531.3411996,https://doi.org/10.1145/3340531.3411996,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,DisenHAN: Disentangled Heterogeneous Graph Attention Network for Recommendation,"Wang, Yifan and Tang, Suyao and Lei, Yuntong and Song, Weiping and Wang, Sheng and Zhang, Ming",inproceedings,10.1145/3340531.3411996,
10.1145/3340531.3412025,10.1145/3340531.3412025,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","temporal point processes, hashtag popularity prediction",10,1335–1344,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Temporal point process (TPP) models have hitherto been moderately good at nowcasting hashtag popularity, but have been very poor at forecasting due to insufficient modeling of Twitter microdynamics. Recent studies have shown that the highly fluctuating nature of hashtag popularity dynamics is due to the influence of two external factors: (i) hashtag-tweet reinforcement and (ii) inter-hashtag competition. In this paper, we propose a marked TPP based on Generative Adversarial Networks (GANs) which can seamlessly incorporate the assistive information necessary to capture the above effects and successfully forecast distant popularity trends. To achieve this, we employ a unique linear semi-autoregressive model for mark generation and couple the time and mark generative aspects. On seven diverse datasets crawled from Twitter covering several real-world events, our model yields remarkably stable performance in predicting hashtag popularity in diverse situations and offers a substantial improvement over the existing state of the art generative models.",10.1145/3340531.3412025,https://doi.org/10.1145/3340531.3412025,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,A GAN-based Framework for Modeling Hashtag Popularity Dynamics Using Assistive Information,"Saha, Avirup and Ganguly, Niloy",inproceedings,10.1145/3340531.3412025,
10.1145/3340531.3412038,10.1145/3340531.3412038,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","recommender systems, path reasoning, neural symbolic reasoning, knowledge graph, explainable recommendation",10,1645–1654,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Recent research explores incorporating knowledge graphs (KG) into e-commerce recommender systems, not only to achieve better recommendation performance, but more importantly to generate explanations of why particular decisions are made. This can be achieved by explicit KG reasoning, where a model starts from a user node, sequentially determines the next step, and walks towards an item node of potential interest to the user. However, this is challenging due to the huge search space, unknown destination, and sparse signals over the KG, so informative and effective guidance is needed to achieve a satisfactory recommendation quality. To this end, we propose a CoArse-to-FinE neural symbolic reasoning approach (CAFE). It first generates user profiles as coarse sketches of user behaviors, which subsequently guide a path-finding process to derive reasoning paths for recommendations as fine-grained predictions. User profiles can capture prominent user behaviors from the history, and provide valuable signals about which kinds of path patterns are more likely to lead to potential items of interest for the user. To better exploit the user profiles, an improved path-finding algorithm called Profile-guided Path Reasoning (PPR) is also developed, which leverages an inventory of neural symbolic reasoning modules to effectively and efficiently find a batch of paths over a large-scale KG. We extensively experiment on four real-world benchmarks and observe substantial gains in the recommendation performance compared with state-of-the-art methods.",10.1145/3340531.3412038,https://doi.org/10.1145/3340531.3412038,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,CAFE: Coarse-to-Fine Neural Symbolic Reasoning for Explainable Recommendation,"Xian, Yikun and Fu, Zuohui and Zhao, Handong and Ge, Yingqiang and Chen, Xu and Huang, Qiaoying and Geng, Shijie and Qin, Zhou and de Melo, Gerard and Muthukrishnan, S. and Zhang, Yongfeng",inproceedings,10.1145/3340531.3412038,
10.1145/3340531.3412152,10.1145/3340531.3412152,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","recommender systems, popularity bias amplification, feedback loop, algorithmic bias",4,2145–2148,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Recommendation algorithms are known to suffer from popularity bias; a few popular items are recommended frequently while the majority of other items are ignored. These recommendations are then consumed by the users, their reaction will be logged and added to the system: what is generally known as a feedback loop. In this paper, we propose a method for simulating the users interaction with the recommenders in an offline setting and study the impact of feedback loop on the popularity bias amplification of several recommendation algorithms. We then show how this bias amplification leads to several other problems such as declining the aggregate diversity, shifting the representation of users' taste over time and also homogenization of the users. In particular, we show that the impact of feedback loop is generally stronger for the users who belong to the minority group.",10.1145/3340531.3412152,https://doi.org/10.1145/3340531.3412152,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Feedback Loop and Bias Amplification in Recommender Systems,"Mansoury, Masoud and Abdollahpouri, Himan and Pechenizkiy, Mykola and Mobasher, Bamshad and Burke, Robin",inproceedings,10.1145/3340531.3412152,
10.1145/3340531.3412711,10.1145/3340531.3412711,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","jobs marketplace, impression pacing",8,2445–2452,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"The goal of Jobs Marketplace at LinkedIn is to match members to promoted job postings such that both job posters' ROI is optimized (amount of money spent per job clicks and applications) and the members are presented with relevant jobs that they are interested in and qualified for. This is achieved via a first-price auction mechanism where each job provides a bid for the member that comes to the job recommendations page. This bid depends on the match of the member to the job, as well as the daily budget that remains for the job, and its capability to spend it via clicks (e.g. some jobs might have more demand and have it easier to spend their budgets via clicks than others). In such a scheme, budget pacing, i.e. the capability of a job to spend its daily budget evenly, or according to a preset plan, is extremely important towards efficient utilization of its budget via reaching a higher number of candidates, and obey a variety of spending plans optimizing for different events such as clicks and applications.In this paper, we propose an impression-based spend computation system, hence an impression-based pacing scheme. This approach works via assigning a projected/expected charge amount each time a job is shown to the user, taking into account both the likelihood that the user will click the job, and the recommender system specific considerations such as the order within a page that a job is recommended. The results of our alternate-day test shows that such a scheme leads to a smoother spending and improved adherence to the planned spend, and increases secondary metrics such as job clicks and applications.",10.1145/3340531.3412711,https://doi.org/10.1145/3340531.3412711,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Impression Pacing for Jobs Marketplace at LinkedIn,"Geyik, Sahin Cem and Chowdhury, Luthfur and Raudies, Florian and Pu, Wen and Shen, Jianqiang",inproceedings,10.1145/3340531.3412711,
10.1145/3340531.3412740,10.1145/3340531.3412740,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","vertical e-commerce search, query-aware generation, abstractive tip generation",8,2893–2900,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"As a concise form of user reviews, tips have unique advantages to explain the search results, assist users' decision making, and further improve user experience in vertical search scenarios. Existing work on tip generation does not take query into consideration, which limits the impact of tips in search scenarios. To address this issue, this paper proposes a query-aware tip generation framework, integrating query information into encoding and subsequent decoding processes. Two specific adaptations of Transformer and Recurrent Neural Network (RNN) are proposed. For Transformer, the query impact is incorporated into the self-attention computation of both the encoder and the decoder. As for RNN, the query-aware encoder adopts a selective network to distill query-relevant information from the review, while the query-aware decoder integrates the query information into the attention computation during decoding. The framework consistently outperforms the competing methods on both public and real-world industrial datasets. Last but not least, online deployment experiments on Dianping demonstrate the advantage of the proposed framework for tip generation as well as its online business values.",10.1145/3340531.3412740,https://doi.org/10.1145/3340531.3412740,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,Query-aware Tip Generation for Vertical Search,"Yang, Yang and Hao, Junmei and Li, Canjia and Wang, Zili and Wang, Jingang and Zhang, Fuzheng and Fu, Rao and Hou, Peixu and Zhang, Gong and Wang, Zhongyuan",inproceedings,10.1145/3340531.3412740,
10.1145/3340531.3412772,10.1145/3340531.3412772,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","web search, search clarification, mixed-initiative conversation, conversational information seeking, clarifying question",8,3189–3196,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"Search clarification has recently attracted much attention due to its applications in search engines. It has also been recognized as a major component in conversational information seeking systems. Despite its importance, the research community still feels the lack of a large-scale dataset for studying different aspects of search clarification. In this paper, we introduce MIMICS, a collection of search clarification datasets for real web search queries sampled from the Bing query logs. Each clarification in MIMICS is generated by a Bing production algorithm and consists of a clarifying question and up to five candidate answers. MIMICS contains three datasets: (1) MIMICS-Click includes over 400k unique queries, their associated clarification panes, and the corresponding aggregated user interaction signals (i.e., clicks). (2) MIMICS-ClickExplore is an exploration data that includes aggregated user interaction signals for over 60k unique queries, each with multiple clarification panes. (3) MIMICS-Manual includes over 2k unique real search queries. Each query-clarification pair in this dataset has been manually labeled by at least three trained annotators. It contains graded quality labels for the clarifying question, the candidate answer set, and the landing result page for each candidate answer.  MIMICS is publicly available for research purposes, thus enables researchers to study a number of tasks related to search clarification, including clarification generation and selection, user engagement prediction for clarification, click models for clarification, and analyzing user interactions with search clarification. We also release the results returned by the Bing's web search API for all the queries in MIMICS. This would allow researchers to utilize search results for the tasks related to search clarification.",10.1145/3340531.3412772,https://doi.org/10.1145/3340531.3412772,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,MIMICS: A Large-Scale Data Collection for Search Clarification,"Zamani, Hamed and Lueck, Gord and Chen, Everest and Quispe, Rodolfo and Luu, Flint and Craswell, Nick",inproceedings,10.1145/3340531.3412772,
10.1145/3340531.3412774,10.1145/3340531.3412774,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","open source, impressions, implicit feedback, dataset, collaborative filtering",8,3093–3100,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"In this article, we introduce the dataset dataset, a collection of implicit interactions and impressions of movies and TV series from an Over-The-Top media service, which delivers its media contents over the Internet. The dataset is distinguished from other already available multimedia recommendation datasets by the availability of impressions, idest the recommendations shown to the user, its size, and by being open-source. We describe the data collection process, the preprocessing applied, its characteristics, and statistics when compared to other commonly used datasets. We also highlight several possible use cases and research questions that can benefit from the availability of user impressions in an open-source dataset. Furthermore, we release software tools to load and split the data, as well as examples of how to use both user interactions and impressions in several common recommendation algorithms.",10.1145/3340531.3412774,https://doi.org/10.1145/3340531.3412774,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,ContentWise Impressions: An Industrial Dataset with Impressions Included,"P\'{e}rez Maurera, Fernando B. and Ferrari Dacrema, Maurizio and Saule, Lorenzo and Scriminaci, Mario and Cremonesi, Paolo",inproceedings,10.1145/3340531.3412774,
10.1145/3340531.3412778,10.1145/3340531.3412778,CIKM.bib,1,['CIKM.bib'],8,CIKM '20,"Virtual Event, Ireland","support software, recommender systems, experiments, evaluation",8,2999–3006,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,"LensKit is an open-source toolkit for building, researching, and learning about recommender systems. First released in 2010 as a Java framework, it has supported diverse published research, small-scale production deployments, and education in both MOOC and traditional classroom settings. In this paper, I present the next generation of the LensKit project, re-envisioning the original tool's objectives as flexible Python package for supporting recommender systems research and development. LensKit for Python (LKPY) enables researchers and students to build robust, flexible, and reproducible experiments that make use of the large and growing PyData and Scientific Python ecosystem, including scikit-learn, and TensorFlow. To that end, it provides classical collaborative filtering implementations, recommender system evaluation metrics, data preparation routines, and tools for efficiently batch running recommendation algorithms, all usable in any combination with each other or with other Python software.  This paper describes the design goals, use cases, and capabilities of LKPY, contextualized in a reflection on the successes and failures of the original LensKit for Java software.",10.1145/3340531.3412778,https://doi.org/10.1145/3340531.3412778,"New York, NY, USA",Association for Computing Machinery,9781450368599,2020,LensKit for Python: Next-Generation Software for Recommender Systems Experiments,"Ekstrand, Michael D.",inproceedings,10.1145/3340531.3412778,
10.1145/3341161.3342894,10.1145/3341161.3342894,KDD.bib,1,['KDD.bib'],8,ASONAM '19,"Vancouver, British Columbia, Canada","fake news detection, multi-modal, social media",8,41–48,Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"How to effectively detect fake news and prevent its diffusion on social media has gained much attention in recent years. However, relatively little focus has been given on exploiting user comments left for posts and latent sentiments therein in detecting fake news. Inspired by the rich information available in user comments on social media, therefore, we investigate whether the latent sentiments hidden in user comments can potentially help distinguish fake news from reliable content. We incorporate users' latent sentiments into an end-to-end deep embedding framework for detecting fake news, named as SAME. First, we use multi-modal networks to deal with heterogeneous data modalities. Second, to learn semantically meaningful spaces per data source, we adopt an adversarial mechanism. Third, we define a novel regularization loss to bring embeddings of relevant pairs closer. Our comprehensive validation using two real-world datasets, PolitiFact and GossipCop, demonstrates the effectiveness of SAME in detecting fake news, significantly outperforming state-of-the-art methods.",10.1145/3341161.3342894,https://doi.org/10.1145/3341161.3342894,"New York, NY, USA",Association for Computing Machinery,9781450368681,2020,SAME: sentiment-aware multi-modal embedding for detecting fake news,"Cui, Limeng and Wang, Suhang and Lee, Dongwon",inproceedings,10.1145/3341161.3342894,
10.1145/3341161.3342940,10.1145/3341161.3342940,KDD.bib,1,['KDD.bib'],7,ASONAM '19,"Vancouver, British Columbia, Canada",,4,489–492,Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Pornography can be distributed in multiple forms on the Internet. Online pornography forms a non-negligible fraction of the total Internet traffic, with adult video streaming gaining significant traction among the most visited global websites. Similar to the rise of User Generated Content (UGC) on general Web 2.0 services, adult video service providers have also promoted social interaction and UGC in what is called 'Porn 2.0'. Discovering the characteristics of Porn 2.0 allows for better understanding of both Internet traffic in general and specifically UGC services. In this paper, using trace-driven analysis, we examined the characteristics of one of the most well-known Porn 2.0 service providers, XHamster. We found that a large proportion of the currently available videos were uploaded in recent years and this has coincided with a rapid growth in the use of video categories. Compared to non-adult UGC services, we found user interaction on XHamster to revolve more strongly around ratings than comments and the average duration and views per video were higher.",10.1145/3341161.3342940,https://doi.org/10.1145/3341161.3342940,"New York, NY, USA",Association for Computing Machinery,9781450368681,2020,Measurement and analysis of an adult video streaming service,"Song, Yo-Der and Gong, Mingwei and Mahanti, Aniket",inproceedings,10.1145/3341161.3342940,
10.1145/3341161.3343527,10.1145/3341161.3343527,KDD.bib,1,['KDD.bib'],8,ASONAM '19,"Vancouver, British Columbia, Canada","data analysis, risk calculation, safety perception, terrorist attacks, threat ranking",8,1128–1135,Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Terrorism is a key risk for prospective visitors of tourist destinations. This work reports on the analysis of past terrorist attack data, focusing on tourist-related attacks and attack types in Mediterranean EU area and the development of algorithms to predict terrorist attack risk levels. Data on attacks in 10 countries have been analyzed to quantify the threat level of tourism-related terrorism based on the data from 2000 to 2017 and formulate predictions for subsequent periods. Results show that predictions on potential target types can be derived with adequate accuracy. Such results are useful for initiating, shifting and validating active terrorism surveillance based on predicted attack and target types per country from real past data.",10.1145/3341161.3343527,https://doi.org/10.1145/3341161.3343527,"New York, NY, USA",Association for Computing Machinery,9781450368681,2020,Data-driven country safety monitoring terrorist attack prediction,"Spiliotopoulos, Dimitris and Vassilakis, Costas and Margaris, Dionisis",inproceedings,10.1145/3341161.3343527,
10.1145/3341161.3343672,10.1145/3341161.3343672,KDD.bib,1,['KDD.bib'],8,ASONAM '19,"Vancouver, British Columbia, Canada","feature-based matrix factorization, neural embedding, point-of-interest recommendation",6,657–662,Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"The focus of point-of-interest recommendation techniques is to suggest a venue to a given user that would match the users' interests and is likely to be adopted by the user. Given the multitude of venues and the sparsity of user check-ins, the problem of recommending venues has shown to be a difficult task. Existing literature has already explored various types of features such as geographical distribution, social structure and temporal behavioral patterns to make a recommendation. In this paper, we propose a new set of features derived based on the neural embeddings of venues and users. We show how the neural embeddings for users and venues can be jointly learnt based on the prior check-in sequence of users and then be used to define three types of features, namely user, venue, and user-venue interaction features. These features are integrated into a feature-based matrix factorization model. Our experiments show that the features defined over the user and venue embeddings are effective for venue recommendation.",10.1145/3341161.3343672,https://doi.org/10.1145/3341161.3343672,"New York, NY, USA",Association for Computing Machinery,9781450368681,2020,Neural embedding features for point-of-interest recommendation,"Pourali, Alireza and Zarrinkalam, Fattane and Bagheri, Ebrahim",inproceedings,10.1145/3341161.3343672,
10.1145/3341161.3345620,10.1145/3341161.3345620,KDD.bib,1,['KDD.bib'],8,ASONAM '19,"Vancouver, British Columbia, Canada","collaborative filtering, evaluation, limited information, near neighbours, online advertising, pearson correlation coefficient, social networks",8,1160–1167,Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Online advertising benefits by recommender systems since the latter analyse reviews and rating of products, providing useful insight of the buyer perception of products and services. When traditional recommender system information is enriched with social network information, more successful recommendations are produced, since more users' aspects are taken into consideration. However, social network information may be unavailable since some users may not have social network accounts or may not consent to their use for recommendations, while rating data may be unavailable due to the cold start phenomenon. In this paper, we propose an algorithm that combines limited collaborative filtering information, comprised only of users' ratings on items, with limited social network information, comprised only of users' social relations, in order to improve (1) prediction accuracy and (2) prediction coverage in collaborative filtering recommender systems, at the same time. The proposed algorithm considerably improves rating prediction accuracy and coverage, while it can be easily integrated in recommender systems.",10.1145/3341161.3345620,https://doi.org/10.1145/3341161.3345620,"New York, NY, USA",Association for Computing Machinery,9781450368681,2020,Social relations versus near neighbours: reliable recommenders in limited information social network collaborative filtering for online advertising,"Margaris, Dionisis and Spiliotopoulos, Dimitris and Vassilakis, Costas",inproceedings,10.1145/3341161.3345620,
10.1145/3357384.3357809,10.1145/3357384.3357809,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","xiaoyi zeng, minghui qiu, jun huang, jingren zhou, forrest sheng bao, deng cai, cen chen, bo wang",7,2509–2515,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Product search and recommendation is a task that every e-commerce platform wants to outperform their peels on. However, training a good search or recommendation model often requires more data than what many platforms have. Fortunately, the search tasks on different platforms share the common underlying structure. Considering each platform as a domain, we propose a cross-domain learning approach to help the task on data-deficient platforms by leveraging the data from data-abundant platforms. In our solution, the importance of features in different domains is addressed by a domain-specific attention network. Meanwhile, a multi-task regularizer based on Wasserstein distance is introduced to help extract both domain-invariant and domain-specific features. Our model consistently outperforms the competing methods on both public and real-world industry datasets. Quantitative evaluation shows that our model can discover important features for different domains, which helps us better understand different user needs across platforms. Last but not least, we have deployed our model online in three big e-commerce platforms namely Taobao, Tmall, and Qintao, and observed better performance than the production models for all the platforms.",10.1145/3357384.3357809,https://doi.org/10.1145/3357384.3357809,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Cross-domain Attention Network with Wasserstein Regularizers for E-commerce Search,"Qiu, Minghui and Wang, Bo and Chen, Cen and Zeng, Xiaoyi and Huang, Jun and Cai, Deng and Zhou, Jingren and Bao, Forrest Sheng",inproceedings,10.1145/3357384.3357809,
10.1145/3357384.3357828,10.1145/3357384.3357828,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","sentiment classification, online reviews, multi-task learning, multi-aspect, attention mechanism",9,2723–2731,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"In the era of big data, online doctor review platforms, which enable patients to give feedback to their doctors, have become one of the most important components in healthcare systems. On one hand, they help patients to choose their doctors based on the experience of others. On the other hand, they help doctors to improve the quality of their service. Moreover, they provide important sources for us to discover common concerns of patients and existing problems in clinics, which potentially improve current healthcare systems. In this paper, we systematically investigate the dataset from one of such review platform, namely, ratemds.com, where each review for a doctor comes with an overall rating and ratings of four different aspects. A comprehensive statistical analysis is conducted first for reviews, ratings, and doctors. Then, we explore the content of reviews by extracting latent topics related to different aspects with unsupervised topic modeling techniques. As the core component of this paper, we propose a multi-task learning framework for the document-level multi-aspect sentiment classification. This task helps us to not only recover missing aspect-level ratings and detect inconsistent rating scores but also identify aspect-keywords for a given review based on ratings. The proposed model takes both features of doctors and aspect-keywords into consideration. Extensive experiments have been conducted on two subsets of ratemds dataset to demonstrate the effectiveness of the proposed model.",10.1145/3357384.3357828,https://doi.org/10.1145/3357384.3357828,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Document-Level Multi-Aspect Sentiment Classification for Online Reviews of Medical Experts,"Shi, Tian and Rakesh, Vineeth and Wang, Suhang and Reddy, Chandan K.",inproceedings,10.1145/3357384.3357828,
10.1145/3357384.3357888,10.1145/3357384.3357888,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","spatio-temporal effect, recommender system, on-demand cinema",10,1553–1562,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"On-demand cinemas are a new type of offline entertainment venues which have shown the rapid expansion in the recent years. Recommending movies of interest to the potential audiences in on-demand cinemas is keen but challenging because the recommendation scenario is totally different from all the existing recommendation applications including online video recommendation, offline item recommendation and group recommendation. In this paper, we propose a novel spatio-temporal approach called Pegasus. Because of the specific characteristics of on-demand cinema recommendation, Pegasus exploits the POI (Point of Interest) information around cinemas and the content descriptions of movies, apart from the historical movie consumption records of cinemas. Pegasus explores the temporal dynamics and spatial influences rooted in audience behaviors, and captures the similarities between cinemas, the changes of audience crowds, time-varying features and regional disparities of movie popularity. It offers an effective and explainable way to recommend movies to on-demand cinemas. The corresponding Pegasus system has been deployed in some pilot on-demand cinemas. Based on the real-world data from on-demand cinemas, extensive experiments as well as pilot tests are conducted. Both experimental results and post-deployment feedback show that Pegasus is effective.",10.1145/3357384.3357888,https://doi.org/10.1145/3357384.3357888,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,A Spatio-temporal Recommender System for On-demand Cinemas,"Xue, Taofeng and Jin, Beihong and Li, Beibei and Wang, Weiqing and Zhang, Qi and Tian, Sihua",inproceedings,10.1145/3357384.3357888,
10.1145/3357384.3357912,10.1145/3357384.3357912,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","micro-videos, long-tail, hashtag recommendation",10,509–518,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Hashtags, a user provides to a micro-video, are the ones which can well describe the semantics of the micro-video's content in his/her mind. At the same time, hashtags have been widely used to facilitate various micro-video retrieval scenarios (e.g., search, browse, and categorization). Despite their importance, numerous micro-videos lack hashtags or contain inaccurate or incomplete hashtags. In light of this, hashtag recommendation, which suggests a list of hashtags to a user when he/she wants to annotate a post, becomes a crucial research problem. However, little attention has been paid to micro-video hashtag recommendation, mainly due to the following three reasons: 1) lack of benchmark dataset; 2) the temporal and multi-modality characteristics of micro-videos; and 3) hashtag sparsity and long-tail distributions. In this paper, we recommend hashtags for micro-videos by presenting a novel multi-view representation interactive embedding model with graph-based information propagation. It is capable of boosting the performance of micro-videos hashtag recommendation by jointly considering the sequential feature learning, the video-user-hashtag interaction, and the hashtag correlations. Extensive experiments on a constructed dataset demonstrate our proposed method outperforms state-of-the-art baselines. As a side research contribution, we have released our dataset and codes to facilitate the research in this community.",10.1145/3357384.3357912,https://doi.org/10.1145/3357384.3357912,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Long-tail Hashtag Recommendation for Micro-videos with Graph Convolutional Network,"Li, Mengmeng and Gan, Tian and Liu, Meng and Cheng, Zhiyong and Yin, Jianhua and Nie, Liqiang",inproceedings,10.1145/3357384.3357912,
10.1145/3357384.3357914,10.1145/3357384.3357914,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","semi-supervised learning, neighborhood inference, metric learning, cross-domain recommendation, collaborative filtering",10,1563–1572,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Providing accurate recommendations to newly joined users (or potential users, so-called cold-start users) has remained a challenging yet important problem in recommender systems. To infer the preferences of such cold-start users based on their preferences observed in other domains, several cross-domain recommendation (CDR) methods have been studied. The state-of-the-art Embedding and Mapping approach for CDR (EMCDR) aims to infer the latent vectors of cold-start users by supervised mapping from the latent space of another domain. In this paper, we propose a novel CDR framework based on semi-supervised mapping, called SSCDR, which effectively learns the cross-domain relationship even in the case that only a few number of labeled data is available. To this end, it first learns the latent vectors of users and items for each domain so that their interactions are represented by the distances, then trains a cross-domain mapping function to encode such distance information by exploiting both overlapping users as labeled data and all the items as unlabeled data. In addition, SSCDR adopts an effective inference technique that predicts the latent vectors of cold-start users by aggregating their neighborhood information. Our extensive experiments on different CDR scenarios show that SSCDR outperforms the state-of-the-art methods in terms of CDR accuracy, particularly in the realistic settings that a small portion of users overlap between two domains.",10.1145/3357384.3357914,https://doi.org/10.1145/3357384.3357914,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Semi-Supervised Learning for Cross-Domain Recommendation to Cold-Start Users,"Kang, SeongKu and Hwang, Junyoung and Lee, Dongha and Yu, Hwanjo",inproceedings,10.1145/3357384.3357914,
10.1145/3357384.3357919,10.1145/3357384.3357919,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","recommender system, rating prediction, gated recurrent unit, attention mechanism",10,1573–1582,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Recommender system plays an important role to provide people with personalized information based on their history records. However, it is still a challenge to capture the preference of users accurately due to the sparsity of rating data and the heterogeneity of review data. In this paper, we propose a hybrid deep collaborative filtering model that jointly learns latent representations from ratings and reviews. Specifically, the model learns the rating feature and textual feature based on ratings and reviews simultaneously. Two embedding layers are employed to learn rating feature for users and items based on the user and item interactions, and two attention-based GRU networks learn context-aware representation from user and item reviews. Then a gating mechanism is used to leverage contributions from rating feature and textual feature. Experimental results on six real-world datasets demonstrate the superior performance of the proposed method over several state-of-the-art methods. Moreover, the keywords in reviews can be highlighted to interpret the predictions with the attention mechanism.",10.1145/3357384.3357919,https://doi.org/10.1145/3357384.3357919,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Leveraging Ratings and Reviews with Gating Mechanism for Recommendation,"Xia, Haifeng and Wang, Zengmao and Du, Bo and Zhang, Lefei and Chen, Shuai and Chun, Gang",inproceedings,10.1145/3357384.3357919,
10.1145/3357384.3357930,10.1145/3357384.3357930,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","hashing-based recommendation, efficient collaborative filtering, candidate generation and re-ranking",10,1523–1532,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Generating the Top-N recommendations from a large corpus is computationally expensive to perform at scale. Candidate generation and re-ranking based approaches are often adopted in industrial settings to alleviate efficiency problems. However it remains to be fully studied how well such schemes approximate complete rankings (or how many candidates are required to achieve a good approximation), or to develop systematic approaches to generate high-quality candidates efficiently. In this paper, we seek to investigate these questions via proposing a candidate generation and re-ranking based framework (CIGAR), which first learns a preference-preserving binary embedding for building a hash table to retrieve candidates, and then learns to re-rank the candidates using real-valued ranking models with a candidate-oriented objective. We perform a comprehensive study on several large-scale real-world datasets consisting of millions of users/items and hundreds of millions of interactions. Our results show that CIGAR significantly boosts the Top-N accuracy against state-of-the-art recommendation models, while reducing the query time by orders of magnitude. We hope that this work could draw more attention to the candidate generation problem in recommender systems.",10.1145/3357384.3357930,https://doi.org/10.1145/3357384.3357930,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Candidate Generation with Binary Codes for Large-Scale Top-N Recommendation,"Kang, Wang-Cheng and McAuley, Julian",inproceedings,10.1145/3357384.3357930,
10.1145/3357384.3357942,10.1145/3357384.3357942,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","neural recommendation model, missing feature value, feature sampling, feature interaction",10,1451–1460,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Most recommendation algorithms mainly make use of user history interactions in the model, while these methods often suffer from the cold-start problem (user/item has no history information). On the other sides, content features help on cold-start scenarios for modeling new users or items. So it is essential to utilize content features to enhance different recommendation models. To take full advantage of content features, feature interactions such as cross features are used by some models and outperform than using raw features. However, in real-world systems, many content features are incomplete, e.g., we may know the occupation and gender of a user, but the values of other features (location, interests, etc.) are missing. This missing-feature-value (MFV) problem is harmful to the model performance, especially for models that rely heavily on rich feature interactions. Unfortunately, this problem has not been well studied previously.In this work, we propose a new adaptive ""Feature Sampling'' strategy to help train different models to fit distinct scenarios, no matter for cold-start or missing feature value cases. With the help of this strategy, more feature interactions can be utilized. A novel model named CC-CC is proposed. The model takes both raw features and the feature interactions into consideration. It has a linear part to memorize useful variant information from the user or item contents and contexts (Content &amp; Context Module), and a deep attentive neural module that models both content and collaborate information to enhance the generalization ability (Content &amp; Collaborate Module). Both parts have feature interactions. The model is evaluated on two public datasets. Comparative results show that the proposed CC-CC model outperforms the state-of-the-art algorithms on both warm and cold scenarios significantly (up to 6.3%). To the best of our knowledge, this model is the first clear and powerful model that proposed to handle the missing feature values problem in deep neural network frameworks for recommender systems.",10.1145/3357384.3357942,https://doi.org/10.1145/3357384.3357942,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Adaptive Feature Sampling for Recommendation with Missing Content Feature Values,"Shi, Shaoyun and Zhang, Min and Yu, Xinxing and Zhang, Yongfeng and Hao, Bin and Liu, Yiqun and Ma, Shaoping",inproceedings,10.1145/3357384.3357942,
10.1145/3357384.3357982,10.1145/3357384.3357982,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","representation learning, heterogeneous network, deep learning, author identification",10,489–498,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Many real-world tasks solved by heterogeneous network embedding methods can be cast as modeling the likelihood of a pairwise relationship between two nodes. For example, the goal of author identification task is to model the likelihood of a paper being written by an author (paper-author pairwise relationship). Existing taskguided embedding methods are node-centric in that they simply measure the similarity between the node embeddings to compute the likelihood of a pairwise relationship between two nodes. However, we claim that for task-guided embeddings, it is crucial to focus on directly modeling the pairwise relationship. In this paper, we propose a novel task-guided pair embedding framework in heterogeneous network, called TaPEm, that directly models the relationship between a pair of nodes that are related to a specific task (e.g., paper-author relationship in author identification). To this end, we 1) propose to learn a pair embedding under the guidance of its associated context path, i.e., a sequence of nodes between the pair, and 2) devise the pair validity classifier to distinguish whether the pair is valid with respect to the specific task at hand. By introducing pair embeddings that capture the semantics behind the pairwise relationships, we are able to learn the fine-grained pairwise relationship between two nodes, which is paramount for task-guided embedding methods. Extensive experiments on author identification task demonstrate that TaPEm outperforms the state-of-the-art methods, especially for authors with few publication records.",10.1145/3357384.3357982,https://doi.org/10.1145/3357384.3357982,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Task-Guided Pair Embedding in Heterogeneous Network,"Park, Chanyoung and Kim, Donghyun and Zhu, Qi and Han, Jiawei and Yu, Hwanjo",inproceedings,10.1145/3357384.3357982,
10.1145/3357384.3357992,10.1145/3357384.3357992,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","recommender systems, multi-task learning, cross-domain recommendation, collaborative filtering",10,1533–1542,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"In order to address the data sparsity problem in recommender systems, in recent years, Cross-Domain Recommendation (CDR) leverages the relatively richer information from a source domain to improve the recommendation performance on a target domain with sparser information. However, each of the two domains may be relatively richer in certain types of information (e.g., ratings, reviews, user profiles, item details, and tags), and thus, if we can leverage such information well, it is possible to improve the recommendation performance on both domains simultaneously (i.e., dual-target CDR), rather than a single target domain only. To this end, in this paper, we propose a new framework, DTCDR, for Dual-Target Cross-Domain Recommendation. In DTCDR, we first extensively utilize rating and multi-source content information to generate rating and document embeddings of users and items. Then, based on Multi-Task Learning (MTL), we design an adaptable embedding-sharing strategy to combine and share the embeddings of common users across domains, with which DTCDR can improve the recommendation performance on both richer and sparser (i.e., dual-target) domains simultaneously. Extensive experiments conducted on real-world datasets demonstrate that DTCDR can significantly improve the recommendation accuracies on both richer and sparser domains and outperform the state-of-the-art single-domain and cross-domain approaches.",10.1145/3357384.3357992,https://doi.org/10.1145/3357384.3357992,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,DTCDR: A Framework for Dual-Target Cross-Domain Recommendation,"Zhu, Feng and Chen, Chaochao and Wang, Yan and Liu, Guanfeng and Zheng, Xiaolin",inproceedings,10.1145/3357384.3357992,
10.1145/3357384.3358001,10.1145/3357384.3358001,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","spatial data, satellite imagery, representation learning, multimodal embeding",10,1993–2002,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Increasing urbanization across the globe has coincided with greater access to urban data; this enables researchers and city administrators with better tools to understand urban dynamics, such as crime, traffic, and living standards. In this paper, we study the Learning an Embedding Space for Regions (LESR) problem, wherein we aim to produce vector representations of discrete regions. Recent studies have shown that embedding geospatial regions in a latent vector space can be useful in a variety of urban computing tasks. However, previous studies do not consider regions across multiple modalities in an end-to-end framework. We argue that doing so facilitates the learning of greater semantic relationships among regions. We propose a novel method, RegionEncoder, that jointly learns region representations from satellite image, point-of-interest, human mobility, and spatial graph data. We demonstrate that these region embeddings are useful as features in two regression tasks and across two distinct urban environments. Additionally, we perform an ablation study that evaluates each major architectural component. Finally, we qualitatively explore the learned embedding space, and show that semantic relationships are discovered across modalities",10.1145/3357384.3358001,https://doi.org/10.1145/3357384.3358001,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Unsupervised Representation Learning of Spatial Data via Multimodal Embedding,"Jenkins, Porter and Farag, Ahmad and Wang, Suhang and Li, Zhenhui",inproceedings,10.1145/3357384.3358001,
10.1145/3357384.3358006,10.1145/3357384.3358006,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","url recommendation, graph neural network, fake news, fact-checking, deep learning",10,1471–1480,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"To combat fake news, researchers mostly focused on detecting fake news and journalists built and maintained fact-checking sites (e.g., Snopes.com and Politifact.com). However, fake news dissemination has been greatly promoted via social media sites, and these fact-checking sites have not been fully utilized. To overcome these problems and complement existing methods against fake news, in this paper we propose a deep-learning based fact-checking URL recommender system to mitigate impact of fake news in social media sites such as Twitter and Facebook. In particular, our proposed framework consists of a multi-relational attentive module and a heterogeneous graph attention network to learn complex/semantic relationship between user-URL pairs, user-user pairs, and URL-URL pairs. Extensive experiments on a real-world dataset show that our proposed framework outperforms eight state-of-the-art recommendation models, achieving at least 3$sim$5.3% improvement. Our source code and dataset are available at urlhttps://web.cs.wpi.edu/~kmlee/data.html .",10.1145/3357384.3358006,https://doi.org/10.1145/3357384.3358006,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Attributed Multi-Relational Attention Network for Fact-checking URL Recommendation,"You, Di and Vo, Nguyen and Lee, Kyumin and LIU, Qiang",inproceedings,10.1145/3357384.3358006,
10.1145/3357384.3358017,10.1145/3357384.3358017,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","recommendation system, probabilistic matrix factorization, interpretable recommendation, collaborative filtering",10,1803–1812,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Interpretability of recommender systems has caused increasing attention due to its promotion of the effectiveness and persuasiveness of recommendation decision, and thus user satisfaction. Most existing methods, such as Matrix Factorization (MF), tend to be black-box machine learning models that lack interpretability and do not provide a straightforward explanation for their outputs. In this paper, we focus on probabilistic factorization model and further assume the absence of any auxiliary information, such as item content or user review. We propose an influence mechanism to evaluate the importance of the users' historical data, so that the most related users and items can be selected to explain each predicted rating. The proposed method is thus called Influencebased Interpretable Recommendation model (In2Rec). To further enhance the recommendation accuracy, we address the important issue of missing not at random, i.e., missing ratings are not independent from the observed and other unobserved ratings, because users tend to only interact what they like. In2Rec models the generative process for both observed and missing data, and integrates the influence mechanism in a Bayesian graphical model. A learning algorithm capitalizing on iterated condition modes is proposed to tackle the non-convex optimization problem pertaining to maximum a posteriori estimation for In2Rec. A series of experiments on four real-world datasets (Movielens 10M, Netflix, Epinions, and Yelp) have been conducted. By comparing with the state-of-the-art recommendation methods, the experimental results have shown that In2Rec can consistently benefit the recommendation system in both rating prediction and ranking estimation tasks, and friendly interpret the recommendation results with the aid of the proposed influence mechanism.",10.1145/3357384.3358017,https://doi.org/10.1145/3357384.3358017,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,In2Rec: Influence-based Interpretable Recommendation,"Liu, Huafeng and Wen, Jingxuan and Jing, Liping and Yu, Jian and Zhang, Xiangliang and Zhang, Min",inproceedings,10.1145/3357384.3358017,
10.1145/3357384.3358030,10.1145/3357384.3358030,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","user-generated item lists, self-attention, recommender system",10,1481–1490,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"User-generated item lists are a popular feature of many different platforms. Examples include lists of books on Goodreads, playlists on Spotify and YouTube, collections of images on Pinterest, and lists of answers on question-answer sites like Zhihu. Recommending item lists is critical for increasing user engagement and connecting users to new items, but many approaches are designed for the item-based recommendation, without careful consideration of the complex relationships between items and lists. Hence, in this paper, we propose a novel user-generated list recommendation model called AttList. Two unique features of AttList are careful modeling of (i) hierarchical user preference, which aggregates items to characterize the list that they belong to, and then aggregates these lists to estimate the user preference, naturally fitting into the hierarchical structure of item lists; and (ii) item and list consistency, through a novel self-attentive aggregation layer designed for capturing the consistency of neighboring items and lists to better model user preference. Through experiments over three real-world datasets reflecting different kinds of user-generated item lists, we find that AttList results in significant improvements in NDCG, Precision@k, and Recall@k versus a suite of state-of-the-art baselines. Furthermore, all code and data are available at https://github.com/heyunh2015/AttList.",10.1145/3357384.3358030,https://doi.org/10.1145/3357384.3358030,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,A Hierarchical Self-Attentive Model for Recommending User-Generated Item Lists,"He, Yun and Wang, Jianling and Niu, Wei and Caverlee, James",inproceedings,10.1145/3357384.3358030,
10.1145/3357384.3358037,10.1145/3357384.3358037,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","target-dependent sentiment, online news, online discussion, graph convolution, conflict modeling",10,1271–1280,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Over the last decade, online forums have become primary news sources for readers around the globe, and social media platforms are the space where these news forums find most of their audience and engagement. Our particular focus in this paper is to study conflict dynamics over online news articles in Reddit, one of the most popular online discussion platforms. We choose to study how conflicts develop around news inside a discussion community, the em r/news subreddit. Mining the characteristics of these engagements often provide useful insights into the behavioral dynamics of large-scale human interactions. Such insights are useful for many reasons -- for news houses to improvise their publishing strategies and potential audience, for data analytics to get a better introspection over media engagement as well as for social media platforms to avoid unnecessary and perilous conflicts. In this work, we present a novel quantification of conflict in online discussion. Unlike previous studies on conflict dynamics, which model conflict as a binary phenomenon, our measure is continuous-valued, which we validate with manually annotated ratings. We address a two-way prediction task. Firstly, we predict the probable degree of conflict a news article will face from its audience. We employ multiple machine learning frameworks for this task using various features extracted from news articles.Secondly, given a pair of users and their interaction history, we predict if their future engagement will result in a conflict. We fuse textual and network-based features together using a support vector machine which achieves an AUC of 0.89. Moreover, we implement a graph convolutional model which exploits engagement histories of users to predict whether a pair of users who never met each other before will have a conflicting interaction, with an AUC of 0.69. We perform our studies on a massive discussion dataset crawled from the Reddit news community, containing over $41k$ news articles and $5.5$ million comments. Apart from the prediction tasks, our studies offer interesting insights on the conflict dynamics -- how users form clusters based on conflicting engagements, how different is the temporal nature of conflict over different online news forums, how is contribution of different language based features to induce conflict, etc. In short, our study paves the way towards new methods of exploration and modeling of conflict dynamics inside online discussion communities.",10.1145/3357384.3358037,https://doi.org/10.1145/3357384.3358037,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Into the Battlefield: Quantifying and Modeling Intra-community Conflicts in Online Discussion,"Dutta, Subhabrata and Das, Dipankar and Kaur, Gunkirat and Mongia, Shreyans and Mukherjee, Arpan and Chakraborty, Tanmoy",inproceedings,10.1145/3357384.3358037,
10.1145/3357384.3358042,10.1145/3357384.3358042,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","recurrent neural network, instagrammers, fashion recommendation, bloggers",10,1583–1592,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Fashion-focused key opinion bloggers on Instagram, Facebook, and other social media platforms are fast becoming critical influencers. They can inspire consumer clothing purchases by linking high fashion visual evolution with daily street style. In this paper, we build thefirst visual influence-aware fashion recommender (FIRN) with leveraging fashion bloggers and their dynamic visual posts. Specifically, we extract thedynamic fashion features highlighted by these bloggers via a BiLSTM that integrates a large corpus of visual posts and community influence. We then learn theimplicit visual influence funnel from bloggers to individual users via a personalized attention layer. Finally, we incorporate user personal style and her preferred fashion features across time in a recurrent recommendation network for dynamic fashion-updated clothing recommendation. Experiments show that FIRN outperforms state-of-the-art fashion recommenders, especially for users who are most impacted by fashion influencers, and utilizing fashion bloggers can bring greater improvements in recommendation compared with using other potential sources of visual information. We also release a largetime-aware high-quality visual dataset of fashion influencers that can be exploited for future research.",10.1145/3357384.3358042,https://doi.org/10.1145/3357384.3358042,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,"Instagrammers, Fashionistas, and Me: Recurrent Fashion Recommendation with Implicit Visual Influence","Zhang, Yin and Caverlee, James",inproceedings,10.1145/3357384.3358042,
10.1145/3357384.3358082,10.1145/3357384.3358082,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","matrix approximation, ensemble learning, collaborative filtering",4,2197–2200,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Ensemble matrix approximation (MA) methods have achieved promising performance in collaborative filtering, many of which perform matrix approximation on multiple submatrices of user-item ratings in parallel and then combine the predictions from the sub-models for higher efficiency. However, data partitioning could lead to suboptimal accuracy due to the lack of capturing structural information related to most or all users/items. This paper proposes a new ensemble learning framework, in which the local models and global models are synergetically updated from each other. This makes it possible to capture both local associations in user-item subgroups and global structures over all users and items. Experiments on three real-world datasets demonstrate that the proposed method outperforms six state-of-the-art methods in recommendation accuracy with decent scalability.",10.1145/3357384.3358082,https://doi.org/10.1145/3357384.3358082,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Synergizing Local and Global Models for Matrix Approximation,"Chen, Chao and Zhang, Hao and Li, Dongsheng and Yan, Junchi and Yang, Xiaokang",inproceedings,10.1145/3357384.3358082,
10.1145/3357384.3358086,10.1145/3357384.3358086,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","rating prediction, neural network, aspect-aware",4,2169–2172,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Review rating prediction is an important task in data mining and natural language processing fields, and has wide applications. Users usually express opinions towards many aspects in their reviews, and the overall review rating is a synthesis of these opinions. However, most existing review rating prediction methods ignore users' opinions on aspects, which is insufficient. In this paper, we propose a neural aspect-aware rating prediction approach for Chinese reviews. In our approach we propose a collaborative learning framework to jointly train review-level rating predictor and multiple aspect-level rating predictors. In our framework different rating predictors share the same review encoder model to exploit the inherent relatedness between them, but have different attention networks to focus on different informative texts for each task. The final review representation for rating prediction is a concatenation of the review representations from all predictors. Since word segmentation of Chinese reviews is usually inaccurate, we propose a multi-view learning model to learn review representations from both words and characters. Extensive experiments on real-world dataset validate the effectiveness of our approach.",10.1145/3357384.3358086,https://doi.org/10.1145/3357384.3358086,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,ARP: Aspect-aware Neural Review Rating Prediction,"Wu, Chuhan and Wu, Fangzhao and Liu, Junxin and Huang, Yongfeng and Xie, Xing",inproceedings,10.1145/3357384.3358086,
10.1145/3357384.3358134,10.1145/3357384.3358134,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","recommendation system, motif, heterogeneous information networks, collaborative filtering",4,2189–2192,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Heterogeneous Information Networks (HIN) has been widely used in recommender systems (RSs). In previous HIN-based RSs, meta-path is used to compute the similarity between users and items. However, existing meta-path based methods only consider first-order relations, ignoring higher-order relations among the nodes ofsame type, captured bymotifs. In this paper, we propose to use motifs to capture higher-order relations among nodes of same type in a HIN and develop the motif-enhanced meta-path (MEMP) to combine motif-based higher-order relations with edge-based first-order relations. With MEMP-based similarities between users and items, we design a recommending model MoHINRec, and experimental results on two real-world datasets, Epinions and CiaoDVD, demonstrate its superiority over existing HIN-based RS methods.",10.1145/3357384.3358134,https://doi.org/10.1145/3357384.3358134,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Motif Enhanced Recommendation over Heterogeneous Information Network,"Zhao, Huan and Zhou, Yingqi and Song, Yangqiu and Lee, Dik Lun",inproceedings,10.1145/3357384.3358134,
10.1145/3357384.3358138,10.1145/3357384.3358138,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","sentiment analysis, memory network, knowledge representation",4,2341–2344,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Neural network methods have achieved great success in sentiment classification. Recent studies have found that incorporating user and product information can effectively improve the performance of review sentiment classification. However, most of these studies only concentrate on the influence of users and products, ignoring the inherent correlation between users or products. This information is important for users or products since they can obtain more information from similar users or products. In this paper, we propose a novel framework for review rating prediction with user and product memory. First, besides the original user or product representations, we construct inferred representations from representative users or products which are stored in memory slots. These memory units can be viewed as refined knowledge representations of users or products learned from the data. Then, we employ two hierarchical networks with user attention and product attention using both the original and inferred representations. Experiments on benchmark datasets show that our method can achieve state-of-the-art performance. Besides, our approach performs much more better in cold-start scenarios where the training data is scarce.",10.1145/3357384.3358138,https://doi.org/10.1145/3357384.3358138,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Neural Review Rating Prediction with User and Product Memory,"Yuan, Zhigang and Wu, Fangzhao and Liu, Junxin and Wu, Chuhan and Huang, Yongfeng and Xie, Xing",inproceedings,10.1145/3357384.3358138,
10.1145/3357384.3358804,10.1145/3357384.3358804,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","recommender systems, parameter tuning, model selection, machine learning, hyperparameter optimization",2,2999–3000,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,Recommender systems have strongly attracted the attention of the machine learning research community with prosperous real-life deployments in the last few decades. The performance and success of most applications developed in this domain highly depend on an elaborate selection of models and configuration of their hyperparameters. The international MoST-Rec 2019 workshop addresses the issues of algorithm selection and parameter tuning for recommender systems. The workshop aims to bring together researchers from the model selection and hyperparameter tuning community in the general scope of machine learning with researchers from the recommender systems community for discussing and exchanging recent advances and open challenges in the field.,10.1145/3357384.3358804,https://doi.org/10.1145/3357384.3358804,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,International Workshop on Model Selection and Parameter Tuning in Recommender Systems,"Sivrikaya, Fikret and Albayrak, Sahin and Lian, Defu",inproceedings,10.1145/3357384.3358804,
10.1145/3357384.3360321,10.1145/3357384.3360321,CIKM.bib,1,['CIKM.bib'],8,CIKM '19,"Beijing, China","utility, review mining, recommendation, multi-stakeholder, multi-objective learning, multi-criteria, generation, explanation, aspect",3,2979–2981,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"Recommender systems are able to produce a list of recommended items tailored to user preferences, while the end user is the only stakeholder in these traditional system. However, there could be multiple stakeholders in several applications domains (e.g., e-commerce, movies, music). Recommendations are necessary to be produced by balancing the needs of different stakeholders. First session of this tutorial introduces multi-stakeholder recommender systems (MSRS) with several case studies, and discusses the corresponding methods and challenges in MSRS. Reviews in an e-commerce platform may be mined to address cold-start problem and to generate explanations. Our earlier tutorial covered aspect-based sentiment analysis of products and topic models/distributed representations that bridge vocabulary gap between user reviews and product descriptions. Focus in the second session of this tutorial instead is on recent neural methods for review text mining - covering hands-on code for its use to enhance product recommendation. Each section will introduce topics from various mechanism (e.g., attention) and task (e.g., review ranking) perspectives, present cutting-edge research and a walk-through of programs executed on Jupyter notebook using real-world data sets.",10.1145/3357384.3360321,https://doi.org/10.1145/3357384.3360321,"New York, NY, USA",Association for Computing Machinery,9781450369763,2019,Recommendation for Multi-stakeholders and through Neural Review Mining,"Chelliah, Muthusamy and Zheng, Yong and Sarkar, Sudeshna",inproceedings,10.1145/3357384.3360321,
10.1145/3366423.3380004,10.1145/3366423.3380004,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Variational inference, Multimodal learning, Micro-video popularity prediction, Deep neural networks, Deep information bottleneck",7,2542–2548,Proceedings of The Web Conference 2020,"Predicting the popularity of a micro-video is a challenging task, due to a number of factors impacting the distribution such as the diversity of the video content and user interests, complex online interactions, etc. In this paper, we propose a multimodal variational encoder-decoder (MMVED) framework that considers the uncertain factors as the randomness for the mapping from the multimodal features to the popularity. Specifically, the MMVED first encodes features from multiple modalities in the observation space into latent representations and learns their probability distributions based on variational inference, where only relevant features in the input modalities can be extracted into the latent representations. Then, the modality-specific hidden representations are fused through Bayesian reasoning such that the complementary information from all modalities is well utilized. Finally, a temporal decoder implemented as a recurrent neural network is designed to predict the popularity sequence of a certain micro-video. Experiments conducted on a real-world dataset demonstrate the effectiveness of our proposed model in the micro-video popularity prediction task.",10.1145/3366423.3380004,https://doi.org/10.1145/3366423.3380004,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,A Multimodal Variational Encoder-Decoder Framework for Micro-video Popularity Prediction,"Xie, Jiayi and Zhu, Yaochen and Zhang, Zhibin and Peng, Jian and Yi, Jing and Hu, Yaosi and Liu, Hongyi and Chen, Zhenzhong",inproceedings,10.1145/3366423.3380004,
10.1145/3366423.3380013,10.1145/3366423.3380013,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Recommender system, Ranking-based model, E-commerce, Demand substitution",7,2606–2612,Proceedings of The Web Conference 2020,"The presence or absence of one item in a recommendation list will affect the demand for other items because customers are often willing to switch to other items if their most preferred items are not available. The cross-item influence, called “peers effect”, has been largely ignored in the literature. In this paper, we develop a peers-aware recommender system, named PARS. We apply a ranking-based choice model to capture the cross-item influence and solve the resultant MaxMin problem with a decomposition algorithm. The MaxMin model solves for the recommendation decision in the meanwhile of estimating users’ preferences towards the items, which yields high-quality recommendations robust to input data variation. Experimental results illustrate that PARS outperforms a few frequently used methods in practice. An online evaluation with a flash sales scenario at Taobao also shows that PARS delivers significant improvements in terms of both conversion rates and user value.",10.1145/3366423.3380013,https://doi.org/10.1145/3366423.3380013,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,PARS: Peers-aware Recommender System,"Mao, Huiqiang and Li, Yanzhi and Li, Chenliang and Chen, Di and Wang, Xiaoqing and Deng, Yuming",inproceedings,10.1145/3366423.3380013,
10.1145/3366423.3380076,10.1145/3366423.3380076,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Temporal Interaction Graphs, Graph Embedding",7,3049–3055,Proceedings of The Web Conference 2020,"Graph embedding has become the research focus in both academic and industrial communities due to its powerful capabilities. The majority of existing work overwhelmingly learn node embeddings in the context of static, plain or attributed, homogeneous graphs. However, many real-world applications frequently involve bipartite graphs with temporal and attributed interaction edges, named temporal interaction graphs. The temporal interactions usually imply different facets of interest and might even evolve over time, thus putting forward huge challenges in learning effective node representations. In this paper, we propose a novel framework named TigeCMN to learn node representations from a sequence of temporal interactions. Specifically, we devise two coupled memory networks to store and update node embeddings in external matrices explicitly and dynamically, which forms deep matrix representations and could enhance the expressiveness of the node embeddings. We conduct experiments on two real-world datasets and the experimental results empirically demonstrate that TigeCMN can outperform the state-of-the-arts with different gains.",10.1145/3366423.3380076,https://doi.org/10.1145/3366423.3380076,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,Learning Temporal Interaction Graph Embedding via Coupled Memory Networks,"Zhang, Zhen and Bu, Jiajun and Ester, Martin and Zhang, Jianfeng and Yao, Chengwei and Li, Zhao and Wang, Can",inproceedings,10.1145/3366423.3380076,
10.1145/3366423.3380135,10.1145/3366423.3380135,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Collaborative Filtering, Wide Autoencoder, Structure Learning, Sparse Autoencoder, Shallow Networks.",11,519–529,Proceedings of The Web Conference 2020,"Autoencoder recommenders have recently shown state-of-the-art performance in the recommendation task due to their ability to model non-linear item relationships effectively. However, existing autoencoder recommenders use fully-connected neural network layers and do not employ structure learning. This can lead to inefficient training, especially when the data is sparse as commonly found in collaborative filtering. The aforementioned results in lower generalization ability and reduced performance. In this paper, we introduce structure learning for autoencoder recommenders by taking advantage of the inherent item groups present in the collaborative filtering domain. Due to the nature of items in general, we know that certain items are more related to each other than to other items. Based on this, we propose a method that first learns groups of related items and then uses this information to determine the connectivity structure of an auto-encoding neural network. This results in a network that is sparsely connected. This sparse structure can be viewed as a prior that guides the network training. Empirically we demonstrate that the proposed structure learning enables the autoencoder to converge to a local optimum with a much smaller spectral norm and generalization error bound than the fully-connected network. The resultant sparse network considerably outperforms the state-of-the-art methods like Mult-vae/Mult-dae on multiple benchmarked datasets even when the same number of parameters and flops are used. It also has a better cold-start performance.",10.1145/3366423.3380135,https://doi.org/10.1145/3366423.3380135,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,Learning the Structure of Auto-Encoding Recommenders,"Khawar, Farhan and Poon, Leonard and Zhang, Nevin L.",inproceedings,10.1145/3366423.3380135,
10.1145/3366423.3380154,10.1145/3366423.3380154,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Probabilistic prediction, Neural Calibration, Field-level Calibration Error, Field-aware Calibration",11,729–739,Proceedings of The Web Conference 2020,"It is often observed that the probabilistic predictions given by a machine learning model can disagree with averaged actual outcomes on specific subsets of data, which is also known as the issue of miscalibration. It is responsible for the unreliability of practical machine learning systems. For example, in online advertising, an ad can receive a click-through rate prediction of 0.1 over some population of users where its actual click rate is 0.15. In such cases, the probabilistic predictions have to be fixed before the system can be deployed. In this paper, we first introduce a new evaluation metric named field-level calibration error that measures the bias in predictions over the sensitive input field that the decision-maker concerns. We show that existing post-hoc calibration methods have limited improvements in the new field-level metric and other non-calibration metrics such as the AUC score. To this end, we propose Neural Calibration, a simple yet powerful post-hoc calibration method that learns to calibrate by making full use of the field-aware information over the validation set. We present extensive experiments on five large-scale datasets. The results showed that Neural Calibration significantly improves against uncalibrated predictions in common metrics such as the negative log-likelihood, Brier score and AUC, as well as the proposed field-level calibration error.",10.1145/3366423.3380154,https://doi.org/10.1145/3366423.3380154,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,Field-aware Calibration: A Simple and Empirically Strong Method for Reliable Probabilistic Predictions,"Pan, Feiyang and Ao, Xiang and Tang, Pingzhong and Lu, Min and Liu, Dapeng and Xiao, Lei and He, Qing",inproceedings,10.1145/3366423.3380154,
10.1145/3366423.3380164,10.1145/3366423.3380164,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","review generation, recommender system, dual learning",11,837–847,Proceedings of The Web Conference 2020,"In many recommender systems, users express item opinions through two kinds of behaviors: giving preferences and writing detailed reviews. As both kinds of behaviors reflect users’ assessment of items, review enhanced recommender systems leverage these two kinds of user behaviors to boost recommendation performance. On the one hand, researchers proposed to better model the user and item embeddings with additional review information for enhancing preference prediction accuracy. On the other hand, some recent works focused on automatically generating item reviews for recommendation explanations with related user and item embeddings. We argue that, while the task of preference prediction with the accuracy goal is well recognized in the community, the task of generating reviews for explainable recommendation is also important to gain user trust and increase conversion rate. Some preliminary attempts have considered jointly modeling these two tasks, with the user and item embeddings are shared. These studies empirically showed that these two tasks are correlated, and jointly modeling them would benefit the performance of both tasks. In this paper, we make a further study of unifying these two tasks for explainable recommendation. Instead of simply correlating these two tasks with shared user and item embeddings, we argue that these two tasks are presented in dual forms. In other words, the input of the primal preference prediction task is exactly the output of the dual review generation task , with and denote the preference value space and review space. Therefore, we could explicitly model the probabilistic correlation between these two dual tasks with . We design a unified dual framework of how to inject the probabilistic duality of the two tasks in the training stage. Furthermore, as the detailed preference and review information are not available for each user-item pair in the test stage, we propose a transfer learning based model for preference prediction and review generation. Finally, extensive experimental results on two real-world datasets clearly show the effectiveness of our proposed model for both user preference prediction and review generation.",10.1145/3366423.3380164,https://doi.org/10.1145/3366423.3380164,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,Dual Learning for Explainable Recommendation: Towards Unifying User Preference Prediction and Review Generation,"Sun, Peijie and Wu, Le and Zhang, Kun and Fu, Yanjie and Hong, Richang and Wang, Meng",inproceedings,10.1145/3366423.3380164,
10.1145/3366423.3380187,10.1145/3366423.3380187,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Personalized Ranking, Negative Sampling, Implicit Feedback",11,1093–1103,Proceedings of The Web Conference 2020,"As the task of predicting a personalized ranking on a set of items, item recommendation has become an important way to address information overload. Optimizing ranking loss aligns better with the ultimate goal of item recommendation, so many ranking-based methods were proposed for item recommendation, such as collaborative filtering with Bayesian Personalized Ranking (BPR) loss, and Weighted Approximate-Rank Pairwise (WARP) loss. However, the ranking-based methods can not consistently beat regression-based models with the gravity regularizer. The key challenge in ranking-based optimization is difficult to fully use the limited number of negative samples, particularly when they are not so informative. To this end, we propose a new ranking loss based on importance sampling so that more informative negative samples can be better used. We then design a series of negative samplers from simple to complex, whose informativeness of negative samples is from less to more. With these samplers, the loss function is easy to use and can be optimized by popular solvers. The proposed algorithms are evaluated with five real-world datasets of varying size and difficulty. The results show that they consistently outperform the state-of-the-art item recommendation algorithms, and the relative improvements with respect to NDCG@50 are more than 19.2% on average. Moreover, the loss function is verified to make better use of negative samples and to require fewer negative samples when they are more informative.",10.1145/3366423.3380187,https://doi.org/10.1145/3366423.3380187,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,Personalized Ranking with Importance Sampling,"Lian, Defu and Liu, Qi and Chen, Enhong",inproceedings,10.1145/3366423.3380187,
10.1145/3366423.3380217,10.1145/3366423.3380217,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Web Monetization, User privacy, User Subscription, Paywalls",12,1433–1444,Proceedings of The Web Conference 2020,"Funding the production of quality online content is a pressing problem for content producers. The most common funding method, online advertising, is rife with well-known performance and privacy harms, and an intractable subject-agent conflict: many users do not want to see advertisements, depriving the site of needed funding. Because of these negative aspects of advertisement-based funding, paywalls are an increasingly popular alternative for websites. This shift to a “pay-for-access” web is one that has potentially huge implications for the web and society. Instead of a system where information (nominally) flows freely, paywalls create a web where high quality information is available to fewer and fewer people, leaving the rest of the web users with less information, that might be also less accurate and of lower quality. Despite the potential significance of a move from an “advertising-but-open” web to a “paywalled” web, we find this issue understudied. This work addresses this gap in our understanding by measuring how widely paywalls have been adopted, what kinds of sites use paywalls, and the distribution of policies enforced by paywalls. A partial list of our findings include that (i) paywall use has increased, and at an increasing rate (2 \texttimes{} more paywalls every 6 months), (ii) paywall adoption differs by country (e.g., 18.75% in US, 12.69% in Australia), (iii) paywall deployment significantly changes how users interact with the site (e.g., higher bounce rates, less incoming links), (iv) the median cost of an annual paywall access is 108 USD per site, and (v) paywalls are in general trivial to circumvent. Finally, we present the design of a novel, automated system for detecting whether a site uses a paywall, through the combination of runtime browser instrumentation and repeated programmatic interactions with the site. We intend this classifier to augment future, longitudinal measurements of paywall use and behavior.",10.1145/3366423.3380217,https://doi.org/10.1145/3366423.3380217,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,Keeping out the Masses: Understanding the Popularity and Implications of Internet Paywalls,"Papadopoulos, Panagiotis and Snyder, Peter and Athanasakis, Dimitrios and Livshits, Benjamin",inproceedings,10.1145/3366423.3380217,
10.1145/3366423.3380297,10.1145/3366423.3380297,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Heterogeneous graph, Graph neural network, Graph embedding",11,2331–2341,Proceedings of The Web Conference 2020,"A large number of real-world graphs or networks are inherently heterogeneous, involving a diversity of node types and relation types. Heterogeneous graph embedding is to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing models usually define multiple metapaths in a heterogeneous graph to capture the composite relations and guide neighbor selection. However, these models either omit node content features, discard intermediate nodes along the metapath, or only consider one metapath. To address these three limitations, we propose a new model named Metapath Aggregated Graph Neural Network (MAGNN) to boost the final performance. Specifically, MAGNN employs three major components, i.e., the node content transformation to encapsulate input node attributes, the intra-metapath aggregation to incorporate intermediate semantic nodes, and the inter-metapath aggregation to combine messages from multiple metapaths. Extensive experiments on three real-world heterogeneous graph datasets for node classification, node clustering, and link prediction show that MAGNN achieves more accurate prediction results than state-of-the-art baselines.",10.1145/3366423.3380297,https://doi.org/10.1145/3366423.3380297,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding,"Fu, Xinyu and Zhang, Jiani and Meng, Ziqiao and King, Irwin",inproceedings,10.1145/3366423.3380297,
10.1145/3366423.3380300,10.1145/3366423.3380300,TheWebConf.bib,1,['TheWebConf.bib'],7,WWW '20,"Taipei, Taiwan",,12,2365–2376,Proceedings of The Web Conference 2020,"Wikipedia is one of the most visited sites on the Web and a common source of information for many users. As an encyclopedia, Wikipedia was not conceived as a source of original information, but as a gateway to secondary sources: according to Wikipedia’s guidelines, facts must be backed up by reliable sources that reflect the full spectrum of views on the topic. Although citations lie at the heart of Wikipedia, little is known about how users interact with them. To close this gap, we built client-side instrumentation for logging all interactions with links leading from English Wikipedia articles to cited references during one month, and conducted the first analysis of readers’ interactions with citations. We find that overall engagement with citations is low: about one in 300 page views results in a reference click (0.29% overall; 0.56% on desktop; 0.13% on mobile). Matched observational studies of the factors associated with reference clicking reveal that clicks occur more frequently on shorter pages and on pages of lower quality, suggesting that references are consulted more commonly when Wikipedia itself does not contain the information sought by the user. Moreover, we observe that recent content, open access sources, and references about life events (births, deaths, marriages, etc.) are particularly popular. Taken together, our findings deepen our understanding of Wikipedia’s role in a global information economy where reliability is ever less certain, and source attribution ever more vital.",10.1145/3366423.3380300,https://doi.org/10.1145/3366423.3380300,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,Quantifying Engagement with Citations on Wikipedia,"Piccardi, Tiziano and Redi, Miriam and Colavizza, Giovanni and West, Robert",inproceedings,10.1145/3366423.3380300,
10.1145/3366423.3380303,10.1145/3366423.3380303,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Top-K Recommendation, Implicit Feedback, Factorization Machines, Efficient Learning, Context-aware",11,2400–2410,Proceedings of The Web Conference 2020,"To provide more accurate recommendation, it is a trending topic to go beyond modeling user-item interactions and take context features into account. Factorization Machines (FM) with negative sampling is a popular solution for context-aware recommendation. However, it is not robust as sampling may lost important information and usually leads to non-optimal performances in practical. Several recent efforts have enhanced FM with deep learning architectures for modelling high-order feature interactions. While they either focus on rating prediction task only, or typically adopt the negative sampling strategy for optimizing the ranking performance. Due to the dramatic fluctuation of sampling, it is reasonable to argue that these sampling-based FM methods are still suboptimal for context-aware recommendation. In this paper, we propose to learn FM without sampling for ranking tasks that helps context-aware recommendation particularly. Despite effectiveness, such a non-sampling strategy presents strong challenge in learning efficiency of the model. Accordingly, we further design a new ideal framework named Efficient Non-Sampling Factorization Machines (ENSFM). ENSFM not only seamlessly connects the relationship between FM and Matrix Factorization (MF), but also resolves the challenging efficiency issue via novel memorization strategies. Through extensive experiments on three real-world public datasets, we show that 1) the proposed ENSFM consistently and significantly outperforms the state-of-the-art methods on context-aware Top-K recommendation, and 2) ENSFM achieves significant advantages in training efficiency, which makes it more applicable to real-world large-scale systems. Moreover, the empirical results indicate that a proper learning method is even more important than advanced neural network structures for Top-K recommendation task. Our implementation has been released 1 to facilitate further developments on efficient non-sampling methods.",10.1145/3366423.3380303,https://doi.org/10.1145/3366423.3380303,"New York, NY, USA",Association for Computing Machinery,9781450370233,2020,Efficient Non-Sampling Factorization Machines for Optimal Context-Aware Recommendation,"Chen, Chong and Zhang, Min and Ma, Weizhi and Liu, Yiqun and Ma, Shaoping",inproceedings,10.1145/3366423.3380303,
10.1145/3366424.3382677,10.1145/3366424.3382677,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","social influence, popularity prediction, information cascades",3,19–21,Companion Proceedings of the Web Conference 2020,"The online information cascades have spatial and temporal characteristics. Retweets in cascades have bi-directional social influence and temporal delay, e.g., a hub node influenced by a root node will further increase the exposure of information, enhance the influence of the root node, and cause subsequent retweets after a certain time. Existing deep learning approaches mostly consider only the decay effects of social influence, ignoring the bi-directional dependency and delay effects between graphs at different moments. Therefore, a novel method is presented here, namely the Graph Sequence Attention Networks (GSAN) , which addresses the bi-directional attention mechanism to learn temporal dynamics of social influence, as well as the cascading structure. A graph transformer block is designed to learn the complicated dependencies of spatial and temporal features in cascades. The proposed method could achieve state-of-the-art performance and large improvements in popularity prediction compared to strong baselines in real-world datasets.",10.1145/3366424.3382677,https://doi.org/10.1145/3366424.3382677,"New York, NY, USA",Association for Computing Machinery,9781450370240,2020,Learning Bi-directional Social Influence in Information Cascades using Graph Sequence Attention Networks,"Huang, Zhenhua and Wang, Zhenyu and Zhang, Rui and Zhao, Yangyang and Zheng, Fadong",inproceedings,10.1145/3366424.3382677,
10.1145/3366424.3382680,10.1145/3366424.3382680,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","Feature Interactions, Factorization-Machines, Attention Network",2,26–27,Companion Proceedings of the Web Conference 2020,"This paper proposes Dual-attentional Factorization-Machines (DFM), which incorporates global-wise attention and element-wise attention with FM for user response prediction. We further extend DFM with a deep neural network and name this new model Dual-attentional Factorization-machines based Network (DFNet). Comprehensive experiments are conducted on two real-world datasets to demonstrate the effectiveness of DFM and DFNet over the state-of-the-art models for user response prediction.",10.1145/3366424.3382680,https://doi.org/10.1145/3366424.3382680,"New York, NY, USA",Association for Computing Machinery,9781450370240,2020,Dual-attentional Factorization-Machines based Neural Network for User Response Prediction,"Liu, Feng and Guo, Wei and Guo, Huifeng and Tang, Ruiming and Ye, Yunming and He, Xiuqiang",inproceedings,10.1145/3366424.3382680,
10.1145/3366424.3383300,10.1145/3366424.3383300,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","word embeddings, recommender systems, link prediction, graph embeddings",5,385–389,Companion Proceedings of the Web Conference 2020,"Recommender systems are paramount in providing personalized content and intelligent content filtering on any social media platform, web portal, and online application. In line with the current trends in the field directed towards mapping problem and data encoding representations from other fields, this research investigates the feasibility of augmenting a graph-based recommender system for Amazon products with two state-of-the-art representation models. In particular, the potential benefits of using the language representation model BERT and GraphSage based representations of nodes and edges for improving the quality of the recommendations were investigated. Link prediction and link attribute inference were used to identify the products that the users will buy and predict the rating they will give to a product, respectively. The initial results of our exploratory study are encouraging and point to potential directions for future research.",10.1145/3366424.3383300,https://doi.org/10.1145/3366424.3383300,"New York, NY, USA",Association for Computing Machinery,9781450370240,2020,Boosting Recommender Systems with Advanced Embedding Models,"Cenikj, Gjorgjina and Gievska, Sonja",inproceedings,10.1145/3366424.3383300,
10.1145/3366424.3383540,10.1145/3366424.3383540,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","neural networks, natural language generation, Explainable recommendation",5,198–202,Companion Proceedings of the Web Conference 2020,"It has been commonly agreed that the explanation associated with recommendation can be effective in increasing the recommender systems (RS)’s transparency and thus users’ satisfaction and acceptance. Among the various types of explanation in RS, the commonly used textual explanation can be roughly classified into two categories, i.e., template-based and generation-based. As for the former, the fixed template may lose flexibility, while, though the latter may enrich the explanation, it may produce less useful content due to the lack of controllability. In this work, we combine the advantages of the two types of method by developing a neural generation approach named Neural Template (NETE) whose explanations are not only flexible but also controllable and useful. Our human evaluation results confirm that the explanations from our model are perceived helpful by users. Furthermore, our case study illustrates that the explanation generation process is controllable. To demonstrate the controllability of our model, we present a demo that can be easily viewed on a Web browser.",10.1145/3366424.3383540,https://doi.org/10.1145/3366424.3383540,"New York, NY, USA",Association for Computing Machinery,9781450370240,2020,Towards Controllable Explanation Generation for Recommender Systems via Neural Template,"Li, Lei and Chen, Li and Zhang, Yongfeng",inproceedings,10.1145/3366424.3383540,
10.1145/3366424.3383543,10.1145/3366424.3383543,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '20,"Taipei, Taiwan","user-aware, tagging system, tag recommendation, tag ranking, social popularity, social media",5,212–216,Companion Proceedings of the Web Conference 2020,"Enhancing social popularity of a post (i.e., the number of views or likes) on social network services is important for both ordinary users and companies who want to promote themselves. In this paper, we have implemented an online tagging support system to achieve this using an algorithm that recommends appropriate hashtags considering not only content popularity but also user popularity. The effectiveness of this technology has been verified by actually uploading photos with recommended hashtags on a real social network service.",10.1145/3366424.3383543,https://doi.org/10.1145/3366424.3383543,"New York, NY, USA",Association for Computing Machinery,9781450370240,2020,Earn More Social Attention: User Popularity Based Tag Recommendation System,"Wang, Xueting and Zhang, Yiwei and Yamasaki, Toshihiko",inproceedings,10.1145/3366424.3383543,
10.1145/3383313.3411452,10.1145/3383313.3411452,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Recommendation systems, benchmark and evaluation framework., efficiency/effectiveness methodology",6,770–775,Proceedings of the 14th ACM Conference on Recommender Systems,"Throughout the years, numerous recommendation algorithms have been developed to address the information filtering problem by leveraging users’ tastes through implicit or explicit feedback. In this paper, we present the work undertaken as part of a PhD thesis focused on exploring new evaluation dimensions centred around the efficiency-effectiveness trade-offs present in state-of-the-art recommendation systems. Firstly, we highlight the lack of efficiency-oriented studies and we formulate the research problem. Then, we propose a mapping of the design space and a classification of the recommendation algorithms/models with respect to salient attributes and characteristics. At the same time, we explain why and how assessing the recommendations on an accuracy versus training cost curve would advance the current knowledge in the area of evaluation, as well as open new research avenues for exploring parameter configurations within well-known algorithms. Finally, we make the case for a comprehensive methodology that incorporates predictive efficiency-effectiveness models, which illustrate the performance and behaviour of the recommendation systems under different recommendation tasks, while satisfying user-defined quality of service constraints and goals.",10.1145/3383313.3411452,https://doi.org/10.1145/3383313.3411452,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Efficiency-Effectiveness Trade-offs in Recommendation Systems,"Paun, Iulia",inproceedings,10.1145/3383313.3411452,
10.1145/3383313.3411456,10.1145/3383313.3411456,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Interpretability, Model Explanation, Pattern Mining",5,782–786,Proceedings of the 14th ACM Conference on Recommender Systems,"A common and recently widely accepted problem in the field of machine learning is the black box nature of many algorithms. In practice, many machine learning algorithms can only be viewed and evaluated in terms of their inputs and outputs, without taking their internal workings into account. Perhaps the most notorious examples in this context are artificial neural networks and deep learning techniques, but they are certainly not the only techniques that suffer from this problem. Matrix factorisation models for recommendation systems, for example, suffer from the same lack of interpretability. Our research focuses on applying and adapting pattern mining techniques to gain meaningful insights in recommendation algorithms by analysing them in terms of both their input and output, also allowing us to compare different algorithms and discover the hidden biases that lead to those differences.",10.1145/3383313.3411456,https://doi.org/10.1145/3383313.3411456,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Exploratory Methods for Evaluating Recommender Systems,"De Pauw, Joey",inproceedings,10.1145/3383313.3411456,
10.1145/3383313.3411457,10.1145/3383313.3411457,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","confidence in recommender systems, ecommerce, user modeling",6,764–769,Proceedings of the 14th ACM Conference on Recommender Systems,"Broadly, the goal of my research is to develop modeling techniques for recommender systems data in the streaming context. Streaming models in recommender systems have received attention in demanding applications such as social media streams and news delivery as model requirements are complex. To date, my work in recommender systems has focused on collaborative filtering with work in exploiting structure in similarity evaluation, modeling event time of user activity, and confidence measures for individual predictions. Exploiting underlying structure in similarity evaluation is shown to positively impact prediction accuracy. Modeling event times of user activity presents many applications in soliciting user involvement in ecommerce settings. Early work is in progress in developing confidence measures for individual rating predictions. While these efforts have not been focused on the streaming environment to date, they do form a basis for future work in which computational demands are higher. Extensions to the streaming domain are discussed.",10.1145/3383313.3411457,https://doi.org/10.1145/3383313.3411457,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,"Developing Work in Confidence, Similarity Structure, and Modeling User Event Time","Munson, Jacob",inproceedings,10.1145/3383313.3411457,
10.1145/3383313.3411529,10.1145/3383313.3411529,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Automated Machine Learning, Hyperparameter Tuning, Model Search, Neural Architecture Search, Recommender Systems",3,582–584,Proceedings of the 14th ACM Conference on Recommender Systems,"Realistic recommender systems are often required to adapt to ever-changing data and tasks or to explore different models systematically. To address the need, we present AutoRec &nbsp;1 &nbsp;2, an open-source automated machine learning (AutoML) platform extended from the TensorFlow&nbsp;[3] ecosystem and, to our knowledge, the first framework to leverage AutoML for model search and hyperparameter tuning in deep recommendation models. AutoRec also supports a highly flexible pipeline that accommodates both sparse and dense inputs, rating prediction and click-through rate (CTR) prediction tasks, and an array of recommendation models. Lastly, AutoRec provides a simple, user-friendly API. Experiments conducted on the benchmark datasets reveal AutoRec is reliable and can identify models which resemble the best model without prior knowledge.",10.1145/3383313.3411529,https://doi.org/10.1145/3383313.3411529,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,AutoRec: An Automated Recommender System,"Wang, Ting-Hsiang and Hu, Xia and Jin, Haifeng and Song, Qingquan and Han, Xiaotian and Liu, Zirui",inproceedings,10.1145/3383313.3411529,
10.1145/3383313.3411532,10.1145/3383313.3411532,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","BERT, Embeddings, Online Social Networks, Recommender Systems",5,623–627,Proceedings of the 14th ACM Conference on Recommender Systems,"The workshop features presentations of accepted contributions to the RecSys Challenge 2020, organized by Politecnico di Bari, Free University of Bozen-Bolzano, TU Wien, University of Colorado, Boulder, and Universidade Federal de Campina Grande, and sponsored by Twitter. The challenge focuses on a real-world task of Tweet engagement prediction in a dynamic environment. The goal is to predict the probability for different types of engagement (Like, Reply, Retweet, and Retweet with comment) of a target user for a set of Tweets, based on heterogeneous input data. To this end, Twitter has released a large public dataset of ~160M public Tweets, obtained by subsampling within ~2 weeks, that contains engagement features, user features, and Tweet features. A peculiarity of this challenge is related to the recent regulations on data protection and privacy. The challenge data set was compliant: if a user deleted a Tweet, or their data from Twitter, the dataset was promptly updated. Moreover, each change in the dataset implied new evaluations of all submissions and the update of the leaderboard metrics. The challenge was well received with 1,131 registered users. In the final phase, 20 teams were competing for the winning position. These teams had an average size of approximately 4 participants and developed an overall number of 127 different methods.",10.1145/3383313.3411532,https://doi.org/10.1145/3383313.3411532,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,RecSys 2020 Challenge Workshop: Engagement Prediction on Twitter’s Home Timeline,"Anelli, Vito Walter and Deli\'{c}, Amra and Sottocornola, Gabriele and Smith, Jessie and Andrade, Nazareno and Belli, Luca and Bronstein, Michael and Gupta, Akshay and Ira Ktena, Sofia and Lung-Yut-Fong, Alexandre and Portman, Frank and Tejani, Alykhan and Xie, Yuanpu and Zhu, Xiao and Shi, Wenzhe",inproceedings,10.1145/3383313.3411532,
10.1145/3383313.3411536,10.1145/3383313.3411536,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","reinforcement learning, recommender systems, offline evaluation, off-policy, multi-armed bandits, causal inference",2,628–629,Proceedings of the 14th ACM Conference on Recommender Systems,"The REVEAL workshop1 focuses on framing the recommendation problem as a one of making personalized interventions, e.g.&nbsp;deciding to recommend a particular item to a particular user. Moreover, these interventions sometimes depend on each other, where a stream of interactions occurs between the user and the system, and where each decision to recommend something will have an impact on future steps and long-term rewards. This framing creates a number of challenges we will discuss at the workshop. How can recommender systems be evaluated offline in such a context? How can we learn recommendation policies that are aware of these delayed consequences and outcomes?",10.1145/3383313.3411536,https://doi.org/10.1145/3383313.3411536,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,REVEAL 2020: Bandit and Reinforcement Learning from User Interactions,"Joachims, Thorsten and Raimond, Yves and Koch, Olivier and Dimakopoulou, Maria and Vasile, Flavian and Swaminathan, Adith",inproceedings,10.1145/3383313.3411536,
10.1145/3383313.3412207,10.1145/3383313.3412207,RecSys.bib,1,['RecSys.bib'],7,RecSys '20,"Virtual Event, Brazil",,6,438–443,Proceedings of the 14th ACM Conference on Recommender Systems,"Nowadays we commonly have multiple sources of data associated with items. Users may provide numerical ratings, or implicit interactions, but may also provide textual reviews. Although many algorithms have been proposed to jointly learn a model over both interactions and textual data, there is room to improve the many factorization models that are proven to work well on interactions data, but are not designed to exploit textual information. Our focus in this work is to propose a simple, yet easily applicable and effective, method to incorporate review data into such factorization models. In particular, we propose to build the user and item embeddings within the topic space of a topic model learned from the review data. This has several advantages: we observe that initializing the user and item embeddings in topic space leads to faster convergence of the factorization algorithm to a model that out-performs models initialized randomly, or with other state-of-the-art initialization strategies. Moreover, constraining user and item factors to topic space allows for the learning of an interpretable model that users can visualise.",10.1145/3383313.3412207,https://doi.org/10.1145/3383313.3412207,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Combining Rating and Review Data by Initializing Latent Factor Models with Topic Models for Top-N Recommendation,"Pe\~{n}a, Francisco J. and O'Reilly-Morgan, Diarmuid and Tragos, Elias Z. and Hurley, Neil and Duriakova, Erika and Smyth, Barry and Lawlor, Aonghus",inproceedings,10.1145/3383313.3412207,
10.1145/3383313.3412210,10.1145/3383313.3412210,RecSys.bib,1,['RecSys.bib'],7,RecSys '20,"Virtual Event, Brazil",,6,551–556,Proceedings of the 14th ACM Conference on Recommender Systems,"This paper focuses on how to generate unbiased recommendations based on biased implicit user-item interactions. We propose a combinational joint learning framework to simultaneously learn unbiased user-item relevance and unbiased propensity. More specifically, we first present a new unbiased objective function for estimating propensity. We then show how a na\""{\i}ve joint learning approach faces an estimation-training overlap problem. Hence, we propose to jointly train multiple sub-models from different parts of the training dataset to avoid this problem. Finally, we show how to incorporate residual components trained by the complete training data to complement the relevance and propensity sub-models. Extensive experiments on two public datasets demonstrate the effectiveness of the proposed model with an improvement of 4% on average over the best alternatives.",10.1145/3383313.3412210,https://doi.org/10.1145/3383313.3412210,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Unbiased Implicit Recommendation and Propensity Estimation via Combinational Joint Learning,"Zhu, Ziwei and He, Yun and Zhang, Yin and Caverlee, James",inproceedings,10.1145/3383313.3412210,
10.1145/3383313.3412213,10.1145/3383313.3412213,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Bias, Longitudinal Effects, Session-based Recommendation",6,474–479,Proceedings of the 14th ACM Conference on Recommender Systems,"Session-based recommendation is a problem setting where the task of a recommender system is to make suitable item suggestions based only on a few observed user interactions in an ongoing session. The lack of long-term preference information about individual users in such settings usually results in a limited level of personalization, where a small set of popular items may be recommended to many users. This repeated exposure of such a subset of the items through the recommendations may in turn lead to a reinforcement effect over time, and to a system which is not able to help users discover new content anymore to the desirable extent. In this work, we investigate such potential longitudinal effects of session-based recommendations in a simulation-based approach. Specifically, we analyze to what extent algorithms of different types may lead to concentration effects over time. Our experiments in the music domain reveal that all investigated algorithms—both neural and heuristic ones—may lead to lower item coverage and to a higher concentration on a subset of the items. Additional simulation experiments however also indicate that relatively simple re-ranking strategies, e.g., by avoiding too many repeated recommendations in the music domain, may help to deal with this problem.",10.1145/3383313.3412213,https://doi.org/10.1145/3383313.3412213,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Exploring Longitudinal Effects of Session-based Recommendations,"Ferraro, Andres and Jannach, Dietmar and Serra, Xavier",inproceedings,10.1145/3383313.3412213,
10.1145/3383313.3412219,10.1145/3383313.3412219,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Autoencoders, Collaborative Filtering, Hyperbolic Geometry, Top-N Recommendation",6,527–532,Proceedings of the 14th ACM Conference on Recommender Systems,"We introduce a simple autoencoder based on hyperbolic geometry for solving standard collaborative filtering problem. In contrast to many modern deep learning techniques, we build our solution using only a single hidden layer. Remarkably, even with such a minimalistic approach, we not only outperform the Euclidean counterpart but also achieve a competitive performance with respect to the current state-of-the-art. We additionally explore the effects of space curvature on the quality of hyperbolic models and propose an efficient data-driven method for estimating its optimal value.",10.1145/3383313.3412219,https://doi.org/10.1145/3383313.3412219,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Performance of Hyperbolic&nbsp;Geometry&nbsp;Models on Top-N&nbsp;Recommendation&nbsp;Tasks,"Mirvakhabova, Leyla and Frolov, Evgeny and Khrulkov, Valentin and Oseledets, Ivan and Tuzhilin, Alexander",inproceedings,10.1145/3383313.3412219,
10.1145/3383313.3412237,10.1145/3383313.3412237,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","knowledge graphs, knowledge-aware document representation, news recommender systems",10,200–209,Proceedings of the 14th ACM Conference on Recommender Systems,"News articles usually contain knowledge entities such as celebrities or organizations. Important entities in articles carry key messages and help to understand the content in a more direct way. An industrial news recommender system contains various key applications, such as personalized recommendation, item-to-item recommendation, news category classification, news popularity prediction and local news detection. We find that incorporating knowledge entities for better document understanding benefits these applications consistently. However, existing document understanding models either represent news articles without considering knowledge entities (e.g., BERT) or rely on a specific type of text encoding model (e.g., DKN) so that the generalization ability and efficiency is compromised. In this paper, we propose KRED, which is a fast and effective model to enhance arbitrary document representation with a knowledge graph. KRED first enriches entities’ embeddings by attentively aggregating information from their neighborhood in the knowledge graph. Then a context embedding layer is applied to annotate the dynamic context of different entities such as frequency, category and position. Finally, an information distillation layer aggregates the entity embeddings under the guidance of the original document representation and transforms the document vector into a new one. We advocate to optimize the model with a multi-task framework, so that different news recommendation applications can be united and useful information can be shared across different tasks. Experiments on a real-world Microsoft News dataset demonstrate that KRED greatly benefits a variety of news recommendation applications.",10.1145/3383313.3412237,https://doi.org/10.1145/3383313.3412237,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,KRED: Knowledge-Aware Document Representation for News Recommendations,"Liu, Danyang and Lian, Jianxun and Wang, Shiyin and Qiao, Ying and Chen, Jiun-Hung and Sun, Guangzhong and Xie, Xing",inproceedings,10.1145/3383313.3412237,
10.1145/3383313.3412238,10.1145/3383313.3412238,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Personalization, Recommender System, Sequential Recommendation, Unexpectedness",10,279–288,Proceedings of the 14th ACM Conference on Recommender Systems,"Classical recommender system methods typically face the filter bubble problem when users only receive recommendations of their familiar items, making them bored and dissatisfied. To address the filter bubble problem, unexpected recommendations have been proposed to recommend items significantly deviating from user’s prior expectations and thus surprising them by presenting ”fresh” and previously unexplored items to the users. In this paper, we describe a novel Personalized Unexpected Recommender System (PURS) model that incorporates unexpectedness into the recommendation process by providing multi-cluster modeling of user interests in the latent space and personalized unexpectedness via the self-attention mechanism and via selection of an appropriate unexpected activation function. Extensive offline experiments on three real-world datasets illustrate that the proposed PURS model significantly outperforms the state-of-the-art baseline approaches in terms of both accuracy and unexpectedness measures. In addition, we conduct an online A/B test at a major video platform Alibaba-Youku, where our model achieves over 3% increase in the average video view per user metric. The proposed model is in the process of being deployed by the company.",10.1145/3383313.3412238,https://doi.org/10.1145/3383313.3412238,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,PURS: Personalized Unexpected Recommender System for Improving User Satisfaction,"Li, Pan and Que, Maofei and Jiang, Zhichao and HU, YAO and Tuzhilin, Alexander",inproceedings,10.1145/3383313.3412238,
10.1145/3383313.3412243,10.1145/3383313.3412243,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Adversarial Machine Learning, Recommender System, Security and Privacy",10,318–327,Proceedings of the 14th ACM Conference on Recommender Systems,"Recommender systems play an important role in modern information and e-commerce applications. While increasing research is dedicated to improving the relevance and diversity of the recommendations, the potential risks of state-of-the-art recommendation models are under-explored, that is, these models could be subject to attacks from malicious third parties, through injecting fake user interactions to achieve their purposes. This paper revisits the adversarially-learned injection attack problem, where the injected fake user ‘behaviors’ are learned locally by the attackers with their own model – one that is potentially different from the model under attack, but shares similar properties to allow attack transfer. We found that most existing works in literature suffer from two major limitations: (1) they do not solve the optimization problem precisely, making the attack less harmful than it could be, (2) they assume perfect knowledge for the attack, causing the lack of understanding for realistic attack capabilities. We demonstrate that the exact solution for generating fake users as an optimization problem could lead to a much larger impact. Our experiments on a real-world dataset reveal important properties of the attack, including attack transferability and its limitations. These findings can inspire useful defensive methods against this possible existing attack.",10.1145/3383313.3412243,https://doi.org/10.1145/3383313.3412243,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Revisiting Adversarially Learned Injection Attacks Against Recommender Systems,"Tang, Jiaxi and Wen, Hongyi and Wang, Ke",inproceedings,10.1145/3383313.3412243,
10.1145/3383313.3412246,10.1145/3383313.3412246,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Similarity-based Generalization, Recommender Systems, Filter Bubbles",10,82–91,Proceedings of the 14th ACM Conference on Recommender Systems,"We study a model of user decision-making in the context of recommender systems via numerical simulation. Our model provides an explanation for the findings of Nguyen, et. al (2014), where, in environments where recommender systems are typically deployed, users consume increasingly similar items over time even without recommendation. We find that recommendation alleviates these natural filter-bubble effects, but that it also leads to an increase in homogeneity across users, resulting in a trade-off between homogenizing across-user consumption and diversifying within-user consumption. Finally, we discuss how our model highlights the importance of collecting data on user beliefs and their evolution over time both to design better recommendations and to further understand their impact.",10.1145/3383313.3412246,https://doi.org/10.1145/3383313.3412246,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Deconstructing the Filter Bubble: User&nbsp;Decision-Making&nbsp;and&nbsp;Recommender&nbsp;Systems,"Aridor, Guy and Goncalves, Duarte and Sikdar, Shan",inproceedings,10.1145/3383313.3412246,
10.1145/3383313.3412248,10.1145/3383313.3412248,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","User Embeddings, Sequence, Music Recommendation, Context",10,53–62,Proceedings of the 14th ACM Conference on Recommender Systems,"Recommender systems play an important role in providing an engaging experience on online music streaming services. However, the musical domain presents distinctive challenges to recommender systems: tracks are short, listened to multiple times, typically consumed in sessions with other tracks, and relevance is highly context-dependent. In this paper, we argue that modeling users’ preferences at the beginning of a session is a practical and effective way to address these challenges. Using a dataset from Spotify, a popular music streaming service, we observe that a) consumption from the recent past and b) session-level contextual variables (such as the time of the day or the type of device used) are indeed predictive of the tracks a user will stream—much more so than static, average preferences. Driven by these findings, we propose CoSeRNN, a neural network architecture that models users’ preferences as a sequence of embeddings, one for each session. CoSeRNN predicts, at the beginning of a session, a preference vector, based on past consumption history and current context. This preference vector can then be used in downstream tasks to generate contextually relevant just-in-time recommendations efficiently, by using approximate nearest-neighbour search algorithms. We evaluate CoSeRNN on session and track ranking tasks, and find that it outperforms the current state of the art by upwards of 10% on different ranking metrics. Dissecting the performance of our approach, we find that sequential and contextual information are both crucial.",10.1145/3383313.3412248,https://doi.org/10.1145/3383313.3412248,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Contextual and Sequential User Embeddings for Large-Scale Music Recommendation,"Hansen, Casper and Hansen, Christian and Maystre, Lucas and Mehrotra, Rishabh and Brost, Brian and Tomasi, Federico and Lalmas, Mounia",inproceedings,10.1145/3383313.3412248,
10.1145/3383313.3412249,10.1145/3383313.3412249,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","probing, conversational search, conversational recommendation",10,388–397,Proceedings of the 14th ACM Conference on Recommender Systems,"Heavily pre-trained transformer models such as BERT have recently shown to be remarkably powerful at language modelling, achieving impressive results on numerous downstream tasks. It has also been shown that they implicitly store factual knowledge in their parameters after pre-training. Understanding what the pre-training procedure of LMs actually learns is a crucial step for using and improving them for Conversational Recommender Systems (CRS). We first study how much off-the-shelf pre-trained BERT “knows” about recommendation items such as books, movies and music. In order to analyze the knowledge stored in BERT’s parameters, we use different probes (i.e., tasks to examine a trained model regarding certain properties) that require different types of knowledge to solve, namely content-based and collaborative-based. Content-based knowledge is knowledge that requires the model to match the titles of items with their content information, such as textual descriptions and genres. In contrast, collaborative-based knowledge requires the model to match items with similar ones, according to community interactions such as ratings. We resort to BERT’s Masked Language Modelling (MLM) head to probe its knowledge about the genre of items, with cloze style prompts. In addition, we employ BERT’s Next Sentence Prediction (NSP) head and representations’ similarity (SIM) to compare relevant and non-relevant search and recommendation query-document inputs to explore whether BERT can, without any fine-tuning, rank relevant items first. Finally, we study how BERT performs in a conversational recommendation downstream task. To this end, we fine-tune BERT to act as a retrieval-based CRS. Overall, our experiments show that: (i) BERT has knowledge stored in its parameters about the content of books, movies and music; (ii) it has more content-based knowledge than collaborative-based knowledge; and (iii) fails on conversational recommendation when faced with adversarial data.",10.1145/3383313.3412249,https://doi.org/10.1145/3383313.3412249,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,"What does BERT know about books, movies and music? Probing BERT for Conversational Recommendation","Penha, Gustavo and Hauff, Claudia",inproceedings,10.1145/3383313.3412249,
10.1145/3383313.3412252,10.1145/3383313.3412252,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Interaction bias, Recommender systems, Reinforcement learning, Simulation",10,190–199,Proceedings of the 14th ACM Conference on Recommender Systems,"Reinforcement learning for recommendation (RL4Rec) methods are increasingly receiving attention as an effective way to improve long-term user engagement. However, applying RL4Rec online comes with risks: exploration may lead to periods of detrimental user experience. Moreover, few researchers have access to real-world recommender systems. Simulations have been put forward as a solution where user feedback is simulated based on logged historical user data, thus enabling optimization and evaluation without being run online. While simulators do not risk the user experience and are widely accessible, we identify an important limitation of existing simulation methods. They ignore the interaction biases present in logged user data, and consequently, these biases affect the resulting simulation. As a solution to this issue, we introduce a debiasing step in the simulation pipeline, which corrects for the biases present in the logged data before it is used to simulate user behavior. To evaluate the effects of bias on RL4Rec simulations, we propose a novel evaluation approach for simulators that considers the performance of policies optimized with the simulator. Our results reveal that the biases from logged data negatively impact the resulting policies, unless corrected for with our debiasing method. While our debiasing methods can be applied to any simulator, we make our complete pipeline publicly available as the Simulator for OFfline leArning and evaluation (SOFA): the first simulator that accounts for interaction biases prior to optimization and evaluation.",10.1145/3383313.3412252,https://doi.org/10.1145/3383313.3412252,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Keeping Dataset Biases out of the Simulation: A Debiased Simulator for Reinforcement Learning based Recommender Systems,"Huang, Jin and Oosterhuis, Harrie and de Rijke, Maarten and van Hoof, Herke",inproceedings,10.1145/3383313.3412252,
10.1145/3383313.3412259,10.1145/3383313.3412259,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","discriminative power, evaluation bias, experimental design, metrics, offline evaluation, target items",10,259–268,Proceedings of the 14th ACM Conference on Recommender Systems,"Target selection is a basic yet often implicit decision in the configuration of offline recommendation experiments. In this paper we research the impact of target sampling on the outcome of comparative recommender system evaluation. Specifically, we undertake a detailed analysis considering the informativeness and consistency of experiments across the target size axis. We find that comparative evaluation using reduced target sets contradicts in many cases the corresponding outcome using large targets, and we provide a principled explanation for these disagreements. We further seek to determine which among the contradicting results may be more reliable. Through comparison to unbiased evaluation, we find that minimum target sets incur in substantial distortion in pairwise system comparisons, while maximum sets may not be ideal either, and better options may lie in between the extremes. We further find means for informing the target size setting in the common case where unbiased evaluation is not possible, by an assessment of the discriminative power of evaluation, that remarkably aligns with the agreement with unbiased evaluation.",10.1145/3383313.3412259,https://doi.org/10.1145/3383313.3412259,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,On Target Item Sampling in&nbsp;Offline&nbsp;Recommender&nbsp;System&nbsp;Evaluation,"Ca\~{n}amares, Roc\'{\i}o and Castells, Pablo",inproceedings,10.1145/3383313.3412259,
10.1145/3383313.3412265,10.1145/3383313.3412265,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","datasets, gaze detection, neural networks, text tagging",9,73–81,Proceedings of the 14th ACM Conference on Recommender Systems,"Item-to-item recommendation (e.g., “People who like this also like...”) is a ubiquitous and important type of recommendation in real-world systems. Observational data from historical interaction logs abound in these settings. However, since virtually all observational data exhibit biases, such as time-in-inventory or interface biases, it is crucial that recommender algorithms account for these biases. In this paper, we develop a principled approach for item-to-item recommendation based on causal inference and present a practical and highly effective method for estimating the causal parameters from a small annotated dataset. Empirically, we find that our approach substantially improves upon existing methods while requiring only small amounts of annotated data.",10.1145/3383313.3412265,https://doi.org/10.1145/3383313.3412265,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Debiasing Item-to-Item Recommendations With Small Annotated Datasets,"Schnabel, Tobias and Bennett, Paul N.",inproceedings,10.1145/3383313.3412265,
10.1145/3383313.3412267,10.1145/3383313.3412267,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","user preferences, user control, onboarding experiences",10,398–407,Proceedings of the 14th ACM Conference on Recommender Systems,"Real-world recommender systems often allow users to adjust the presented content through a variety of preference elicitation techniques such as “liking” or interest profiles. These elicitation techniques trade-off time and effort to users with the richness of the signal they provide to learning component driving the recommendations. In this paper, we explore this trade-off, seeking new ways for people to express their preferences with the goal of improving communication channels between users and the recommender system. Through a need-finding study, we observe the patterns in how people express their preferences during curation task, propose a taxonomy for organizing them, and point out research opportunities. We present a case study that illustrates how using this taxonomy to design an onboarding experience can lead to more accurate machine-learned recommendations while maintaining user satisfaction under low effort.",10.1145/3383313.3412267,https://doi.org/10.1145/3383313.3412267,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,“Who doesn’t like dinosaurs?” Finding and Eliciting Richer Preferences for Recommendation,"Schnabel, Tobias and Ramos, Gonzalo and Amershi, Saleema",inproceedings,10.1145/3383313.3412267,
10.1145/3383313.3412268,10.1145/3383313.3412268,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Neural Attention Networks, Deep Learning, Context-Aware Recommender Systems",10,338–347,Proceedings of the 14th ACM Conference on Recommender Systems,"Collaborative filtering with implicit feedback is a ubiquitous class of recommendation problems where only positive interactions such as purchases or clicks are observed. Autoencoder-based recommendation models have shown strong performance on many implicit feedback benchmarks. However, these models tend to suffer from popularity bias making recommendations less personalized. User-generated reviews contain a rich source of preference information, often with specific details that are important to each user, and can help mitigate the popularity bias. Since not all reviews are equally useful, existing work has been exploring various forms of attention to distill relevant information. In the majority of proposed approaches, representations from implicit feedback and review branches are simply concatenated at the end to generate predictions. This can prevent the model from learning deeper correlations between the two modalities and affect prediction accuracy. To address these problems, we propose a novel Two-headed Attention Fused Autoencoder (TAFA) model that jointly learns representations from user reviews and implicit feedback to make recommendations. We apply early and late modality fusion which allows the model to fully correlate and extract relevant information from both input sources. To further combat popularity bias, we leverage the Noise Contrastive Estimation (NCE) objective to “de-popularize” the fused user representation via a two-headed decoder architecture. Empirically, we show that TAFA outperforms leading baselines on multiple real-world benchmarks. Moreover, by tracing attention weights back to reviews we can provide explanations for the generated recommendations and gain further insights into user preferences. Full code for this work is available here:&nbsp;https://github.com/layer6ai-labs/TAFA.",10.1145/3383313.3412268,https://doi.org/10.1145/3383313.3412268,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,TAFA: Two-headed Attention Fused Autoencoder for Context-Aware Recommendations,"Zhou, Jin Peng and Cheng, Zhaoyue and Perez, Felipe and Volkovs, Maksims",inproceedings,10.1145/3383313.3412268,
10.1145/3383313.3412269,10.1145/3383313.3412269,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","recommender systems, path algebra, modeling",10,289–298,Proceedings of the 14th ACM Conference on Recommender Systems,"We argue that most recommendation approaches can be abstracted as a graph exploration problem. In particular, we describe a graph-theoretic framework with two primary parts: (a) a recommendation graph, modeling all the elements of an (application) domain from a recommendation perspective, including the subjects and objects of recommendations as well as the relationships between them; (b) a set of path operations, inferring new edges, i.e., implicit or unknown relationships, by traversing and combining paths on the graph. The resulting path algebra model provides an abstraction and a common foundation that is beneficial to three aspects of recommendations: (a) expressive power - expression and subsequent use of several significantly different, existing but also novel recommendation approaches is reduced to parameterizing a unique model; (b) usability - by capturing part of the recommendation mechanisms in the underlying path algebra semantics, specification of recommendation approaches becomes easier and less tedious; (c) processing speed - implementing recommender systems on top of graph engines opens up the door for several optimizations that speed up execution. We demonstrate the above benefits by expressing several categories of recommendation approaches in the path algebra model and benchmarking some of them in a recommender system implemented on top of Neo4J, a widely used graph system.",10.1145/3383313.3412269,https://doi.org/10.1145/3383313.3412269,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Recommendations as Graph Explorations,"Kyriakidi, Marialena and Koutrika, Georgia and Ioannidis, Yannis",inproceedings,10.1145/3383313.3412269,
10.1145/3383313.3412488,10.1145/3383313.3412488,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Neural Collaborative Filtering, Matrix Factorization, Item Recommendation",9,240–248,Proceedings of the 14th ACM Conference on Recommender Systems,"Embedding based models have been the state of the art in collaborative filtering for over a decade. Traditionally, the dot product or higher order equivalents have been used to combine two or more embeddings, e.g., most notably in matrix factorization. In recent years, it was suggested to replace the dot product with a learned similarity e.g. using a multilayer perceptron (MLP). This approach is often referred to as neural collaborative filtering (NCF). In this work, we revisit the experiments of the NCF paper that popularized learned similarities using MLPs. First, we show that with a proper hyperparameter selection, a simple dot product substantially outperforms the proposed learned similarities. Second, while a MLP can in theory approximate any function, we show that it is non-trivial to learn a dot product with an MLP. Finally, we discuss practical issues that arise when applying MLP based similarities and show that MLPs are too costly to use for item recommendation in production environments while dot products allow to apply very efficient retrieval algorithms. We conclude that MLPs should be used with care as embedding combiner and that dot products might be a better default choice.",10.1145/3383313.3412488,https://doi.org/10.1145/3383313.3412488,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Neural Collaborative Filtering vs. Matrix Factorization Revisited,"Rendle, Steffen and Krichene, Walid and Zhang, Li and Anderson, John",inproceedings,10.1145/3383313.3412488,
10.1145/3383313.3412489,10.1145/3383313.3412489,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Benchmarks, Recommender Systems, Reproducible Evaluation",10,23–32,Proceedings of the 14th ACM Conference on Recommender Systems,"With tremendous amount of recommendation algorithms proposed every year, one critical issue has attracted a considerable amount of attention: there are no effective benchmarks for evaluation, which leads to two major concerns, i.e., unreproducible evaluation and unfair comparison. This paper aims to conduct rigorous (i.e., reproducible and fair) evaluation for implicit-feedback based top-N recommendation algorithms. We first systematically review 85 recommendation papers published at eight top-tier conferences (e.g., RecSys, SIGIR) to summarize important evaluation factors, e.g., data splitting and parameter tuning strategies, etc. Through a holistic empirical study, the impacts of different factors on recommendation performance are then analyzed in-depth. Following that, we create benchmarks with standardized procedures and provide the performance of seven well-tuned state-of-the-arts across six metrics on six widely-used datasets as a reference for later study. Additionally, we release a user-friendly Python toolkit, which differs from existing ones in addressing the broad scope of rigorous evaluation for recommendation. Overall, our work sheds light on the issues in recommendation evaluation and lays the foundation for further investigation. Our code and datasets are available at GitHub (https://github.com/AmazingDD/daisyRec).",10.1145/3383313.3412489,https://doi.org/10.1145/3383313.3412489,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Are We Evaluating Rigorously? Benchmarking Recommendation for Reproducible Evaluation and Fair Comparison,"Sun, Zhu and Yu, Di and Fang, Hui and Yang, Jie and Qu, Xinghua and Zhang, Jie and Geng, Cong",inproceedings,10.1145/3383313.3412489,
10.1145/3383313.3418487,10.1145/3383313.3418487,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Algorithmic bias, Calibration, Popularity bias amplification, Recommender systems",6,726–731,Proceedings of the 14th ACM Conference on Recommender Systems,"Recently there has been a growing interest in fairness-aware recommender systems including fairness in providing consistent performance across different users or groups of users. A recommender system could be considered unfair if the recommendations do not fairly represent the tastes of a certain group of users while other groups receive recommendations that are consistent with their preferences. In this paper, we use a metric called miscalibration for measuring how a recommendation algorithm is responsive to users’ true preferences and we consider how various algorithms may result in different degrees of miscalibration for different users. In particular, we conjecture that popularity bias which is a well-known phenomenon in recommendation is one important factor leading to miscalibration in recommendation. Our experimental results using two real-world datasets show that there is a connection between how different user groups are affected by algorithmic popularity bias and their level of interest in popular items. Moreover, we show that the more a group is affected by the algorithmic popularity bias, the more their recommendations are miscalibrated.",10.1145/3383313.3418487,https://doi.org/10.1145/3383313.3418487,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,"The Connection Between Popularity Bias, Calibration, and Fairness in Recommendation","Abdollahpouri, Himan and Mansoury, Masoud and Burke, Robin and Mobasher, Bamshad",inproceedings,10.1145/3383313.3418487,
10.1145/3383313.3418491,10.1145/3383313.3418491,RecSys.bib,1,['RecSys.bib'],8,RecSys '20,"Virtual Event, Brazil","Causal Impact, Counterfactual Predictions, Recommender Systems",5,687–691,Proceedings of the 14th ACM Conference on Recommender Systems,"With over 20,000 tracks being released each day, recommendation systems that power music streaming services should not only be responsive to such large volumes of content, but also be adept at understanding the impact of such new releases on, both, users’ listening behavior and popularity of artists. Inferring the causal impact of new track releases is critical to fully characterizing the interplay between artists and listeners, as well as among the artists. In this study, we infer and quantify causality using a diffusion-regression state-space model that constructs counterfactual outcomes using a set of synthetic controls, which predict potential outcomes in absence of the intervention. Based on large scale experiments spanning over 21 million users and 1 billion streams on a real world streaming platform, our findings suggest that releasing a new track has a positive impact on the popularity of other tracks by the same artist. Interestingly, other related and competing artists also benefit from a new track release, which hints at the presence of a positive platform-effect wherein some artists gain significantly from activities of other artists.",10.1145/3383313.3418491,https://doi.org/10.1145/3383313.3418491,"New York, NY, USA",Association for Computing Machinery,9781450375832,2020,Inferring the Causal Impact of New Track Releases on Music Recommendation Platforms through Counterfactual Predictions,"Mehrotra, Rishabh and Bhattacharya, Prasanta and Lalmas, Mounia",inproceedings,10.1145/3383313.3418491,
10.1145/3394486.3403051,10.1145/3394486.3403051,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","directional statistics, multi-aspect ranking",10,85–94,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"User-provided multi-aspect evaluations manifest users' detailed feedback on the recommended items and enable fine-grained understanding of their preferences. Extensive studies have shown that modeling such data greatly improves the effectiveness and explainability of the recommendations. However, as ranking is essential in recommendation, there is no principled solution yet for collectively generating multiple item rankings over different aspects.In this work, we propose a directional multi-aspect ranking criterion to enable a holistic ranking of items with respect to multiple aspects. Specifically, we view multi-aspect evaluation as an integral effort from a user that forms a vector of his/her preferences over aspects. Our key insight is that the direction of the difference vector between two multi-aspect preference vectors reveals the pairwise order of comparison. Hence, it is necessary for a multi-aspect ranking criterion to preserve the observed directions from such pairwise comparisons. We further derive a complete solution for the multi-aspect ranking problem based on a probabilistic multivariate tensor factorization model. Comprehensive experimental analysis on a large TripAdvisor multi-aspect rating dataset and a Yelp review text dataset confirms the effectiveness of our solution.",10.1145/3394486.3403051,https://doi.org/10.1145/3394486.3403051,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,Directional Multivariate Ranking,"Wang, Nan and Wang, Hongning",inproceedings,10.1145/3394486.3403051,
10.1145/3394486.3403113,10.1145/3394486.3403113,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","cold-start problem, meta learning, recommender systems",10,688–697,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"A common challenge for most current recommender systems is the cold-start problem. Due to the lack of user-item interactions, the fine-tuned recommender systems are unable to handle situations with new users or new items. Recently, some works introduce the meta-optimization idea into the recommendation scenarios, i.e. predicting the user preference by only a few of past interacted items. The core idea is learning a global sharing initialization parameter for all users and then learning the local parameters for each user separately. However, most meta-learning based recommendation approaches adopt model-agnostic meta-learning for parameter initialization, where the global sharing parameter may lead the model into local optima for some users. In this paper, we design two memory matrices that can store task-specific memories and feature-specific memories. Specifically, the feature-specific memories are used to guide the model with personalized parameter initialization, while the task-specific memories are used to guide the model fast predicting the user preference. And we adopt a meta-optimization approach for optimizing the proposed method. We test the model on two widely used recommendation datasets and consider four cold-start situations. The experimental results show the effectiveness of the proposed methods.",10.1145/3394486.3403113,https://doi.org/10.1145/3394486.3403113,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,MAMO: Memory-Augmented Meta-Optimization for Cold-start Recommendation,"Dong, Manqing and Yuan, Feng and Yao, Lina and Xu, Xiwei and Zhu, Liming",inproceedings,10.1145/3394486.3403113,
10.1145/3394486.3403121,10.1145/3394486.3403121,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","Bayesian inference, latent variable models, recommender systems",11,783–793,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"A common task for recommender systems is to build a profile of the interests of a user from items in their browsing history and later to recommend items to the user from the same catalog. The users' behavior consists of two parts: the sequence of items that they viewed without intervention (the organic part) and the sequences of items recommended to them and their outcome (the bandit part).In this paper, we propose Bayesian Latent Organic Bandit model (BLOB), a probabilistic approach to combine the 'organic' and 'bandit' signals in order to improve the estimation of recommendation quality. The bandit signal is valuable as it gives direct feedback of recommendation performance, but the signal quality is very uneven, as it is highly concentrated on the recommendations deemed optimal by the past version of the recommender system. In contrast, the organic signal is typically strong and covers most items, but is not always relevant to the recommendation task. In order to leverage the organic signal to efficiently learn the bandit signal in a Bayesian model we identify three fundamental types of distances, namely action-history, action-action and history-history distances. We implement a scalable approximation of the full model using variational auto-encoders and the local re-paramerization trick. We show using extensive simulation studies that our method out-performs or matches the value of both state-of-the-art organic-based recommendation algorithms, and of bandit-based methods (both value and policy-based) both in organic and bandit-rich environments.",10.1145/3394486.3403121,https://doi.org/10.1145/3394486.3403121,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,BLOB: A Probabilistic Model for Recommendation that Combines Organic and Bandit Signals,"Sakhi, Otmane and Bonner, Stephen and Rohde, David and Vasile, Flavian",inproceedings,10.1145/3394486.3403121,
10.1145/3394486.3403147,10.1145/3394486.3403147,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","adaptive learning, margin ranking loss, metric learning, recommender systems",9,1036–1044,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Personalized recommender systems are playing an increasingly important role as more content and services become available and users struggle to identify what might interest them. Although matrix factorization and deep learning based methods have proved effective in user preference modeling, they violate the triangle inequality and fail to capture fine-grained preference information. To tackle this, we develop a distance-based recommendation model with several novel aspects: (i) each user and item are parameterized by Gaussian distributions to capture the learning uncertainties; (ii) an adaptive margin generation scheme is proposed to generate the margins regarding different training triplets; (iii) explicit user-user/item-item similarity modeling is incorporated in the objective function. The Wasserstein distance is employed to determine preferences because it obeys the triangle inequality and can measure the distance between probabilistic distributions. Via a comparison using five real-world datasets with state-of-the-art methods, the proposed model outperforms the best existing models by 4-22% in terms of recall@K on Top-K recommendation.",10.1145/3394486.3403147,https://doi.org/10.1145/3394486.3403147,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,Probabilistic Metric Learning with Adaptive Margin for Top-K Recommendation,"Ma, Chen and Ma, Liheng and Zhang, Yingxue and Tang, Ruiming and Liu, Xue and Coates, Mark",inproceedings,10.1145/3394486.3403147,
10.1145/3394486.3403175,10.1145/3394486.3403175,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","bandit feedback, counterfactual learning, policy learning",11,1223–1233,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Conventional approaches to recommendation often do not explicitly take into account information on previously shown recommendations and their recorded responses. One reason is that, since we do not know the outcome of actions the system did not take, learning directly from such logs is not a straightforward task. Several methods for off-policy or counterfactual learning have been proposed in recent years, but their efficacy for the recommendation task remains understudied. Due to the limitations of offline datasets and the lack of access of most academic researchers to online experiments, this is a non-trivial task. Simulation environments can provide a reproducible solution to this problem.In this work, we conduct the first broad empirical study of counterfactual learning methods for recommendation, in a simulated environment. We consider various different policy-based methods that make use of the Inverse Propensity Score (IPS) to perform Counterfactual Risk Minimisation (CRM), as well as value-based methods based on Maximum Likelihood Estimation (MLE). We highlight how existing off-policy learning methods fail due to stochastic and sparse rewards, and show how a logarithmic variant of the traditional IPS estimator can solve these issues, whilst convexifying the objective and thus facilitating its optimisation. Additionally, under certain assumptions the value- and policy-based methods have an identical parameterisation, allowing us to propose a new model that combines both the MLE and CRM objectives. Extensive experiments show that this ""Dual Bandit"" approach achieves state-of-the-art performance in a wide range of scenarios, for varying logging policies, action spaces and training sample sizes.",10.1145/3394486.3403175,https://doi.org/10.1145/3394486.3403175,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,Joint Policy-Value Learning for Recommendation,"Jeunen, Olivier and Rohde, David and Vasile, Flavian and Bompaire, Martin",inproceedings,10.1145/3394486.3403175,
10.1145/3394486.3403176,10.1145/3394486.3403176,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","active sampling, communication costs, faster training, federated learning, recommender systems",9,1234–1242,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Federated learning (FL) is quickly becoming the de facto standard for the distributed training of deep recommendation models, using on-device user data and reducing server costs. In a typical FL process, a central server tasks end-users to train a shared recommendation model using their local data. The local models are trained over several rounds on the users' devices and the server combines them into a global model, which is sent to the devices for the purpose of providing recommendations. Standard FL approaches use randomly selected users for training at each round, and simply average their local models to compute the global model. The resulting federated recommendation models require significant client effort to train and many communication rounds before they converge to a satisfactory accuracy. Users are left with poor quality recommendations until the late stages of training. We present a novel technique, FedFast, to accelerate distributed learning which achieves good accuracy for all users very early in the training process. We achieve this by sampling from a diverse set of participating clients in each training round and applying an active aggregation method that propagates the updated model to the other clients. Consequently, with FedFast the users benefit from far lower communication costs and more accurate models that can be consumed anytime during the training process even at the very early stages. We demonstrate the efficacy of our approach across a variety of benchmark datasets and in comparison to state-of-the-art recommendation techniques.",10.1145/3394486.3403176,https://doi.org/10.1145/3394486.3403176,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,FedFast: Going Beyond Average for Faster Training of Federated Recommender Systems,"Muhammad, Khalil and Wang, Qinqin and O'Reilly-Morgan, Diarmuid and Tragos, Elias and Smyth, Barry and Hurley, Neil and Geraci, James and Lawlor, Aonghus",inproceedings,10.1145/3394486.3403176,
10.1145/3394486.3403207,10.1145/3394486.3403207,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","cold-start recommendation, heterogeneous information network, meta-learning",11,1563–1573,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Cold-start recommendation has been a challenging problem due to sparse user-item interactions for new users or items. Existing efforts have alleviated the cold-start issue to some extent, most of which approach the problem at the data level. Earlier methods often incorporate auxiliary data as user or item features, while more recent methods leverage heterogeneous information networks (HIN) to capture richer semantics via higher-order graph structures. On the other hand, recent meta-learning paradigm sheds light on addressing cold-start recommendation at the model level, given its ability to rapidly adapt to new tasks with scarce labeled data, or in the context of cold-start recommendation, new users and items with very few interactions. Thus, we are inspired to develop a novel meta-learning approach named MetaHIN to address cold-start recommendation on HINs, to exploit the power of meta-learning at the model level and HINs at the data level simultaneously. The solution is non-trivial, for how to capture HIN-based semantics in the meta-learning setting, and how to learn the general knowledge that can be easily adapted to multifaceted semantics, remain open questions. In MetaHIN, we propose a novel semantic-enhanced tasks constructor and a co-adaptation meta-learner to address the two questions. Extensive experiments demonstrate that MetaHIN significantly outperforms the state of the arts in various cold-start scenarios. (Code and dataset are available at https://github.com/rootlu/MetaHIN.)",10.1145/3394486.3403207,https://doi.org/10.1145/3394486.3403207,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,Meta-learning on Heterogeneous Information Networks for Cold-start Recommendation,"Lu, Yuanfu and Fang, Yuan and Shi, Chuan",inproceedings,10.1145/3394486.3403207,
10.1145/3394486.3403251,10.1145/3394486.3403251,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","chatter prediction, deep learning, exogenous influence, reddit",10,1999–2008,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Modeling user engagement dynamics on social media has compelling applications in market trend analysis, user-persona detection, and political discourse mining. Most existing approaches depend heavily on knowledge of the underlying user network. However, a large number of discussions happen on platforms that either lack any reliable social network (news portal, blogs, Buzzfeed) or reveal only partially the inter-user ties (Reddit, Stackoverflow). Many approaches require observing a discussion for some considerable period before they can make useful predictions. In real-time streaming scenarios, observations incur costs. Lastly, most models do not capture complex interactions between exogenous events (such as news articles published externally) and in-network effects (such as follow-up discussions on Reddit) to determine engagement levels. To address the three limitations noted above, we propose a novel framework, ChatterNet, which, to our knowledge, is the first that can model and predict user engagement without considering the underlying user network. Given streams of timestamped news articles and discussions, the task is to observe the streams for a short period leading up to a time horizon, then predict chatter: the volume of discussions through a specified period after the horizon. ChatterNet processes text from news and discussions using a novel time-evolving recurrent network architecture that captures both temporal properties within news and discussions, as well as influence of news on discussions. We report on extensive experiments using a two-month-long discussion corpus of Reddit, and a contemporaneous corpus of online news articles from the Common Crawl. ChatterNet shows considerable improvements beyond recent state-of-the-art models of engagement prediction. Detailed studies controlling observation and prediction windows, over 43 different subreddits, yield further useful insights.",10.1145/3394486.3403251,https://doi.org/10.1145/3394486.3403251,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,Deep Exogenous and Endogenous Influence Combination for Social Chatter Intensity Prediction,"Dutta, Subhabrata and Masud, Sarah and Chakrabarti, Soumen and Chakraborty, Tanmoy",inproceedings,10.1145/3394486.3403251,
10.1145/3394486.3403276,10.1145/3394486.3403276,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","explainable neural networks, social sciences, user modeling",11,2269–2279,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"With the rapid growth and prevalence of social network applications (Apps) in recent years, understanding user engagement has become increasingly important, to provide useful insights for future App design and development. While several promising neural modeling approaches were recently pioneered for accurate user engagement prediction, their black-box designs are unfortunately limited in model explainability. In this paper, we study a novel problem of explainable user engagement prediction for social network Apps. First, we propose a flexible definition of user engagement for various business scenarios, based on future metric expectations. Next, we design an end-to-end neural framework, FATE, which incorporates three key factors that we identify to influence user engagement, namely friendships, user actions, and temporal dynamics to achieve explainable engagement predictions. FATE is based on a tensor-based graph neural network (GNN), LSTM and a mixture attention mechanism, which allows for (a) predictive explanations based on learned weights across different feature categories, (b) reduced network complexity, and (c) improved performance in both prediction accuracy and training/inference time. We conduct extensive experiments on two large-scale datasets from Snapchat, where FATE outperforms state-of-the-art approaches by 10% error and 20% runtime reduction. We also evaluate explanations from FATE, showing strong quantitative and qualitative performance.",10.1145/3394486.3403276,https://doi.org/10.1145/3394486.3403276,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,"Knowing your FATE: Friendship, Action and Temporal Explanations for User Engagement Prediction on Social Apps","Tang, Xianfeng and Liu, Yozen and Shah, Neil and Shi, Xiaolin and Mitra, Prasenjit and Wang, Suhang",inproceedings,10.1145/3394486.3403276,
10.1145/3394486.3403278,10.1145/3394486.3403278,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","collaborative filtering, content filtering, hybrid model, negative sampling, real-time, recommender systems, recurrent neural networks",9,2291–2299,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Personalized real-time recommendation has had a profound impact on retail, media, entertainment and other industries. However, developing recommender systems for every use case is costly, time consuming and resource-intensive. To fill this gap, we present a black-box recommender system that can adapt to a diverse set of scenarios without the need for manual tuning. We build on techniques that go beyond simple matrix factorization to incorporate important new sources of information: the temporal order of events [Hidasi et al., 2015], contextual information to bootstrap cold-start users, metadata information about items [Rendle 2012] and the additional information surrounding each event. Additionally, we address two fundamental challenges when putting recommender systems in the real-world: how to efficiently train them with even millions of unique items and how to cope with changing item popularity trends [Wu et al., 2017]. We introduce a compact model, which we call hierarchical recurrent network with meta data (HRNN-meta) to address the real-time and diverse metadata needs; we further provide efficient training techniques via importance sampling that can scale to millions of items with little loss in performance. We report significant improvements on a wide range of real-world datasets and provide intuition into model capabilities with synthetic experiments. Parts of HRNN-meta have been deployed in production at scale for customers to use at Amazon Web Services and serves as the underlying recommender engine for thousands of websites.",10.1145/3394486.3403278,https://doi.org/10.1145/3394486.3403278,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,Temporal-Contextual Recommendation in Real-Time,"Ma, Yifei and Narayanaswamy, Balakrishnan (Murali) and Lin, Haibin and Ding, Hao",inproceedings,10.1145/3394486.3403278,
10.1145/3394486.3403282,10.1145/3394486.3403282,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","item response theory, knowledge tracing, monotonic attention, personalized learning",10,2330–2339,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Knowledge tracing (KT) refers to the problem of predicting future learner performance given their past performance in educational applications. Recent developments in KT using flexible deep neural network-based models excel at this task. However, these models often offer limited interpretability, thus making them insufficient for personalized learning, which requires using interpretable feedback and actionable recommendations to help learners achieve better learning outcomes. In this paper, we propose attentive knowledge tracing (AKT), which couples flexible attention-based neural network models with a series of novel, interpretable model components inspired by cognitive and psychometric models. AKT uses a novel monotonic attention mechanism that relates a learner's future responses to assessment questions to their past responses; attention weights are computed using exponential decay and a context-aware relative distance measure, in addition to the similarity between questions. Moreover, we use the Rasch model to regularize the concept and question embeddings; these embeddings are able to capture individual differences among questions on the same concept without using an excessive number of parameters. We conduct experiments on several real-world benchmark datasets and show that AKT outperforms existing KT methods (by up to $6%$ in AUC in some cases) on predicting future learner responses. We also conduct several case studies and show that AKT exhibits excellent interpretability and thus has potential for automated feedback and personalization in real-world educational settings.",10.1145/3394486.3403282,https://doi.org/10.1145/3394486.3403282,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,Context-Aware Attentive Knowledge Tracing,"Ghosh, Aritra and Heffernan, Neil and Lan, Andrew S.",inproceedings,10.1145/3394486.3403282,
10.1145/3394486.3403344,10.1145/3394486.3403344,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","multi-interest framework, recommender system, sequential recommendation",10,2942–2951,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Recently, neural networks have been widely used in e-commerce recommender systems, owing to the rapid development of deep learning. We formalize the recommender system as a sequential recommendation problem, intending to predict the next items that the user might be interacted with. Recent works usually give an overall embedding from a user's behavior sequence. However, a unified user embedding cannot reflect the user's multiple interests during a period. In this paper, we propose a novel controllable multi-interest framework for the sequential recommendation, called ComiRec. Our multi-interest module captures multiple interests from user behavior sequences, which can be exploited for retrieving candidate items from the large-scale item pool. These items are then fed into an aggregation module to obtain the overall recommendation. The aggregation module leverages a controllable factor to balance the recommendation accuracy and diversity. We conduct experiments for the sequential recommendation on two real-world datasets, Amazon and Taobao. Experimental results demonstrate that our framework achieves significant improvements over state-of-the-art models. Our framework has also been successfully deployed on the offline Alibaba distributed cloud platform.",10.1145/3394486.3403344,https://doi.org/10.1145/3394486.3403344,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,Controllable Multi-Interest Framework for Recommendation,"Cen, Yukuo and Zhang, Jianwei and Zou, Xu and Zhou, Chang and Yang, Hongxia and Tang, Jie",inproceedings,10.1145/3394486.3403344,
10.1145/3394486.3403373,10.1145/3394486.3403373,KDD.bib,1,['KDD.bib'],8,KDD '20,"Virtual Event, CA, USA","dynamic graph embedding, heterogeneous graph neural networks, real-time event embedding",11,3213–3223,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,"Customer response prediction is critical in many industrial applications such as online advertising and recommendations. In particular, the challenge is greater for ride-hailing platforms such as Uber and DiDi, because the response prediction models need to consider historical and real-time event information in the physical environment, such as surrounding traffic and supply and demand conditions. In this paper, we propose to use dynamically constructed heterogeneous graph for each ongoing event to encode the attributes of the event and its surroundings. In addition, we propose a multi-layer graph neural network model to learn the impact of historical actions and the surrounding environment on the current events, and generate an effective event representation to improve the accuracy of the response model. We investigate this framework to two practical applications on the DiDi platform. Offline and online experiments show that the framework can significantly improve prediction performance. The framework has been deployed in the online production environment and serves tens of millions of event prediction requests every day.",10.1145/3394486.3403373,https://doi.org/10.1145/3394486.3403373,"New York, NY, USA",Association for Computing Machinery,9781450379984,2020,Dynamic Heterogeneous Graph Neural Network for Real-time Event Prediction,"Luo, Wenjuan and Zhang, Han and Yang, Xiaodi and Bo, Lin and Yang, Xiaoqing and Li, Zang and Qie, Xiaohu and Ye, Jieping",inproceedings,10.1145/3394486.3403373,
10.1145/3415959.3415994,10.1145/3415959.3415994,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '20,"Virtual Event, Brazil","ACM RecSys Challenge 2020, Gradient boosting decision trees, Recommender systems",5,6–10,Proceedings of the Recommender Systems Challenge 2020,"The RecSys Challenge 2020 is a competition with a task of predicting four types of user engagements on Twitter: Like, Reply, Retweet and Retweet with comment. In this paper, we describe Team Wantedly’s approach to this challenge, which won the third place. We found that the targets are highly correlated and it is important to use every engagement to predict the other engagements. Therefore, we choose to stack LightGBM models to use this co-occurrences effectively in the large dataset. Our final scores are as follows: 1.5266&nbsp;(Retweet PR-AUC), 30.06&nbsp;(Retweet RCE), 0.1918&nbsp;(Reply PR-AUC), 20.44&nbsp;(Reply RCE), 0.7716&nbsp;(Like PR-AUC), 24.76&nbsp;(Like RCE), 0.0724&nbsp;(Retweet with comment PR-AUC), 14.86&nbsp;(Reply RCE). Our code is available at https://github.com/wantedly/recsys2020-challenge.",10.1145/3415959.3415994,https://doi.org/10.1145/3415959.3415994,"New York, NY, USA",Association for Computing Machinery,9781450388351,2020,A Stacking Ensemble Model for Prediction of Multi-type Tweet Engagements,"Goda, Shuhei and Agata, Naomichi and Matsumura, Yuya",inproceedings,10.1145/3415959.3415994,
10.1145/3415959.3415998,10.1145/3415959.3415998,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '20,"Virtual Event, Brazil","ACM RecSys Challenge 2020, Blending, Gradient Boosting for Decision Trees, Neural Networks, Recommender Systems",5,29–33,Proceedings of the Recommender Systems Challenge 2020,"In this paper we provide a description of the methods we used as team BanaNeverAlone for the ACM RecSys Challenge 2020, organized by Twitter. The challenge addresses the problem of user engagement prediction: the goal is to predict the probability of a user engagement (Like, Reply, Retweet or Retweet with comment), based on a series of past interactions on the Twitter platform. Our proposed solution relies on several features that we extracted from the original dataset, as well as on consolidated models, such as gradient boosting for decision trees and neural networks. The ensemble model, built using blending, and a multi-objective optimization allowed our team to rank in position 4.",10.1145/3415959.3415998,https://doi.org/10.1145/3415959.3415998,"New York, NY, USA",Association for Computing Machinery,9781450388351,2020,Multi-Objective Blended Ensemble For Highly Imbalanced Sequence Aware Tweet Engagement Prediction,"Felicioni, Nicol\`{o} and Donati, Andrea and Conterio, Luca and Bartoccioni, Luca and Hu, Davide Yi Xian and Bernardis, Cesare and Ferrari Dacrema, Maurizio",inproceedings,10.1145/3415959.3415998,
10.1145/3415959.3415999,10.1145/3415959.3415999,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '20,"Virtual Event, Brazil","Twitter, recommender systems, user engagement prediction",4,34–37,Proceedings of the Recommender Systems Challenge 2020,"Most social media websites make use of recommender systems to show the content of interest for their users and to keep them engaged with the platform. On Twitter users can share and engage with the content by tweets. The ACM RecSys challenge 2020 focuses on predicting tweet engagements by users. In this paper, we present our approach for modeling this task. We take a deep look into the dataset and provide interesting observations from the dataset. Based on these findings, we construct a set of features and use gradient boosting trees to classify different types of engagements. Our method ranked 28 in the final leaderboard with an overall score of 63.",10.1145/3415959.3415999,https://doi.org/10.1145/3415959.3415999,"New York, NY, USA",Association for Computing Machinery,9781450388351,2020,Engaging with Tweets: The Missing Dataset On Social Media,"Alhosseini, Seyed Ali and Bin Tareaf, Raad and Meinel, Christoph",inproceedings,10.1145/3415959.3415999,
10.1145/3415959.3416001,10.1145/3415959.3416001,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '20,"Virtual Event, Brazil","Evaluation, Machine Learning Competitions",6,44–49,Proceedings of the Recommender Systems Challenge 2020,"For the past few years most published research on recommendation algorithms has been based on deep learning (DL) methods. Following common research practices in our field, these works usually demonstrate that a new DL method is outperforming other models not based on deep learning in offline experiments. This almost consistent success of DL based models is however not observed in recommendation-related machine learning competitions like the challenges that are held with the yearly ACM RecSys conference. Instead the winning solutions mostly consist of substantial feature engineering efforts and the use of gradient boosting or ensemble techniques. In this paper we investigate possible reasons for this surprising phenomenon. We consider multiple possible factors such as the characteristics and complexity of the problem settings, datasets, and DL methods; the background of the competition participants; or the particularities of the evaluation approach.",10.1145/3415959.3416001,https://doi.org/10.1145/3415959.3416001,"New York, NY, USA",Association for Computing Machinery,9781450388351,2020,Why Are Deep Learning Models Not Consistently Winning Recommender Systems Competitions Yet? A Position Paper,"Jannach, Dietmar and de Souza P. Moreira, Gabriel and Oldridge, Even",inproceedings,10.1145/3415959.3416001,
10.1145/3437963.3441665,10.1145/3437963.3441665,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","bias, collaborative filtering, discrimination, fairness, machine learning, personalized rankings, recommender systems",3,1147–1149,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"The goal of this tutorial is to provide the WSDM community with recent advances on the assessment and mitigation of data and algorithmic bias in recommender systems. We first introduce conceptual foundations, by presenting the state of the art and describing real-world examples of how bias can impact on recommendation algorithms from several perspectives (e.g., ethical and system objectives). The tutorial continues with a systematic showcase of algorithmic countermeasures to uncover, assess, and reduce bias along the recommendation design process. A practical part then provides attendees with implementations of pre-, in-, and post-processing bias mitigation algorithms, leveraging open-source tools and public datasets; in this part, tutorial participants are engaged in the design of bias countermeasures and in articulating impacts on stakeholders. We conclude the tutorial by analyzing emerging open issues and future directions in this rapidly evolving research area (Website: https://biasinrecsys.github.io/wsdm2021).",10.1145/3437963.3441665,https://doi.org/10.1145/3437963.3441665,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Advances in Bias-aware Recommendation on the Web,"Boratto, Ludovico and Marras, Mirko",inproceedings,10.1145/3437963.3441665,
10.1145/3437963.3441669,10.1145/3437963.3441669,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","neural networks, recommendation systems, side information",2,1111–1112,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"Recommendation Systems (RS) are designed to assist users in decision making by recommending the most appropriate information or products for them. Nonetheless, many RS suffer from limitations such as data sparsity and cold-start. Side information (SI) can be integrated into a recommender system to tackle these limitations. In my Ph.D. research, I seek to build on and extend the use of SI for RS. Specifically, I propose new types and representations of SI and develop new methods to integrate SI into RS to boost its performance. This paper presents the conceptual foundation and motivation of my Ph.D. research.",10.1145/3437963.3441669,https://doi.org/10.1145/3437963.3441669,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Deep Recommender Systems Utilizing Side Information,"Livne, Amit",inproceedings,10.1145/3437963.3441669,
10.1145/3437963.3441670,10.1145/3437963.3441670,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","classification, data mining, life trajectories, neural networks, sequence mining",2,1113–1114,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"There is a diverse variety of demographic data that can be analyzed with modern methods of data mining to achieve better results. On the one hand, the main chosen task is to compare different methods for the next event prediction and gender prediction, on the other hand, we pay special attention to interpretable patterns describing demographic behavior in the studied problems. There were considered interpretable methods as decision trees and their ensembles and semi- or non-interpretable methods, such as the SVM method with different customized kernels tailored for demographers' needs and neural networks, respectively. The best accuracy results were obtained with two-channel Convolutional Neural Networks.",10.1145/3437963.3441670,https://doi.org/10.1145/3437963.3441670,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Interpretability and Effectiveness of Machine Learning Methods for Sequence Mining in Various Domains,"Muratova, Anna",inproceedings,10.1145/3437963.3441670,
10.1145/3437963.3441703,10.1145/3437963.3441703,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","ego network, influence visualisation, networks of time series",4,1085–1088,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"The collective attention on online items such as web pages, search terms, and videos reflects trends that are of social, cultural, and economic interest. Moreover, attention trends of different items exhibit mutual influence via mechanisms such as hyperlinks or recommendations. Many visualisation tools exist for time series, network evolution, or network influence; however, few systems connect all three. In this work, we present AttentionFlow, a new system to visualise networks of time series and the dynamic influence they have on one another. Centred around an ego node, our system simultaneously presents the time series on each node using two visual encodings: a tree ring for an overview and a line chart for details. AttentionFlow supports interactions such as overlaying time series of influence, and filtering neighbours by time or flux. We demonstrate AttentionFlow using two real-world datasets, VevoMusic and WikiTraffic. We show that attention spikes in songs can be explained by external events such as major awards, or changes in the network such as the release of a new song. Separate case studies also demonstrate how an artist's influence changes over their career, and that correlated Wikipedia traffic is driven by cultural interests. More broadly, AttentionFlow can be generalised to visualise networks of time series on physical infrastructures such as road networks, or natural phenomena such as weather and geological measurements.",10.1145/3437963.3441703,https://doi.org/10.1145/3437963.3441703,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,AttentionFlow: Visualising Influence in Networks of Time Series,"Shin, Minjeong and Tran, Alasdair and Wu, Siqi and Mathews, Alexander and Wang, Rong and Lyall, Georgiana and Xie, Lexing",inproceedings,10.1145/3437963.3441703,
10.1145/3437963.3441708,10.1145/3437963.3441708,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","hawkes processes, information diffusion, open source software, reshare cascades",4,1097–1100,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"Modeling online discourse dynamics is a core activity in understanding the spread of information, both offline and online, and emergent online behavior. There is currently a disconnect between the practitioners of online social media analysis --- usually social, political and communication scientists --- and the accessibility to tools capable of examining online discussions of users. Here we present evently, a tool for modeling online reshare cascades, and particularly retweet cascades, using self-exciting processes. It provides a comprehensive set of functionalities for processing raw data from Twitter public APIs, modeling the temporal dynamics of processed retweet cascades and characterizing online users with a wide range of diffusion measures. This tool is designed for researchers with a wide range of computer expertise, and it includes tutorials and detailed documentation. We illustrate the usage of evently with an end-to-end analysis of online user behavior on a topical dataset relating to COVID-19. We show that, by characterizing users solely based on how their content spreads online, we can disentangle influential users and online bots.",10.1145/3437963.3441708,https://doi.org/10.1145/3437963.3441708,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Evently: Modeling and Analyzing Reshare Cascades with Hawkes Processes,"Kong, Quyu and Ram, Rohit and Rizoiu, Marian-Andrei",inproceedings,10.1145/3437963.3441708,
10.1145/3437963.3441714,10.1145/3437963.3441714,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","data mining, machine learning, social media analysis",4,890–893,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"In this technical demonstration, we showcase the World's first personality-driven marketing content generation platform, called SoMin.ai. The platform combines deep multi-view personality profiling framework and style generative adversarial networks facilitating the automatic creation of content that appeals to different human personality types. The platform can be used for enhancement of the social networking user experience as well as for content marketing routines. Guided by the MBTI personality type, automatically derived from a user social network content, SoMin.ai generates new social media content based on the preferences of other users with a similar personality type aiming at enhancing the user experience on social networking venues as well diversifying the efforts of marketers when crafting new content for digital marketing campaigns. The real-time user feedback to the platform via the platform's GUI fine-tunes the content generation model and the evaluation results demonstrate the promising performance of the proposed multi-view personality profiling framework when being applied in the content generation scenario. By leveraging content generation at a large scale, marketers will be able to execute more effective digital marketing campaigns at a lower cost.",10.1145/3437963.3441714,https://doi.org/10.1145/3437963.3441714,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,SoMin.ai: Personality-Driven Content Generation Platform,"Farseev, Aleksandr and Yang, Qi and Filchenkov, Andrey and Lepikhin, Kirill and Chu-Farseeva, Yu-Yi and Loo, Daron-Benjamin",inproceedings,10.1145/3437963.3441714,
10.1145/3437963.3441726,10.1145/3437963.3441726,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","explainable recommendation, natural language generation, sentiment alignment",9,1029–1037,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"Textual explanations have proved to help improve user satisfaction on machine-made recommendations. However, current mainstream solutions loosely connect the learning of explanation with the learning of recommendation: for example, they are often separately modeled as rating prediction and content generation tasks. In this work, we propose to strengthen their connection by enforcing the idea of sentiment alignment between a recommendation and its corresponding explanation. At training time, the two learning tasks are joined by a latent sentiment vector, which is encoded by the recommendation module and used to make word choices for explanation generation. At both training and inference time, the explanation module is required to generate explanation text that matches sentiment predicted by the recommendation module. Extensive experiments demonstrate our solution outperforms a rich set of baselines in both recommendation and explanation tasks, especially on the improved quality of its generated explanations. More importantly, our user studies confirm our generated explanations help users better recognize the differences between recommended items and understand why an item is recommended.",10.1145/3437963.3441726,https://doi.org/10.1145/3437963.3441726,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Explanation as a Defense of Recommendation,"Yang, Aobo and Wang, Nan and Deng, Hongbo and Wang, Hongning",inproceedings,10.1145/3437963.3441726,
10.1145/3437963.3441769,10.1145/3437963.3441769,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","mainstream bias, recommender systems, user fairness",9,103–111,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"In a collaborative-filtering recommendation scenario, biases in the data will likely propagate in the learned recommendations. In this paper we focus on the so-called mainstream bias: the tendency of a recommender system to provide better recommendations to users who have a mainstream taste, as opposed to non-mainstream users. We propose NAECF, a conceptually simple but effective idea to address this bias. The idea consists of adding an autoencoder (AE) layer when learning user and item representations with text-based Convolutional Neural Networks. The AEs, one for the users and one for the items, serve as adversaries to the process of minimizing the rating prediction error when learning how to recommend. They enforce that the specific unique properties of all users and items are sufficiently well incorporated and preserved in the learned representations. These representations, extracted as the bottlenecks of the corresponding AEs, are expected to be less biased towards mainstream users, and to provide more balanced recommendation utility across all users. Our experimental results confirm these expectations, significantly improving the recommendations for non-mainstream users while maintaining the recommendation quality for mainstream users. Our results emphasize the importance of deploying extensive content-based features, such as online reviews, in order to better represent users and items to maximize the de-biasing effect.",10.1145/3437963.3441769,https://doi.org/10.1145/3437963.3441769,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Leave No User Behind: Towards Improving the Utility of Recommender Systems for Non-mainstream Users,"Li, Roger Zhe and Urbano, Juli\'{a}n and Hanjalic, Alan",inproceedings,10.1145/3437963.3441769,
10.1145/3437963.3441770,10.1145/3437963.3441770,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","ensemble, neural networks, neuron activation, prediction uncertainty, recommender systems",9,76–84,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"Despite deep neural network (DNN)'s impressive prediction performance in various domains, it is well known now that a set of DNN models trained with the same model specification and the exact same training data could produce very different prediction results. People have relied on the state-of-the-art ensemble method to estimate prediction uncertainty. However, ensembles are expensive to train and serve for web-scale traffic systems.In this paper, we seek to advance the understanding of prediction variation estimated by the ensemble method. Through empirical experiments on two widely used benchmark datasets Movielens and Criteo in recommender systems, we observe that prediction variations come from various randomness sources, including training data shuffling, and random initialization. When we add more randomness sources to ensemble members, we see higher prediction variations among these ensemble members, and more accurate mean prediction. Moreover, we propose to infer prediction variation from neuron activation strength and demonstrate its strong prediction power. Our approach provides a simple way for prediction variation estimation, and opens up new opportunities for future work in many interesting areas (e.g., model-based reinforcement learning) without relying on serving expensive ensemble models.",10.1145/3437963.3441770,https://doi.org/10.1145/3437963.3441770,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Beyond Point Estimate: Inferring Ensemble Prediction Variation from Neuron Activation Strength in Recommender Systems,"Chen, Zhe and Wang, Yuyan and Lin, Dong and Cheng, Derek Zhiyuan and Hong, Lichan and Chi, Ed H. and Cui, Claire",inproceedings,10.1145/3437963.3441770,
10.1145/3437963.3441771,10.1145/3437963.3441771,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","ad platform, deep GSP, e-commerce advertising, learning-based mechanism design, multiple performance metrics optimization",9,993–1001,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"In e-commerce advertising, the ad platform usually relies on auction mechanisms to optimize different performance metrics, such as user experience, advertiser utility, and platform revenue. However, most of the state-of-the-art auction mechanisms only focus on optimizing a single performance metric, e.g., either social welfare or revenue, and are not suitable for e-commerce advertising with various, dynamic, difficult to estimate, and even conflicting performance metrics. In this paper, we propose a new mechanism called Deep GSP auction, which leverages deep learning to design new rank score functions within the celebrated GSP auction framework. These new rank score functions are implemented via deep neural network models under the constraints of monotone allocation and smooth transition. The requirement of monotone allocation ensures Deep GSP auction nice game theoretical properties, while the requirement of smooth transition guarantees the advertiser utilities would not fluctuate too much when the auction mechanism switches among candidate mechanisms to achieve different optimization objectives. We deployed the proposed mechanisms in a leading e-commerce ad platform and conducted comprehensive experimental evaluations with both offline simulations and online A/B tests. The results demonstrated the effectiveness of the Deep GSP auction compared to the state-of-the-art auction mechanisms.",10.1145/3437963.3441771,https://doi.org/10.1145/3437963.3441771,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Optimizing Multiple Performance Metrics with Deep GSP Auctions for E-commerce Advertising,"Zhang, Zhilin and Liu, Xiangyu and Zheng, Zhenzhe and Zhang, Chenrui and Xu, Miao and Pan, Junwei and Yu, Chuan and Wu, Fan and Xu, Jian and Gai, Kun",inproceedings,10.1145/3437963.3441771,
10.1145/3437963.3441773,10.1145/3437963.3441773,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","cold-start recommendation, graph neural networks, knowledge graph, knowledge-aware recommendation, semi-supervised learning",9,931–939,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"Solving cold-start problems is indispensable to provide meaningful recommendation results for new users and items. Under sparsely observed data, unobserved user-item pairs are also a vital source for distilling latent users' information needs. Most present works leverage unobserved samples for extracting negative signals. However, such an optimisation strategy can lead to biased results toward already popular items by frequently handling new items as negative instances. In this study, we tackle the cold-start problems for new users/items by appropriately leveraging unobserved samples. We propose a knowledge graph (KG)-aware recommender based on graph neural networks, which augments labelled samples through pseudo-labelling. Our approach aggressively employs unobserved samples as positive instances and brings new items into the spotlight. To avoid exhaustive label assignments to all possible pairs of users and items, we exploit a KG for selecting probably positive items for each user. We also utilise an improved negative sampling strategy and thereby suppress the exacerbation of popularity biases. Through experiments, we demonstrate that our approach achieves improvements over the state-of-the-art KG-aware recommenders in a variety of scenarios; in particular, our methodology successfully improves recommendation performance for cold-start users/items.",10.1145/3437963.3441773,https://doi.org/10.1145/3437963.3441773,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Alleviating Cold-Start Problems in Recommendation through Pseudo-Labelling over Knowledge Graph,"Togashi, Riku and Otani, Mayu and Satoh, Shin'ichi",inproceedings,10.1145/3437963.3441773,
10.1145/3437963.3441775,10.1145/3437963.3441775,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","diversity, music, recommender systems, shifting consumption",9,238–246,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"Algorithmic recommendations shape music consumption at scale, and understanding the impact of various algorithmic models on how content is consumed is a central question for music streaming platforms. The ability to shift consumption towards less popular content and towards content different from user's typical historic tastes not only affords the platform ways of handling issues such as filter bubbles and popularity bias, but also contributes to maintaining a healthy and sustainable consumption patterns necessary for overall platform success.In this work, we view diversity as an enabler for shifting consumption and consider two notions of music diversity, based on taste similarity and popularity, and investigate how four different recommendation approaches optimized for user satisfaction, fare on diversity metrics. To investigate how the ranker complexity influences diversity, we use two well-known rankers and propose two new models of increased complexity: a feedback aware neural ranker and a reinforcement learning (RL) based ranker. We demonstrate that our models lead to gains in satisfaction, but at the cost of diversity. Such trade-off between model complexity and diversity necessitates the need for explicitly encoding diversity in the modeling process, for which we consider four types of approaches: interleaving based, submodularity based, interpolation, and RL reward modeling based. We find that our reward modeling based RL approach achieves the best trade-off between optimizing the satisfaction metric and surfacing diverse content, thereby enabling consumption shifting at scale. Our findings have implications for the design and deployment of practical approaches for music diversification, which we discuss at length.",10.1145/3437963.3441775,https://doi.org/10.1145/3437963.3441775,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Shifting Consumption towards Diverse Content on Music Streaming Platforms,"Hansen, Christian and Mehrotra, Rishabh and Hansen, Casper and Brost, Brian and Maystre, Lucas and Lalmas, Mounia",inproceedings,10.1145/3437963.3441775,
10.1145/3437963.3441786,10.1145/3437963.3441786,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","bandits, diversity, preference elicitation, recommender systems",9,130–138,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"Personalized recommender systems rely on knowledge of user preferences to produce recommendations. While those preferences are often obtained from past user interactions with the recommendation catalog, in some situations such observations are insufficient or unavailable. The most widely studied case is with new users, although other similar situations arise where explicit preference elicitation is valuable. At the same time, a seemingly disparate challenge is that there is a well-known popularity bias in many algorithmic approaches to recommender systems. The most common way of addressing this challenge is diversification, which tends to be applied to the output of a recommender algorithm, prior to items being presented to users. We tie these two problems together, showing a tight relationship. Our results show that popularity bias in preference elicitation contributes to popularity bias in recommendation. In particular, most elicitation methods directly optimize only for the relevance of recommendations that would result from collected preferences. This focus on recommendation accuracy biases the preferences collected. We demonstrate how diversification can instead be applied directly at elicitation time. Our model diversifies the preferences elicited using Multi-Armed Bandits, a classical exploration-exploitation framework from reinforcement learning. This leads to a broader understanding of users' preferences, and improved diversity and serendipity of recommendations, without necessitating post-hoc debiasing corrections.",10.1145/3437963.3441786,https://doi.org/10.1145/3437963.3441786,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Diverse User Preference Elicitation with Multi-Armed Bandits,"Parapar, Javier and Radlinski, Filip",inproceedings,10.1145/3437963.3441786,
10.1145/3437963.3441799,10.1145/3437963.3441799,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","propensity estimation, rating prediction, selection bias",9,427–435,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"Recommendation datasets are prone to selection biases due to self-selection behavior of users and item selection process of systems. This makes explicitly combating selection biases an essential problem in training recommender systems. Most previous studies assume no unbiased data available for training. We relax this assumption and assume that a small subset of training data is unbiased. Then, we propose a novel objective that utilizes the unbiased data to adaptively assign propensity weights to biased training ratings. This objective, combined with unbiased performance estimators, alleviates the effects of selection biases on the training of recommender systems. To optimize the objective, we propose an efficient algorithm that minimizes the variance of propensity estimates for better generalized recommender systems. Extensive experiments on two real-world datasets confirm the advantages of our approach in significantly reducing both the error of rating prediction and the variance of propensity estimation.",10.1145/3437963.3441799,https://doi.org/10.1145/3437963.3441799,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Combating Selection Biases in Recommender Systems with a Few Unbiased Ratings,"Wang, Xiaojie and Zhang, Rui and Sun, Yu and Qi, Jianzhong",inproceedings,10.1145/3437963.3441799,
10.1145/3437963.3441808,10.1145/3437963.3441808,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","autoencoders, collaborative filtering, local latent factor model",9,734–742,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"This work presents a generalized local factor model, namely Local Collaborative Autoencoders (LOCA). To our knowledge, it is the first generalized framework under the local low-rank assumption that builds on the neural recommendation models. We explore a large number of local models by adopting a generalized framework with different weight schemes for training and aggregating them. Besides, we develop a novel method of discovering a sub-community to maximize the coverage of local models. Our experimental results demonstrate that LOCA is highly scalable, achieving state-of-the-art results by outperforming existing AE-based and local latent factor models on several large-scale public benchmarks.",10.1145/3437963.3441808,https://doi.org/10.1145/3437963.3441808,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Local Collaborative Autoencoders,"Choi, Minjin and Jeong, Yoonki and Lee, Joonseok and Lee, Jongwuk",inproceedings,10.1145/3437963.3441808,
10.1145/3437963.3441820,10.1145/3437963.3441820,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","equal opportunity, recommendation bias, recommender systems, statistical parity",9,85–93,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"This paper connects equal opportunity to popularity bias in implicit recommenders to introduce the problem of popularity-opportunity bias. That is, conditioned on user preferences that a user likes both items, the more popular item is more likely to be recommended (or ranked higher) to the user than the less popular one. This type of bias is harmful, exerting negative effects on the engagement of both users and item providers. Thus, we conduct a three-part study: (i) By a comprehensive empirical study, we identify the existence of the popularity-opportunity bias in fundamental matrix factorization models on four datasets; (ii) coupled with this empirical study, our theoretical study shows that matrix factorization models inherently produce the bias; and (iii) we demonstrate the potential of alleviating this bias by both in-processing and post-processing algorithms. Extensive experiments on four datasets show the effective debiasing performance of these proposed methods compared with baselines designed for conventional popularity bias.",10.1145/3437963.3441820,https://doi.org/10.1145/3437963.3441820,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Popularity-Opportunity Bias in Collaborative Filtering,"Zhu, Ziwei and He, Yun and Zhao, Xing and Zhang, Yin and Wang, Jianling and Caverlee, James",inproceedings,10.1145/3437963.3441820,
10.1145/3437963.3441824,10.1145/3437963.3441824,WSDM.bib,1,['WSDM.bib'],8,WSDM '21,"Virtual Event, Israel","constrained policy optimization, long-term fairness, recommender system, reinforcement learning, unbiased recommendation",9,445–453,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"As Recommender Systems (RS) influence more and more people in their daily life, the issue of fairness in recommendation is becoming more and more important. Most of the prior approaches to fairness-aware recommendation have been situated in a static or one-shot setting, where the protected groups of items are fixed, and the model provides a one-time fairness solution based on fairness-constrained optimization. This fails to consider the dynamic nature of the recommender systems, where attributes such as item popularity may change over time due to the recommendation policy and user engagement. For example, products that were once popular may become no longer popular, and vice versa. As a result, the system that aims to maintain long-term fairness on the item exposure in different popularity groups must accommodate this change in a timely fashion.Novel to this work, we explore the problem of long-term fairness in recommendation and accomplish the problem through dynamic fairness learning. We focus on the fairness of exposure of items in different groups, while the division of the groups is based on item popularity, which dynamically changes over time in the recommendation process. We tackle this problem by proposing a fairness-constrained reinforcement learning algorithm for recommendation, which models the recommendation problem as a Constrained Markov Decision Process (CMDP), so that the model can dynamically adjust its recommendation policy to make sure the fairness requirement is always satisfied when the environment changes. Experiments on several real-world datasets verify our framework's superiority in terms of recommendation performance, short-term fairness, and long-term fairness.",10.1145/3437963.3441824,https://doi.org/10.1145/3437963.3441824,"New York, NY, USA",Association for Computing Machinery,9781450382977,2021,Towards Long-term Fairness in Recommendation,"Ge, Yingqiang and Liu, Shuchang and Gao, Ruoyuan and Xian, Yikun and Li, Yunqi and Zhao, Xiangyu and Pei, Changhua and Sun, Fei and Ge, Junfeng and Ou, Wenwu and Zhang, Yongfeng",inproceedings,10.1145/3437963.3441824,
10.1145/3442381.3449788,10.1145/3442381.3449788,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","popularity bias, causal embedding, Recommender systems",12,2980–2991,Proceedings of the Web Conference 2021,"Recommendation models are usually trained on observational interaction data. However, observational interaction data could result from users’ conformity towards popular items, which entangles users’ real interest. Existing methods tracks this problem as eliminating popularity bias, e.g., by re-weighting training samples or leveraging a small fraction of unbiased data. However, the variety of user conformity is ignored by these approaches, and different causes of an interaction are bundled together as unified representations, hence robustness and interpretability are not guaranteed when underlying causes are changing. In this paper, we present DICE, a general framework that learns representations where interest and conformity are structurally disentangled, and various backbone recommendation models could be smoothly integrated. We assign users and items with separate embeddings for interest and conformity, and make each embedding capture only one cause by training with cause-specific data which is obtained according to the colliding effect of causal inference. Our proposed methodology outperforms state-of-the-art baselines with remarkable improvements on two real-world datasets on top of various backbone models. We further demonstrate that the learned embeddings successfully capture the desired causes, and show that DICE guarantees the robustness and interpretability of recommendation.",10.1145/3442381.3449788,https://doi.org/10.1145/3442381.3449788,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,Disentangling User Interest and Conformity for Recommendation with Causal Embedding,"Zheng, Yu and Gao, Chen and Li, Xiang and He, Xiangnan and Li, Yong and Jin, Depeng",inproceedings,10.1145/3442381.3449788,
10.1145/3442381.3449846,10.1145/3442381.3449846,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","Reinforcement learning, Recommender system, Multi-objective optimization",11,425–435,Proceedings of the Web Conference 2021,"Formulating recommender system with reinforcement learning (RL) frameworks has attracted increasing attention from both academic and industry communities. While many promising results have been achieved, existing models mostly simulate the environment reward with a unified value, which may hinder the understanding of users’ complex preferences and limit the model performance. In this paper, we consider how to model user multi-aspect preferences in the context of RL-based recommender system. More specifically, we base our model on the framework of deterministic policy gradient (DPG), which is effective in dealing with large action spaces. A major challenge for modeling user multi-aspect preferences lies in the fact that they may contradict with each other. To solve this problem, we introduce Pareto optimization into the DPG framework. We assign each aspect with a tailored critic, and all the critics share the same actor. The Pareto optimization is realized by a gradient-based method, which can be easily integrated into the actor and critic learning process. Based on the designed model, we theoretically analyze its gradient bias in the optimization process, and we design a weight-reuse mechanism to lower the upper bound of this bias, which is shown to be effective for improving the model performance. We conduct extensive experiments based on three real-world datasets to demonstrate our model’s superiorities.",10.1145/3442381.3449846,https://doi.org/10.1145/3442381.3449846,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,Reinforcement Recommendation with User Multi-aspect Preference,"Chen, Xu and Du, Yali and Xia, Long and Wang, Jun",inproceedings,10.1145/3442381.3449846,
10.1145/3442381.3449866,10.1145/3442381.3449866,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","Recommendation System, Re-ranking, Fairness, AI Ethics",9,624–632,Proceedings of the Web Conference 2021,"As a highly data-driven application, recommender systems could be affected by data bias, resulting in unfair results for different data groups, which could be a reason that affects the system performance. Therefore, it is important to identify and solve the unfairness issues in recommendation scenarios. In this paper, we address the unfairness problem in recommender systems from the user perspective. We group users into advantaged and disadvantaged groups according to their level of activity, and conduct experiments to show that current recommender systems will behave unfairly between two groups of users. Specifically, the advantaged users (active) who only account for a small proportion in data enjoy much higher recommendation quality than those disadvantaged users (inactive). Such bias can also affect the overall performance since the disadvantaged users are the majority. To solve this problem, we provide a re-ranking approach to mitigate this unfairness problem by adding constraints over evaluation metrics. The experiments we conducted on several real-world datasets with various recommendation algorithms show that our approach can not only improve group fairness of users in recommender systems, but also achieve better overall recommendation performance.",10.1145/3442381.3449866,https://doi.org/10.1145/3442381.3449866,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,User-oriented Fairness in Recommendation,"Li, Yunqi and Chen, Hanxiong and Fu, Zuohui and Ge, Yingqiang and Zhang, Yongfeng",inproceedings,10.1145/3442381.3449866,
10.1145/3442381.3449869,10.1145/3442381.3449869,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","probabilistic generative models, Sinkhorn divergence, Latent factor models",11,582–592,Proceedings of the Web Conference 2021,"Recommender systems play a vital role in modern web services. In a typical recommender system, we are given a set of observed user-item interaction records and seek to uncover the hidden behavioral patterns of users from these historical interactions. By exploiting these hidden patterns, we aim to discover users’ personalized tastes and recommend them new items. Among various types of recommendation methods, the latent factor collaborative filtering models have dominated the field. In this paper, we develop a unified view for the existing latent factor models from a probabilistic perspective. The unified framework enables us to discern the underlying connections of different latent factor models and deepen our understandings of their advantages and limitations. In particular, we observe that the loss functions adopted by the existing models are oblivious to the geometry induced by the item-similarity. To address this, we propose a novel model—SinkhornCF—based on Sinkhorn divergence. To address the challenge of the expensive computational cost of Sinkhorn divergence, we also propose new techniques to enable the resulting model to be able to scale to large datasets. Its effectiveness is verified on two real-world recommendation datasets.",10.1145/3442381.3449869,https://doi.org/10.1145/3442381.3449869,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,Sinkhorn Collaborative Filtering,"Li, Xiucheng and Chin, Jin Yao and Chen, Yile and Cong, Gao",inproceedings,10.1145/3442381.3449869,
10.1145/3442381.3449926,10.1145/3442381.3449926,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","User modeling, Privacy heterogeneity, Model personalization, Federated learning",12,957–968,Proceedings of the Web Conference 2021,"User modeling aims to capture the latent characteristics of users from their behaviors, and is widely applied in numerous applications. Usually, centralized user modeling suffers from the risk of privacy leakage. Instead, federated user modeling expects to provide a secure multi-client collaboration for user modeling through federated learning. Existing federated learning methods are mainly designed for consistent clients, which cannot be directly applied to practical scenarios, where different clients usually store inconsistent user data. Therefore, it is a crucial demand to design an appropriate federated solution that can better adapt to user modeling tasks, and however, meets following critical challenges: 1) Statistical heterogeneity. The distributions of user data in different clients are not always independently identically distributed which leads to personalized clients; 2) Privacy heterogeneity. User data contains both public and private information, which have different levels of privacy. It means we should balance different information to be shared and protected; 3) Model heterogeneity. The local user models trained with client records are heterogeneous which need flexible aggregation in the server. In this paper, we propose a novel client-server architecture framework, namely Hierarchical Personalized Federated Learning (HPFL) to serve federated learning in user modeling with inconsistent clients. In the framework, we first define hierarchical information to finely partition the data with privacy heterogeneity. On this basis, the client trains a user model which contains different components designed for hierarchical information. Moreover, client processes a fine-grained personalized update strategy to update personalized user model for statistical heterogeneity. Correspondingly, the server completes a differentiated component aggregation strategy to flexibly aggregate heterogeneous user models in the case of privacy and model heterogeneity. Finally, we conduct extensive experiments on real-world datasets, which demonstrate the effectiveness of the HPFL framework.",10.1145/3442381.3449926,https://doi.org/10.1145/3442381.3449926,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,Hierarchical Personalized Federated Learning for User Modeling,"Wu, Jinze and Liu, Qi and Huang, Zhenya and Ning, Yuting and Wang, Hao and Chen, Enhong and Yi, Jinfeng and Zhou, Bowen",inproceedings,10.1145/3442381.3449926,
10.1145/3442381.3449973,10.1145/3442381.3449973,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","Recommender Systems, Collaborative Reasoning, Collaborative Filtering, Cognitive Reasoning, Cognitive Intelligence",12,1516–1527,Proceedings of the Web Conference 2021,"Existing Collaborative Filtering (CF) methods are mostly designed based on the idea of matching, i.e., by learning user and item embeddings from data using shallow or deep models, they try to capture the associative relevance patterns in data, so that a user embedding can be matched with relevant item embeddings using designed or learned similarity functions. However, as a cognition rather than a perception intelligent task, recommendation requires not only the ability of pattern recognition and matching from data, but also the ability of cognitive reasoning in data. In this paper, we propose to advance Collaborative Filtering (CF) to Collaborative Reasoning (CR), which means that each user knows part of the reasoning space, and they collaborate for reasoning in the space to estimate preferences for each other. Technically, we propose a Neural Collaborative Reasoning (NCR) framework to bridge learning and reasoning. Specifically, we integrate the power of representation learning and logical reasoning, where representations capture similarity patterns in data from perceptual perspectives, and logic facilitates cognitive reasoning for informed decision making. An important challenge, however, is to bridge differentiable neural networks and symbolic reasoning in a shared architecture for optimization and inference. To solve the problem, we propose a modularized reasoning architecture, which learns logical operations such as AND (∧), OR (∨) and NOT (¬) as neural modules for implication reasoning (→). In this way, logical expressions can be equivalently organized as neural networks, so that logical reasoning and prediction can be conducted in a continuous space. Experiments on real-world datasets verified the advantages of our framework compared with both shallow, deep and reasoning models.",10.1145/3442381.3449973,https://doi.org/10.1145/3442381.3449973,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,Neural Collaborative Reasoning,"Chen, Hanxiong and Shi, Shaoyun and Li, Yunqi and Zhang, Yongfeng",inproceedings,10.1145/3442381.3449973,
10.1145/3442381.3449986,10.1145/3442381.3449986,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","Subgraph, Recommendation, Message-Passing Strategy, Interest-aware, Graph Convolution Networks",10,1296–1305,Proceedings of the Web Conference 2021,"Graph Convolution Networks (GCNs) manifest great potential in recommendation. This is attributed to their capability on learning good user and item embeddings by exploiting the collaborative signals from the high-order neighbors. Like other GCN models, the GCN based recommendation models also suffer from the notorious over-smoothing problem – when stacking more layers, node embeddings become more similar and eventually indistinguishable, resulted in performance degradation. The recently proposed LightGCN and LR-GCN alleviate this problem to some extent, however, we argue that they overlook an important factor for the over-smoothing problem in recommendation, that is, high-order neighboring users with no common interests of a user can be also involved in the user’s embedding learning in the graph convolution operation. As a result, the multi-layer graph convolution will make users with dissimilar interests have similar embeddings. In this paper, we propose a novel Interest-aware Message-Passing GCN (IMP-GCN) recommendation model, which performs high-order graph convolution inside subgraphs. The subgraph consists of users with similar interests and their interacted items. To form the subgraphs, we design an unsupervised subgraph generation module, which can effectively identify users with common interests by exploiting both user feature and graph structure. To this end, our model can avoid propagating negative information from high-order neighbors into embedding learning. Experimental results on three large-scale benchmark datasets show that our model can gain performance improvement by stacking more layers and outperform the state-of-the-art GCN-based recommendation models significantly.",10.1145/3442381.3449986,https://doi.org/10.1145/3442381.3449986,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,Interest-aware Message-Passing GCN for Recommendation,"Liu, Fan and Cheng, Zhiyong and Zhu, Lei and Gao, Zan and Nie, Liqiang",inproceedings,10.1145/3442381.3449986,
10.1145/3442381.3449999,10.1145/3442381.3449999,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","Tabular Data Synthesis, Neural Ordinary Differential Equations, Generative Adversarial Networks",10,1506–1515,Proceedings of the Web Conference 2021,"Synthesizing tabular data is attracting much attention these days for various purposes. With sophisticate synthetic data, for instance, one can augment its training data. For the past couple of years, tabular data synthesis techniques have been greatly improved. Recent work made progress to address many problems in synthesizing tabular data, such as the imbalanced distribution and multimodality problems. However, the data utility of state-of-the-art methods is not satisfactory yet. In this work, we significantly improve the utility by designing our generator and discriminator based on neural ordinary differential equations (NODEs). After showing that NODEs have theoretically preferred characteristics for generating tabular data, we introduce our designs. The NODE-based discriminator performs a hidden vector evolution trajectory-based classification rather than classifying with a hidden vector at the last layer only. Our generator also adopts an ODE layer at the very beginning of its architecture to transform its initial input vector (i.e., the concatenation of a noisy vector and a condition vector in our case) onto another latent vector space suitable for the generation process. We conduct experiments with 13 datasets, including but not limited to insurance fraud detection, online news article prediction, and so on, and our presented method outperforms other state-of-the-art tabular data synthesis methods in many cases of our classification, regression, and clustering experiments.",10.1145/3442381.3449999,https://doi.org/10.1145/3442381.3449999,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,OCT-GAN: Neural ODE-based Conditional Tabular GANs,"Kim, Jayoung and Jeon, Jinsung and Lee, Jaehoon and Hyeong, Jihyeon and Park, Noseong",inproceedings,10.1145/3442381.3449999,
10.1145/3442381.3450011,10.1145/3442381.3450011,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","importance coding, hash codes, collaborative filtering",9,261–269,Proceedings of the Web Conference 2021,"When reasoning about tasks that involve large amounts of data, a common approach is to represent data items as objects in the Hamming space where operations can be done efficiently and effectively. Object similarity can then be computed by learning binary representations (hash codes) of the objects and computing their Hamming distance. While this is highly efficient, each bit dimension is equally weighted, which means that potentially discriminative information of the data is lost. A more expressive alternative is to use real-valued vector representations and compute their inner product; this allows varying the weight of each dimension but is many magnitudes slower. To fix this, we derive a new way of measuring the dissimilarity between two objects in the Hamming space with binary weighting of each dimension (i.e., disabling bits): we consider a field-agnostic dissimilarity that projects the vector of one object onto the vector of the other. When working in the Hamming space, this results in a novel projected Hamming dissimilarity, which by choice of projection, effectively allows a binary importance weighting of the hash code of one object through the hash code of the other. We propose a variational hashing model for learning hash codes optimized for this projected Hamming dissimilarity, and experimentally evaluate it in collaborative filtering experiments. The resultant hash codes lead to effectiveness gains of up to +7% in NDCG and +14% in MRR compared to state-of-the-art hashing-based collaborative filtering baselines, while requiring no additional storage and no computational overhead compared to using the Hamming distance.",10.1145/3442381.3450011,https://doi.org/10.1145/3442381.3450011,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,Projected Hamming Dissimilarity for Bit-Level Importance Coding in Collaborative Filtering,"Hansen, Christian and Hansen, Casper and Simonsen, Jakob Grue and Lioma, Christina",inproceedings,10.1145/3442381.3450011,
10.1145/3442381.3450015,10.1145/3442381.3450015,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","user modeling, graph based recommendation, fairness, fair Representation learning, fair Recommendation",11,2198–2208,Proceedings of the Web Conference 2021,"As a key application of artificial intelligence, recommender systems are among the most pervasive computer aided systems to help users find potential items of interests. Recently, researchers paid considerable attention to fairness issues for artificial intelligence applications. Most of these approaches assumed independence of instances, and designed sophisticated models to eliminate the sensitive information to facilitate fairness. However, recommender systems differ greatly from these approaches as users and items naturally form a user-item bipartite graph, and are collaboratively correlated in the graph structure. In this paper, we propose a novel graph based technique for ensuring fairness of any recommendation models. Here, the fairness requirements refer to not exposing sensitive feature set in the user modeling process. Specifically, given the original embeddings from any recommendation models, we learn a composition of filters that transform each user’s and each item’s original embeddings into a filtered embedding space based on the sensitive feature set. For each user, this transformation is achieved under the adversarial learning of a user-centric graph, in order to obfuscate each sensitive feature between both the filtered user embedding and the sub graph structures of this user. Finally, extensive experimental results clearly show the effectiveness of our proposed model for fair recommendation. We publish the source code at https://github.com/newlei/FairGo.",10.1145/3442381.3450015,https://doi.org/10.1145/3442381.3450015,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,Learning Fair Representations for Recommendation: A Graph-based Perspective,"Wu, Le and Chen, Lei and Shao, Pengyang and Hong, Richang and Wang, Xiting and Wang, Meng",inproceedings,10.1145/3442381.3450015,
10.1145/3442381.3450054,10.1145/3442381.3450054,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","sparse embeddings, high-dimensional embeddings, collaborative filtering, cholesky decomposition",7,575–581,Proceedings of the Web Conference 2021,"A widely adopted paradigm in the design of recommender systems is to represent users and items as vectors, often referred to as latent factors or embeddings. Embeddings can be obtained using a variety of recommendation models and served in production using a variety of data engineering solutions. Embeddings also facilitate transfer learning, where trained embeddings from one model are reused in another. In contrast, some of the best-performing collaborative filtering models today are high-dimensional linear models that do not rely on factorization, and so they do not produce embeddings&nbsp;[27, 28]. They also require pruning, amounting to a trade-off between the model size and the density of the predicted affinities. This paper argues for the use of high-dimensional, sparse latent factor models, instead. We propose a new recommendation model based on a full-rank factorization of the inverse Gram matrix. The resulting high-dimensional embeddings can be made sparse while still factorizing a dense affinity matrix. We show how the embeddings combine the advantages of latent representations with the performance of high-dimensional linear models.",10.1145/3442381.3450054,https://doi.org/10.1145/3442381.3450054,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,High-dimensional Sparse Embeddings for Collaborative Filtering,"Van Balen, Jan and Goethals, Bart",inproceedings,10.1145/3442381.3450054,
10.1145/3442381.3450075,10.1145/3442381.3450075,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","Treatment Selection, Personalization, Heterogeneous causal effects, Constraint optimization",12,1574–1585,Proceedings of the Web Conference 2021,"Randomized experimentation (also known as A/B testing or bucket testing) is widely used in the internet industry to measure the metric impact obtained by different treatment variants. A/B tests identify the treatment variant showing the best performance, which then becomes the chosen or selected treatment for the entire population. However, the effect of a given treatment can differ across experimental units and a personalized approach for treatment selection can greatly improve upon the usual global selection strategy. In this work, we develop a framework for personalization through (i) estimation of heterogeneous treatment effect at either a cohort or member-level, followed by (ii) selection of optimal treatment variants for cohorts (or members) obtained through (deterministic or stochastic) constrained optimization. We perform a two-fold evaluation of our proposed methods. First, a simulation analysis is conducted to study the effect of personalized treatment selection under carefully controlled settings. This simulation illustrates the differences between the proposed methods and the suitability of each with increasing uncertainty. We also demonstrate the effectiveness of the method through a real-life example related to serving notifications at Linkedin. The solution significantly outperformed both heuristic solutions and the global treatment selection baseline leading to a sizable win on top-line metrics like member visits.",10.1145/3442381.3450075,https://doi.org/10.1145/3442381.3450075,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,Personalized Treatment Selection using Causal Heterogeneity,"Tu, Ye and Basu, Kinjal and DiCiccio, Cyrus and Bansal, Romil and Nandy, Preetam and Jaikumar, Padmini and Chatterjee, Shaunak",inproceedings,10.1145/3442381.3450075,
10.1145/3442381.3450086,10.1145/3442381.3450086,TheWebConf.bib,1,['TheWebConf.bib'],7,WWW '21,"Ljubljana, Slovenia",,12,2220–2231,Proceedings of the Web Conference 2021,"Highly skewed long-tail item distribution is very common in recommendation systems. It significantly hurts model performance on tail items. To improve tail-item recommendation, we conduct research to transfer knowledge from head items to tail items, leveraging the rich user feedback in head items and the semantic connections between head and tail items. Specifically, we propose a novel dual transfer learning framework that jointly learns the knowledge transfer from both model-level and item-level: 1. The model-level knowledge transfer builds a generic meta-mapping of model parameters from few-shot to many-shot model. It captures the implicit data augmentation on the model-level to improve the representation learning of tail items. 2. The item-level transfer connects head and tail items through item-level features, to ensure a smooth transfer of meta-mapping from head items to tail items. The two types of transfers are incorporated to ensure the learned knowledge from head items can be well applied for tail item representation learning in the long-tail distribution settings. Through extensive experiments on two benchmark datasets, results show that our proposed dual transfer learning framework significantly outperforms other state-of-the-art methods for tail item recommendation in hit ratio and NDCG. It is also very encouraging that our framework further improves head items and overall performance on top of the gains on tail items.",10.1145/3442381.3450086,https://doi.org/10.1145/3442381.3450086,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,A Model of Two Tales: Dual Transfer Learning Framework for Improved Long-tail Item Recommendation,"Zhang, Yin and Cheng, Derek Zhiyuan and Yao, Tiansheng and Yi, Xinyang and Hong, Lichan and Chi, Ed H.",inproceedings,10.1145/3442381.3450086,
10.1145/3442381.3450101,10.1145/3442381.3450101,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","Recommender Systems, Hyperbolic Embeddings, Graph Convolutions",9,593–601,Proceedings of the Web Conference 2021,"Hyperbolic spaces offer a rich setup to learn embeddings with superior properties that have been leveraged in areas such as computer vision, natural language processing and computational biology. Recently, several hyperbolic approaches have been proposed to learn robust representations for users and items in the recommendation setting. However, these approaches don’t capture the higher order relationships that typically exist in the recommendation domain. Graph convolutional neural networks (GCNs) on the other hand excel at capturing higher order information by applying multiple levels of aggregation to local representations. In this paper we combine these frameworks in a novel way, by proposing a hyperbolic GCN model for collaborative filtering. We demonstrate that our model can be effectively learned with a margin ranking loss, and show that hyperbolic space has desirable properties under the rank margin setting. At test time, inference in our model is done using the hyperbolic distance which preserves the structure of the learned space. We conduct extensive empirical analysis on three public benchmarks and compare against a large set of baselines. Our approach achieves highly competitive results and outperforms leading baselines including the Euclidean GCN counterpart. We further study the properties of the learned hyperbolic embeddings and show that they offer meaningful insights into the data. Full code for this work is available here:&nbsp;https://github.com/layer6ai-labs/HGCF.",10.1145/3442381.3450101,https://doi.org/10.1145/3442381.3450101,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,HGCF: Hyperbolic Graph Convolution Networks for Collaborative Filtering,"Sun, Jianing and Cheng, Zhaoyue and Zuberi, Saba and Perez, Felipe and Volkovs, Maksims",inproceedings,10.1145/3442381.3450101,
10.1145/3442381.3450107,10.1145/3442381.3450107,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","time series, science of science, dynamic heterogeneous information network, Citation prediction",10,3158–3167,Proceedings of the Web Conference 2021,"Accurate prediction of scientific impact is important for scientists, academic recommender systems, and granting organizations alike. Existing approaches rely on many years of leading citation values to predict a scientific paper’s citations (a proxy for impact), even though most papers make their largest contributions in the first few years after they are published. In this paper, we tackle a new problem: predicting a new paper’s citation time series from the date of publication (i.e., without leading values). We propose HINTS, a novel end-to-end deep learning framework that converts citation signals from dynamic heterogeneous information networks (DHIN) into citation time series. HINTS imputes pseudo-leading values for a paper in the years before it is published from DHIN embeddings, and then transforms these embeddings into the parameters of a formal model that can predict citation counts immediately after publication. Empirical analysis on two real-world datasets from Computer Science and Physics show that HINTS is competitive with baseline citation prediction models. While we focus on citations, our approach generalizes to other “cold start” time series prediction tasks where relational data is available and accurate prediction in early timestamps is crucial.",10.1145/3442381.3450107,https://doi.org/10.1145/3442381.3450107,"New York, NY, USA",Association for Computing Machinery,9781450383127,2021,HINTS: Citation Time Series Prediction for New Publications via Dynamic Heterogeneous Information Network Embedding,"Jiang, Song and Koch, Bernard and Sun, Yizhou",inproceedings,10.1145/3442381.3450107,
10.1145/3442442.3451370,10.1145/3442442.3451370,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","peer reviews, interpretability, acceptance prediction",7,461–467,Companion Proceedings of the Web Conference 2021,"Measuring the quality of research work is an essential component of the scientific process. With the ever-growing rates of articles being submitted to top-tier conferences, and the potential consistency and bias issues in the peer review process identified by scientific community, it is thus of great necessary and challenge to automatically evaluate submissions. Existing works mainly focus on exploring relevant factors and applying machine learning models to simply be accurate at predicting the acceptance of a given academic paper, while ignoring the interpretability power which is required by a wide range of applications. In this paper, we propose a framework to construct decision sets that consist of unordered if-then rules for predicting paper acceptance. We formalize decision set learning problem via a joint objective function that simultaneously optimize accuracy and interpretability of the rules, rather than organizing them in a hierarchy. We evaluate the effectiveness of the proposed framework by applying it on a public scientific peer reviews dataset. Experimental results demonstrate that the learned interpretable decision sets by our framework performs on par with state-of-the-art classification algorithms which optimize exclusively for predictive accuracy and much more interpretable than rule-based methods.",10.1145/3442442.3451370,https://doi.org/10.1145/3442442.3451370,"New York, NY, USA",Association for Computing Machinery,9781450383134,2021,Predicting Paper Acceptance via Interpretable Decision Sets,"Bao, Peng and Hong, Weihui and Li, Xuanya",inproceedings,10.1145/3442442.3451370,
10.1145/3442442.3452341,10.1145/3442442.3452341,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","Wikipedia Trends, Wikipedia Page Views, WikiShark, Data Dumps",14,558–571,Companion Proceedings of the Web Conference 2021,"Wikipedia is a major source of information utilized by internet users around the globe for fact-checking and access to general, encyclopedic information. For researchers, it offers an unprecedented opportunity to measure how societies respond to events and how our collective perception of the world evolves over time and in response to events. Wikipedia use and the reading patterns of its users reflect our collective interests and the way they are expressed in our search for information – whether as part of fleeting, zeitgeist-fed trends or long-term – on most every topic, from personal to business, through political, health-related, academic and scientific. In a very real sense, events are defined by how we interpret them and how they affect our perception of the context in which they occurred, rendering Wikipedia invaluable for understanding events and their context. This paper introduces WikiShark (www.wikishark.com) – an online tool that allows researchers to analyze Wikipedia traffic and trends quickly and effectively, by (1) instantly querying pageview traffic data; (2) comparing traffic across articles; (3) surfacing and analyzing trending topics; and (4) easily leveraging findings for use in their own research.",10.1145/3442442.3452341,https://doi.org/10.1145/3442442.3452341,"New York, NY, USA",Association for Computing Machinery,9781450383134,2021,WikiShark: An Online Tool for Analyzing Wikipedia Traffic and Trends,"Vardi, Elad and Muchnik, Lev and Conway, Alex and Breakstone, Micha",inproceedings,10.1145/3442442.3452341,
10.1145/3442442.3452354,10.1145/3442442.3452354,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '21,"Ljubljana, Slovenia","Wikipedia, Opinion dynamics, Group decision-making, Discussion outcome prediction, Computational Social Science, Article for Deletion",8,632–639,Companion Proceedings of the Web Conference 2021,"Wikipedia, the online encyclopedia, is a trusted source of knowledge for millions of individuals worldwide. As everyone can start a new article, it is often necessary to decide whether certain entries meet the standards for inclusion set forth by the community. These decisions (which are known as “Article for Deletion”, or AfD) are taken by groups of editors in a deliberative fashion, and are known for displaying a number of common biases associated to group decision making. Here, we present an analysis of 1,967,768 AfD discussions between 2005 and 2018. We perform a signed network analysis to capture the dynamics of agreement and disagreement among editors. We measure the preference of each editor for voting toward either inclusion or deletion. We further describe the evolution of individual editors and their voting preferences over time, finding four major opinion groups. Finally, we develop a predictive model of discussion outcomes based on latent factors. Our results shed light on an important, yet overlooked, aspect of curation dynamics in peer production communities, and could inform the design of improved processes of collective deliberation on the web.",10.1145/3442442.3452354,https://doi.org/10.1145/3442442.3452354,"New York, NY, USA",Association for Computing Machinery,9781450383134,2021,Characterizing Opinion Dynamics and Group Decision Making in Wikipedia Content Discussions,"Tasnim Huq, Khandaker and Ciampaglia, Giovanni Luca",inproceedings,10.1145/3442442.3452354,
10.1145/3447548.3467067,10.1145/3447548.3467067,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","causal embedding, cross-domain recommendation, debiasing learning",10,3190–3199,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"As it becomes prevalent that user information exists in multiple platforms or services, cross-domain recommendation has been an important task in industry. Although it is well known that users tend to show different preferences in different domains, existing studies seldom model how domain biases affect user preferences. Focused on this issue, we develop a casual-based approach to mitigating the domain biases when transferring the user information cross domains. To be specific, this paper presents a novel debiasing learning based cross-domain recommendation framework with causal embedding. In this framework, we design a novel Inverse-Propensity-Score (IPS) estimator designed for cross-domain scenario, and further propose three kinds of restrictions for propensity score learning. Our framework can be generally applied to various recommendation algorithms for cross-domain recommendation. Extensive experiments on both public and industry datasets have demonstrated the effectiveness of the proposed framework.",10.1145/3447548.3467067,https://doi.org/10.1145/3447548.3467067,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Debiasing Learning based Cross-domain Recommendation,"Li, Siqing and Yao, Liuyi and Mu, Shanlei and Zhao, Wayne Xin and Li, Yaliang and Guo, Tonglei and Ding, Bolin and Wen, Ji-Rong",inproceedings,10.1145/3447548.3467067,
10.1145/3447548.3467103,10.1145/3447548.3467103,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","e-commerce advertising, learning-based mechanism design, neural auction",11,3354–3364,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"In e-commerce advertising, it is crucial to jointly consider various performance metrics, e.g., user experience, advertiser utility, and platform revenue. Traditional auction mechanisms, such as GSP and VCG auctions, can be suboptimal due to their fixed allocation rules to optimize a single performance metric (e.g., revenue or social welfare). Recently, data-driven auctions, learned directly from auction outcomes to optimize multiple performance metrics, have attracted increasing research interests. However, the procedure of auction mechanisms involves various discrete calculation operations, making it challenging to be compatible with continuous optimization pipelines in machine learning. In this paper, we design Deep Neural Auctions (DNAs) to enable end-to-end auction learning by proposing a differentiable model to relax the discrete sorting operation, a key component in auctions. We optimize the performance metrics by developing deep models to efficiently extract contexts from auctions, providing rich features for auction design. We further integrate the game theoretical conditions within the model design, to guarantee the stability of the auctions. DNAs have been successfully deployed in the e-commerce advertising system at Taobao. Experimental evaluation results on both large-scale data set as well as online A/B test demonstrated that DNAs significantly outperformed other mechanisms widely adopted in industry.",10.1145/3447548.3467103,https://doi.org/10.1145/3447548.3467103,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Neural Auction: End-to-End Learning of Auction Mechanisms for E-Commerce Advertising,"Liu, Xiangyu and Yu, Chuan and Zhang, Zhilin and Zheng, Zhenzhe and Rong, Yu and Lv, Hongtao and Huo, Da and Wang, Yiqing and Chen, Dagui and Xu, Jian and Wu, Fan and Chen, Guihai and Zhu, Xiaoqiang",inproceedings,10.1145/3447548.3467103,
10.1145/3447548.3467109,10.1145/3447548.3467109,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","attention pooling, bag representation, instance representation, multiple instance learning, multiple instance regression, neural networks",11,3117–3127,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"In recent years, non representative survey sampling and non response bias constitute major obstacles in obtaining a reliable population quantity estimate from finite survey samples. As such, researchers have been focusing on identifying methods to resolve these biases. In this paper, we look at this well known problem from a fresh perspective, and formulate it as a learning problem. To meet this challenge, we suggest solving the learning problem using a multiple instance learning (MIL) paradigm. We devise two different MIL based neural network topologies, each based on a different implementation of an attention pooling layer. These models are trained to accurately infer the population quantity of interest even when facing a biased sample. To the best of our knowledge, this is the first time MIL has ever been suggested as a solution to this problem. In contrast to commonly used statistical methods, this approach can be accomplished without having to collect sensitive personal data of the respondents and without having to access population level statistics of the same sensitive data. To validate the effectiveness of our approaches, we test them on a real-world movie rating dataset which is used to mimic a biased survey by experimentally contaminating it with different kinds of survey bias. We show that our suggested topologies outperform other MIL architectures, and are able to partly counter the adverse effect of biased sampling on the estimation quality. We also demonstrate how these methods can be easily adapted to perform well even when part of the survey is based on a small number of respondents.",10.1145/3447548.3467109,https://doi.org/10.1145/3447548.3467109,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Addressing Non-Representative Surveys using Multiple Instance Learning,"Katz, Yaniv and Vainas, Oded",inproceedings,10.1145/3447548.3467109,
10.1145/3447548.3467111,10.1145/3447548.3467111,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","click-through rate prediction, inclusion relation, online travel platform, user response prediction",9,3059–3067,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"User response prediction plays a crucial role in many applications (e.g. search ranking and personalized recommendation) at online travel platforms. Although existing methods have made a great success by focusing on feature interaction or user behaviors, they cannot synthetically exploit item inclusion relations describing relationships of an item including or being included by another one, which are important components among travel items. To this end, in this paper, we propose a novel Deep Inclusion Relation-aware Network (DIRN) for user response prediction by synthetically exploiting inclusion relations among travel items. Specifically, on the item graph constructed with inclusion relations, we first leverage a node embedding approach to learn the item graph-based embedding. Then, we design Representation-based Interest Layer and Relation Path Interest Layer to extract user latent interest with user behaviors in two ways. Representation-based Interest Layer models the item-to-item similarity based on item representations containing the graph-based embedding with an attention mechanism and obtains user temporal interest by summing up representations of interacted items with similarities. Relation Path Interest Layer measures item-to-item realistic associations to extract user interest with inclusion relation paths. Offline experiments on a real-world data from Fliggy clearly validate the effectiveness of DIRN. Furthermore, DIRN has been successfully deployed online in search ranking at Fliggy and achieves significant improvement.",10.1145/3447548.3467111,https://doi.org/10.1145/3447548.3467111,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Deep Inclusion Relation-aware Network for User Response Prediction at Fliggy,"Huang, Zai and Tao, Mingyuan and Zhang, Bufeng",inproceedings,10.1145/3447548.3467111,
10.1145/3447548.3467151,10.1145/3447548.3467151,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","graph representation learning, live streaming e-commence, multi-task learning, product recommendation",9,3886–3894,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Recently, a new form of online shopping becomes more and more popular, which combines live streaming with E-Commerce activity. The streamers introduce products and interact with their audiences, and hence greatly improve the performance of selling products. Despite of the successful applications in industries, the live stream E-commerce has not been well studied in the data science community. To fill this gap, we investigate this brand-new scenario and collect a real-world Live Stream E-Commerce (LSEC) dataset. Different from conventional E-commerce activities, the streamers play a pivotal role in the LSEC events. Hence, the key is to make full use of rich interaction information among streamers, users, and products. We first conduct data analysis on the tripartite interaction data and quantify the streamer's influence on users' purchase behavior. Based on the analysis results, we model the tripartite information as a heterogeneous graph, which can be decomposed to multiple bipartite graphs in order to better capture the influence. We propose a novel Live Stream E-Commerce Graph Neural Network framework (LSEC-GNN) to learn the node representations of each bipartite graph, and further design a multi-task learning approach to improve product recommendation. Extensive experiments on two real-world datasets with different scales show that our method can significantly outperform various baseline approaches.",10.1145/3447548.3467151,https://doi.org/10.1145/3447548.3467151,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Leveraging Tripartite Interaction Information from Live Stream E-Commerce for Improving Product Recommendation,"Yu, Sanshi and Jiang, Zhuoxuan and Chen, Dong-Dong and Feng, Shanshan and Li, Dongsheng and Liu, Qi and Yi, Jinfeng",inproceedings,10.1145/3447548.3467151,
10.1145/3447548.3467172,10.1145/3447548.3467172,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","incremental online learning, mixed-effect models, personalization, recommender systems, reinforcement learning",11,3492–3502,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"One of the most well-established applications of machine learning is in deciding what content to show website visitors. When observation data comes from high-velocity, user-generated data streams, machine learning methods perform a balancing act between model complexity, training time, and computational costs. Furthermore, when model freshness is critical, the training of models becomes time-constrained. Parallelized batch offline training, although horizontally scalable, is often not time-considerate or cost-effective. In this paper, we propose Lambda Learner, a new framework for training models by incremental updates in response to mini-batches from data streams. We show that the resulting model of our framework closely estimates a periodically updated model trained on offline data and outperforms it when model updates are time-sensitive. We provide theoretical proof that the incremental learning updates improve the loss-function over a stale batch model. We present a large-scale deployment on the sponsored content platform for a large social network, serving hundreds of millions of users across different channels (e.g., desktop, mobile). We address challenges and complexities from both algorithms and infrastructure perspectives, illustrate the system details for computation, storage, stream processing training data, and open-source the system.",10.1145/3447548.3467172,https://doi.org/10.1145/3447548.3467172,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Lambda Learner: Fast Incremental Learning on Data Streams,"Ramanath, Rohan and Salomatin, Konstantin and Gee, Jeffrey D. and Talanine, Kirill and Dalal, Onkar and Polatkan, Gungor and Smoot, Sara and Kumar, Deepak",inproceedings,10.1145/3447548.3467172,
10.1145/3447548.3467188,10.1145/3447548.3467188,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","instant search, music search, neural information retrieval, podcast search",9,2984–2992,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Over recent years, podcasts have emerged as a novel medium for sharing and broadcasting information over the Internet. Audio streaming platforms originally designed for music content, such as Amazon Music, Pandora, and Spotify, have reported a rapid growth, with millions of users consuming podcasts every day. With podcasts emerging as a new medium for consuming information, the need to develop information access systems that enable efficient and effective discovery from a heterogeneous collection of music and podcasts is more important than ever. However, information access in such domains still remains understudied. In this work, we conduct a large-scale log analysis to study and compare podcast and music search behavior on Spotify, a major audio streaming platform. Our findings suggest that there exist fundamental differences in user behavior while searching for podcasts compared to music. Specifically, we identify the need to improve podcast search performance. We propose a simple yet effective transformer-based neural instant search model that retrieves items from a heterogeneous collection of music and podcast content. Our model takes advantage of multi-task learning to optimize for a ranking objective in addition to a query intent type identification objective. Our experiments on large-scale search logs show that the proposed model significantly outperforms strong baselines for both podcast and music queries.",10.1145/3447548.3467188,https://doi.org/10.1145/3447548.3467188,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Neural Instant Search for Music and Podcast,"Hashemi, Helia and Pappu, Aasish and Tian, Mi and Chandar, Praveen and Lalmas, Mounia and Carterette, Benjamin",inproceedings,10.1145/3447548.3467188,
10.1145/3447548.3467192,10.1145/3447548.3467192,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","deployment infrastructure, exploration-exploitation, multi-armed bandit, optimal design, recommender system",9,3817–3825,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Selecting the optimal recommender via online exploration-exploitation is catching increasing attention where the traditional A/B testing can be slow and costly, and offline evaluations are prone to the bias of history data. Finding the optimal online experiment is nontrivial since both the users and displayed recommendations carry contextual features that are informative to the reward. While the problem can be formalized via the lens of multi-armed bandits, the existing solutions are found less satisfactorily because the general methodologies do not account for the case-specific structures, particularly for the e-commerce recommendation we study. To fill in the gap, we leverage the D-optimal design from the classical statistics literature to achieve the maximum information gain during exploration, and reveal how it fits seamlessly with the modern infrastructure of online inference. To demonstrate the effectiveness of the optimal designs, we provide semi-synthetic simulation studies with published code and data for reproducibility purposes. We then use our deployment example on Walmart.com to fully illustrate the practical insights and effectiveness of the proposed methods.",10.1145/3447548.3467192,https://doi.org/10.1145/3447548.3467192,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Towards the D-Optimal Online Experiment Design for Recommender Selection,"Xu, Da and Ruan, Chuanwei and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan",inproceedings,10.1145/3447548.3467192,
10.1145/3447548.3467208,10.1145/3447548.3467208,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","AutoML, loss functions, recommender systems",9,3959–3967,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Designing an effective loss function plays a crucial role in training deep recommender systems. Most existing works often leverage a predefined and fixed loss function that could lead to suboptimal recommendation quality and training efficiency. Some recent efforts rely on exhaustively or manually searched weights to fuse a group of candidate loss functions, which is exceptionally costly in computation and time. They also neglect the various convergence behaviors of different data examples. In this work, we propose an AutoLoss framework that can automatically and adaptively search for the appropriate loss function from a set of candidates. To be specific, we develop a novel controller network, which can dynamically adjust the loss probabilities in a differentiable manner. Unlike existing algorithms, the proposed controller can adaptively generate the loss probabilities for different data examples according to their varied convergence behaviors. Such design improves the model's generalizability and transferability between deep recommender systems and datasets. We evaluate the proposed framework on two benchmark datasets. The results show that AutoLoss outperforms representative baselines. Further experiments have been conducted to deepen our understandings of AutoLoss, including its transferability, components and training efficiency.",10.1145/3447548.3467208,https://doi.org/10.1145/3447548.3467208,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,AutoLoss: Automated Loss Function Search in Recommendations,"Zhao, Xiangyu and Liu, Haochen and Fan, Wenqi and Liu, Hui and Tang, Jiliang and Wang, Chong",inproceedings,10.1145/3447548.3467208,
10.1145/3447548.3467212,10.1145/3447548.3467212,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","biological networks, drug response prediction, interpretability, neural networks",11,3558–3568,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Predicting drug response based on the genomic profile of a cancer patient is one of the hallmarks of precision oncology. Despite current methods for drug response prediction becoming more accurate, there is still a need to switch from 'black box' predictions to methods that offer high accuracy as well as interpretable predictions. This is of particular importance in real-world applications such as drug response prediction in cancer patients. In this paper, we propose BDKANN, a novel knowledge-based method that employs the hierarchical information on how proteins form complexes and act together in pathways to form the architecture of a deep neural network. We employ BDKANN to predict cancer drug response from cell line gene expression data and our experimental results demonstrate that not only does BDKANN have a low prediction error compared to baseline models but it also allows meaningful interpretation of the network. These interpretations can both explain predictions made and discover novel connections in the biological knowledge that may lead to new hypotheses about mechanisms of drug action.",10.1145/3447548.3467212,https://doi.org/10.1145/3447548.3467212,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Interpretable Drug Response Prediction using a Knowledge-based Neural Network,"Snow, Oliver and Sharifi-Noghabi, Hossein and Lu, Jialin and Zolotareva, Olga and Lee, Mark and Ester, Martin",inproceedings,10.1145/3447548.3467212,
10.1145/3447548.3467216,10.1145/3447548.3467216,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","information retrieval, recommender systems, tabular data",11,1379–1389,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Prediction over tabular data is an essential task in many data science applications such as recommender systems, online advertising, medical treatment, etc. Tabular data is structured into rows and columns, with each row as a data sample and each column as a feature attribute. Both the columns and rows of the tabular data carry useful patterns that could improve the model prediction performance. However, most existing models focus on the cross-column patterns yet overlook the cross-rowpatterns as they deal with single samples independently. In this work, we propose a general learning framework named Retrieval &amp; Interaction Machine (RIM) that fully exploits both cross-row and cross-column patterns among tabular data. Specifically, RIM first leverages search engine techniques to efficiently retrieve useful rows of the table to assist the label prediction of the target row, then uses feature interaction networks to capture the cross-column patterns among the target row and the retrieved rows so as to make the final label prediction. We conduct extensive experiments on 11 datasets of three important tasks, i.e., CTR prediction (classification), top-n recommendation (ranking) and rating prediction (regression). Experimental results show that RIM achieves significant improvements over the state-of-the-art and various baselines, demonstrating the superiority and efficacy of RIM.",10.1145/3447548.3467216,https://doi.org/10.1145/3447548.3467216,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Retrieval &amp; Interaction Machine for Tabular Data Prediction,"Qin, Jiarui and Zhang, Weinan and Su, Rong and Liu, Zhirong and Liu, Weiwen and Tang, Ruiming and He, Xiuqiang and Yu, Yong",inproceedings,10.1145/3447548.3467216,
10.1145/3447548.3467220,10.1145/3447548.3467220,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","elastic embeddings, lightweight recommendation",10,138–147,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"In today's context, deploying data-driven services like recommendation on edge devices instead of cloud servers becomes increasingly attractive due to privacy and network latency concerns. A common practice in building compact on-device recommender systems is to compress their embeddings which are normally the cause of excessive parameterization. However, despite the vast variety of devices and their associated memory constraints, existing memory-efficient recommender systems are only specialized for a fixed memory budget in every design and training life cycle, where a new model has to be retrained to obtain the optimal performance while adapting to a smaller/larger memory budget. In this paper, we present a novel lightweight recommendation paradigm that allows a well-trained recommender to be customized for arbitrary device-specific memory constraints without retraining. The core idea is to compose elastic embeddings for each item, where an elastic embedding is the concatenation of a set of embedding blocks that are carefully chosen by an automated search function. Correspondingly, we propose an innovative approach, namely recommendation with universally learned elastic embeddings (RULE). To ensure the expressiveness of all candidate embedding blocks, RULE enforces a diversity-driven regularization when learning different embedding blocks. Then, a performance estimator-based evolutionary search function is designed, allowing for efficient specialization of elastic embeddings under any memory constraint for on-device recommendation. Extensive experiments on real-world datasets reveal the superior performance of RULE under tight memory budgets.",10.1145/3447548.3467220,https://doi.org/10.1145/3447548.3467220,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Learning Elastic Embeddings for Customizing On-Device Recommenders,"Chen, Tong and Yin, Hongzhi and Zheng, Yujia and Huang, Zi and Wang, Yang and Wang, Meng",inproceedings,10.1145/3447548.3467220,
10.1145/3447548.3467233,10.1145/3447548.3467233,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","adversarial learning, data poisoning, recommender system",11,2154–2164,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Recent studies reveal that recommender systems are vulnerable to data poisoning attack due to their openness nature. In data poisoning attack, the attacker typically recruits a group of controlled users to inject well-crafted user-item interaction data into the recommendation model's training set to modify the model parameters as desired. Thus, existing attack approaches usually require full access to the training data to infer items' characteristics and craft the fake interactions for controlled users. However, such attack approaches may not be feasible in practice due to the attacker's limited data collection capability and the restricted access to the training data, which sometimes are even perturbed by the privacy preserving mechanism of the service providers. Such design-reality gap may cause failure of attacks. In this paper, we fill the gap by proposing two novel adversarial attack approaches to handle the incompleteness and perturbations in user-item interaction data. First, we propose a bi-level optimization framework that incorporates a probabilistic generative model to find the users and items whose interaction data is sufficient and has not been significantly perturbed, and leverage these users and items' data to craft fake user-item interactions. Moreover, we reverse the learning process of recommendation models and develop a simple yet effective approach that can incorporate context-specific heuristic rules to handle data incompleteness and perturbations. Extensive experiments on two datasets against three representative recommendation models show that the proposed approaches can achieve better attack performance than existing approaches.",10.1145/3447548.3467233,https://doi.org/10.1145/3447548.3467233,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Data Poisoning Attack against Recommender System Using Incomplete and Perturbed Data,"Zhang, Hengtong and Tian, Changxin and Li, Yaliang and Su, Lu and Yang, Nan and Zhao, Wayne Xin and Gao, Jing",inproceedings,10.1145/3447548.3467233,
10.1145/3447548.3467244,10.1145/3447548.3467244,KDD.bib,1,['KDD.bib'],7,KDD '21,"Virtual Event, Singapore",,9,2369–2377,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Online rating system serves as an indispensable building block for many web applications such as Amazon, TripAdvior and Yelp. It enables production quality estimation via aggregate ratings (a.k.a. wisdom of the crowd) as well as product recommendation via inferring user preference from ratings, etc. Previous studies showed that due to assimilate-contrast effects, historical ratings can significantly distort user's ratings, leading to low accuracy of product quality estimation and recommendation. To understand assimilate-contrast effects, an ""accurate'' model is still missing as previous models do not capture important factors like rating recency, selection bias, etc. Furthermore, an analytical framework to characterize product estimation accuracy under assimilate-contrast effects is also missing. This paper aims to fill in this gap. We propose a mathematical model to quantify the aforementioned important factors on assimilate-contrast effects. Our model attains a good balance between model complexity and model accuracy, such that it is neat enough for us to develop an analytical framework to study assimilate-contrast effects. Based on our model, we derive sufficient conditions, under which the product estimation and collective opinion converges to the ""ground-truth''. These conditions reveal important insights on how the aforementioned factors influence the convergence and guide the online rating system operator to design appropriate rating aggregation rules and rating displaying strategies. To demonstrate the versatility of our model, we apply to rating prediction tasks and product recommendation tasks. Experiment results on four public datasets show that our model can improve the rating prediction and and recommendation accuracy over previous models significantly.",10.1145/3447548.3467244,https://doi.org/10.1145/3447548.3467244,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,"Quantifying Assimilate-Contrast Effects in Online Rating Systems: Modeling, Analysis and Application","Zhong, Mingze and Xie, Hong and Zhu, Qingsheng",inproceedings,10.1145/3447548.3467244,
10.1145/3447548.3467289,10.1145/3447548.3467289,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","causal reasoning, popularity bias, recommendation",10,1791–1800,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"The general aim of the recommender system is to provide personalized suggestions to users, which is opposed to suggesting popular items. However, the normal training paradigm, i.e., fitting a recommender model to recover the user behavior data with pointwise or pairwise loss, makes the model biased towards popular items. This results in the terrible Matthew effect, making popular items be more frequently recommended and become even more popular. Existing work addresses this issue with Inverse Propensity Weighting (IPW), which decreases the impact of popular items on the training and increases the impact of long-tail items. Although theoretically sound, IPW methods are highly sensitive to the weighting strategy, which is notoriously difficult to tune.In this work, we explore the popularity bias issue from a novel and fundamental perspective --- cause-effect. We identify that popularity bias lies in the direct effect from the item node to the ranking score, such that an item's intrinsic property is the cause of mistakenly assigning it a higher ranking score. To eliminate popularity bias, it is essential to answer the counterfactual question that what the ranking score would be if the model only uses item property. To this end, we formulate a causal graph to describe the important cause-effect relations in the recommendation process. During training, we perform multi-task learning to achieve the contribution of each cause; during testing, we perform counterfactual inference to remove the effect of item popularity. Remarkably, our solution amends the learning process of recommendation which is agnostic to a wide range of models --- it can be easily implemented in existing methods. We demonstrate it on Matrix Factorization (MF) and LightGCN [20], which are representative of the conventional and SOTA model for collaborative filtering. Experiments on five real-world datasets demonstrate the effectiveness of our method.",10.1145/3447548.3467289,https://doi.org/10.1145/3447548.3467289,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System,"Wei, Tianxin and Feng, Fuli and Chen, Jiawei and Wu, Ziwei and Yi, Jinfeng and He, Xiangnan",inproceedings,10.1145/3447548.3467289,
10.1145/3447548.3467376,10.1145/3447548.3467376,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","dynamic recommendation, popularity bias",11,2439–2449,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Popularity bias is a long-standing challenge in recommender systems: popular items are overly recommended at the expense of less popular items that users may be interested in being under-recommended. Such a bias exerts detrimental impact on both users and item providers, and many efforts have been dedicated to studying and solving such a bias. However, most existing works situate the popularity bias in a static setting, where the bias is analyzed only for a single round of recommendation with logged data. These works fail to take account of the dynamic nature of real-world recommendation process, leaving several important research questions unanswered: how does the popularity bias evolve in a dynamic scenario? what are the impacts of unique factors in a dynamic recommendation process on the bias? and how to debias in this long-term dynamic process? In this work, we investigate the popularity bias in dynamic recommendation and aim to tackle these research gaps. Concretely, we conduct an empirical study by simulation experiments to analyze popularity bias in the dynamic scenario and propose a dynamic debiasing strategy and a novel False Positive Correction method utilizing false positive signals to debias, which show effective performance in extensive experiments.",10.1145/3447548.3467376,https://doi.org/10.1145/3447548.3467376,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Popularity Bias in Dynamic Recommendation,"Zhu, Ziwei and He, Yun and Zhao, Xing and Caverlee, James",inproceedings,10.1145/3447548.3467376,
10.1145/3447548.3467399,10.1145/3447548.3467399,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","automated machine learning, collaborative filtering, recommender system",11,415–425,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Collaborative filtering (CF), as a fundamental approach for recommender systems, is usually built on the latent factor model with learnable parameters to predict users' preferences towards items. However, designing a proper CF model for a given data is not easy, since the properties of datasets are highly diverse. In this paper, motivated by the recent advances in automated machine learning (AutoML), we propose to design a data-specific CF model by AutoML techniques. The key here is a new framework that unifies state-of-the-art (SOTA) CF methods and splits them into disjoint stages of input encoding, embedding function, interaction function, and prediction function. We further develop an easy-to-use, robust, and efficient search strategy, which utilizes random search and a performance predictor for efficient searching within the above framework. In this way, we can combinatorially generalize data-specific CF models, which have not been visited in the literature, from SOTA ones. Extensive experiments on five real-world datasets demonstrate that our method can consistently outperform SOTA ones for various CF tasks. Further experiments verify the rationality of the proposed framework and the efficiency of the search strategy. The searched CF models can also provide insights for exploring more effective methods in the future.",10.1145/3447548.3467399,https://doi.org/10.1145/3447548.3467399,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Efficient Data-specific Model Search for Collaborative Filtering,"Gao, Chen and Yao, Quanming and Jin, Depeng and Li, Yong",inproceedings,10.1145/3447548.3467399,
10.1145/3447548.3467408,10.1145/3447548.3467408,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","collaborative filtering, graph neural networks, negative sampling, recommender systems",10,665–674,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Graph neural networks (GNNs) have recently emerged as state-of-the-art collaborative filtering (CF) solution. A fundamental challenge of CF is to distill negative signals from the implicit feedback, but negative sampling in GNN-based CF has been largely unexplored. In this work, we propose to study negative sampling by leveraging both the user-item graph structure and GNNs' aggregation process. We present the MixGCF method---a general negative sampling plugin that can be directly used to train GNN-based recommender systems. In MixGCF, rather than sampling raw negatives from data, we design the hop mixing technique to synthesize hard negatives. Specifically, the idea of hop mixing is to generate the synthetic negative by aggregating embeddings from different layers of raw negatives' neighborhoods. The layer and neighborhood selection process are optimized by a theoretically-backed hard selection strategy. Extensive experiments demonstrate that by using MixGCF, state-of-the-art GNN-based recommendation models can be consistently and significantly improved, e.g., 26% for NGCF and 22% for LightGCN in terms of NDCG@20.",10.1145/3447548.3467408,https://doi.org/10.1145/3447548.3467408,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems,"Huang, Tinglin and Dong, Yuxiao and Ding, Ming and Yang, Zhen and Feng, Wenzheng and Wang, Xinyu and Tang, Jie",inproceedings,10.1145/3447548.3467408,
10.1145/3447548.3467421,10.1145/3447548.3467421,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","hyperbolic space, node embeddings, recommender systems",9,2223–2231,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Hyperbolic space and hyperbolic embeddings are becoming a popular research field for recommender systems. However, it is not clear under what circumstances the hyperbolic space should be considered. To fill this gap, This paper provides theoretical analysis and empirical results on when and where to use hyperbolic space and hyperbolic embeddings in recommender systems. Specifically, we answer the questions that which type of models and datasets are more suited for hyperbolic space, as well as which latent size to choose. We evaluate our answers by comparing the performance of Euclidean space and hyperbolic space on different latent space models in both general item recommendation domain and social recommendation domain, with 6 widely used datasets and different latent sizes. Additionally, we propose a new metric learning based recommendation method called SCML and its hyperbolic version HSCML. We evaluate our conclusions regarding hyperbolic space on SCML and show the state-of-the-art performance of hyperbolic space by comparing HSCML with other baseline methods.",10.1145/3447548.3467421,https://doi.org/10.1145/3447548.3467421,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Where are we in embedding spaces?,"Zhang, Sixiao and Chen, Hongxu and Ming, Xiao and Cui, Lizhen and Yin, Hongzhi and Xu, Guandong",inproceedings,10.1145/3447548.3467421,
10.1145/3447548.3467428,10.1145/3447548.3467428,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","hyper-parameter search, linear model, low-rank regression, matrix factorization, recommender systems",10,776–785,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Recently, linear regression models have shown to often produce rather competitive results against more sophisticated deep learning models. Meanwhile, the (weighted) matrix factorization approaches have been popular choices for recommendation in the past and widely adopted in the industry. In this work, we aim to theoretically understand the relationship between these two approaches, which are the cornerstones of model-based recommendations. Through the derivation and analysis of the closed-form solutions for two basic regression and matrix factorization approaches, we found these two approaches are indeed inherently related but also diverge in how they ""scale-down"" the singular values of the original user-item interaction matrix. We further introduce a new learning algorithm in searching (hyper)parameters for the closed-form solution and utilize it to discover the nearby models of the existing solutions. The experimental results demonstrate that the basic models and their closed-form solutions are indeed quite competitive against the state-of-the-art models, thus, confirming the validity of studying the basic models. The effectiveness of exploring the nearby models are also experimentally validated.",10.1145/3447548.3467428,https://doi.org/10.1145/3447548.3467428,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,Towards a Better Understanding of Linear Models for Recommendation,"Jin, Ruoming and Li, Dong and Gao, Jing and Liu, Zhi and Chen, Li and Zhou, Yang",inproceedings,10.1145/3447548.3467428,
10.1145/3447548.3469444,10.1145/3447548.3469444,KDD.bib,1,['KDD.bib'],8,KDD '21,"Virtual Event, Singapore","deep learning, high-dimensional, sparse data",2,4187–4188,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,"Recently, we have witnessed that deep learning-based approaches has been widely applied to empower many internet-scale applications. However, the data in these internet-scale applications are high dimensional and extremely sparse, which makes it different from those applications with dense data processing, such as image classification and speech recognition, where deep learning-based approaches have been extensively studied. One of the main applications is the user-centric platform that consists of great deal of users, items and user generated tabular data which are quite high-dimensional. The characteristics of such data pose unique challenges to the adoption of deep learning in these applications, including modeling, training, and online serving, etc. More and more communities from both academia and industry have initiated the endeavors to solve these challenges. This workshop will provide a venue for both the research and engineering communities to discuss and formulate the challenges, utilize opportunities, and propose new ideas in the practice of deep learning on high-dimensional sparse data.",10.1145/3447548.3469444,https://doi.org/10.1145/3447548.3469444,"New York, NY, USA",Association for Computing Machinery,9781450383325,2021,3rd International Workshop on Deep Learning Practice for High-Dimensional Sparse Data with KDD 2021,"Zhu, Xiaoqiang and Lee, Kuang-chih and Zhou, Guorui and Jiang, Biye and Wang, Zhe and Tang, Ruiming and Ren, Kan and Ai, Qingyao and Zhang, Weinan",inproceedings,10.1145/3447548.3469444,
10.1145/3459637.3481901,10.1145/3459637.3481901,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","regression discontinuity design, recommender system, causal collaborative filtering",11,4253–4263,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"To improve user experience and profits of corporations, modern industrial recommender systems usually aim to select the items that are most likely to be interacted with (e.g., clicks and purchases). However, they overlook the fact that users may purchase the items even without recommendations. The real effective items are the ones that can contribute to purchase probability uplift. To select these effective items, it is essential to estimate the causal effect of recommendations. Nevertheless, it is difficult to obtain the real causal effect since we can only recommend or not recommend an item to a user at one time. Furthermore, previous works usually rely on the randomized controlled trial (RCT) experiment to evaluate their performance. However, it is usually not practicable in the recommendation scenario due to its expensive experimental cost. To tackle these problems, in this paper, we propose a causal collaborative filtering (CausCF) method inspired by the widely adopted collaborative filtering (CF) technique. It is based on the idea that similar users not only have a similar taste on items but also have similar treatment effects under recommendations. CausCF extends the classical matrix factorization to the tensor factorization with three dimensions---user, item, and treatment. Furthermore, we also employ regression discontinuity design (RDD) to evaluate the precision of the estimated causal effects from different models. With the testable assumptions, RDD analysis can provide an unbiased causal conclusion without RCT experiments. Through dedicated experiments on both offline and online experiments, we demonstrate the effectiveness of our proposed CausCF on the causal effect estimation and ranking performance improvement.",10.1145/3459637.3481901,https://doi.org/10.1145/3459637.3481901,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,CausCF: Causal Collaborative Filtering for Recommendation Effect Estimation,"Xie, Xu and Liu, Zhaoyang and Wu, Shiwen and Sun, Fei and Liu, Cihang and Chen, Jiawei and Gao, Jinyang and Cui, Bin and Ding, Bolin",inproceedings,10.1145/3459637.3481901,
10.1145/3459637.3481923,10.1145/3459637.3481923,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","order delivery time estimation, on-demand food delivery, fulfillment-time-aware recommendation, food ranking",9,4184–4192,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"On-demand food delivery (OFD) platforms have greatly impacted the food service industry, where OFD recommendation systems play a central role in enhancing user experience and raising revenues. OFD recommendation, compared with existing online e-commerce recommendation systems, needs to put more emphasis on fulfillment time related variables, because the order fulfillment cycle time (OFCT) which refers to the time elapsed between a user placing a food order and receiving the food significantly influences a user's choice from the recommended items. In this paper, we investigate the OFCT related information and propose a Fulfillment-Time-Aware Personalized Ranking (FTAPR) method for recommendation. FTAPR mainly consists of three components. First, Transformers are used to estimate OFCT based on a large amount of user order sequences. Then, the predicted OFCT and other OFCT related features are fused and encoded by a deep &amp; cross network to learn fulfillment time related feature representation. At the last step, the time bias representation from the deep &amp; cross network is integrated into the ranking system to deliver final search results. Extensive offline and online experiments on real-world datasets collected from one of China's largest OFD platforms Ele.me show the superiority of our model, e.g., an online A/B testing shows that FTAPR brings 1.3% and 2.5% gains in CTR and CVR compared with baselines.",10.1145/3459637.3481923,https://doi.org/10.1145/3459637.3481923,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Fulfillment-Time-Aware Personalized Ranking for On-Demand Food Recommendation,"Wang, Haishuai and Li, Zhao and Liu, Xuanwu and Ding, Donghui and Hu, Zehong and Zhang, Peng and Zhou, Chuan and Bu, Jiajun",inproceedings,10.1145/3459637.3481923,
10.1145/3459637.3481940,10.1145/3459637.3481940,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","recommendation diversity, explainability, app recommendation",10,4302–4311,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"This paper introduces an enterprise app recommendation problem with a new ""to-business'' use case, which aims to assist a sales team acting as the bridge connecting the applications and developers with the customers who apply these apps to solve their business problems. Our recommender system is an assistant to the sales team, helping recommend relevant apps to the customers for their businesses and increasing the likelihood of improving sales revenue. Besides recommendation accuracy, recommendation diversity and explainability are even more crucial since they provide more exposure opportunities for app developers and improve the transparency and trustworthiness of the recommender system. To allow the sales team to explore unpopular but relevant apps and understand why such apps are recommended, we propose a novel framework for improving aggregate recommendation diversity and generating recommendation explanations, which supports a wide variety of models for improving recommendation accuracy. The model in our framework is simple yet effective, which can be trained in an end-to-end manner and deployed as a recommendation service easily. Furthermore, our framework can also apply to other generic recommender systems for improving diversity and generating explanations. Experiments on public and private datasets demonstrate the effectiveness of our framework and solution.",10.1145/3459637.3481940,https://doi.org/10.1145/3459637.3481940,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,On the Diversity and Explainability of Recommender Systems: A Practical Framework for Enterprise App Recommendation,"Yang, Wenzhuo and Li, Jia and Li, Chenxi and Barnett, Latrice and Anderle, Markus and Arajarvi, Simo and Utharavalli, Harshavardhan and Xiong, Caiming and HOI, Steven",inproceedings,10.1145/3459637.3481940,
10.1145/3459637.3481952,10.1145/3459637.3481952,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","self-supervised learning, recommender systems, neural networks, contrastive learning",10,4321–4330,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Large scale recommender models find most relevant items from huge catalogs, and they play a critical role in modern search and recommendation systems. To model the input space with large-vocab categorical features, a typical recommender model learns a joint embedding space through neural networks for both queries and items from user feedback data. However, with millions to billions of items in the corpus, users tend to provide feedback for a very small set of them, causing a power-law distribution. This makes the feedback data for long-tail items extremely sparse. Inspired by the recent success in self-supervised representation learning research in both computer vision and natural language understanding, we propose a multi-task self-supervised learning (SSL) framework for large-scale item recommendations. The framework is designed to tackle the label sparsity problem by learning better latent relationship of item features. Specifically, SSL improves item representation learning as well as serving as additional regularization to improve generalization. Furthermore, we propose a novel data augmentation method that utilizes feature correlations within the proposed framework.We evaluate our framework using two real-world datasets with 500M and 1B training examples respectively. Our results demonstrate the effectiveness of SSL regularization and show its superior performance over the state-of-the-art regularization techniques. We also have already launched the proposed techniques to a web-scale commercial app-to-app recommendation system, with significant improvements top-tier business metrics demonstrated in A/B experiments on live traffic. Our online results also verify our hypothesis that our framework indeed improves model performance even more on slices that lack supervision.",10.1145/3459637.3481952,https://doi.org/10.1145/3459637.3481952,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Self-supervised Learning for Large-scale Item Recommendations,"Yao, Tiansheng and Yi, Xinyang and Cheng, Derek Zhiyuan and Yu, Felix and Chen, Ting and Menon, Aditya and Hong, Lichan and Chi, Ed H. and Tjoa, Steve and Kang, Jieqi (Jay) and Ettinger, Evan",inproceedings,10.1145/3459637.3481952,
10.1145/3459637.3482016,10.1145/3459637.3482016,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","toolkit, recommender system, collaborative filtering",12,4653–4664,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"In recent years, there are a large number of recommendation algorithms proposed in the literature, from traditional collaborative filtering to deep learning algorithms. However, the concerns about how to standardize open source implementation of recommendation algorithms continually increase in the research community. In the light of this challenge, we propose a unified, comprehensive and efficient recommender system library called RecBole (pronounced as [rEk'boUl@r]), which provides a unified framework to develop and reproduce recommendation algorithms for research purpose. In this library, we implement 73 recommendation models on 28 benchmark datasets, covering the categories of general recommendation, sequential recommendation, context-aware recommendation and knowledge-based recommendation. We implement the RecBole library based on PyTorch, which is one of the most popular deep learning frameworks. Our library is featured in many aspects, including general and extensible data structures, comprehensive benchmark models and datasets, efficient GPU-accelerated execution, and extensive and standard evaluation protocols. We provide a series of auxiliary functions, tools, and scripts to facilitate the use of this library, such as automatic parameter tuning and break-point resume. Such a framework is useful to standardize the implementation and evaluation of recommender systems. The project and documents are released at https://recbole.io/.",10.1145/3459637.3482016,https://doi.org/10.1145/3459637.3482016,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,"RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms","Zhao, Wayne Xin and Mu, Shanlei and Hou, Yupeng and Lin, Zihan and Chen, Yushuo and Pan, Xingyu and Li, Kaiyuan and Lu, Yujie and Wang, Hui and Tian, Changxin and Min, Yingqian and Feng, Zhichao and Fan, Xinyan and Chen, Xu and Wang, Pengfei and Ji, Wendi and Li, Yaliang and Wang, Xiaoling and Wen, Ji-Rong",inproceedings,10.1145/3459637.3482016,
10.1145/3459637.3482046,10.1145/3459637.3482046,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","recommender systems, bias, adversarial machine learning",5,2852–2856,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Recommender systems (RSs) employ user-item feedback, e.g., ratings, to match customers to personalized lists of products. Approaches to top-k recommendation mainly rely on Learning-To-Rank algorithms and, among them, the most widely adopted is Bayesian Personalized Ranking (BPR), which bases on a pair-wise optimization approach. Recently, BPR has been found vulnerable against adversarial perturbations of its model parameters. Adversarial Personalized Ranking (APR) mitigates this issue by robustifying BPR via an adversarial training procedure. The empirical improvements of APR's accuracy performance on BPR have led to its wide use in several recommender models. However, a key overlooked aspect has been the beyond-accuracy performance of APR, i.e., novelty, coverage, and amplification of popularity bias, considering that recent results suggest that BPR, the building block of APR, is sensitive to the intensification of biases and reduction of recommendation novelty. In this work, we model the learning characteristics of the BPR and APR optimization frameworks to give mathematical evidence that, when the feedback data have a tailed distribution, APR amplifies the popularity bias more than BPR due to an unbalanced number of received positive updates from short-head items. Using matrix factorization (MF), we empirically validate the theoretical results by performing preliminary experiments on two public datasets to compare BPR-MF and APR-MF performance on accuracy and beyond-accuracy metrics. The experimental results consistently show the degradation of novelty and coverage measures and a worrying amplification of bias.",10.1145/3459637.3482046,https://doi.org/10.1145/3459637.3482046,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,A Formal Analysis of Recommendation Quality of Adversarially-trained Recommenders,"Anelli, Vito Walter and Deldjoo, Yashar and Di Noia, Tommaso and Merra, Felice Antonio",inproceedings,10.1145/3459637.3482046,
10.1145/3459637.3482071,10.1145/3459637.3482071,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","session-based recommendations, popularity bias, causal inference",5,3048–3052,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Recommender Systems (RS) tend to recommend more popular items instead of the relevant long-tail items. Mitigating such popularity bias is crucial to ensure that less popular but relevant items are part of the recommendation list shown to the user. In this work, we study the phenomenon of popularity bias in session-based RS (SRS) obtained via deep learning (DL) models. We observe that DL models trained on the historical user-item interactions in session logs (having long-tailed item-click distributions) tend to amplify popularity bias. To understand the source of this bias amplification, we consider potential sources of bias at two distinct stages in the modeling process: i. the data-generation stage (user-item interactions captured as session logs), ii. the DL model training stage. We highlight that the popularity of an item has a causal effect on i. user-item interactions via conformity bias, as well as ii. item ranking from DL models via biased training process due to class (target item) imbalance. While most existing approaches in literature address only one of these effects, we consider a comprehensive causal inference framework that identifies and mitigates the effects at both stages. Through extensive empirical evaluation on simulated and real-world datasets, we show that our approach improves upon several strong baselines from literature for popularity bias and long-tailed classification. Ablation studies show the advantage of our comprehensive causal analysis to identify and handle bias in data generation as well as training stages.",10.1145/3459637.3482071,https://doi.org/10.1145/3459637.3482071,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,CauSeR: Causal Session-based Recommendations for Handling Popularity Bias,"Gupta, Priyanka and Sharma, Ankit and Malhotra, Pankaj and Vig, Lovekesh and Shroff, Gautam",inproceedings,10.1145/3459637.3482071,
10.1145/3459637.3482172,10.1145/3459637.3482172,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","textual reviews, recommender systems, neural network, attention mechanism",5,3293–3297,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Two-tower neural networks are popularly used in review-aware recommender systems, in which two encoders are separately employed to learn representations for users and items from reviews. However, such an architecture isolates the information exchange between two encoders, resulting in suboptimal recommendation accuracy. To this end, we propose a novel two-tower style Neural Recommendation with Cross-modality Mutual Attention (NRCMA), which bridges user encoder and item encoder crossing reviews and ratings, in order to select informative words and reviews to learn better representation for users and items. Extensive experiments on three benchmark datasets demonstrate that the cross-modality mutual attention is beneficial to two-tower neural networks, and NRCMA consistently outperforms state-of-the-art review-aware item recommendation techniques.",10.1145/3459637.3482172,https://doi.org/10.1145/3459637.3482172,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Review-Aware Neural Recommendation with Cross-Modality Mutual Attention,"Luo, Songyin and Lu, Xiangkui and Wu, Jun and Yuan, Jianbo",inproceedings,10.1145/3459637.3482172,
10.1145/3459637.3482181,10.1145/3459637.3482181,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","review-based recommendation, sentiment analysis",5,3627–3631,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Recent studies in recommender systems have managed to achieve significantly improved performance. However, despite being extensively studied, these methods still suffer from two limitations. First, previous studies either encode the document or extract latent sentiment via neural networks, which are difficult to interpret the sentiment of reviewers intuitively. Second, they neglect the personalized interaction of reviews with user/item, i.e., each review has different contributions when modeling the preference of user/item To remedy these issues, we propose a Sentiment-aware Interactive Fusion Network (SIFN) for review-based item recommendation. Specifically, we first encode user/item reviews via BERT and propose a light-weighted sentiment learner to extract semantic features of each review. Then, we propose a sentiment prediction task that guides the sentiment learner to extract sentiment-aware features via explicit sentiment labels. Finally, we design a rating prediction task that contains a rating learner with an interactive and fusion module to fuse the identity (i.e., user and item ID) and each review representation so that various interactive features can synergistically influence the final rating score. Experimental results demonstrate that the proposed model is superior to state-of-the-art models.",10.1145/3459637.3482181,https://doi.org/10.1145/3459637.3482181,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,SIFN: A Sentiment-aware Interactive Fusion Network for Review-based Item Recommendation,"Zhang, Kai and Qian, Hao and Liu, Qi and Zhang, Zhiqiang and Zhou, Jun and Ma, Jianhui and Chen, Enhong",inproceedings,10.1145/3459637.3482181,
10.1145/3459637.3482202,10.1145/3459637.3482202,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","time-aware recommendation, session-based recommendation, recommender system, irregularly-sampled time series",5,2872–2876,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"The overload of information on the Internet becomes ubiquitous nowadays, which makes the role of recommender systems more important. In recommender systems, the interest of users and popularity of items are not static, but can change drastically. Thus modeling the temporal dynamic of user-item interactions is crucial in recommender systems. The newly proposed Neural Ordinary Differential Equation (NODE) method is able to modeling the temporal mechanism of a system with neural networks. By using the ODE-LSTM method, which unites the ability of NODE to handle continuous time and that of LSTM to address sequential data, in this paper we achieve significant improvements for the recommendation task on several real-world datasets with the time irregularity. To handle sessions with different timestamps in ODE-LSTM, we propose a collective timeline technique that contributes a lot to the performance improvement. Moreover, we find that reducing the scale of time intervals in sessions significantly improves the recommendation performance.",10.1145/3459637.3482202,https://doi.org/10.1145/3459637.3482202,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Time-Aware Recommender System via Continuous-Time Modeling,"Bao, Jianghan and Zhang, Yu",inproceedings,10.1145/3459637.3482202,
10.1145/3459637.3482221,10.1145/3459637.3482221,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","matrix factorization, explainable recommendation, collaborative filtering",5,2847–2851,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Collaborative filtering (CF) methods are making an impact on our daily lives in a wide range of applications, including recommender systems and personalization. Latent factor methods, e.g., matrix factorization (MF), have been the state-of-the-art in CF, however they lack interpretability and do not provide a straightforward explanation for their predictions. Explainability is gaining momentum in recommender systems for accountability, and because a good explanation can swing an undecided user. Most recent explainable recommendation methods require auxiliary data such as review text or item content on top of item ratings. In this paper, we address the case where no additional data are available and propose augmenting the classical MF framework for CF with a prior that encodes each user's embedding as a sparse linear combination of item embeddings, and vice versa for each item embedding. Our XPL-CF approach automatically reveals these user-item relationships, which underpin the latent factors and explain how the resulting recommendations are formed. We showcase the effectiveness of XPL-CF on real data from various application domains. We also evaluate the explainability of the user-item relationship obtained from XPL-CF through numeric evaluation and case study examples.",10.1145/3459637.3482221,https://doi.org/10.1145/3459637.3482221,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,XPL-CF: Explainable Embeddings for Feature-based Collaborative Filtering,"Almutairi, Faisal M. and Sidiropoulos, Nicholas D. and Yang, Bo",inproceedings,10.1145/3459637.3482221,
10.1145/3459637.3482246,10.1145/3459637.3482246,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","user response prediction, self-attention, recommender system, cross feature modeling",10,221–230,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"User response prediction, which aims to predict the probability that a user will provide a predefined positive response in a given context such as clicking on an ad or purchasing an item, is crucial to many industrial applications such as online advertising, recommender systems, and search ranking. For these tasks and many other machine learning tasks, an indispensable part of success is feature engineering, where cross features are a significant type of feature transformations. However, due to the high dimensionality and super sparsity of the data collected in these tasks, handcrafting cross features is inevitably time expensive. Prior studies in predicting user response leveraged the feature interactions by enhancing feature vectors with products of features to model second-order or high-order cross features, either explicitly or implicitly. However, these existing methods can be hindered by not learning sufficient cross features due to model architecture limitations or modeling all high-order feature interactions with equal weights. Different features should contribute differently to the prediction, and not all cross features are with the same prediction power.This work aims to fill this gap by proposing a novel architecture Deep Cross Attentional Product Network (DCAP), which keeps cross network's benefits in modeling high-order feature interactions explicitly at the vector-wise level. By computing the inner product or outer product between attentional feature embeddings and original input embeddings as each layer's output, we can model cross features with a higher degree of order as the network's depth increases. We concatenate all the outputs from each layer, which further helps the model capture much information on cross features of different orders. Beyond that, it can differentiate the importance of different cross features in each network layer inspired by the multi-head attention mechanism and Product Neural Network (PNN), allowing practitioners to perform a more in-depth analysis of user behaviors. Additionally, our proposed model can be easily implemented and train in parallel. We conduct comprehensive experiments on three real-world datasets. The results have robustly demonstrated that our proposed model DCAP achieves superior prediction performance compared with the state-of-the-art models. Public codes are available at https://github.com/zachstarkk/DCAP.",10.1145/3459637.3482246,https://doi.org/10.1145/3459637.3482246,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,DCAP: Deep Cross Attentional Product Network for User Response Prediction,"Chen, Zekai and Zhong, Fangtian and Chen, Zhumin and Zhang, Xiao and Pless, Robert and Cheng, Xiuzhen",inproceedings,10.1145/3459637.3482246,
10.1145/3459637.3482256,10.1145/3459637.3482256,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","sequential recommendation, knowledge graph, interest modeling",10,1889–1898,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Sequential recommendation which aims to predict a user's next interaction based on his/her previous behaviors, has attracted great attention. Recent studies mainly employ deep recurrent neural networks or self-attention networks to capture dynamic user preferences. However, existing methods merely focus on modeling users' clear interests in interacted items. We argue that for an interaction, the user may also have ambiguous interests in items that are semantically related to the interacted one. For comprehensively capturing user preferences, it is beneficial to discover potential interests from historical interactions at a broader itemset level. Therefore, in this paper, we propose a knowledge graph enhanced sequential recommendation model namely KGIE, which focuses on enhancing user interest modeling with knowledge-enriched itemsets by incorporating the knowledge graph. Specifically, in addition to item-level interest modeling with interacted items, we further construct knowledge-enriched itemsets that are extracted via high-order knowledge associations with the interacted items. For capturing personalized itemset-level interests, we design an attentive aggregation unit to combine item embeddings considering both inherent and contextual personalization signals. Furthermore, to balance the contributions of both two levels of interest modeling, we adaptively learn high-level preference representations with a gating fusion unit. Extensive experiments on three real-world datasets demonstrate the superior performance beyond state-of-the-art methods and recommendation interpretability of our model.",10.1145/3459637.3482256,https://doi.org/10.1145/3459637.3482256,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Enhancing User Interest Modeling with Knowledge-Enriched Itemsets for Sequential Recommendation,"Wang, Chunyang and Zhu, Yanmin and Liu, Haobing and Ma, Wenze and Zang, Tianzi and Yu, Jiadi",inproceedings,10.1145/3459637.3482256,
10.1145/3459637.3482270,10.1145/3459637.3482270,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","multi-modal learning, modality alignment, cross-modal retrieval",10,2221–2230,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"This paper presents a three-tier modality alignment approach to learning text-image joint embedding, coined as JEMA, for cross-modal retrieval of cooking recipes and food images. The first tier improves recipe text embedding by optimizing the LSTM networks with term extraction and ranking enhanced sequence patterns, and optimizes the image embedding by combining the ResNeXt-101 image encoder with the category embedding using wideResNet-50 with word2vec. The second tier modality alignment optimizes the textual-visual joint embedding loss function using a double batch-hard triplet loss with soft-margin optimization. The third modality alignment incorporates two types of cross-modality alignments as the auxiliary loss regularizations to further reduce the alignment errors in the joint learning of the two modality-specific embedding functions. The category-based cross-modal alignment aims to align the image category with the recipe category as a loss regularization to the joint embedding. The cross-modal discriminator-based alignment aims to add the visual-textual embedding distribution alignment to further regularize the joint embedding loss. Extensive experiments with the one-million recipes benchmark dataset Recipe1M demonstrate that the proposed JEMA approach outperforms the state-of-the-art cross-modal embedding methods for both image-to-recipe and recipe-to-image retrievals.",10.1145/3459637.3482270,https://doi.org/10.1145/3459637.3482270,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Learning Joint Embedding with Modality Alignments for Cross-Modal Retrieval of Recipes and Food Images,"Xie, Zhongwei and Liu, Ling and Li, Lin and Zhong, Luo",inproceedings,10.1145/3459637.3482270,
10.1145/3459637.3482276,10.1145/3459637.3482276,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","search explanation, product search, attention mechanism",11,5–15,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Product retrieval systems have served as the main entry for customers to discover and purchase products online. With increasing concerns on the transparency and accountability of AI systems, studies on explainable information retrieval has received more and more attention in the research community. Interestingly, in the domain of e-commerce, despite the extensive studies on explainable product recommendation, the studies of explainable product search is still in an early stage. In this paper, we study how to construct effective explainable product search by comparing model-agnostic explanation paradigms with model-intrinsic paradigms and analyzing the important factors that determine the performance of product search explanations. We propose an explainable product search model with model-intrinsic interpretability and conduct crowdsourcing to compare it with the state-of-the-art explainable product search model with model-agnostic interpretability. We observe that both paradigms have their own advantages and the effectiveness of search explanations on different properties are affected by different factors. For example, explanation fidelity is more important for user's overall satisfaction on the system while explanation novelty may be more useful in attracting user purchases. These findings could have important implications for the future studies and design of explainable product search engines.",10.1145/3459637.3482276,https://doi.org/10.1145/3459637.3482276,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Model-agnostic vs. Model-intrinsic Interpretability for Explainable Product Search,"Ai, Qingyao and Narayanan.R, Lakshmi",inproceedings,10.1145/3459637.3482276,
10.1145/3459637.3482296,10.1145/3459637.3482296,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","user behavior modeling, sequential recommendation, representation learning, collaborative filtering",10,2160–2169,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"User behavior sequences contain rich information about user interests and are exploited to predict user's future clicking in sequential recommendation. Existing approaches, especially recently proposed deep learning models, often embed a sequence of clicked items into a single vector, i.e., a point in vector space, which suffer from limited expressiveness for complex distributions of user interests with multi-modality and heterogeneous concentration. In this paper, we propose a new representation model, named as Seq2Bubbles, for sequential user behaviors via embedding an input sequence into a set of bubbles each of which is represented by a center vector and a radius vector in embedding space. The bubble embedding can effectively identify and accommodate multi-modal user interests and diverse concentration levels. Furthermore, we design an efficient scheme to compute distance between a target item and the bubble embedding of a user sequence to achieve next-item recommendation. We also develop a self-supervised contrastive loss based on our bubble embeddings as an effective regularization approach. Extensive experiments on four benchmark datasets demonstrate that our bubble embedding can consistently outperform state-of-the-art sequential recommendation models.",10.1145/3459637.3482296,https://doi.org/10.1145/3459637.3482296,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Seq2Bubbles: Region-Based Embedding Learning for User Behaviors in Sequential Recommenders,"Wu, Qitian and Yang, Chenxiao and Yu, Shuodian and Gao, Xiaofeng and Chen, Guihai",inproceedings,10.1145/3459637.3482296,
10.1145/3459637.3482298,10.1145/3459637.3482298,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","spatio-temporal-social features extraction, spatio fine-grained, graph convolution network, content delivery services",10,750–759,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"The arrival of 5G networks has extensively promoted the growth of content delivery services (CDSs). Understanding and predicting the spatio-temporal distribution of CDSs are beneficial to mobile users, Internet Content Providers and carriers. Conventional methods for predicting the spatio-temporal distribution of CDSs are mostly base-stations (BSs) centric, leading to weak generalization and spatio coarse-grained. To improve the spatio accuracy and generalization of modeling, we propose user-centric methods for CDSs spatio-temporal analysis. With geocoding and spatio-temporal graphs modeling algorithms, CDSs records collected from mobile devices are modeled as dynamic graphs with spatio-temporal attributes. Moreover, we propose a spatio-temporal-social multi-feature extraction framework for spatio fine-grained CDSs hot spots prediction. Specifically, an edge-enhanced graph convolutional block is designed to encode CDSs information based on the social relations and the spatio dependence features. Besides, we introduce the Long Short Term Memory (LSTM) to further capture the temporal dependence. Experiments on two real-world CDSs datasets verified the effectiveness of the proposed framework, and ablation studies are taken to evaluate the importance of each feature.",10.1145/3459637.3482298,https://doi.org/10.1145/3459637.3482298,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Spatio-Temporal-Social Multi-Feature-based Fine-Grained Hot Spots Prediction for Content Delivery Services in 5G Era,"Huang, Shaoyuan and Zhang, Heng and Wang, Xiaofei and Chen, Min and Li, Jianxin and Leung, Victor C. M.",inproceedings,10.1145/3459637.3482298,
10.1145/3459637.3482374,10.1145/3459637.3482374,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","topic-aware modeling, information diffusion, cascade modeling",10,1899–1908,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Information diffusion prediction targets on forecasting how information items spread among a set of users. Recently, neural networks have been widely used in modeling information diffusion, owing to the great successes of deep learning. However, in real-world information diffusion scenarios, users are likely to have different behaviors to information items from different topics. Existing neural-based methods failed to model the topic-specific diffusion patterns and dependencies, which have been shown to be useful in conventional non-neural methods. In this paper, we propose Topic-aware Attention Network (TAN) to take advantage of both topic-specific diffusion modeling and deep learning techniques. We jointly model the text content of information items and cascade sequences by incorporating topical context and user/position dependencies into user representations via attention mechanisms. A time-decayed aggregation module is further employed to integrate user representations for cascade representations, which can encode the topic-specific diffusion dependencies independently. Experimental results on diffusion prediction tasks over three realistic cascade datasets show that our model can achieve a relative improvement up to 9% against the best performing baseline in terms of Hits@10.",10.1145/3459637.3482374,https://doi.org/10.1145/3459637.3482374,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Neural Information Diffusion Prediction with Topic-Aware Attention Network,"Wang, Hao and Yang, Cheng and Shi, Chuan",inproceedings,10.1145/3459637.3482374,
10.1145/3459637.3482398,10.1145/3459637.3482398,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","text mining, generative topic model, comparative documents",10,2507–2516,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"As a well-established probabilistic method, topic models seek to uncover latent semantics from plain text. In addition to having textual content, we observe that documents are usually compared in listwise rankings based on their content. For instance, world-wide countries are compared in an international ranking in terms of electricity production based on their national reports. Such document comparisons constitute additional information that reveal documents' relative similarities. Incorporating them into topic modeling could yield comparative topics that help to differentiate and rank documents. Furthermore, based on different comparison criteria, the observed document comparisons usually cover multiple aspects, each expressing a distinct ranked list. For example, a country may be ranked higher in terms of electricity production, but fall behind others in terms of life expectancy or government budget. Each comparison criterion, or aspect, observes a distinct ranking. Considering such multiple aspects of comparisons based on different ranking criteria allows us to derive one set of topics that inform heterogeneous document similarities. We propose a generative topic model aimed at learning topics that are well aligned to multi-aspect listwise comparisons. Experiments on public datasets demonstrate the advantage of the proposed method in jointly modeling topics and ranked lists against baselines comprehensively.",10.1145/3459637.3482398,https://doi.org/10.1145/3459637.3482398,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Topic Modeling for Multi-Aspect Listwise Comparisons,"Zhang, Delvin Ce and Lauw, Hady W.",inproceedings,10.1145/3459637.3482398,
10.1145/3459637.3482414,10.1145/3459637.3482414,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","recommender systems, deep neural network, click-through rate prediction, boosting",10,1150–1159,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Deep learning (DL) algorithms have played a major role in achieving state-of-the-art (SOTA) performance in various learning applications, including computer vision, natural language processing, and recommendation systems (RSs). However, these methods are based on a vast amount of data and do not perform as well when there is a limited amount of data available. Moreover, some of these applications (e.g., RSs) suffer from other issues such as data sparsity and the cold-start problem. While recent research on RSs used DL models based on side information (SI) (e.g., product reviews, film plots, etc.) to tackle these challenges, we propose boosting neural network (BNN), a new DL framework for capturing complex patterns, which requires just a limited amount of data. Unlike conventional boosting, BNN does not sum the predictions generated by its components. Instead, it uses these predictions as new SI features which enhances accuracy. Our framework can be utilized for many problems, including classification, regression, and ranking. In this paper, we demonstrate BNN's use for addressing a classification task. Comprehensive experiments conducted to illustrate BNN's effectiveness on three real-world datasets demonstrated its ability to outperform existing SOTA models for classification tasks (e.g., clickthrough rate prediction).",10.1145/3459637.3482414,https://doi.org/10.1145/3459637.3482414,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,BNN: Boosting Neural Network Framework Utilizing Limited Amount of Data,"Livne, Amit and Dor, Roy and Shapira, Bracha and Rokach, Lior",inproceedings,10.1145/3459637.3482414,
10.1145/3459637.3482461,10.1145/3459637.3482461,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","popularity bias, dialogue state management, debiasing, conversational recommender system",10,494–503,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Recent conversational recommender systems (CRS) provide a promising solution to accurately capture a user's preferences by communicating with users in natural language to interactively guide them while pro-actively eliciting their current interests. Previous research on this mainly focused on either learning a supervised model with semantic features extracted from the user's responses, or training a policy network to control the dialogue state. However, none of them has considered the issue of popularity bias in a CRS. This paper proposes a human-in-the-loop popularity debiasing framework that integrates real-time semantic understanding of open-ended user utterances as well as historical records, while also effectively managing the dialogue with the user. This allows the CRS to balance the recommendation performance as well as the item popularity so as to avoid the well-known ""long-tail'' effect. We demonstrate the effectiveness of our approach via experiments on two conversational recommendation datasets, and the results confirm that our proposed approach achieves high-accuracy recommendation while mitigating popularity bias.",10.1145/3459637.3482461,https://doi.org/10.1145/3459637.3482461,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Popcorn: Human-in-the-loop Popularity Debiasing in Conversational Recommender Systems,"Fu, Zuohui and Xian, Yikun and Geng, Shijie and de Melo, Gerard and Zhang, Yongfeng",inproceedings,10.1145/3459637.3482461,
10.1145/3459637.3482462,10.1145/3459637.3482462,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","news recommendation, neural network, multi-view learning",10,1949–1958,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"News recommendation is of vital importance to alleviating in-formation overload. Recent research shows that precise modeling of news content and user interests become critical for news rec-ommendation. Existing methods usually utilize information such as news title, abstract, entities to predict Click Through Rate(CTR) or add some auxiliary tasks to a multi-task learning framework. However, none of them directly consider predicted news popularity and the degree of users' attention to popular news into the CTR prediction results. Meanwhile, multiple inter-ests may arise throughout users' browsing history. Thus it is hard to represent user interests via a single user vector. In this paper, we propose PENR, a Popularity-Enhanced News Recommenda-tion method, which integrates popularity prediction task to im-prove the performance of the news encoder. News popularity score is predicted and added to the final CTR, while news popu-larity is utilized to model the degree of users' tendency to follow hot news. Moreover, user interests are modeled from different perspectives via a subspace projection method that assembles the browsing history to multiple subspaces. In this way, we capture users' multi-view interest representations. Experiments on a real-world dataset validate the effectiveness of our PENR approach.",10.1145/3459637.3482462,https://doi.org/10.1145/3459637.3482462,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Popularity-Enhanced News Recommendation with Multi-View Interest Representation,"Wang, Jingkun and Chen, Yipu and Wang, Zichun and Zhao, Wen",inproceedings,10.1145/3459637.3482462,
10.1145/3459637.3482465,10.1145/3459637.3482465,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","pdmp, overprescribing detection, opioid overdose, lstm, graph neural network, drug abuse",10,2537–2546,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"Prescription (aka Rx) drugs can be easily overprescribed and lead to drug abuse or opioid overdose. Accordingly, a state-run prescription drug monitoring program (PDMP) in the United States has been developed to reduce Overprescribing. However, PDMP has limited capability in detecting patients' potential overprescribing behaviors, impairing its effectiveness in preventing drug abuse and overdose in patients. Despite a few machine-learning-based methods that have been proposed for detecting overprescribing, they usually ignore the patient prescribing behavior and their performances are not satisfying. In light of this, we propose a novel model RxNet for overprescribing detection in PDMP. RxNet builds a dynamic heterogeneous graph to model Rx refills that are essentially prescribing and dispensing (P&amp;D) relationships among various Rx entries (e.g., patients) whose representations are encoded by graph neural network. In addition, to explore the dynamic Rx-refill behavior and medical condition variation of patients, an RxLSTM network is designed to update representations of patients. Based on the output of RxLSTM, a dosing-adaptive network is leveraged to extract and recalibrate dosing patterns and obtain the refined patient representations which are finally utilized for overprescribing detection. The extensive experimental results on a 1-year Ohio PDMP data demonstrate that RxNet consistently outperforms state-of-the-art methods in predicting patients at high risk of opioid overdose and drug abuse, with an average of 5.7% and 7.3% improvement on F1 score respectively.",10.1145/3459637.3482465,https://doi.org/10.1145/3459637.3482465,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,RxNet: Rx-refill Graph Neural Network for Overprescribing Detection,"Zhang, Jianfei and Kuo, Ai-Te and Zhao, Jianan and Wen, Qianlong and Winstanley, Erin and Zhang, Chuxu and Ye, Yanfang",inproceedings,10.1145/3459637.3482465,
10.1145/3459637.3482493,10.1145/3459637.3482493,CIKM.bib,1,['CIKM.bib'],8,CIKM '21,"Virtual Event, Queensland, Australia","product recommendation, meta-learning, market adaptation, domain adaptation, cross-market recommendation",10,110–119,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,"We study the problem of recommending relevant products to users in relatively resource-scarce markets by leveraging data from similar, richer in resource auxiliary markets. We hypothesize that data from one market can be used to improve performance in another. Only a few studies have been conducted in this area, partly due to the lack of publicly available experimental data. To this end, we collect and release XMarket, a large dataset covering 18 local markets on 16 different product categories, featuring 52.5 million user-item interactions.  We introduce and formalize the problem of cross-market product recommendation, i.e., market adaptation. We explore different market-adaptation techniques inspired by state-of-the-art domain-adaptation and meta-learning approaches and propose a novel neural approach for market adaptation, named FOREC. Our model follows a three-step procedure - pre-training, forking, and fine-tuning - in order to fully utilize the data from an auxiliary market as well as the target market. We conduct extensive experiments studying the impact of market adaptation on different pairs of markets. Our proposed approach demonstrates robust effectiveness, consistently improving the performance on target markets compared to competitive baselines selected for our analysis. In particular, FOREC improves on average 24% and up to 50% in terms of nDCG@10, compared to the NMF baseline. Our analysis and experiments suggest specific future directions in this research area. We release our data and code for academic purposes.",10.1145/3459637.3482493,https://doi.org/10.1145/3459637.3482493,"New York, NY, USA",Association for Computing Machinery,9781450384469,2021,Cross-Market Product Recommendation,"Bonab, Hamed and Aliannejadi, Mohammad and Vardasbi, Ali and Kanoulas, Evangelos and Allan, James",inproceedings,10.1145/3459637.3482493,
10.1145/3460231.3473324,10.1145/3460231.3473324,RecSys.bib,1,['RecSys.bib'],7,RecSys '21,"Amsterdam, Netherlands",,4,834–837,Proceedings of the 15th ACM Conference on Recommender Systems,"Recommender systems typically learn from user-item preference data such as ratings and clicks. This information is sparse in nature, i.e., observed user-item preferences often represent less than 5% of possible interactions. One promising direction to alleviate data sparsity is to leverage auxiliary information that may encode additional clues on how users consume items. Examples of such data (referred to as modalities) are social networks, item’s descriptive text, product images. The objective of this tutorial is to offer a comprehensive review of recent advances to represent, transform and incorporate the different modalities into recommendation models. Moreover, through practical hands-on sessions, we consider cross model/modality comparisons to investigate the importance of different methods and modalities. The hands-on exercises are conducted with Cornac (https://cornac.preferred.ai ), a comparative framework for multimodal recommender systems. The materials are made available on https://preferred.ai/recsys21-tutorial/.",10.1145/3460231.3473324,https://doi.org/10.1145/3460231.3473324,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Multi-Modal Recommender Systems: Hands-On Exploration,"Truong, Quoc-Tuan and Salah, Aghiles and Lauw, Hady",inproceedings,10.1145/3460231.3473324,
10.1145/3460231.3474234,10.1145/3460231.3474234,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","diversity, metrics, offline evaluation, recommender systems",10,75–84,Proceedings of the 15th ACM Conference on Recommender Systems,"Recommender systems evaluation has evolved rapidly in recent years. However, for offline evaluation, accuracy is the de facto standard for assessing the superiority of one method over another, with most research comparisons focused on tasks ranging from rating prediction to ranking metrics for top-n recommendation. Simultaneously, recommendation diversity and novelty have become recognized as critical to users’ perceived utility, with several new metrics recently proposed for evaluating these aspects of recommendation lists. Consequently, the accuracy-diversity dilemma frequently shows up as a choice to make when creating new recommendation algorithms. We propose a novel adaptation of a unified metric, derived from one commonly used for search system evaluation, to Recommender Systems. The proposed metric combines topical diversity and accuracy, and we show it to satisfy a set of desired properties that we formulate axiomatically. These axioms are defined as fundamental constraints that a good unified metric should always satisfy. Moreover, beyond the axiomatic analysis, we present an experimental evaluation of the metric with collaborative filtering data. Our analysis shows that the metric respects the desired theoretical constraints and behaves as expected when performing offline evaluation.",10.1145/3460231.3474234,https://doi.org/10.1145/3460231.3474234,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Towards Unified Metrics for Accuracy and Diversity for Recommender Systems,"Parapar, Javier and Radlinski, Filip",inproceedings,10.1145/3460231.3474234,
10.1145/3460231.3474237,10.1145/3460231.3474237,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","recommender systems, neural networks, denoising",11,400–410,Proceedings of the 15th ACM Conference on Recommender Systems,"For better user satisfaction and business effectiveness, more and more attention has been paid to the sequence-based recommendation system, which is used to infer the evolution of users’ dynamic preferences, and recent studies have noticed that the evolution of users’ preferences can be better understood from the implicit and explicit feedback sequences. However, most of the existing recommendation techniques do not consider the noise contained in implicit feedback, which will lead to the biased representation of user interest and a suboptimal recommendation performance. Meanwhile, the existing methods utilize item sequence for capturing the evolution of user interest. The performance of these methods is limited by the length of the sequence, and can not effectively model the long-term interest in a long period of time. Based on this observation, we propose a novel CTR model named denoising user-aware memory network (DUMN). Specifically, the framework: (i) proposes a feature purification module based on orthogonal mapping, which use the representation of explicit feedback to purify the representation of implicit feedback, and effectively denoise the implicit feedback; (ii) designs a user memory network to model the long-term interests in a fine-grained way by improving the memory network, which is ignored by the existing methods; and (iii) develops a preference-aware interactive representation component to fuse the long-term and short-term interests of users based on gating to understand the evolution of unbiased preferences of users. Extensive experiments on two real e-commerce user behavior datasets show that DUMN has a significant improvement over the state-of-the-art baselines.",10.1145/3460231.3474237,https://doi.org/10.1145/3460231.3474237,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Denoising User-aware Memory Network for Recommendation,"Bian, Zhi and Zhou, Shaojun and Fu, Hao and Yang, Qihong and Sun, Zhenqi and Tang, Junjie and Liu, Guiquan and Liu, Kaikui and Li, Xiaolong",inproceedings,10.1145/3460231.3474237,
10.1145/3460231.3474239,10.1145/3460231.3474239,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","Continual Learning, Incremental Training, Meta Learning",11,411–421,Proceedings of the 15th ACM Conference on Recommender Systems,"Recommender Systems (RSs) in real-world applications often deal with billions of user interactions daily. To capture the most recent trends effectively, it is common to update the model incrementally using only the newly arrived data. However, this may impede the model’s ability to retain long-term information due to the potential overfitting and forgetting issues. To address this problem, we propose a novel Adaptive Sequential Model Generation (ASMG) framework, which generates a better serving model from a sequence of historical models via a meta generator. For the design of the meta generator, we propose to employ Gated Recurrent Units (GRUs) to leverage its ability to capture the long-term dependencies. We further introduce some novel strategies to apply together with the GRU meta generator, which not only improve its computational efficiency but also enable more accurate sequential modeling. By instantiating the model-agnostic framework on a general deep learning-based RS model, we demonstrate that our method achieves state-of-the-art performance on three public datasets and one industrial dataset.",10.1145/3460231.3474239,https://doi.org/10.1145/3460231.3474239,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Learning an Adaptive Meta Model-Generator for Incrementally Updating Recommender Systems,"Peng, Danni and Pan, Sinno Jialin and Zhang, Jie and Zeng, Anxiang",inproceedings,10.1145/3460231.3474239,
10.1145/3460231.3474243,10.1145/3460231.3474243,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","knowledge graphs, feature factorization, entropy",12,154–165,Proceedings of the 15th ACM Conference on Recommender Systems,"Deep Learning and factorization-based collaborative filtering recommendation models have undoubtedly dominated the scene of recommender systems in recent years. However, despite their outstanding performance, these methods require a training time proportional to the size of the embeddings and it further increases when also side information is considered for the computation of the recommendation list. In fact, in these cases we have that with a large number of high-quality features, the resulting models are more complex and difficult to train. This paper addresses this problem by presenting KGFlex: a sparse factorization approach that grants an even greater degree of expressiveness. To achieve this result, KGFlex analyzes the historical data to understand the dimensions the user decisions depend on (e.g., movie direction, musical genre, nationality of book writer). KGFlex represents each item feature as an embedding and it models user-item interactions as a factorized entropy-driven combination of the item attributes relevant to the user. KGFlex facilitates the training process by letting users update only those relevant features on which they base their decisions. In other words, the user-item prediction is mediated by the user’s personal view that considers only relevant features. An extensive experimental evaluation shows the approach’s effectiveness, considering the recommendation results’ accuracy, diversity, and induced bias. The public implementation of KGFlex is available at https://split.to/kgflex.",10.1145/3460231.3474243,https://doi.org/10.1145/3460231.3474243,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Sparse Feature Factorization for Recommender Systems with Knowledge Graphs,"Anelli, Vito Walter and Di Noia, Tommaso and Di Sciascio, Eugenio and Ferrara, Antonio and Mancino, Alberto Carlo Maria",inproceedings,10.1145/3460231.3474243,
10.1145/3460231.3474249,10.1145/3460231.3474249,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","Variational Autoencoder, Critiquing, Conversational Recommendation",11,209–219,Proceedings of the 15th ACM Conference on Recommender Systems,"Recent studies have shown that providing personalized explanations alongside recommendations increases trust and perceived quality. Furthermore, it gives users an opportunity to refine the recommendations by critiquing parts of the explanations. On one hand,&nbsp;current recommender systems model the recommendation, explanation, and critiquing objectives jointly, but this creates an inherent trade-off between their respective performance. On the other hand, although recent latent linear critiquing approaches are built&nbsp;upon an existing recommender system, they suffer from computational inefficiency at inference due to the objective optimized at each&nbsp;conversation’s turn. We address these deficiencies with M&amp;Ms-VAE, a novel variational autoencoder for recommendation and explanation that is based on multimodal modeling assumptions. We train the model under a weak supervision scheme to simulate both&nbsp;fully&nbsp;and partially observed variables. Then, we leverage the generalization ability of a trained M&amp;Ms-VAE model to embed the user preference and the critique separately. Our work’s most important innovation is our critiquing module, which is built upon and trained in&nbsp;a&nbsp;self-supervised manner with a simple ranking objective. Experiments on four real-world datasets demonstrate that among state-of-the-art models, our system is the first to dominate or match the performance in terms of recommendation, explanation, and multi-step critiquing. Moreover, M&amp;Ms-VAE processes the critiques up to 25.6x faster than the best baselines. Finally, we show that our model&nbsp;infers coherent joint and cross generation, even under weak supervision, thanks to our multimodal-based modeling and training&nbsp;scheme.",10.1145/3460231.3474249,https://doi.org/10.1145/3460231.3474249,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Fast Multi-Step Critiquing for VAE-based Recommender&nbsp;Systems,"Antognini, Diego and Faltings, Boi",inproceedings,10.1145/3460231.3474249,
10.1145/3460231.3474250,10.1145/3460231.3474250,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","Audience dynamics, Bursty methods, Multi-Armed bandit, Time series",10,292–301,Proceedings of the 15th ACM Conference on Recommender Systems,"In this paper, we introduce a non-stationary and context-free Multi-Armed Bandit (MAB) problem and a novel algorithm (which we refer to as BMAB) to solve it. The problem is context-free in the sense that no side information about users or items is needed. We work in a continuous-time setting where each timestamp corresponds to a visit by a user and a corresponding decision regarding recommendation. The main novelty is that we model the reward distribution as a consequence of variations in the intensity of the activity, and thereby we assist the exploration/exploitation dilemma by exploring the temporal dynamics of the audience. To achieve this, we assume that the recommendation procedure can be split into two different states: the loyal and the curious state. We identify the current state by modelling the events as a mixture of two Poisson processes, one for each of the possible states. We further assume that the loyal audience is associated with a single stationary reward distribution, but each bursty period comes with its own reward distribution. We test our algorithm and compare it to several baselines in two strands of experiments: synthetic data simulations and real-world datasets. The results demonstrate that BMAB achieves competitive results when compared to state-of-the-art methods.",10.1145/3460231.3474250,https://doi.org/10.1145/3460231.3474250,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Burst-induced Multi-Armed Bandit for Learning Recommendation,"Alves, Rodrigo and Ledent, Antoine and Kloft, Marius",inproceedings,10.1145/3460231.3474250,
10.1145/3460231.3474263,10.1145/3460231.3474263,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","Recommender systems, Information bottleneck, Confounding bias, Causal diagrams",10,351–360,Proceedings of the 15th ACM Conference on Recommender Systems,"How to effectively mitigate the bias of feedback in recommender systems is an important research topic. In this paper, we first describe the generation process of the biased and unbiased feedback in recommender systems via two respective causal diagrams, where the difference between them can be regarded as the source of bias. We then define this difference as a confounding bias, which can be regarded as a collection of some specific biases that have previously been studied. For the case with biased feedback alone, we derive the conditions that need to be satisfied to obtain a debiased representation from the causal diagrams. Based on information theory, we propose a novel method called debiased information bottleneck (DIB) to optimize these conditions and then find a tractable solution for it. In particular, the proposed method constrains the model to learn a biased embedding vector with independent biased and unbiased components in the training phase, and uses only the unbiased component in the test phase to deliver more accurate recommendations. Finally, we conduct extensive experiments on a public dataset and a real product dataset to verify the effectiveness of the proposed method and discuss its properties.",10.1145/3460231.3474263,https://doi.org/10.1145/3460231.3474263,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Mitigating Confounding Bias in Recommendation via Information Bottleneck,"Liu, Dugang and Cheng, Pengxiang and Zhu, Hong and Dong, Zhenhua and He, Xiuqiang and Pan, Weike and Ming, Zhong",inproceedings,10.1145/3460231.3474263,
10.1145/3460231.3474266,10.1145/3460231.3474266,RecSys.bib,1,['RecSys.bib'],7,RecSys '21,"Amsterdam, Netherlands",,8,55–62,Proceedings of the 15th ACM Conference on Recommender Systems,"Matrix factorization-based methods are among the most popular methods for collaborative filtering tasks with implicit feedback. The most effective of these methods do not apply sign constraints, such as non-negativity, to their factors. Despite their simplicity, the latent factors for users and items lack interpretability, which is becoming an increasingly important requirement. In this work, we provide a theoretical link between unconstrained and the interpretable non-negative matrix factorization in terms of the personalized ranking induced by these methods. We also introduce a novel, latent Dirichlet allocation-inspired model for recommenders and extend our theoretical link to also allow the interpretation of an unconstrained matrix factorization as an adjoint formulation of our new model. Our experiments indicate that this novel approach represents the unknown processes of implicit user-item interactions in the real world much better than unconstrained matrix factorization while being interpretable.",10.1145/3460231.3474266,https://doi.org/10.1145/3460231.3474266,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Matrix Factorization for Collaborative Filtering Is Just Solving an Adjoint Latent Dirichlet Allocation Model After All,"Wilhelm, Florian",inproceedings,10.1145/3460231.3474266,
10.1145/3460231.3474267,10.1145/3460231.3474267,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","datasets, live-streaming, ranking methods, recommender systems, repeat consumption",10,390–399,Proceedings of the 15th ACM Conference on Recommender Systems,"Live-streaming platforms broadcast user-generated video in real-time. Recommendation on these platforms shares similarities with traditional settings, such as a large volume of heterogeneous content and highly skewed interaction distributions. However, several challenges must be overcome to adapt recommendation algorithms to live-streaming platforms: first, content availability is dynamic which restricts users to choose from only a subset of items at any given time; during training and inference we must carefully handle this factor in order to properly account for such signals, where ‘non-interactions’ reflect availability as much as implicit preference. Streamers are also fundamentally different from ‘items’ in traditional settings: repeat consumption of specific channels plays a significant role, though the content itself is fundamentally ephemeral. In this work, we study recommendation in this setting of a dynamically evolving set of available items. We propose LiveRec, a self-attentive model that personalizes item ranking based on both historical interactions and current availability. We also show that carefully modelling repeat consumption plays a significant role in model performance. To validate our approach, and to inspire further research on this setting, we release a dataset containing 475M user interactions on Twitch over a 43-day period. We evaluate our approach on a recommendation task and show our method to outperform various strong baselines in ranking the currently available content.",10.1145/3460231.3474267,https://doi.org/10.1145/3460231.3474267,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Recommendation on Live-Streaming Platforms: Dynamic Availability and Repeat Consumption,"Rappaz, J\'{e}r\'{e}mie and McAuley, Julian and Aberer, Karl",inproceedings,10.1145/3460231.3474267,
10.1145/3460231.3474268,10.1145/3460231.3474268,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","Collaborative Filtering, Few-shot learning., Meta Learning, Recommendation System",10,166–175,Proceedings of the 15th ACM Conference on Recommender Systems,"In recent times, deep learning methods have supplanted conventional collaborative filtering approaches as the backbone of modern recommender systems. However, their gains are skewed towards popular items with a drastic performance drop for the vast collection of long-tail items with sparse interactions. Moreover, we empirically show that prior neural recommenders lack the resolution power to accurately rank relevant items within the long-tail. In this paper, we formulate long-tail item recommendations as a few-shot learning problem of learning-to-recommend few-shot items with very few interactions. We propose a novel meta-learning framework&nbsp;ProtoCF&nbsp;that learns-to-compose robust prototype representations for few-shot items. ProtoCF utilizes episodic few-shot learning to extract meta-knowledge across a collection of diverse meta-training tasks designed to mimic item ranking within the tail. To further enhance discriminative power, we propose a novel architecture-agnostic technique based on knowledge distillation to extract, relate, and transfer knowledge from neural base recommenders. Our experimental results demonstrate that&nbsp;ProtoCF&nbsp;consistently outperforms state-of-art approaches on overall recommendation (by 5% Recall@50) while achieving significant gains (of 60-80% Recall@50) for tail items with less than 20 interactions.",10.1145/3460231.3474268,https://doi.org/10.1145/3460231.3474268,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,ProtoCF: Prototypical Collaborative Filtering for Few-shot Recommendation,"Sankar, Aravind and Wang, Junting and Krishnan, Adit and Sundaram, Hari",inproceedings,10.1145/3460231.3474268,
10.1145/3460231.3474269,10.1145/3460231.3474269,RecSys.bib,1,['RecSys.bib'],7,RecSys '21,"Amsterdam, Netherlands",,10,380–389,Proceedings of the 15th ACM Conference on Recommender Systems,"The role of recommendation systems in the diversity of content consumption on platforms is a much-debated issue. The quantitative state of the art often overlooks the existence of individual attitudes toward guidance, and eventually of different categories of users in this regard. Focusing on the case of music streaming, we analyze the complete listening history of about 9k users over one year and demonstrate that there is no blanket answer to the intertwinement of recommendation use and consumption diversity: it depends on users. First we compute for each user the relative importance of different access modes within their listening history, introducing a trichotomy distinguishing so-called ‘organic’ use from algorithmic and editorial guidance. We thereby identify four categories of users. We then focus on two scales related to content diversity, both in terms of dispersion – how much users consume the same content repeatedly – and popularity – how popular is the content they consume. We show that the two types of recommendation offered by music platforms – algorithmic and editorial – may drive the consumption of more or less diverse content in opposite directions, depending also strongly on the type of users. Finally, we compare users’ streaming histories with the music programming of a selection of popular French radio stations during the same period. While radio programs are usually more tilted toward repetition than users’ listening histories, they often program more songs from less popular artists. On the whole, our results highlight the nontrivial effects of platform-mediated recommendation on consumption, and lead us to speak of ‘filter niches’ rather than ‘filter bubbles’. They hint at further ramifications for the study and design of recommendation systems.",10.1145/3460231.3474269,https://doi.org/10.1145/3460231.3474269,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Follow the guides: disentangling human and algorithmic curation in online music consumption,"Villermet, Quentin and Poiroux, J\'{e}r\'{e}mie and Moussallam, Manuel and Louail, Thomas and Roth, Camille",inproceedings,10.1145/3460231.3474269,
10.1145/3460231.3474274,10.1145/3460231.3474274,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","Debiased Machine Learning, Explainability, Exposure Bias, Fairness in AI, Pairwise Ranking",11,321–331,Proceedings of the 15th ACM Conference on Recommender Systems,"Recent work in recommender systems has emphasized the importance of fairness, with a particular interest in bias and transparency, in addition to predictive accuracy. In this paper, we focus on the state of the art pairwise ranking model, Bayesian Personalized Ranking (BPR), which has previously been found to outperform pointwise models in predictive accuracy, while also being able to handle implicit feedback. Specifically, we address two limitations of BPR: (1) BPR is a black box model that does not explain its outputs, thus limiting the user’s trust in the recommendations, and the analyst’s ability to scrutinize a model’s outputs; and (2) BPR is vulnerable to exposure bias due to the data being Missing Not At Random (MNAR). This exposure bias usually translates into an unfairness against the least popular items because they risk being under-exposed by the recommender system. In this work, we first propose a novel explainable loss function and a corresponding Matrix Factorization-based model called Explainable Bayesian Personalized Ranking (EBPR) that generates recommendations along with item-based explanations. Then, we theoretically quantify additional exposure bias resulting from the explainability, and use it as a basis to propose an unbiased estimator for the ideal EBPR loss. The result is a ranking model that aptly captures both debiased and explainable user preferences. Finally, we perform an empirical study on three real-world datasets that demonstrate the advantages of our proposed models.",10.1145/3460231.3474274,https://doi.org/10.1145/3460231.3474274,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Debiased Explainable Pairwise Ranking from Implicit Feedback,"Damak, Khalil and Khenissi, Sami and Nasraoui, Olfa",inproceedings,10.1145/3460231.3474274,
10.1145/3460231.3475943,10.1145/3460231.3475943,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","Evaluation, Metrics, Sampled Metrics, Sequential Item Recommendation",10,505–514,Proceedings of the 15th ACM Conference on Recommender Systems,"At the present time, sequential item recommendation models are compared by calculating metrics on a small item subset (target set) to speed up computation. The target set contains the relevant item and a set of negative items that are sampled from the full item set. Two well-known strategies to sample negative items are uniform random sampling and sampling by popularity to better approximate the item frequency distribution in the dataset. Most recently published papers on sequential item recommendation rely on sampling by popularity to compare the evaluated models. However, recent work has already shown that an evaluation with uniform random sampling may not be consistent with the full ranking, that is, the model ranking obtained by evaluating a metric using the full item set as target set, which raises the question whether the ranking obtained by sampling by popularity is equal to the full ranking. In this work, we re-evaluate current state-of-the-art sequential recommender models from the point of view, whether these sampling strategies have an impact on the final ranking of the models. We therefore train four recently proposed sequential recommendation models on five widely known datasets. For each dataset and model, we employ three evaluation strategies. First, we compute the full model ranking. Then we evaluate all models on a target set sampled by the two different sampling strategies, uniform random sampling and sampling by popularity with the commonly used target set size of 100, compute the model ranking for each strategy and compare them with each other. Additionally, we vary the size of the sampled target set. Overall, we find that both sampling strategies can produce inconsistent rankings compared with the full ranking of the models. Furthermore, both sampling by popularity and uniform random sampling do not consistently produce the same ranking when compared over different sample sizes. Our results suggest that like uniform random sampling, rankings obtained by sampling by popularity do not equal the full ranking of recommender models and therefore both should be avoided in favor of the full ranking when establishing state-of-the-art.",10.1145/3460231.3475943,https://doi.org/10.1145/3460231.3475943,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,A Case Study on Sampling Strategies for Evaluating Neural Sequential Item Recommendation Models,"Dallmann, Alexander and Zoller, Daniel and Hotho, Andreas",inproceedings,10.1145/3460231.3475943,
10.1145/3460231.3478515,10.1145/3460231.3478515,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","BERT, Embeddings, Fairness, Online Social Networks, Recommender Systems",6,819–824,Proceedings of the 15th ACM Conference on Recommender Systems,"The workshop features presentations of accepted contributions to the RecSys Challenge 2021, organized by Politecnico di Bari, ETH Z\""{u}rich, J\""{o}nk\""{o}ping University, and the data set is provided by Twitter. The challenge focuses on a real-world task of tweet engagement prediction in a dynamic environment. For 2021, the challenge considers four different engagement types: Likes, Retweet, Quote, and replies. This year’s challenge brings the problem even closer to Twitter’s real recommender systems by introducing latency constraints. We also increases the data size to encourage novel methods. Also, the data density is increased in terms of the graph where users are considered to be nodes and interactions as edges. The goal is twofold: to predict the probability of different engagement types of a target user for a set of Tweets based on heterogeneous input data while providing fair recommendations. In fact, multi-goal optimization considering accuracy and fairness is particularly challenging. However, we believed that the recommendation community was nowadays mature enough to face the challenge of providing accurate and, at the same time, fair recommendations. To this end, Twitter has released a public dataset of close to 1 billion data points, &gt; 40 million each day over 28 days. Week 1 − 3 will be used for training and week 4 for evaluation and testing. Each datapoint contains the tweet along with engagement features, user features, and tweet features. A peculiarity of this challenge is related to keeping the dataset updated with the platform: if a user deletes a Tweet, or their data from Twitter, the dataset is promptly updated. Moreover, each change in the dataset implied new evaluations of all submissions and the update of the leaderboard metrics. The challenge was well received with 578 registered users, and 386 submissions.",10.1145/3460231.3478515,https://doi.org/10.1145/3460231.3478515,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,RecSys 2021 Challenge Workshop: Fairness-aware engagement prediction at scale on Twitter’s Home Timeline,"Anelli, Vito Walter and Kalloori, Saikishore and Ferwerda, Bruce and Belli, Luca and Tejani, Alykhan and Portman, Frank and Lung-Yut-Fong, Alexandre and Chamberlain, Ben and Xie, Yuanpu and Hunt, Jonathan and Bronstein, Michael and Shi, Wenzhe",inproceedings,10.1145/3460231.3478515,
10.1145/3460231.3478843,10.1145/3460231.3478843,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","fairness, gender, music recommendation, popularity bias",6,601–606,Proceedings of the 15th ACM Conference on Recommender Systems,"Several studies have identified discrepancies between the popularity of items in user profiles and the corresponding recommendation lists. Such behavior, which concerns a variety of recommendation algorithms, is referred to as popularity bias. Existing work predominantly adopts simple statistical measures, such as the difference of mean or median popularity, to quantify popularity bias. Moreover, it does so irrespective of user characteristics other than the inclination to popular content. In this work, in contrast, we propose to investigate popularity differences (between the user profile and recommendation list) in terms of median, a variety of statistical moments, as well as similarity measures that consider the entire popularity distributions (Kullback-Leibler divergence and Kendall’s τ rank-order correlation). This results in a more detailed picture of the characteristics of popularity bias. Furthermore, we investigate whether such algorithmic popularity bias affects users of different genders in the same way. We focus on music recommendation and conduct experiments on the recently released standardized LFM-2b dataset, containing listening profiles of Last.fm users. We investigate the algorithmic popularity bias of seven common recommendation algorithms (five collaborative filtering and two baselines). Our experiments show that (1) the studied metrics provide novel insights into popularity bias in comparison with only using average differences, (2) algorithms less inclined towards popularity bias amplification do not necessarily perform worse in terms of utility (NDCG), (3) the majority of the investigated recommenders intensify the popularity bias of the female users.",10.1145/3460231.3478843,https://doi.org/10.1145/3460231.3478843,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,Analyzing Item Popularity Bias of Music Recommender Systems: Are Different Genders Equally Affected?,"Lesota, Oleg and Melchiorre, Alessandro and Rekabsaz, Navid and Brandl, Stefan and Kowald, Dominik and Lex, Elisabeth and Schedl, Markus",inproceedings,10.1145/3460231.3478843,
10.1145/3460231.3478855,10.1145/3460231.3478855,RecSys.bib,1,['RecSys.bib'],8,RecSys '21,"Amsterdam, Netherlands","Federated recommendation, Item ranking, Rating prediction, Secret sharing, Sequential recommendation",6,668–673,Proceedings of the 15th ACM Conference on Recommender Systems,"With the implementation of privacy protection laws such as GDPR, it is increasingly difficult for organizations to legally collect user data. However, a typical recommendation algorithm based on machine learning requires user data to learn user preferences. In order to protect user privacy, a lot of recent works turn to develop federated learning-based recommendation algorithms. However, some of these works can only protect the users’ rating values, some can only protect the users’ rating behavior (i.e., the engaged items), and only a few works can protect the both types of privacy at the same time. Moreover, most of them can only be applied to a specific algorithm or a class of similar algorithms. In this paper, we propose a generic cross-user federated recommendation framework called FR-FMSS. Our FR-FMSS can not only protect the two types of user privacy, but can also be applied to most recommendation algorithms for rating prediction, item ranking, and sequential recommendation. Specifically, we use fake marks and secret sharing to modify the data uploaded by the clients to the server, which protects user privacy without loss of model accuracy. We take three representative recommendation algorithms, i.e., MF-MPC, eALS, and Fossil, as examples to show how to apply our FR-FMSS to a specific algorithm.",10.1145/3460231.3478855,https://doi.org/10.1145/3460231.3478855,"New York, NY, USA",Association for Computing Machinery,9781450384582,2021,FR-FMSS: Federated Recommendation via Fake Marks and Secret Sharing,"Lin, Zhaohao and Pan, Weike and Ming, Zhong",inproceedings,10.1145/3460231.3478855,
10.1145/3485447.3511934,10.1145/3485447.3511934,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Attention model, Graph neural networks, Knowledge graph, Video popularity prediction",9,2879–2887,Proceedings of the ACM Web Conference 2022,"Predicting the popularity of online videos has many real-world applications, such as recommendation, precise advertising, and edge caching strategies. Despite many efforts have been dedicated to the online video popularity prediction, there still exist several challenges: (1) The meta-data from online videos is usually sparse and noisy, which makes it difficult to learn a stable and robust representation. (2) The influence of content features and temporal features in different life cycles of online videos is dynamically changing, so it is necessary to build a model that can capture the dynamics. (3) Besides, there is a great need to interpret the predictive behavior of the model to assist administrators of video platforms in the subsequent decision-making. In this paper, we propose a Knowledge-based Temporal Fusion Network (KTFN) that incorporates knowledge graph representation to address the aforementioned challenges in the task of online video popularity prediction. To be more specific, we design a Tree Attention Network (TAN) to learn the embedding of online video entities in knowledge graphs via selectively aggregating local neighborhood information, thus enabling our model to learn the importance of different entities under the same relation. Besides, an Attention-based Long Short-Term Memory (ALSTM) is utilized to learn the temporal feature representation. Finally, we propose an Adaptively Temporal Feature Fusion (ATFF) scheme to adaptively fuse content features and temporal features, in which a learnable exponential decay function with the global attention mechanism is constructed. We collect two large-scale real-world datasets from the server logs of two popular Chinese online video platforms, and experimental results on the two datasets have demonstrated the superiority and interpretability of KTFN.",10.1145/3485447.3511934,https://doi.org/10.1145/3485447.3511934,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Knowledge-based Temporal Fusion Network for Interpretable Online Video Popularity Prediction,"Tang, Shisong and Li, Qing and Ma, Xiaoteng and Gao, Ci and Wang, Dingmin and Jiang, Yong and Ma, Qian and Zhang, Aoyang and Chen, Hechang",inproceedings,10.1145/3485447.3511934,
10.1145/3485447.3511956,10.1145/3485447.3511956,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Collaborative filtering, Negative sampler, Recommendation system",9,277–285,Proceedings of the ACM Web Conference 2022,"Selecting reliable negative training instances is the challenging task in the implicit feedback-based recommendation, which is optimized by pairwise learning on user feedback data. The existing methods usually exploit various negative samplers (i.e., heuristic-based or GAN-based sampling) on user feedback data to improve the quality of negative samples. However, these methods usually focused on maintaining the hard negative samples with a high gradient for training, causing the false negative samples to be selected preferentially. The limitation of the false negative noise amplification may lead to overfitting and further poor generalization of the model. To address this issue, we propose a Gain-Tuning Dynamic Negative Sampling GDNS to make the recommendation more robust and effective. Our proposed model designs an expectational gain sampler, concerning the expectation of user’ preference gap between the positive and negative samples in training, to guide the negative selection dynamically. This gain-tuning negative sampler can effectively identify the false negative samples and further diminish the risk of introducing false negative instances. Moreover, for improving the training efficiency, we construct positive and negative groups for each user in each iteration, and develop a group-wise optimizer to optimize them in a cross manner. Experiments on two real-world datasets show our approach significantly outperforms state-of-the-art negative sampling baselines.",10.1145/3485447.3511956,https://doi.org/10.1145/3485447.3511956,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,A Gain-Tuning Dynamic Negative Sampler for Recommendation,"Zhu, Qiannan and Zhang, Haobo and He, Qing and Dou, Zhicheng",inproceedings,10.1145/3485447.3511956,
10.1145/3485447.3511963,10.1145/3485447.3511963,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Cold-start problem, Meta learning, Recommender systems, Transfer learning",12,348–359,Proceedings of the ACM Web Conference 2022,"User cold-start recommendation is a serious problem that limits the performance of recommender systems (RSs). Recent studies have focused on treating this issue as a few-shot problem and seeking solutions with model-agnostic meta-learning (MAML). Such methods regard making recommendations for one user as a task and adapt to new users with a few steps of gradient updates on the meta-model. However, none of those methods consider the limitation of user representation learning imposed by the special task setting of MAML-based RSs. And they learn a common meta-model for all users while ignoring the implicit grouping distribution induced by the correlation differences among users. In response to the above problems, we propose a pretrained network modulation and task adaptation approach (PNMTA) for user cold-start recommendation. In the pretraining stage, a pretrained model is obtained with non-meta-learning methods to achieve better user representation and generalization, which can also transfer the learned knowledge to the meta-learning stage for modulation. During the meta-learning stage, an encoder modulator is utilized to realize the memorization and correction of prior parameters for the meta-learning task, and a predictor modulator is introduced to condition the model initialization on the task identity for adaptation steps. In addition, PNMTA can also make use of the existing non-cold-start users for pretraining. Comprehensive experiments on two benchmark datasets demonstrate that our model can achieve significant and consistent improvements against other state-of-the-art methods.",10.1145/3485447.3511963,https://doi.org/10.1145/3485447.3511963,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,PNMTA: A Pretrained Network Modulation and Task Adaptation Approach for User Cold-Start Recommendation,"Pang, Haoyu and Giunchiglia, Fausto and Li, Ximing and Guan, Renchu and Feng, Xiaoyue",inproceedings,10.1145/3485447.3511963,
10.1145/3485447.3512010,10.1145/3485447.3512010,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Popularity Bias, Recommendation, Unbiased Learning-to-Rank",9,2370–2378,Proceedings of the ACM Web Conference 2022,"Most recommender systems optimize the model on observed interaction data, which is affected by the previous exposure mechanism and exhibits many biases like popularity bias. The loss functions, such as the mostly used pointwise Binary Cross-Entropy and pairwise Bayesian Personalized Ranking, are not designed to consider the biases in observed data. As a result, the model optimized on the loss would inherit the data biases, or even worse, amplify the biases. For example, a few popular items take up more and more exposure opportunities, severely hurting the recommendation quality on niche items — known as the notorious Mathew effect. In this work, we develop a new learning paradigm named Cross Pairwise Ranking (CPR) that achieves unbiased recommendation without knowing the exposure mechanism. Distinct from inverse propensity scoring (IPS), we change the loss term of a sample — we innovatively sample multiple observed interactions once and form the loss as the combination of their predictions. We prove in theory that this way offsets the influence of user/item propensity on the learning, removing the influence of data biases caused by the exposure mechanism. Advantageous to IPS, our proposed CPR ensures unbiased learning for each training instance without the need of setting the propensity scores. Experimental results demonstrate the superiority of CPR over state-of-the-art debiasing solutions in both model generalization and training efficiency. The codes are available at https://github.com/Qcactus/CPR.",10.1145/3485447.3512010,https://doi.org/10.1145/3485447.3512010,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Cross Pairwise Ranking for Unbiased Item Recommendation,"Wan, Qi and He, Xiangnan and Wang, Xiang and Wu, Jiancan and Guo, Wei and Tang, Ruiming",inproceedings,10.1145/3485447.3512010,
10.1145/3485447.3512021,10.1145/3485447.3512021,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Pareto frontier, auxiliary tasks, multi-task learning, neural networks",11,3009–3019,Proceedings of the ACM Web Conference 2022,"Multi-task learning aims to solve multiple machine learning tasks at the same time, with good solutions being both generalizable and Pareto optimal. A multi-task deep learning model consists of a shared representation learned to capture task commonalities, and task-specific sub-networks capturing the specificities of each task. In this work, we offer insights on the under-explored trade-off between minimizing task training conflicts in multi-task learning and improving multi-task generalization, i.e. the generalization capability of the shared presentation across all tasks. The trade-off can be viewed as the tension between multi-objective optimization and shared representation learning: As a multi-objective optimization problem, sufficient parameterization is needed for mitigating task conflicts in a constrained solution space; However, from a representation learning perspective, over-parameterizing the task-specific sub-networks may give the model too many ”degrees of freedom” and impedes the generalizability of the shared representation. Specifically, we first present insights on understanding the parameterization effect of multi-task deep learning models and empirically show that larger models are not necessarily better in terms of multi-task generalization. A delicate balance between mitigating task training conflicts vs. improving generalizability of the shared presentation learning is needed to achieve optimal performance across multiple tasks. Motivated by our findings, we then propose the use of a under-parameterized self-auxiliary head alongside each task-specific sub-network during training, which automatically balances the aforementioned trade-off. As the auxiliary heads are small in size and are discarded during inference time, the proposed method incurs minimal training cost and no additional serving cost. We conduct experiments with the proposed self-auxiliaries on two public datasets and live experiments on one of the largest industrial recommendation platforms serving billions of users. The results demonstrate the effectiveness of the proposed method in improving the predictive performance across multiple tasks in multi-task models.",10.1145/3485447.3512021,https://doi.org/10.1145/3485447.3512021,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Can Small Heads Help? Understanding and Improving Multi-Task Generalization,"Wang, Yuyan and Zhao, Zhe and Dai, Bo and Fifty, Christopher and Lin, Dong and Hong, Lichan and Wei, Li and Chi, Ed H.",inproceedings,10.1145/3485447.3512021,
10.1145/3485447.3512024,10.1145/3485447.3512024,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Fine-to-coarse reasoning, Natural language processing, Product rating, Sentiment analysis, Text mining",10,3042–3051,Proceedings of the ACM Web Conference 2022,"Joint aspect category sentiment analysis (ACSA) and rating prediction (RP) is a newly proposed task (namely ASAP) that integrates the characteristics of both fine-grained and coarse-grained sentiment analysis. However, the prior joint models for the ASAP task only consider the shallow interaction between the two granularities. In this work, we gain the inspiration from human intuition, presenting an innovative from-fine-to-coarse reasoning framework for better joint task performance. Our system advances mainly in three aspects. First, we additionally make use of the category label text features, co-encoding them with the input document texts, allowing to accurately capture the key clues of each category. Second, we build a fine-to-coarse hierarchical label graph, modeling the aspect categories and the overall rating as a hierarchical structure for full interaction of the two granularities. Third, we propose to perform global iterative reasoning with a cross-collaboration between the hierarchical label graph and the context graphs, enabling sufficient communication between categories and review contexts. Based on the ASAP dataset, experimental results demonstrate that our proposed framework outperforms state-of-the-art baselines by large margins. Further in-depth analyses prove that our method is effective on addressing both the unbalanced data distribution and the long-text issue.",10.1145/3485447.3512024,https://doi.org/10.1145/3485447.3512024,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Making Decision like Human: Joint Aspect Category Sentiment Analysis and Rating Prediction with Fine-to-Coarse Reasoning,"Fei, Hao and Li, Jingye and Ren, Yafeng and Zhang, Meishan and Ji, Donghong",inproceedings,10.1145/3485447.3512024,
10.1145/3485447.3512029,10.1145/3485447.3512029,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","explainability, rationalization, recommendation",10,3092–3101,Proceedings of the ACM Web Conference 2022,"Auxiliary information, such as reviews, have been widely adopted to improve collaborative filtering (CF) algorithms, e.g., to boost the accuracy and provide explanations. However, most of the existing methods cannot distinguish between co-appearance and causality when learning from the reviews, so that they may rely on spurious correlations rather than causal relations in the recommendation — leading to poor generalization performance and unconvincing explanations. In this paper, we propose a Recommendation via Review Rationalization (R3) method including 1) a rationale generator to extract rationales from reviews to alleviate the effects of spurious correlations; 2) a rationale predictor to predict user ratings on items only from generated rationales; and 3) a correlation predictor upon both rationales and correlational features to ensure conditional independence between spurious correlations and rating predictions given causal rationales. Extensive experiments on real-world datasets show that the proposed method can achieve better generalization performance than state-of-the-art CF methods and provide causal-aware explanations even when the test data distribution changes.",10.1145/3485447.3512029,https://doi.org/10.1145/3485447.3512029,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Accurate and Explainable Recommendation via Review Rationalization,"Pan, Sicheng and Li, Dongsheng and Gu, Hansu and Lu, Tun and Luo, Xufang and Gu, Ning",inproceedings,10.1145/3485447.3512029,
10.1145/3485447.3512031,10.1145/3485447.3512031,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","comparative explanation, explainable recommendation, extract-and-refine, text generation",11,3113–3123,Proceedings of the ACM Web Conference 2022,"As recommendation is essentially a comparative (or ranking) process, a good explanation should illustrate to users why an item is believed to be better than another, i.e., comparative explanations about the recommended items. Ideally, after reading the explanations, a user should reach the same ranking of items as the system’s. Unfortunately, little research attention has yet been paid on such comparative explanations. In this work, we develop an extract-and-refine architecture to explain the relative comparisons among a set of ranked items from a recommender system. For each recommended item, we first extract one sentence from its associated reviews that best suits the desired comparison against a set of reference items. Then this extracted sentence is further articulated with respect to the target user through a generative model to better explain why the item is recommended. We design a new explanation quality metric based on BLEU to guide the end-to-end training of the extraction and refinement components, which avoids generation of generic content. Extensive offline evaluations on two large recommendation benchmark datasets and serious user studies against an array of state-of-the-art explainable recommendation algorithms demonstrate the necessity of comparative explanations and the effectiveness of our solution.",10.1145/3485447.3512031,https://doi.org/10.1145/3485447.3512031,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Comparative Explanations of Recommendations,"Yang, Aobo and Wang, Nan and Cai, Renqin and Deng, Hongbo and Wang, Hongning",inproceedings,10.1145/3485447.3512031,
10.1145/3485447.3512077,10.1145/3485447.3512077,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Self-Attention, Sequential Recommendation, Transformer, Uncertainty",12,2036–2047,Proceedings of the ACM Web Conference 2022,"Sequential recommendation models the dynamics of a user’s previous behaviors in order to forecast the next item, and has drawn a lot of attention. Transformer-based approaches, which embed items as vectors and use dot-product self-attention to measure the relationship between items, demonstrate superior capabilities among existing sequential methods. However, users’ real-world sequential behaviors are uncertain rather than deterministic, posing a significant challenge to present techniques. We further suggest that dot-product-based approaches cannot fully capture collaborative transitivity, which can be derived in item-item transitions inside sequences and is beneficial for cold start items. We further argue that BPR loss has no constraint on positive and sampled negative items, which misleads the optimization. We propose a novel STOchastic Self-Attention&nbsp;(STOSA) to overcome these issues. STOSA, in particular, embeds each item as a stochastic Gaussian distribution, the covariance of which encodes the uncertainty. We devise a novel Wasserstein Self-Attention module to characterize item-item position-wise relationships in sequences, which effectively incorporates uncertainty into model training. Wasserstein attentions also enlighten the collaborative transitivity learning as it satisfies triangle inequality. Moreover, we introduce a novel regularization term to the ranking loss, which assures the dissimilarity between positive and the negative items. Extensive experiments on five real-world benchmark datasets demonstrate the superiority of the proposed model over state-of-the-art baselines, especially on cold start items. The code is available in https://github.com/zfan20/STOSA.",10.1145/3485447.3512077,https://doi.org/10.1145/3485447.3512077,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Sequential Recommendation via Stochastic Self-Attention,"Fan, Ziwei and Liu, Zhiwei and Wang, Yu and Wang, Alice and Nazari, Zahra and Zheng, Lei and Peng, Hao and Yu, Philip S.",inproceedings,10.1145/3485447.3512077,
10.1145/3485447.3512078,10.1145/3485447.3512078,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","recommendation system, self-supervised learning, unbiased recommendation",10,2048–2057,Proceedings of the ACM Web Conference 2022,"Real-world recommendation datasets have been shown to be subject to selection bias, which can challenge recommendation models to learn real preferences of users, so as to make accurate recommendations. Existing approaches to mitigate selection bias, such as data imputation and inverse propensity score, are sensitive to the quality of the additional imputation or propensity estimation models. To break these limitations, in this work, we propose a novel self-supervised learning (SSL) framework, i.e., Rating Distribution Calibration (RDC), to tackle selection bias without introducing additional models. In addition to the original training objective, we introduce a rating distribution calibration loss. It aims to correct the predicted rating distribution of biased users by taking advantage of that of their similar unbiased users. We empirically evaluate RDC on two real-world datasets and one synthetic dataset. The experimental results show that RDC outperforms the original model as well as the state-of-the-art debiasing approaches by a significant margin.",10.1145/3485447.3512078,https://doi.org/10.1145/3485447.3512078,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Rating Distribution Calibration for Selection Bias Mitigation in Recommendations,"Liu, Haochen and Tang, Da and Yang, Ji and Zhao, Xiangyu and Liu, Hui and Tang, Jiliang and Cheng, Youlong",inproceedings,10.1145/3485447.3512078,
10.1145/3485447.3512093,10.1145/3485447.3512093,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Auxiliary Learning, Gradient-based Optimization, Multi-Task Learning, Personalized Recommendation",11,2205–2215,Proceedings of the ACM Web Conference 2022,"In many personalized recommendation scenarios, the generalization ability of a target task can be improved via learning with additional auxiliary tasks alongside this target task on a multi-task network. However, this method often suffers from a serious optimization imbalance problem. On the one hand, one or more auxiliary tasks might have a larger influence than the target task and even dominate the network weights, resulting in worse recommendation accuracy for the target task. On the other hand, the influence of one or more auxiliary tasks might be too weak to assist the target task. More challenging is that this imbalance dynamically changes throughout the training process and varies across the parts of the same network. We propose a new method: MetaBalance to balance auxiliary losses via directly manipulating their gradients w.r.t the shared parameters in the multi-task network. Specifically, in each training iteration and adaptively for each part of the network, the gradient of an auxiliary loss is carefully reduced or enlarged to have a closer magnitude to the gradient of the target loss, preventing auxiliary tasks from being so strong that dominate the target task or too weak to help the target task. Moreover, the proximity between the gradient magnitudes can be flexibly adjusted to adapt MetaBalance to different scenarios. The experiments show that our proposed method achieves a significant improvement of 8.34% in terms of NDCG@10 upon the strongest baseline on two real-world datasets. The code of our approach can be found at here.1",10.1145/3485447.3512093,https://doi.org/10.1145/3485447.3512093,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,MetaBalance: Improving Multi-Task Recommendations via Adapting Gradient Magnitudes of Auxiliary Tasks,"He, Yun and Feng, Xue and Cheng, Cheng and Ji, Geng and Guo, Yunsong and Caverlee, James",inproceedings,10.1145/3485447.3512093,
10.1145/3485447.3512105,10.1145/3485447.3512105,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","contrastive learning, educational data mining, intelligent tutoring system, knowledge tracing, personalized learning",9,2330–2338,Proceedings of the ACM Web Conference 2022,"Knowledge tracing is the task of understanding student’s knowledge acquisition processes by estimating whether to solve the next question correctly or not. Most deep learning-based methods tackle this problem by identifying hidden representations of knowledge states from learning histories. However, due to the sparse interactions between students and questions, the hidden representations can be easily over-fitted and often fail to capture student’s knowledge states accurately. This paper introduces a contrastive learning framework for knowledge tracing that reveals semantically similar or dissimilar examples of a learning history and stimulates to learn their relationships. To deal with the complexity of knowledge acquisition during learning, we carefully design the components of contrastive learning, such as architectures, data augmentation methods, and hard negatives, taking into account pedagogical rationales. Our extensive experiments on six benchmarks show statistically significant improvements from the previous methods. Further analysis shows how our methods contribute to improving knowledge tracing performances.",10.1145/3485447.3512105,https://doi.org/10.1145/3485447.3512105,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Contrastive Learning for Knowledge Tracing,"Lee, Wonsung and Chun, Jaeyoon and Lee, Youngmin and Park, Kyoungsoo and Park, Sungrae",inproceedings,10.1145/3485447.3512105,
10.1145/3485447.3512166,10.1145/3485447.3512166,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Domain Adaptation, Recommendation, Transfer Learning",10,1181–1190,Proceedings of the ACM Web Conference 2022,"Cross-Domain Recommendation (CDR) has been popularly studied to utilize different domain knowledge to solve the data sparsity and cold-start problem in recommender systems. In this paper, we focus on the Review-based Non-overlapped Recommendation (RNCDR) problem. The problem is commonly-existed and challenging due to two main aspects, i.e, there are only positive user-item ratings on the target domain and there is no overlapped user across different domains. Most previous CDR approaches cannot solve the RNCDR problem well, since (1) they cannot effectively combine review with other information (e.g., ID or ratings) to obtain expressive user or item embedding, (2) they cannot reduce the domain discrepancy on users and items. To fill this gap, we propose Collaborative Filtering with Attribution Alignment model (CFAA), a cross-domain recommendation framework for the RNCDR problem. CFAA&nbsp;includes two main modules, i.e., rating prediction module and embedding attribution alignment module. The former aims to jointly mine review, one-hot ID, and multi-hot historical ratings to generate expressive user and item embeddings. The later includes vertical attribution alignment and horizontal attribution alignment, tending to reduce the discrepancy based on multiple perspectives. Our empirical study on Douban and Amazon datasets demonstrates that CFAA&nbsp;significantly outperforms the state-of-the-art models under the RNCDR setting.",10.1145/3485447.3512166,https://doi.org/10.1145/3485447.3512166,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Collaborative Filtering with Attribution Alignment for Review-based Non-overlapped Cross Domain Recommendation,"Liu, Weiming and Zheng, Xiaolin and Hu, Mengling and Chen, Chaochao",inproceedings,10.1145/3485447.3512166,
10.1145/3485447.3512168,10.1145/3485447.3512168,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Extraction-based explanation, graph neural networks",9,2163–2171,Proceedings of the ACM Web Conference 2022,"Explanations in a recommender system assist users make informed decisions among a set of recommended items. Extensive research attention has been devoted to generate natural language explanations to depict how the recommendations are generated and why the users should pay attention to them. However, due to different limitations of those solutions, e.g., template-based or generation-based, it is hard to make the explanations easily perceivable, reliable, and personalized at the same time. In this work, we develop a graph attentive neural network model that seamlessly integrates user, item, attributes and sentences for extraction-based explanation. The attributes of items are selected as the intermediary to facilitate message passing for user-item specific evaluation of sentence relevance. And to balance individual sentence relevance, overall attribute coverage and content redundancy, we solve an integer linear programming problem to make the final selection of sentences. Extensive empirical evaluations against a set of state-of-the-art baseline methods on two benchmark review datasets demonstrated the generation quality of proposed solution.",10.1145/3485447.3512168,https://doi.org/10.1145/3485447.3512168,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Graph-based Extractive Explainer for Recommendations,"Wang, Peng and Cai, Renqin and Wang, Hongning",inproceedings,10.1145/3485447.3512168,
10.1145/3485447.3512216,10.1145/3485447.3512216,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Fake Engagement, Online Abuse, View Fraud",9,555–563,Proceedings of the ACM Web Conference 2022,"Social media platforms are driven by user engagement metrics. Unfortunately, such metrics are susceptible to manipulation and expose the platforms to abuse. Video view fraud is a unique class of fake engagement abuse on video-sharing platforms, such as YouTube, where the view count of videos is artificially inflated. There exists limited research on such abuse, and prior work focused on automated or bot-driven approaches. In this paper, we explore organic or human-driven approaches to view fraud, conducting a case study on a long-running YouTube view fraud campaign operated on a popular free video streaming service, 123Movies. Before 123Movies users are allowed to access a stream on the service, they must watch an unsolicited YouTube video displayed as a pre-roll advertisement. Due to 123Movies’ popularity, this activity drives large-scale YouTube view fraud. In this study, we reverse-engineer how 123Movies distributes these YouTube videos as pre-roll advertisements, and track the YouTube videos involved over a 9-month period. For a subset of these videos, we monitor their view counts and metrics for their respective YouTube channels over the same period. Our analysis reveals the characteristics of YouTube channels and videos participating in this view fraud, as well as the efficacy of such view fraud efforts. Ultimately, our study provides empirical grounding on organic YouTube view fraud.",10.1145/3485447.3512216,https://doi.org/10.1145/3485447.3512216,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,A View into YouTube View Fraud,"Kuchhal, Dhruv and Li, Frank",inproceedings,10.1145/3485447.3512216,
10.1145/3485447.3512255,10.1145/3485447.3512255,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Distributional robustness, Recommendation., Robust learning",5,3606–3610,Proceedings of the ACM Web Conference 2022,"Modern recommender systems have evolved rapidly along with deep learning models that are well-optimized for overall performance, especially those trained under Empirical Risk Minimization (ERM). However, a recommendation algorithm that focuses solely on the average performance may reinforce the exposure bias and exacerbate the “rich-get-richer” effect, leading to unfair user experience. In a simulation study, we demonstrate that such performance gap among various user groups is enlarged by an ERM-trained recommender in the long-term. To mitigate such amplification effects, we propose to optimize for the worst-case performance under the Distributionally Robust Optimization (DRO) framework, with the goal of improving long-term fairness for disadvantaged subgroups. In addition, we propose a simple-yet-effective streaming optimization improvement called Streaming-DRO (S-DRO), which effectively reduces loss variances for recommendation problems with sparse and long-tailed data distributions. Our results on two large-scale datasets suggest that (1) DRO is a flexible and effective technique for improving worst-case performance, and (2) Streaming-DRO outperforms vanilla DRO and other strong baselines by improving the worst-case and overall performance at the same time.",10.1145/3485447.3512255,https://doi.org/10.1145/3485447.3512255,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Distributionally-robust Recommendations for Improving Worst-case User Experience,"Wen, Hongyi and Yi, Xinyang and Yao, Tiansheng and Tang, Jiaxi and Hong, Lichan and Chi, Ed H.",inproceedings,10.1145/3485447.3512255,
10.1145/3485447.3512285,10.1145/3485447.3512285,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","latent variable learning, multi-party conversation, newcomer socialization, response prediction",10,1663–1672,Proceedings of the ACM Web Conference 2022,"With the increasing popularity of social media, online interpersonal communication now plays an essential role in people’s everyday information exchange. Whether and how a newcomer can better engage in the community has attracted great interest due to its application in many scenarios. Although some prior works that explore early socialization have obtained salient achievements, they are focusing on sociological surveys based on the small group. To help individuals get through the early socialization period and engage well in online conversations, we study a novel task to foresee whether a newcomer’s message will be responded to by other participants in a multi-party conversation (henceforth Successful New-entry Prediction)1. The task would be an important part of the research in online assistants and social media. To further investigate the key factors indicating such engagement success, we employ an unsupervised neural network, Variational Auto-Encoder (VAE), to examine the topic content and discourse behavior from newcomer’s chatting history and conversation’s ongoing context. Furthermore, two large-scale datasets, from Reddit and Twitter, are collected to support further research on new-entries. Extensive experiments on both Twitter and Reddit datasets show that our model significantly outperforms all the baselines and popular neural models. Additional explainable and visual analyses on new-entry behavior shed light on how to better join in others’ discussions.",10.1145/3485447.3512285,https://doi.org/10.1145/3485447.3512285,"New York, NY, USA",Association for Computing Machinery,9781450390965,2022,Successful New-entry Prediction for Multi-Party Online Conversations via Latent Topics and Discourse Modeling,"Wang, Lingzhi and Li, Jing and Zeng, Xingshan and Wong, Kam-Fai",inproceedings,10.1145/3485447.3512285,
10.1145/3487351.3488340,10.1145/3487351.3488340,KDD.bib,1,['KDD.bib'],8,ASONAM '21,"Virtual Event, Netherlands","Facebook, Instagram, online social networks, popularity evolution, temporal dynamics, user engagement",5,129–133,Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"A relevant fraction of human interactions occurs on online social networks. Freshness of content seems to play an important role, with content popularity rapidly vanishing over time. In this paper, we investigate how influencers' generated content (i.e., posts) attracts interactions, measured by number of likes or reactions. We analyse the activity of Italian influencers and followers over more than 5 years, focusing on two popular social networks: Facebook and Instagram, including more than 13 billion interactions and about 4 million posts. We characterise the influencers' and followers' behaviour over time, show that influencers' posts are short-lived with an exponential temporal decay, and characterise the time evolution of the interactions from their initial peak till the end of a post lifetime. Finally, leveraging our findings, we discuss how they can be exploited to develop an analytical model of the interactions temporal dynamics.",10.1145/3487351.3488340,https://doi.org/10.1145/3487351.3488340,"New York, NY, USA",Association for Computing Machinery,9781450391283,2022,Temporal dynamics of posts and user engagement of influencers on Facebook and Instagram,"Vassio, Luca and Garetto, Michele and Chiasserini, Carla and Leonardi, Emilio",inproceedings,10.1145/3487351.3488340,
10.1145/3487351.3488357,10.1145/3487351.3488357,KDD.bib,1,['KDD.bib'],8,ASONAM '21,"Virtual Event, Netherlands","WhatsApp, attention, small groups, social computing, topic modeling",5,64–68,Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Attention is a scarce resource disputed by algorithms and people on the Internet. This competition for attention is part of online spaces especially online small groups where there is a limited number of individuals interacting with each other using text and media content that is not controlled by algorithms or human curators. In these groups, as certain participants and piece of content can catch the collective attention, a question that naturally arises is: how to analyze topic attention in online small groups? In this paper, we propose a methodology aimed at answering this question. Our proposal consists of sets of analyses over topical (obtained from topic analysis) transition graphs for characterizing attention allocation, permanence and shifting as well as participant role characterization during discussions in online small groups. We experimented with our methodology using WhatsApp groups as a case study. Among other results, we identified and characterized abrupt and smooth topic transitions as well as patterns of participant activity related to certain topics.",10.1145/3487351.3488357,https://doi.org/10.1145/3487351.3488357,"New York, NY, USA",Association for Computing Machinery,9781450391283,2022,Analyzing topic attention in online small groups,"Caetano, Josemar Alves and Almeida, Jussara and Gon\c{c}alves, Marcos and Meira, Wagner and Marques-Neto, Humberto T. and Almeida, Virg\'{\i}lio",inproceedings,10.1145/3487351.3488357,
10.1145/3487351.3488555,10.1145/3487351.3488555,KDD.bib,1,['KDD.bib'],7,ASONAM '21,"Virtual Event, Netherlands",,8,455–462,Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"An information outbreak occurs on social media along with the COVID-19 pandemic and leads to infodemic. Predicting the popularity of online content, known as cascade prediction, allows for not only catching in advance hot information that deserves attention, but also identifying false information that will widely spread and require quick response to mitigate its impact. Among the various information diffusion patterns leveraged in previous works, the spillover effect of the information exposed to users on their decision to participate in diffusing certain information is still not studied. In this paper, we focus on the diffusion of information related to COVID-19 preventive measures. Through our collected Twitter dataset, we validated the existence of this spillover effect. Building on the finding, we proposed extensions to three cascade prediction methods based on Graph Neural Networks (GNNs). Experiments conducted on our dataset demonstrated that the use of the identified spillover effect significantly improves the state-of-the-art GNNs methods in predicting the popularity of not only preventive measure messages, but also other COVID-19 related messages.",10.1145/3487351.3488555,https://doi.org/10.1145/3487351.3488555,"New York, NY, USA",Association for Computing Machinery,9781450391283,2022,From #jobsearch to #mask: improving COVID-19 cascade prediction with spillover effects,"Chen, Ninghan and Chen, Xihui and Zhong, Zhiqiang and Pang, Jun",inproceedings,10.1145/3487351.3488555,
10.1145/3487553.3524215,10.1145/3487553.3524215,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","recommender systems, open source, behavioral testing",6,99–104,Companion Proceedings of the Web Conference 2022,"As with most Machine Learning systems, recommender systems are typically evaluated through performance metrics computed over held-out data points. However, real-world behavior is undoubtedly nuanced: ad hoc error analysis and tests must be employed to ensure the desired quality in actual deployments. We introduce RecList, a testing methodology providing a general plug-and-play framework to scale up behavioral testing. We demonstrate its capabilities by analyzing known algorithms and black-box APIs, and we release it as an open source, extensible package for the community.",10.1145/3487553.3524215,https://doi.org/10.1145/3487553.3524215,"New York, NY, USA",Association for Computing Machinery,9781450391306,2022,Beyond NDCG: Behavioral Testing of Recommender Systems with RecList,"Chia, Patrick John and Tagliabue, Jacopo and Bianchi, Federico and He, Chloe and Ko, Brian",inproceedings,10.1145/3487553.3524215,
10.1145/3487553.3524231,10.1145/3487553.3524231,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","popularity prediction, graph convolutional network, dynamic graph representation learning",4,239–242,Companion Proceedings of the Web Conference 2022,"Effectively predicting the future popularity of online content has important implications in a wide range of areas, including online advertising, user recommendation, and fake news detection. Existing approaches mainly consider the popularity prediction task via path modeling or discrete graph modeling. However, most of them heavily exploit underlying diffusion structural and sequential information, while ignoring the temporal evolution information among different snapshots of cascades. In this paper, we propose a graph temporal information learning framework based on an improved graph convolutional network (GTGCN), which can capture both the temporal information governing the spread of information in a snapshot, and the inherent temporal dependencies among different snapshots. We validate the effectiveness of the GTGCN by applying it on a Sina Weibo dataset in the scenario of predicting retweet cascades. Experimental results demonstrate the superiority of our proposed method over the state-of-the-art approaches.",10.1145/3487553.3524231,https://doi.org/10.1145/3487553.3524231,"New York, NY, USA",Association for Computing Machinery,9781450391306,2022,A Graph Temporal Information Learning Framework for Popularity Prediction,"Yang, Caipiao and Bao, Peng and Yan, Rong and Li, Jianian and Li, Xuanya",inproceedings,10.1145/3487553.3524231,
10.1145/3487553.3524249,10.1145/3487553.3524249,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Temporal Elapse Inference, Pre-training, Popularity Prediction",5,243–247,Companion Proceedings of the Web Conference 2022,"Predicting the popularity of online content is a fundamental problem in various applications. One practical challenge takes roots in the varying length of observation time or prediction horizon, i.e., a good model for popularity prediction is desired to handle various prediction settings. However, most existing methods adopt a separate training paradigm for each prediction setting and the obtained model for one setting is difficult to be generalized to others, causing a great waste of computational resources and a large demand for downstream labels. To solve the above issues, we propose a novel pre-training framework for popularity prediction, namely PREP, aiming to pre-train a general representation model from the readily available unlabeled diffusion data, which can be effectively transferred into various prediction settings. We design a novel pretext task for pre-training, i.e., temporal elapse inference for two randomly sampled time slices of popularity dynamics, impelling the representation model to learn intrinsic knowledge about popularity dynamics. Experimental results conducted on two real datasets demonstrate the generalization and efficiency of the pre-training framework for different popularity prediction task settings.",10.1145/3487553.3524249,https://doi.org/10.1145/3487553.3524249,"New York, NY, USA",Association for Computing Machinery,9781450391306,2022,PREP: Pre-training with Temporal Elapse Inference for Popularity Prediction,"Cao, Qi and Shen, Huawei and Liu, Yuanhao and Gao, Jinhua and Cheng, Xueqi",inproceedings,10.1145/3487553.3524249,
10.1145/3487553.3524646,10.1145/3487553.3524646,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","Spreading Phenomena, Social Networks, Location, Geographic Information Retrieval",4,656–659,Companion Proceedings of the Web Conference 2022,"Understanding and prediction of spreading phenomena are vital for numerous applications. The massive availability of social network data provides a platform for studying spreading phenomena. Past works studying and predicting spreading phenomena have explored the spread in dimensions of time and volume, such as predicting total infected users, predicting popularity, predicting the time when content receives a threshold number of infected users. However, as the information spreads from user to user, it also spreads from location to location. In this paper, we attempt to predict the spread in the dimension of geographic space. In accordance with the past spreading prediction problems, we design our problem to predict the spatial spread at an early stage. For this, we utilized spatial features, social features, and emotion features. We feed these features into existing classification algorithms and evaluate on three datasets from Twitter.",10.1145/3487553.3524646,https://doi.org/10.1145/3487553.3524646,"New York, NY, USA",Association for Computing Machinery,9781450391306,2022,Predicting Spatial Spread on Social Media,"Rimjhim and Dandapat, Sourav",inproceedings,10.1145/3487553.3524646,
10.1145/3487553.3524647,10.1145/3487553.3524647,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '22,"Virtual Event, Lyon, France","multi-modal learning, multi-modal content analysis, content reliability, content popularity",11,694–704,Companion Proceedings of the Web Conference 2022,"Social media content routinely incorporates multi-modal design to covey information and shape meanings, and sway interpretations toward desirable implications, but the choices and impacts of using both texts and visual images have not been sufficiently studied. This work proposes a computational approach to analyze the impacts of persuasive multi-modal content on popularity and reliability, in COVID-19-related news articles shared on Twitter. The two aspects are intertwined in the spread of misinformation: for example, an unreliable article that aims to misinform has to attain some popularity. This work has several contributions. First, we propose a multi-modal (image and text) approach to effectively identify popularity and reliability of information sources simultaneously. Second, we identify textual and visual elements that are predictive to information popularity and reliability. Third, by modeling cross-modal relations and similarity, we are able to uncover how unreliable articles construct multi-modal meaning in a distorted, biased fashion. Our work demonstrates how to use multi-modal analysis for understanding influential content and has implications to social media literacy and engagement.",10.1145/3487553.3524647,https://doi.org/10.1145/3487553.3524647,"New York, NY, USA",Association for Computing Machinery,9781450391306,2022,Visual Persuasion in COVID-19 Social Media Content: A Multi-Modal Characterization,"Unal, Mesut Erhan and Kovashka, Adriana and Chung, Wen-Ting and Lin, Yu-Ru",inproceedings,10.1145/3487553.3524647,
10.1145/3487572.3487573,10.1145/3487572.3487573,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '21,"Amsterdam, Netherlands","engagement prediction, fairness challenge, large-scale dataset, personalization, recommender system, twitter",6,1–6,Proceedings of the Recommender Systems Challenge 2021,"After the success the RecSys 2020 Challenge, we are describing a novel and bigger dataset that was released in conjunction with the ACM RecSys Challenge 2021. This year’s dataset is not only bigger (~1B data points, a 5 fold increase), but for the first time it take into consideration fairness aspects of the challenge. Unlike many static datsets, a lot of effort went into making sure that the dataset was synced with the Twitter platform: if a user deleted their content, the same content would be promptly removed from the dataset too. In this paper, we introduce the dataset and challenge, highlighting some of the issues that arise when creating recommender systems at Twitter scale.",10.1145/3487572.3487573,https://doi.org/10.1145/3487572.3487573,"New York, NY, USA",Association for Computing Machinery,9781450386937,2021,The 2021 RecSys Challenge Dataset: Fairness is not optional,"Belli, Luca and Tejani*, Alykhan and Portman*, Frank and Lung-Yut-Fong*, Alexandre and Chamberlain, Ben and Xie, Yuanpu and Lum, Kristian and Hunt, Jonathan and Bronstein, Michael and Anelli, Vito Walter and Kalloori, Saikishore and Ferwerda, Bruce and Shi, Wenzhe",inproceedings,10.1145/3487572.3487573,
10.1145/3487572.3487599,10.1145/3487572.3487599,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '21,"Amsterdam, Netherlands","RecSys Twitter Challenge, deep learning, neural networks, recommendation systems",7,15–21,Proceedings of the Recommender Systems Challenge 2021,"In this paper we present our 2nd place solution to ACM RecSys 2021 Challenge organized by Twitter. The challenge aims to predict user engagement for a set of tweets, offering an exceptionally large data set of 1 billion data points sampled from over four weeks of real Twitter interactions. Each data point contains multiple sources of information, such as tweet text along with engagement features, user features, and tweet features. The challenge brings the problem close to a real production environment by introducing strict latency constraints in the model evaluation phase: the average inference time for single tweet engagement prediction is limited to 6ms on a single CPU core with 64GB memory. Our proposed model relies on extensive feature engineering performed with methods such as the Efficient Manifold Density Estimator (EMDE) - our previously introduced algorithm based on Locality Sensitive Hashing method, and novel Fourier Feature Encoding, among others. In total, we create numerous features describing user twitter account status and content of a tweet. In order to adhere to the strict latency constraints, the underlying model is a simple residual feed-forward neural network. The system is a variation of our previous methods which proved successful in KDD Cup 2021, WSDM Challenge 2021, and SIGIR eCom Challenge 2020. We release the source code at: https://github.com/Synerise/recsys-challenge-2021.",10.1145/3487572.3487599,https://doi.org/10.1145/3487572.3487599,"New York, NY, USA",Association for Computing Machinery,9781450386937,2021,Synerise at RecSys 2021: Twitter user engagement prediction with a fast neural model,"Daniluk, Michal and Dabrowski, Jacek and Rychalska, Barbara and Goluchowski, Konrad",inproceedings,10.1145/3487572.3487599,
10.1145/3488560.3498372,10.1145/3488560.3498372,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","causal effect estimation, hidden confounder, multi-aspect sentiment, multi-modality, online reviews",10,103–112,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"Online reviews enable consumers to engage with companies and provide important feedback. Due to the complexity of the high-dimensional text, these reviews are often simplified as a single numerical score, e.g., ratings or sentiment scores. This work empirically examines the causal effects of user-generated online reviews on a granular level: we consider multiple aspects, e.g., the Food and Service of a restaurant. Understanding consumers' opinions toward different aspects can help evaluate business performance in detail and strategize business operations effectively. Specifically, we aim to answer interventional questions such as What will the restaurant popularity be if the quality w.r.t. its aspect Service is increased by 10%? The defining challenge of causal inference with observational data is the presence of ""confounder'', which might not be observed or measured, e.g., consumers' preference to food type, rendering the estimated effects biased and high-variance. To address this challenge, we have recourse to the multi-modal proxies such as the consumer profile information and interactions between consumers and businesses. We show how to effectively leverage the rich information to identify and estimate causal effects of multiple aspects embedded in online reviews. Empirical evaluations on synthetic and real-world data corroborate the efficacy and shed light on the actionable insight of the proposed approach.",10.1145/3488560.3498372,https://doi.org/10.1145/3488560.3498372,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,Estimating Causal Effects of Multi-Aspect Online Reviews with Multi-Modal Proxies,"Cheng, Lu and Guo, Ruocheng and Liu, Huan",inproceedings,10.1145/3488560.3498372,
10.1145/3488560.3498375,10.1145/3488560.3498375,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","dynamic user preferences, recommendation, selection bias",9,381–389,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"User interactions with recommender systems (RSs) are affected by user selection bias, e.g., users are more likely to rate popular items (popularity bias) or items that they expect to enjoy beforehand (positivity bias). Methods exist for mitigating the effects of selection bias in user ratings on the evaluation and optimization of RSs. However, these methods treat selection bias as static, despite the fact that the popularity of an item may change drastically over time and the fact that user preferences may also change over time.We focus on the age of an item and its effect on selection bias and user preferences. Our experimental analysis reveals that the rating behavior of users on the MovieLens dataset is better captured by methods that consider effects from the age of item on bias and preferences. We theoretically show that in a dynamic scenario in which both the selection bias and user preferences are dynamic, existing debiasing methods are no longer unbiased. To address this limitation, we introduce DebiAsing in the dyNamiC scEnaRio (DANCER), a novel debiasing method that extends the inverse propensity scoring debiasing method to account for dynamic selection bias and user preferences. Our experimental results indicate that DANCER improves rating prediction performance compared to debiasing methods that incorrectly assume that selection bias is static in a dynamic scenario. To the best of our knowledge, DANCER is the first debiasing method that accounts for dynamic selection bias and user preferences in RSs.",10.1145/3488560.3498375,https://doi.org/10.1145/3488560.3498375,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,It Is Different When Items Are Older: Debiasing Recommendations When Selection Bias and User Preferences Are Dynamic,"Huang, Jin and Oosterhuis, Harrie and de Rijke, Maarten",inproceedings,10.1145/3488560.3498375,
10.1145/3488560.3498386,10.1145/3488560.3498386,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","deep learning, federated recommender system, poisoning attack",9,1415–1423,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"Due to the growing privacy concerns, decentralization emerges rapidly in personalized services, especially recommendation. Also, recent studies have shown that centralized models are vulnerable to poisoning attacks, compromising their integrity. In the context of recommender systems, a typical goal of such poisoning attacks is to promote the adversary's target items by interfering with the training dataset and/or process. Hence, a common practice is to subsume recommender systems under the decentralized federated learning paradigm, which enables all user devices to collaboratively learn a global recommender while retaining all the sensitive data locally. Without exposing the full knowledge of the recommender and entire dataset to end-users, such federated recommendation is widely regarded 'safe' towards poisoning attacks. In this paper, we present a systematic approach to backdooring federated recommender systems for targeted item promotion. The core tactic is to take advantage of the inherent popularity bias that commonly exists in data-driven recommenders. As popular items are more likely to appear in the recommendation list, our innovatively designed attack model enables the target item to have the characteristics of popular items in the embedding space. Then, by uploading carefully crafted gradients via a small number of malicious users during the model update, we can effectively increase the exposure rate of a target (unpopular) item in the resulted federated recommender. Evaluations on two real-world datasets show that 1) our attack model significantly boosts the exposure rate of the target item in a stealthy way, without harming the accuracy of the poisoned recommender; and 2) existing defenses are not effective enough, highlighting the need for new defenses against our local model poisoning attacks to federated recommender systems.",10.1145/3488560.3498386,https://doi.org/10.1145/3488560.3498386,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,PipAttack: Poisoning Federated Recommender Systems for Manipulating Item Promotion,"Zhang, Shijie and Yin, Hongzhi and Chen, Tong and Huang, Zi and Nguyen, Quoc Viet Hung and Cui, Lizhen",inproceedings,10.1145/3488560.3498386,
10.1145/3488560.3498388,10.1145/3488560.3498388,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","adversarial learning, autoencoder, cross-domain recommendation, learning representation, sequential recommendation",11,571–581,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"Cross-domain recommendation can help alleviate the data sparsity issue in traditional sequential recommender systems. In this paper, we propose the RecGURU algorithm framework to generate a Generalized User Representation (GUR) incorporating user information across domains in sequential recommendation, even when there is minimum or no common users in the two domains. We propose a self-attentive autoencoder to derive latent user representations, and a domain discriminator, which aims to predict the origin domain of a generated latent representation. We propose a novel adversarial learning method to train the two modules to unify user embeddings generated from different domains into a single global GUR for each user. The learned GUR captures the overall preferences and characteristics of a user and thus can be used to augment the behavior data and improve recommendations in any single domain in which the user is involved. Extensive experiments have been conducted on two public cross-domain recommendation datasets as well as a large dataset collected from real-world applications. The results demonstrate that RecGURU boosts performance and outperforms various state-of-the-art sequential recommendation and cross-domain recommendation methods. The collected data will be released to facilitate future research.",10.1145/3488560.3498388,https://doi.org/10.1145/3488560.3498388,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,RecGURU: Adversarial Learning of Generalized User Representations for Cross-Domain Recommendation,"Li, Chenglin and Zhao, Mingjun and Zhang, Huanming and Yu, Chenyun and Cheng, Lei and Shu, Guoqiang and Kong, BeiBei and Niu, Di",inproceedings,10.1145/3488560.3498388,
10.1145/3488560.3498440,10.1145/3488560.3498440,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","conversational search, mixed-initiative search, user simulation",9,888–896,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"Clarifying the underlying user information need by asking clarifying questions is an important feature of modern conversational search system. However, evaluation of such systems through answering prompted clarifying questions requires significant human effort, which can be time-consuming and expensive. In this paper, we propose a conversational User Simulator, called USi, for automatic evaluation of such conversational search systems. Given a description of an information need, USi is capable of automatically answering clarifying questions about the topic throughout the search session. Through a set of experiments, including automated natural language generation metrics and crowdsourcing studies, we show that responses generated by USi are both inline with the underlying information need and comparable to human-generated answers. Moreover, we make the first steps towards multi-turn interactions, where conversational search systems asks multiple questions to the (simulated) user with a goal of clarifying the user need. To this end, we expand on currently available datasets for studying clarifying questions, i.e., Qulac and ClariQ, by performing a crowdsourcing-based multi-turn data acquisition. We show that our generative, GPT2-based model, is capable of providing accurate and natural answers to unseen clarifying questions in the single-turn setting and discuss capabilities of our model in the multi-turn setting. We provide the code, data, and the pre-trained model to be used for further research on the topic.",10.1145/3488560.3498440,https://doi.org/10.1145/3488560.3498440,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,Evaluating Mixed-initiative Conversational Search Systems via User Simulation,"Sekuli\'{c}, Ivan and Aliannejadi, Mohammad and Crestani, Fabio",inproceedings,10.1145/3488560.3498440,
10.1145/3488560.3498471,10.1145/3488560.3498471,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","diversity, multi-objective reinforcement learning, novelty, recommendation, reinforcement learning",9,957–965,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"Since the inception of Recommender Systems (RS), the accuracy of the recommendations in terms of relevance has been the golden criterion for evaluating the quality of RS algorithms. However, by focusing on item relevance, one pays a significant price in terms of other important metrics: users get stuck in a ""filter bubble"" and their array of options is significantly reduced, hence degrading the quality of the user experience and leading to churn. Recommendation, and in particular session-based/sequential recommendation, is a complex task with multiple - and often conflicting objectives - that existing state-of-the-art approaches fail to address. In this work, we take on the aforementioned challenge and introduce Scalarized Multi-Objective Reinforcement Learning (SMORL) for the RS setting, a novel Reinforcement Learning (RL) framework that can effectively address multi-objective recommendation tasks. The proposed SMORL agent augments standard recommendation models with additional RL layers that enforce it to simultaneously satisfy three principal objectives: accuracy, diversity, and novelty of recommendations. We integrate this framework with four state-of-the-art session-based recommendation models and compare it with a single-objective RL agent that only focuses on accuracy. Our experimental results on two real-world datasets reveal a substantial increase in aggregate diversity, a moderate increase in accuracy, reduced repetitiveness of recommendations, and demonstrate the importance of reinforcing diversity and novelty as complementary objectives.",10.1145/3488560.3498471,https://doi.org/10.1145/3488560.3498471,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,Choosing the Best of Both Worlds: Diverse and Novel Recommendations through Multi-Objective Reinforcement Learning,"Stamenkovic, Dusan and Karatzoglou, Alexandros and Arapakis, Ioannis and Xin, Xin and Katevas, Kleomenis",inproceedings,10.1145/3488560.3498471,
10.1145/3488560.3498476,10.1145/3488560.3498476,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","future information, gan, recommendation",9,1177–1185,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"Personalized recommendation often relies on user historical behaviors to provide items for users. It is intuitive that future information also contains essential messages as supplements to user historical behaviors. However, we cannot directly encode future information into models, since we are unable to get future information in online serving. In this work, we propose a novel adversarial future encoding (AFE) framework to make full use of informative future features in different types of recommendation models. Specifically, AFE contains a future-aware discriminator and a generator. The future-aware discriminator takes both common features and future features as inputs, working as a recommendation prophet to judge user-item pairs. In contrast, the generator is considered as a challenger, which generates items with only common features, aiming to confuse the future-aware prophet. The future-aware discriminator can inspire the generator (to be deployed online) to produce better results. We further conduct a multi-factor optimization to enable a fast and stable model convergence via the direct learning and knowledge distillation losses. Moreover, we have adopted AFE on both a list-wise RL-based ranking model and a point-wise ranking model to verify its universality. In experiments, we conduct sufficient evaluations on two large-scale datasets, achieving significant improvements on both offline and online evaluations. Currently, we have deployed AFE on a real-world system, affecting millions of users. The source code is in https://github.com/modriczhang/AFE.",10.1145/3488560.3498476,https://doi.org/10.1145/3488560.3498476,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,A Peep into the Future: Adversarial Future Encoding in Recommendation,"Xie, Ruobing and Zhang, Shaoliang and Wang, Rui and Xia, Feng and Lin, Leyu",inproceedings,10.1145/3488560.3498476,
10.1145/3488560.3498487,10.1145/3488560.3498487,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","multi-objective reinforcement learning, pareto efficient fairness, recommender system, unbiased recommendation",9,316–324,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"The issue of fairness in recommendation is becoming increasingly essential as Recommender Systems (RS) touch and influence more and more people in their daily lives. In fairness-aware recommendation, most of the existing algorithmic approaches mainly aim at solving a constrained optimization problem by imposing a constraint on the level of fairness while optimizing the main recommendation objective, e.g., click through rate (CTR). While this alleviates the impact of unfair recommendations, the expected return of an approach may significantly compromise the recommendation accuracy due to the inherent trade-off between fairness and utility. This motivates us to deal with these conflicting objectives and explore the optimal trade-off between them in recommendation. One conspicuous approach is to seek aPareto efficient/optimal solution to guarantee optimal compromises between utility and fairness. Moreover, considering the needs of real-world e-commerce platforms, it would be more desirable if we can generalize the wholePareto Frontier, so that the decision-makers can specify any preference of one objective over another based on their current business needs. Therefore, in this work, we propose a fairness-aware recommendation framework usingmulti-objective reinforcement learning (MORL), called MoFIR (pronounced ""more fair ''), which is able to learn a single parametric representation for optimal recommendation policies over the space of all possible preferences. Specially, we modify traditional Deep Deterministic Policy Gradient (DDPG) by introducingconditioned network (CN) into it, which conditions the networks directly on these preferences and outputs Q-value-vectors. Experiments on several real-world recommendation datasets verify the superiority of our framework on both fairness metrics and recommendation measures when compared with all other baselines. We also extract the approximate Pareto Frontier on real-world datasets generated by MoFIR and compare to state-of-the-art fairness methods.",10.1145/3488560.3498487,https://doi.org/10.1145/3488560.3498487,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,Toward Pareto Efficient Fairness-Utility Trade-off in Recommendation through Reinforcement Learning,"Ge, Yingqiang and Zhao, Xiaoting and Yu, Lucia and Paul, Saurabh and Hu, Diane and Hsieh, Chu-Cheng and Zhang, Yongfeng",inproceedings,10.1145/3488560.3498487,
10.1145/3488560.3498496,10.1145/3488560.3498496,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","user navigation, wikipedia clickstream, wikipedia server logs",11,16–26,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"Every day millions of people read Wikipedia. When navigating the vast space of available topics using hyperlinks, readers describe trajectories on the article network. Understanding these navigation patterns is crucial to better serve readers' needs and address structural biases and knowledge gaps. However, systematic studies of navigation on Wikipedia are hindered by a lack of publicly available data due to the commitment to protect readers' privacy by not storing or sharing potentially sensitive data. In this paper, we ask: How well can Wikipedia readers' navigation be approximated by using publicly available resources, most notably the Wikipedia clickstream data? We systematically quantify the differences between real navigation sequences and synthetic sequences generated from the clickstream data, in 6 analyses across 8 Wikipedia language versions. Overall, we find that the differences between real and synthetic sequences are statistically significant, but with small effect sizes, often well below 10%. This constitutes quantitative evidence for the utility of the Wikipedia clickstream data as a public resource: clickstream data can closely capture reader navigation on Wikipedia and provides a sufficient approximation for most practical downstream applications relying on reader data. More broadly, this study provides an example for how clickstream-like data can generally enable research on user navigation on online platforms while protecting users' privacy.",10.1145/3488560.3498496,https://doi.org/10.1145/3488560.3498496,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,Wikipedia Reader Navigation: When Synthetic Data Is Enough,"Arora, Akhil and Gerlach, Martin and Piccardi, Tiziano and Garc\'{\i}a-Dur\'{a}n, Alberto and West, Robert",inproceedings,10.1145/3488560.3498496,
10.1145/3488560.3498519,10.1145/3488560.3498519,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","data characteristics, datasets, evaluation, item recommendation",9,141–149,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"There has been sustained interest from both academia and industry throughout the years due to the importance and practicability of recommendation systems. However, several recent papers have pointed out critical issues with the evaluation process in recommender systems. Likewise, this paper takes an in-depth look at a fundamental but often neglected aspect of the evaluation procedure, i.e. the datasets themselves. To do so, we adopt a systematic and comprehensive approach to understand the datasets used for implicit feedback based top-K recommendation. We start by examining recent papers from top-tier conferences to find out how different datasets have been utilised thus far. Next, we look at the characteristics of these datasets to understand their similarities and differences. Finally, we conduct an empirical study to determine whether the choice of datasets used for evaluation can influence the observations and/or conclusions obtained. Our findings suggest that greater attention needs to be paid to the selection process of datasets used for evaluating recommender systems in order to improve the robustness of the obtained results.",10.1145/3488560.3498519,https://doi.org/10.1145/3488560.3498519,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,The Datasets Dilemma: How Much Do We Really Know About Recommendation Datasets?,"Chin, Jin Yao and Chen, Yile and Cong, Gao",inproceedings,10.1145/3488560.3498519,
10.1145/3488560.3498520,10.1145/3488560.3498520,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","collaborative filtering, empirical evaluation, graph neural networks",11,1109–1119,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"In recent years, Graph Neural Networks (GNNs) have been widely used in Collaborative Filtering (CF), one of the most popular methods in recommender systems. However, most existing works focus on designing an individual model architecture given a specific scenario, without studying the influences of different design dimensions. Thus, it remains a challenging problem to quickly obtain a top-performing model in a new recommendation scenario. To address the problem, in this work, we make the first attempt to profile the design space of GNN-based CF methods to enrich the understanding of different design dimensions as well as provide a novel paradigm of model design. Specifically, a unified framework of GNN-based CF is proposed, on top of which a design space is developed and evaluated by extensive experiments. Interesting findings on the impacts of different design dimensions on recommendation performance are obtained. Guided by the empirical findings, we further prune the design space to obtain a compact one containing a higher concentration of top-performing models. Empirical studies demonstrate its high quality and strong generalization ability.",10.1145/3488560.3498520,https://doi.org/10.1145/3488560.3498520,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,Profiling the Design Space for Graph Neural Networks based Collaborative Filtering,"Wang, Zhenyi and Zhao, Huan and Shi, Chuan",inproceedings,10.1145/3488560.3498520,
10.1145/3488560.3498522,10.1145/3488560.3498522,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","community trend, dynamic evolution, e-commerce, heterogeneous graph",9,1319–1327,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"In online shopping, ever-changing fashion trends make merchants need to prepare more differentiated products to meet the diversified demands, and e-commerce platforms need to capture the market trend with a prophetic vision. For the trend prediction, the attribute tags, as the essential description of items, can genuinely reflect the decision basis of consumers. However, few existing works explore the attribute trend in the specific community for e-commerce. In this paper, we focus on the community trend prediction on the item attribute and propose a unified framework that combines the dynamic evolution of two graph patterns to predict the attribute trend in a specific community. Specifically, we first design a community-attribute bipartite graph at each time step to learn the collaboration of different communities. Next, we transform the bipartite graph into a hypergraph to exploit the associations of different attribute tags in one community. Lastly, we introduce a dynamic evolution component based on the recurrent neural networks to capture the fashion trend of attribute tags. Extensive experiments on three real-world datasets in a large e-commerce platform show the superiority of the proposed approach over several strong alternatives and demonstrate the ability to discover the community trend in advance.",10.1145/3488560.3498522,https://doi.org/10.1145/3488560.3498522,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,Community Trend Prediction on Heterogeneous Graph in E-commerce,"Yuan, Jiahao and Li, Zhao and Zou, Pengcheng and Gao, Xuan and Pan, Jinwei and Ji, Wendi and Wang, Xiaoling",inproceedings,10.1145/3488560.3498522,
10.1145/3488560.3502192,10.1145/3488560.3502192,WSDM.bib,1,['WSDM.bib'],8,WSDM '22,"Virtual Event, AZ, USA","recommender systems, robustness",4,1597–1600,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,"Robust machine learning is an increasingly important topic that focuses on developing models resilient to various forms of imperfect data. Due to the pervasiveness of recommender systems in online technologies, researchers have carried out several robustness studies focusing on data sparsity and profile injection attacks. Instead, we propose a more holistic view of robustness for recommender systems that encompasses multiple dimensions - robustness with respect to sub-populations, transformations, distributional disparity, attack, and data sparsity. While there are several libraries that allow users to compare different recommender system models, there is no software library for comprehensive robustness evaluation of recommender system models under different scenarios. As our main contribution, we present a robustness evaluation toolkit, Robustness Gym for RecSys (RGRecSys), that allows us to quickly and uniformly evaluate the robustness of recommender system models.",10.1145/3488560.3502192,https://doi.org/10.1145/3488560.3502192,"New York, NY, USA",Association for Computing Machinery,9781450391320,2022,RGRecSys: A Toolkit for Robustness Evaluation of Recommender Systems,"Ovaisi, Zohreh and Heinecke, Shelby and Li, Jia and Zhang, Yongfeng and Zheleva, Elena and Xiong, Caiming",inproceedings,10.1145/3488560.3502192,
10.1145/3511808.3557066,10.1145/3511808.3557066,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","feedback loop, exploration, empirical Bayes, e-commerce search, discovery, cold start, bias",11,3141–3151,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Cold start is a challenge in product search. Profuse literature addresses related problems such as bias and diversity in search, and cold start is a classic topic in recommender systems research. While search cold start might be seen conceptually as a particular case in such areas, we find that available solutions fail to specifically and practically solve the cold-start problem in product search. The problem is complex as exposing new products may come at the expense of primary business metrics (e.g. revenue), and involves a complex balance between customer satisfaction, seller satisfaction, business performance, short-term gains and long-term value.In this paper, we propose a principled approach to deal with cold start in a large-scale e-commerce search system. We discuss how product ranking is affected by non-behavioral topical relevance and behavioral popularity, and their role in introducing biases that result in cold-start for ranking new products. Our approach applies Empirical Bayes to model behavioral information via non-behavioral signals in terms of priors, and effectively estimate true engagement posterior updates. We report comprehensive offline and online experiments over large datasets that show the effectiveness of our methods to address cold start, and provide further insights. An online A/B test on 50 million queries shows a significant improvement in new product impressions by 13.53% and a significant increase in new product purchase by 11.14%, with overall purchases up by 0.08%, highlighting the empirical effectiveness of the approach.",10.1145/3511808.3557066,https://doi.org/10.1145/3511808.3557066,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Addressing Cold Start in Product Search via Empirical Bayes,"Han, Cuize and Castells, Pablo and Gupta, Parth and Xu, Xu and Salaka, Vamsi",inproceedings,10.1145/3511808.3557066,
10.1145/3511808.3557083,10.1145/3511808.3557083,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","reinforcement learning, off-policy evaluation, mobile notifications",10,3614–3623,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Mobile notification systems have taken a major role in driving and maintaining user engagement for online platforms. They are interesting recommender systems to machine learning practitioners with more sequential and long-term feedback considerations. Most machine learning applications in notification systems are built around response-prediction models, trying to attribute both short-term impact and long-term impact to a notification decision. However, a user's experience depends on a sequence of notifications and attributing impact to a single notification is not always accurate, if not impossible. In this paper, we argue that reinforcement learning is a better framework for notification systems in terms of performance and iteration speed. We propose an offline reinforcement learning framework to optimize sequential notification decisions for driving user engagement. We describe a state-marginalized importance sampling policy evaluation approach, which can be used to evaluate the policy offline and tune learning hyperparameters. Through simulations that approximate the notifications ecosystem, we demonstrate the performance and benefits of the offline evaluation approach as a part of the reinforcement learning modeling approach. Finally, we collect data through online exploration in the production system, train an offline Double Deep Q-Network and launch a successful policy online. We also discuss the practical considerations and results obtained by deploying these policies for a large-scale recommendation system use-case.",10.1145/3511808.3557083,https://doi.org/10.1145/3511808.3557083,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Offline Reinforcement Learning for Mobile Notifications,"Yuan, Yiping and Muralidharan, Ajith and Nandy, Preetam and Cheng, Miao and Prabhakar, Prakruthi",inproceedings,10.1145/3511808.3557083,
10.1145/3511808.3557106,10.1145/3511808.3557106,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","pre-training, online recommendation, knowledge plugging, knowledge extraction",10,3684–3693,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"An industrial recommender system generally presents a hybrid list that contains results from multiple subsystems. In practice, each subsystem is optimized with its own feedback data to avoid the disturbance among different subsystems. However, we argue that such data usage may lead to sub-optimal online performance because of thedata sparsity. To alleviate this issue, we propose to extract knowledge from thesuper-domain that contains web-scale and long-time impression data, and further assist the online recommendation task (downstream task). To this end, we propose a novel industrial KnowlEdge Extraction and Plugging (KEEP) framework, which is a two-stage framework that consists of 1) a supervised pre-training knowledge extraction module on super-domain, and 2) a plug-in network that incorporates the extracted knowledge into the downstream model. This makes it friendly for incremental training of online recommendation. Moreover, we design an efficient empirical approach for KEEP and introduce our hands-on experience during the implementation of KEEP in a large-scale industrial system. Experiments conducted on two real-world datasets demonstrate that KEEP can achieve promising results. It is notable that KEEP has also been deployed on the display advertising system in Alibaba, bringing a lift of +5.4% CTR and +4.7% RPM.",10.1145/3511808.3557106,https://doi.org/10.1145/3511808.3557106,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,KEEP: An Industrial Pre-Training Framework for Online Recommendation via Knowledge Extraction and Plugging,"Zhang, Yujing and Chan, Zhangming and Xu, Shuhao and Bian, Weijie and Han, Shuguang and Deng, Hongbo and Zheng, Bo",inproceedings,10.1145/3511808.3557106,
10.1145/3511808.3557127,10.1145/3511808.3557127,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","skip-gram, purchase prediction, machine learning, embedding, e-commerce, customer representation",10,2873–2882,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Customers are increasingly using online channels to buy products. For e-commerce companies, this offers new opportunities to tailor the shopping experience to customers' needs. Therefore, it is of great importance for a company to know their customers' intentions while browsing their webpage. A major challenge is the real-time analysis of a customer's intention during browsing sessions. To this end, a representation of the customer's browsing behavior must be retrieved from their live interactions on the webpage. Typically, characteristic behavioral features are extracted manually based on the knowledge of marketing experts. In this paper, we propose a customer embedding representation that is based on the customer's click-events recorded during browsing sessions. Thus, our approach does not use manually extracted features and is not based on marketing expert domain knowledge, which makes it transferable to different webpages and different online markets. We demonstrate our approach using three different e-commerce datasets to successfully predict whether a customer is going to purchase a specific product. For the prediction, we utilize the customer embedding representations as input for different machine learning models. We compare our approach with existing state-of-the-art approaches for real-time purchase prediction and show that our proposed customer representation with an LSTM predictor outperforms the state-of-the-art approach on all three datasets. Additionally, the creation process of our customers' representation is on average 235 times faster than the creation process of the baseline.",10.1145/3511808.3557127,https://doi.org/10.1145/3511808.3557127,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Will This Online Shopping Session Succeed? Predicting Customer's Purchase Intention Using Embeddings,"Alves Gomes, Miguel and Meyes, Richard and Meisen, Philipp and Meisen, Tobias",inproceedings,10.1145/3511808.3557127,
10.1145/3511808.3557132,10.1145/3511808.3557132,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","workload assessment, order grouping, last-mile delivery",10,3361–3370,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"The popularity of e-commerce has promoted the rapid development of the logistics industry in recent years. As an important step in logistics, last-mile delivery from delivery stations to customers' addresses is now mainly finished by couriers, which requires accurate workload assessment based on actual efforts. However, the state-of-the-practice assessment methods neglect a vital factor that orders with the same customer's address (i.e., Homogeneous orders) can be delivered in a group (i.e., in a single trip) or separately (i.e., in multiple trips). It would cause unfair assessment among couriers if following the same rule. Thus, grouping homogeneous order accurately in the workload assessment is significant for achieving fair courier's workload assessment. To this end, we design, implement, and deploy a nationwide homogeneous order grouping system called FHOG for improving the accuracy of homogeneous order grouping in last-mile delivery for fair courier's workload assessment. FHOG utilizes the courier's reporting behavior for order inspection, collection, and delivery to identify homogeneous orders in the delivery station simultaneously for homogeneous order grouping. Compared with the state-of-the-practice method, our evaluation shows FHOG can effectively reduce order amounts with the higher and lower assessed courier's workload. We further deploy FHOG online in 8336 delivery stations to provide homogeneous order grouping service for more than 120 thousand couriers and 12 million daily orders. The results of the two surveys show that the couriers' acceptance rate is improved by 67% with FHOG after the promotion.",10.1145/3511808.3557132,https://doi.org/10.1145/3511808.3557132,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Towards Fair Workload Assessment via Homogeneous Order Grouping in Last-mile Delivery,"Lyu, Wenjun and Zhang, Kexin and Guo, Baoshen and Hong, Zhiqing and Yang, Guang and Wang, Guang and Yang, Yu and Liu, Yunhuai and Zhang, Desheng",inproceedings,10.1145/3511808.3557132,
10.1145/3511808.3557229,10.1145/3511808.3557229,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","recommendation, data importance, bilevel optimization",10,2148–2157,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Implicit feedback is frequently used for developing personalized recommendation services due to its ubiquity and accessibility in real-world systems. In order to effectively utilize such information, most research adopts the pairwise ranking method on constructed training triplets (user, positive item, negative item) and aims to distinguish between positive items and negative items for each user. However, most of these methods treat all the training triplets equally, which ignores the subtle difference between different positive or negative items. On the other hand, even though some other works make use of the auxiliary information (e.g., dwell time) of user behaviors to capture this subtle difference, such auxiliary information is hard to obtain. To mitigate the aforementioned problems, we propose a novel training framework named Triplet Importance Learning (TIL), which adaptively learns the importance score of training triplets. We devise two strategies for the importance score generation and formulate the whole procedure as a bilevel optimization, which does not require any rule-based design. We integrate the proposed training procedure with several Matrix Factorization (MF)- and Graph Neural Network (GNN)-based recommendation models, demonstrating the compatibility of our framework. Via a comparison using three real-world datasets with many state-of-the-art methods, we show that our proposed method outperforms the best existing models by 3-21% in terms of Recall@k for the top-k recommendation.",10.1145/3511808.3557229,https://doi.org/10.1145/3511808.3557229,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Adapting Triplet Importance of Implicit Feedback for Personalized Recommendation,"Wu, Haolun and Ma, Chen and Zhang, Yingxue and Liu, Xue and Tang, Ruiming and Coates, Mark",inproceedings,10.1145/3511808.3557229,
10.1145/3511808.3557284,10.1145/3511808.3557284,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","view-temporal interaction, news recommendation, causal convolution, attention mechanism",11,2640–2650,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Personalized news recommendation aims to provide people with customized content, which can effectively improve the reading experience. Because user interests in news are diverse and changeable, how to learn accurate user representations is the core challenge in news recommendation. However, most of the previous works only apply news-level representation for user modeling directly, the views of news, such as title, abstract, and category, are only implied and compressed into a single vector of news, which makes it impossible for different views in different news to interact with each other. In this paper, we first focus on the view-level information for user modeling and propose Deep View-Temporal Interaction Network (DeepVT) for news recommendation. It mainly contains two components, i.e., 2D semi-causal convolutional neural network (SC-CNN) and multi-operator attention (MoA). SC-CNN can synthesize interaction information at the view-level and temporal information at the news-level simultaneously and efficiently. And MoA integrates different similarity operators in self-attention functions to avoid attention bias and enhance robustness. By collaboration with SC-CNN, the global interaction at the view-level becomes more sufficient. Experiments on a large-scale real-world dataset, Microsoft News Dataset (MIND), show that our model outperforms previous models in terms of all metrics significantly.",10.1145/3511808.3557284,https://doi.org/10.1145/3511808.3557284,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,DeepVT: Deep View-Temporal Interaction Network for News Recommendation,"Zhang, Xuanyu and Yang, Qing and Xu, Dongliang",inproceedings,10.1145/3511808.3557284,
10.1145/3511808.3557298,10.1145/3511808.3557298,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","self-attention, purchase prediction, next-item prediction, multi-behavior sequential recommendation",10,1379–1388,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Recently, sequential recommendation has become a research hotspot while multi-behavior sequential recommendation (MBSR) that exploits users' heterogeneous interactions in sequences has received relatively little attention. Existing works often overlook the complementary effect of different perspectives when addressing the MBSR problem. In addition, there are two specific challenges remained to be addressed. One is the heterogeneity of a user's intention and the context information, the other one is the sparsity of the interactions of target behavior. To release the potential of multi-behavior interaction sequences, we propose a novel framework named NextIP that adopts a dual-task learning strategy to convert the problem to two specific tasks, i.e., &lt;u&gt;next&lt;/u&gt;-&lt;u&gt;i&lt;/u&gt;tem prediction and &lt;u&gt;p&lt;/u&gt;urchase prediction. For next-item prediction, we design a target-behavior aware context aggregator (TBCG), which utilizes the next behavior to guide all kinds of behavior-specific item sub-sequences to jointly predict the next item. For purchase prediction, we design a behavior-aware self-attention (BSA) mechanism to extract a user's behavior-specific interests and treat them as negative samples to learn the user's purchase preferences. Extensive experimental results on two public datasets show that our NextIP performs significantly better than the state-of-the-art methods.",10.1145/3511808.3557298,https://doi.org/10.1145/3511808.3557298,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Dual-Task Learning for Multi-Behavior Sequential Recommendation,"Luo, Jinwei and He, Mingkai and Lin, Xiaolin and Pan, Weike and Ming, Zhong",inproceedings,10.1145/3511808.3557298,
10.1145/3511808.3557320,10.1145/3511808.3557320,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","rating prediction, personalized federated learning, cross-domain recommendation, cold-start problem",10,2179–2188,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"The cold-start problem, faced when providing recommendations to newly joined users with no historical interaction record existing in the platform, is one of the most critical problems that negatively impact the performance of a recommendation system. Fortunately, cross-domain recommendation~(CDR) is a promising approach for solving this problem, which can exploit the knowledge of these users from source domains to provide recommendations in the target domain. However, this method requires that the central server has the interaction behaviour data in both domains of all the users, which prevents users from participating due to privacy issues.In this work, we propose FedCDR, a federated learning based cross-domain recommendation system that effectively trains the recommendation model while keeping users' raw data and private user-specific parameters located on their own devices. Unlike existing CDR models, a personal module and a transfer module are designed to adapt to the extremely heterogeneous data on the participating devices. Specifically, the personal module extracts private user features for each user, while the transfer module is responsible for transferring the knowledge between the two domains. Moreover, in order to provide personalized recommendations with less storage and communication costs while effectively protecting privacy, we design a personalized update strategy for each client and a personalized aggregation strategy for the server. In addition, we conduct comprehensive experiments on the representative Amazon 5-cores datasets for three popular rating prediction tasks to evaluate the effectiveness of FedCDR. The results show that FedCDR outperforms the state-of-the-art methods in mean absolute error (MAE) and root mean squared error (RMSE). For example, in task Movie&amp;Music, FedCDR can effectively improve the performance up to 65.83% and 55.45% on MAE and RMSE, respectively, when the new users are in the movie domain.",10.1145/3511808.3557320,https://doi.org/10.1145/3511808.3557320,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,FedCDR: Federated Cross-Domain Recommendation for Privacy-Preserving Rating Prediction,"Meihan, Wu and Li, Li and Tao, Chang and Rigall, Eric and Xiaodong, Wang and Cheng-Zhong, Xu",inproceedings,10.1145/3511808.3557320,
10.1145/3511808.3557341,10.1145/3511808.3557341,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","recommender system, neural networks, imbalanced distribution",11,2199–2209,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Rating prediction is a core problem in recommender systems to quantify users' preferences towards items. However, rating imbalance naturally roots in real-world user ratings that cause biased predictions and lead to poor performance on tail ratings. While existing approaches in the rating prediction task deploy weighted cross-entropy to re-weight training samples, such approaches commonly assume a normal distribution, a symmetrical and balanced space. In contrast to the normal assumption, we propose a novel Gumbel-based Variational Network framework (GVN) to model rating imbalance and augment feature representations by the Gumbel distributions. We propose a Gumbel-based variational encoder to transform features into non-normal vector space. Second, we deploy a multi-scale convolutional fusion network to integrate comprehensive views of users and items from the rating matrix and user reviews. Third, we adopt a skip connection module to personalize final rating predictions. We conduct extensive experiments on five datasets with both errors- and ranking-based metrics. Experiments on ranking and regression evaluation tasks prove that the GVN can effectively achieve state-of-the-art performance across the datasets and reduce the biased predictions of tail ratings. We compare with various distributions (e.g., normal and Poisson) and demonstrate the effectiveness of Gumbel-based methods on class-imbalance modeling. The code is available at https://github.com/woqingdoua/Gumbel-recommendation-for-imbalanced-data.",10.1145/3511808.3557341,https://doi.org/10.1145/3511808.3557341,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,A Gumbel-based Rating Prediction Framework for Imbalanced Recommendation,"Wu, Yuexin and Huang, Xiaolei",inproceedings,10.1145/3511808.3557341,
10.1145/3511808.3557354,10.1145/3511808.3557354,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","recommender system, graph embedding, context-aware recommendation, attention",10,1389–1398,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"The recent popularity of edge devices and Artificial Intelligent of Things (AIoT) has driven a new wave of contextual recommendations, such as location based Point of Interest (PoI) recommendations and computing resource-aware mobile app recommendations. In many such recommendation scenarios, contexts are drifting over time. For example, in a mobile game recommendation, contextual features like locations, battery, and storage levels of mobile devices are frequently drifting over time. However, most existing graph-based collaborative filtering methods are designed under the assumption of static features. Therefore, they would require frequent retraining and/or yield graphical models burgeoning in sizes, impeding their suitability for context-drifting recommendations.In this work, we propose a specifically tailor-made Hybrid Static and Adaptive Graph Embedding (HySAGE) network for context-drifting recommendations. Our key idea is to disentangle the relatively static user-item interaction and rapidly drifting contextual features. Specifically, our proposed HySAGE network learns a relatively static graph embedding from user-item interaction and an adaptive embedding from drifting contextual features. These embeddings are incorporated into an interest network to generate the user interest in some certain context. We adopt an interactive attention module to learn the interactions among static graph embeddings, adaptive contextual embeddings, and user interest, helping to achieve a better final representation. Extensive experiments on real-world datasets demonstrate that HySAGE significantly improves the performance of the existing state-of-the-art recommendation algorithms.",10.1145/3511808.3557354,https://doi.org/10.1145/3511808.3557354,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,HySAGE: A Hybrid Static and Adaptive Graph Embedding Network for Context-Drifting Recommendations,"Luo, Sichun and Zhang, Xinyi and Xiao, Yuanzhang and Song, Linqi",inproceedings,10.1145/3511808.3557354,
10.1145/3511808.3557396,10.1145/3511808.3557396,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","web data, time series, reaction-diffusion systems, neural networks, data mininig",11,1521–1531,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Large quantifies of online user activity data, such as weekly web search volumes, which co-evolve with the mutual influence of several queries and locations, serve as an important social sensor. It is an important task to accurately forecast the future activity by discovering latent interactions from such data, i.e., the ecosystems between each query and the flow of influences between each area. However, this is a difficult problem in terms of data quantity and complex patterns covering the dynamics. To tackle the problem, we propose FluxCube, which is an effective mining method that forecasts large collections of co-evolving online user activity and provides good interpretability. Our model is the expansion of a combination of two mathematical models: a reaction-diffusion system provides a framework for modeling the flow of influences between local area groups and an ecological system models the latent interactions between each query. Also, by leveraging the concept of physics-informed neural networks, FluxCube achieves high interpretability obtained from the parameters and high forecasting performance, together. Extensive experiments on real datasets showed that FluxCube outperforms comparable models in terms of the forecasting accuracy, and each component in FluxCube contributes to the enhanced performance. We then show some case studies that FluxCube can extract useful latent interactions between queries and area groups.",10.1145/3511808.3557396,https://doi.org/10.1145/3511808.3557396,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Mining Reaction and Diffusion Dynamics in Social Activities,"Murayama, Taichi and Matsubara, Yasuko and Sakurai, Yasushi",inproceedings,10.1145/3511808.3557396,
10.1145/3511808.3557407,10.1145/3511808.3557407,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","simulation, popularity bias, pandemic-like events, human needs, herding behavior, concept drift, collaborative filtering",11,1430–1440,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"We outline a simulation-based study of the effect rapid population-scale concept drifts have on Collaborative Filtering (CF) models. We create a framework for analyzing the effects of macro-trends in population dynamics on the behavior of such models. Our framework characterizes population-scale concept drifts in item preferences and provides a lens to understand the influence events, such as a pandemic, have on CF models. Our experimental results show the initial impact on CF performance at the initial stage of such events, followed by an aggravated population herding effect during the event. The herding introduces a popularity bias that may benefit affected users, but which comes at the expense of a normal user experience. We propose an adaptive ensemble method that can effectively apply optimal algorithms to cope with the change brought about by different stages of the event.",10.1145/3511808.3557407,https://doi.org/10.1145/3511808.3557407,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,NEST: Simulating Pandemic-like Events for Collaborative Filtering by Modeling User Needs Evolution,"Ma, Chenglong and Ren, Yongli and Castells, Pablo and Sanderson, Mark",inproceedings,10.1145/3511808.3557407,
10.1145/3511808.3557423,10.1145/3511808.3557423,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","popularity bias, debiasing, conversational recommender system",10,1238–1247,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Conversational recommender systems (CRS) have shown great success in accurately capturing a user's current and detailed preference through the multi-round interaction cycle while effectively guiding users to a more personalized recommendation. Perhaps surprisingly, conversational recommender systems can be plagued by popularity bias, much like traditional recommender systems. In this paper, we systematically study the problem of popularity bias in CRSs. We demonstrate the existence of popularity bias in existing state-of-the-art CRSs from an exposure rate, a success rate, and a conversational utility perspective, and propose a suite of popularity bias metrics designed specifically for the CRS setting. We then introduce a debiasing framework with three unique features: (i) Popularity-Aware Focused Learning, to reduce the popularity-distorting impact on preference prediction; (ii) Cold-Start Item Embedding Reconstruction via Attribute Mapping, to improve the modeling of cold-start items; and (iii) Dual-Policy Learning, to better guide the CRS when dealing with either popular or unpopular items. Through extensive experiments on two frequently used CRS datasets, we find the proposed model-agnostic debiasing framework not only mitigates the popularity bias in state-of-the-art CRSs but also improves the overall recommendation performance.",10.1145/3511808.3557423,https://doi.org/10.1145/3511808.3557423,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Quantifying and Mitigating Popularity Bias in Conversational Recommender Systems,"Lin, Allen and Wang, Jianling and Zhu, Ziwei and Caverlee, James",inproceedings,10.1145/3511808.3557423,
10.1145/3511808.3557431,10.1145/3511808.3557431,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","unbiased learning, logged feedback, counterfactual learning",10,2220–2229,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"The logged feedback for training recommender systems is usually subject to selection bias, which could not reflect real user preference. Thus, many efforts have been made to learn the de-biased recommender system from biased feedback. However, existing methods for dealing with selection bias are usually affected by the error of propensity weight estimation, have high variance, or assume access to uniform data, which is expensive to be collected in practice. In this work, we address these issues by proposing Learning De-biased Representations (LDR), a framework derived from the representation learning perspective. LDR bridges the gap between propensity weight estimation (WE) and unbiased weighted learning (WL) and provides an end-to-end solution that iteratively conducts WE and WL. We show LDR can effectively alleviate selection bias with bounded variance. We also perform theoretical analysis on the statistical properties of LDR, such as its bias, variance, and generalization performance. Extensive experiments on both semi-synthetic and real-world datasets demonstrate the effectiveness of LDR.",10.1145/3511808.3557431,https://doi.org/10.1145/3511808.3557431,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Representation Matters When Learning From Biased Feedback in Recommendation,"Xiao, Teng and Chen, Zhengyu and Wang, Suhang",inproceedings,10.1145/3511808.3557431,
10.1145/3511808.3557434,10.1145/3511808.3557434,CIKM.bib,1,['CIKM.bib'],7,CIKM '22,"Atlanta, GA, USA",,11,293–303,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"A cross-domain recommendation has shown promising results in solving data-sparsity and cold-start problems. Despite such progress, existing methods focus on domain-shareable information (overlapped users or same contexts) for a knowledge transfer, and they fail to generalize well without such requirements. To deal with these problems, we suggest utilizing review texts that are general to most e-commerce systems. Our model (named SER) uses three text analysis modules, guided by a single domain discriminator for disentangled representation learning. Here, we suggest a novel optimization strategy that can enhance the quality of domain disentanglement, and also debilitates detrimental information of a source domain. Also, we extend the encoding network from a single to multiple domains, which has proven to be powerful for review-based recommender systems. Extensive experiments and ablation studies demonstrate that our method is efficient, robust, and scalable compared to the state-of-the-art single and cross-domain recommendation methods.",10.1145/3511808.3557434,https://doi.org/10.1145/3511808.3557434,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Review-Based Domain Disentanglement without Duplicate Users or Contexts for Cross-Domain Recommendation,"Choi, Yoonhyuk and Choi, Jiho and Ko, Taewook and Byun, Hyungho and Kim, Chong-Kwon",inproceedings,10.1145/3511808.3557434,
10.1145/3511808.3557471,10.1145/3511808.3557471,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","transfer learning, recommendation system, graph neural network, attention mechanism",10,2403–2412,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Deep learning-based recommendation systems have made significant strides in recent years. However, the problem of recommendation systems' generalizability has not been solved. After the training phase, most current models can only solve problems on a particular dataset and are not as generalizable as NLP and CV models. Therefore, a large amount of computing power is required to make conventional recommendation models available to different trades. In real-world scenarios, offline retailers often opt out of recommendation algorithms due to a lack of computer capacity, which puts them at a competitive disadvantage. As a result, we propose an Interaction Graph Auto-encoder Network (IGA) based on topology-aware to address the transferable recommendation problem. IGA is composed primarily of the following components: Interaction Feature Subgraph Extraction, Subgraph Node Labeling, Subgraph Interaction Auto-encoder, and Interaction Preference Attention Network. IGA can transfer knowledge from the training dataset to the new dataset without fine-tuning and give users reliable, personalized recommendation results. Experiments on the MovieLens, Douban, LastFM, and Book-Crossing datasets demonstrate that IGA outperforms state-of-the-art approaches in transferable scenarios. Additionally, IGA requires fewer computing power and is highly adaptable across datasets.",10.1145/3511808.3557471,https://doi.org/10.1145/3511808.3557471,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,The Interaction Graph Auto-encoder Network Based on Topology-aware for Transferable Recommendation,"Yu, Ruiyun and Yang, Kang and Guo, Bingyang",inproceedings,10.1145/3511808.3557471,
10.1145/3511808.3557473,10.1145/3511808.3557473,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","time lag aware, sequential recommendation, hierarchical self-attention",10,212–221,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Although a variety of methods have been proposed for sequential recommendation, it is still far from being well solved partly due to two challenges. First, the existing methods often lack the simultaneous consideration of the global stability and local fluctuation of user preference, which might degrade the learning of a user's current preference. Second, the existing methods often use a scalar based weighting schema to fuse the long-term and short-term preferences, which is too coarse to learn an expressive embedding of current preference. To address the two challenges, we propose a novel model called Time Lag aware Sequential Recommendation (TLSRec), which integrates a hierarchical modeling of user preference and a time lag sensitive fine-grained fusion of the long-term and short-term preferences. TLSRec employs a hierarchical self-attention network to learn users' preference at both global and local time scales, and a neural time gate to adaptively regulate the contributions of the long-term and short-term preferences for the learning of a user's current preference at the aspect level and based on the lag between the current time and the time of the last behavior of a user. The extensive experiments conducted on real datasets verify the effectiveness of TLSRec.",10.1145/3511808.3557473,https://doi.org/10.1145/3511808.3557473,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Time Lag Aware Sequential Recommendation,"Chen, Lihua and Yang, Ning and Yu, Philip S.",inproceedings,10.1145/3511808.3557473,
10.1145/3511808.3557502,10.1145/3511808.3557502,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","graph analysis, cryptocurrency price prediction, blockchain data",4,5140–5143,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"The mainstream adoption of blockchains led to the preparation of many decentralized applications and web platforms, including Web 3.0, a peer-to-peer internet with no single authority. The data stored in blockchain can be considered as big data -- massive-volume, dynamic, and heterogeneous. Due to highly connected structure, graph-based modeling is an optimal tool to analyze the data stored in blockchains. Recently, several research works performed graph analysis on the publicly available blockchain data to reveal insights into its business transactions and for critical downstream tasks, e.g., cryptocurrency price prediction, phishing scams and counterfeit token detection. In this tutorial, we discuss relevant literature on blockchain data structures, storage, categories, data extraction and graphs construction, graph mining, topological data analysis, and machine learning methods used, target applications, and the new insights revealed by them, aiming towards providing a clear view of unified graph-data models for UTXO and account-based blockchains. We also emphasize future research directions.",10.1145/3511808.3557502,https://doi.org/10.1145/3511808.3557502,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Graph-based Management and Mining of Blockchain Data,"Khan, Arijit and Akcora, Cuneyt Gurcan",inproceedings,10.1145/3511808.3557502,
10.1145/3511808.3557558,10.1145/3511808.3557558,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","sentiment bias, recommender systems, causal inference",5,4014–4018,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Biases and de-biasing in recommender systems have received increasing attention recently. This study focuses on a newly identified bias, i.e., sentiment bias, which is defined as the divergence in recommendation performance between positive users/items and negative users/items. Existing methods typically employ a regularization strategy to eliminate the bias. However, blindly fitting the data without modifying the training procedure would result in a biased model, sacrificing recommendation performance.In this study, we resolve the sentiment bias with causal reasoning. We develop a causal graph to model the cause-effect relationships in recommender systems, in which the sentiment polarity presented by review text acts as a confounder between user/item representations and observed ratings. The existence of confounders inspires us to go beyond conditional probability and embrace causal inference. To that aim, we use causal intervention in model training to remove the negative effect of sentiment bias. Furthermore, during model inference, we adjust the prediction score to produce personalized recommendations. Extensive experiments on five benchmark datasets validate that the deconfounded training can remove the sentiment bias and the inference adjustment is helpful to improve recommendation accuracy.",10.1145/3511808.3557558,https://doi.org/10.1145/3511808.3557558,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Causal Intervention for Sentiment De-biasing in Recommendation,"He, Ming and Chen, Xin and Hu, Xinlei and Li, Changshu",inproceedings,10.1145/3511808.3557558,
10.1145/3511808.3557559,10.1145/3511808.3557559,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","pseudo-intervention, negative transfer, multi-task learning, feature selection, causal inference",5,3883–3887,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Multi-task learning (MTL) has been successfully applied to a wide range of real-world applications. However, MTL models often suffer from performance degradation with negative transfer due to sharing all features without distinguishing their helpfulness for all tasks. To this end, many works on feature selection for multi-task learning (FS-MTL) have been proposed to alleviate negative transfer between tasks by learning features selectively for each specific task. However, due to latent confounders between features and task targets, the correlations captured by the feature selection modules proposed in these works may fail to reflect the actual effect of the features on the targets. This paper explains negative transfer in FS-MTL from a causal perspective and presents a novel architecture called Causal Feature Selection for Multi-task Learning(CFS-MTL). This method incorporates the idea of causal inference into feature selection for multi-task learning via pseudo-intervention. It aims to select features with more stable causal effects rather than spurious correlations for each task by regularizing the distance between feature ITEs and feature importance. We conduct extensive experiments based on three real-world datasets to demonstrate that our proposed CFS-MTL outperforms state-of-the-art MTL models significantly in the AUC metric.",10.1145/3511808.3557559,https://doi.org/10.1145/3511808.3557559,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,CFS-MTL: A Causal Feature Selection Mechanism for Multi-task Learning via Pseudo-intervention,"Chen, Zhongde and Wu, Ruize and Jiang, Cong and Li, Honghui and Dong, Xin and Long, Can and He, Yong and Cheng, Lei and Mo, Linjian",inproceedings,10.1145/3511808.3557559,
10.1145/3511808.3557576,10.1145/3511808.3557576,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","recommender systems, inverse propensity scoring, graph neural networks, exposure bias, collaborative filtering",5,4128–4132,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Graph neural networks (GNNs) have achieved remarkable success in recommender systems by representing users and items based on their historical interactions. However, little attention was paid to GNN's vulnerability to exposure bias: users are exposed to a limited number of items so that a system only learns a biased view of user preference to result in suboptimal recommendation quality. Although inverse propensity weighting is known to recognize and alleviate exposure bias, it usually works on the final objective with the model outputs, whereas GNN can also be biased during neighbor aggregation. In this paper, we propose a simple but effective approach, neighbor aggregation via inverse propensity (NAVIP) for GNNs. Specifically, given a user-item bipartite graph, we first derive propensity score of each user-item interaction in the graph. Then, inverse of the propensity score with Laplacian normalization is applied to debias neighbor aggregation from exposure bias. We validate the effectiveness of our approach through our extensive experiments on two public and Amazon Alexa datasets where the performance enhances up to 14.2%.",10.1145/3511808.3557576,https://doi.org/10.1145/3511808.3557576,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Debiasing Neighbor Aggregation for Graph Neural Network in Recommender Systems,"Kim, Minseok and Oh, Jinoh and Do, Jaeyoung and Lee, Sungjin",inproceedings,10.1145/3511808.3557576,
10.1145/3511808.3557629,10.1145/3511808.3557629,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","review-based recommender systems, knowledge distillation, bias in recommender systems",5,4620–4624,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Review-based recommender systems (RRS) have received an increasing interest since reviews greatly enhance recommendation quality and interpretability. However, existing RRS suffer from high computational complexity, biased recommendation and poor generalization. The three problems make them inadequate to handle real recommendation scenarios. Previous studies address each issue separately, while none of them consider solving three problems together under a unified framework. This paper presents LUME (a Lightweight Unbiased Multi-teacher Ensemble) for RRS. LUME is a novel framework that addresses the three problems simultaneously. LUME uses multi-teacher ensemble and debiased knowledge distillation to aggregate knowledge from multiple pretrained RRS, and generates a small, unbiased student recommender which generalizes better. Extensive experiments on various real-world benchmarks demonstrate that LUME successfully tackles the three problems and has superior performance than state-of-the-art RRS and knowledge distillation based RS.",10.1145/3511808.3557629,https://doi.org/10.1145/3511808.3557629,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Lightweight Unbiased Multi-teacher Ensemble for Review-based Recommendation,"Xv, Guipeng and Liu, Xinyi and Lin, Chen and Li, Hui and Li, Chenliang and Huang, Zhenhua",inproceedings,10.1145/3511808.3557629,
10.1145/3511808.3557668,10.1145/3511808.3557668,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","recommender system, personalization, federated learning",5,4289–4293,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Federated recommendation applies federated learning techniques in recommendation systems to help protect user privacy by exchanging models instead of raw user data between user devices and the central server. Due to the heterogeneity in user's attributes and local data, attaining personalized models is critical to help improve the federated recommendation performance. In this paper, we propose a Graph Neural Network based Personalized Federated Recommendation (PerFedRec) framework via joint representation learning, user clustering, and model adaptation. Specifically, we construct a collaborative graph and incorporate attribute information to jointly learn the representation through a federated GNN. Based on these learned representations, we cluster users into different user groups and learn personalized models for each cluster. Then each user learns a personalized model by combining the global federated model, the cluster-level federated model, and the user's fine-tuned local model. To alleviate the heavy communication burden, we intelligently select a few representative users (instead of randomly picked users) from each cluster to participate in training. Experiments on real-world datasets show that our proposed method achieves superior performance over existing methods.",10.1145/3511808.3557668,https://doi.org/10.1145/3511808.3557668,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,"Personalized Federated Recommendation via Joint Representation Learning, User Clustering, and Model Adaptation","Luo, Sichun and Xiao, Yuanzhang and Song, Linqi",inproceedings,10.1145/3511808.3557668,
10.1145/3511808.3557720,10.1145/3511808.3557720,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","urban computing, geographic information systems, data mining",5,4294–4298,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Profiling urban regions is essential for urban analytics and planning. Although existing studies have made great efforts to learn urban region representation from multi-source urban data, there are still limitations on modelling local-level signals, developing an effective yet integrated fusion framework, and performing well in regions with high variance socioeconomic attributes. Thus, we propose a multi-graph representation learning framework, called Region2Vec, for urban region profiling. Specifically, except that human mobility is encoded for inter-region relations, geographic neighborhood is introduced for capturing geographical contextual information while POI side information is adopted for representing intra-region information. Then, graphs are used to capture accessibility, vicinity, and functionality correlations among regions. An encoder-decoder multi-graph fusion module is further proposed to jointly learn comprehensive representations. Experiments on real-world datasets show that Region2Vec can be employed in three applications and outperforms all state-of-the-art baselines. Particularly, Region2Vec has better performance than previous studies in regions with high variance socioeconomic attributes.",10.1145/3511808.3557720,https://doi.org/10.1145/3511808.3557720,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Urban Region Profiling via Multi-Graph Representation Learning,"Luo, Yan and Chung, Fu-lai and Chen, Kai",inproceedings,10.1145/3511808.3557720,
10.1145/3511808.3557816,10.1145/3511808.3557816,CIKM.bib,1,['CIKM.bib'],8,CIKM '22,"Atlanta, GA, USA","statistical inference, recommender systems, offline evaluation, candidate set sampling",4,5120–5123,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,"Top-N recommendation evaluation experiments are complex, with many decisions needed. These decisions are often made inconsistently, and we don't have clear best practices for many of them. The goal of this project, is to identify, substantiate, and document best practices to improve evaluations.",10.1145/3511808.3557816,https://doi.org/10.1145/3511808.3557816,"New York, NY, USA",Association for Computing Machinery,9781450392365,2022,Best Practices for Top-N Recommendation Evaluation: Candidate Set Sampling and Statistical Inference Techniques,"Ihemelandu, Ngozi",inproceedings,10.1145/3511808.3557816,
10.1145/3523227.3546753,10.1145/3523227.3546753,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Algorithms, Evaluation metrics and Studies, Novel Machine Learning Approaches",10,188–197,Proceedings of the 16th ACM Conference on Recommender Systems,"Sequential recommender systems are becoming widespread in the online retail and streaming industry. These systems are often trained to predict the next item given a sequence of a user’s recent actions, and standard evaluation metrics reward systems that can identify the most probable items that might appear next. However, some recent papers instead evaluate recommendation systems with popularity-sampled metrics, which measure how well the model can find a user’s next item when hidden amongst generally-popular items. We argue that these popularity-sampled metrics are more appropriate for recommender systems, because the most probable items for a user often include generally-popular items. If the probability that a customer will watch Toy Story is not much more probable than for the average customer, then the movie isn’t especially relevant for them and we should not recommend it. This paper shows that optimizing popularity-sampled metrics is closely related to estimating point-wise mutual information (PMI). We propose and compare two techniques to fit PMI directly, which both improve popularity-sampled metrics for state-of-the-art recommender systems. The improvements are large compared to differences between recently-proposed model architectures.",10.1145/3523227.3546753,https://doi.org/10.1145/3523227.3546753,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Don’t recommend the obvious: estimate probability ratios,"Pellegrini, Roberto and Zhao, Wenjie and Murray, Iain",inproceedings,10.1145/3523227.3546753,
10.1145/3523227.3546757,10.1145/3523227.3546757,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","model bias, popularity bias, recommender systems, regularization",11,145–155,Proceedings of the 16th ACM Conference on Recommender Systems,"Recommendation system often suffers from popularity bias. Often the training data inherently exhibits long-tail distribution in item popularity (data bias). Moreover, the recommendation systems could give unfairly higher recommendation scores to popular items even among items a user equally liked, resulting in over-recommendation of popular items (model bias). In this study we propose a novel method to reduce the model bias while maintaining accuracy by directly regularizing the recommendation scores to be equal across items a user preferred. Akin to contrastive learning, we extend the widely used pairwise loss (BPR loss) which maximizes the score differences between preferred and unpreferred items, with a regularization term that minimizes the score differences within preferred and unpreferred items, respectively, thereby achieving both high debias and high accuracy performance with no additional training. To test the effectiveness of the proposed method, we design an experiment using a synthetic dataset which induces model bias with baseline training; we showed applying the proposed method resulted in drastic reduction of model bias while maintaining accuracy. Comprehensive comparison with earlier debias methods showed the proposed method had advantages in terms of computational validity and efficiency. Further empirical experiments utilizing four benchmark datasets and four recommendation models indicated the proposed method showed general improvements over performances of earlier debias methods. We hope that our method could help users enjoy diverse recommendations promoting serendipitous findings. Code available at https://github.com/stillpsy/popbias.",10.1145/3523227.3546757,https://doi.org/10.1145/3523227.3546757,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Countering Popularity Bias by Regularizing Score Differences,"Rhee, Wondo and Cho, Sung Min and Suh, Bongwon",inproceedings,10.1145/3523227.3546757,
10.1145/3523227.3546758,10.1145/3523227.3546758,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","batch RL, off-policy actor-critic, pessimism, recommender systems, reinforcement learning",12,338–349,Proceedings of the 16th ACM Conference on Recommender Systems,"Industrial recommendation platforms are increasingly concerned with how to make recommendations that cause users to enjoy their long term experience on the platform. Reinforcement learning emerged naturally as an appealing approach for its promise in 1) combating feedback loop effect resulted from myopic system behaviors; and 2) sequential planning to optimize long term outcome. Scaling RL algorithms to production recommender systems serving billions of users and contents, however remain challenging. Sample inefficiency and instability of online RL hinder its widespread adoption in production. Offline RL enables usage of off-policy data and batch learning. It on the other hand faces significant challenges in learning due to the distribution shift. A REINFORCE agent&nbsp;[3] was successfully tested for YouTube recommendation, significantly outperforming a sophisticated supervised learning production system. Off-policy correction was employed to learn from logged data. The algorithm partially mitigates the distribution shift by employing a one-step importance weighting. We resort to the off-policy actor critic algorithms to addresses the distribution shift to a better extent. Here we share the key designs in setting up an off-policy actor-critic agent for production recommender systems. It extends &nbsp;[3] with a critic network that estimates the value of any state-action pairs under the target learned policy through temporal difference learning. We demonstrate in offline and live experiments that the new framework out-performs baseline and improves long term user experience. An interesting discovery along our investigation is that recommendation agents that employ a softmax policy parameterization, can end up being too pessimistic about out-of-distribution (OOD) actions. Finding the right balance between pessimism and optimism on OOD actions is critical to the success of offline RL for recommender systems.",10.1145/3523227.3546758,https://doi.org/10.1145/3523227.3546758,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Off-Policy Actor-critic for Recommender Systems,"Chen, Minmin and Xu, Can and Gatto, Vince and Jain, Devanshu and Kumar, Aviral and Chi, Ed",inproceedings,10.1145/3523227.3546758,
10.1145/3523227.3546763,10.1145/3523227.3546763,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Collaborative Filtering, Next Basket Recommendation, Recommender Systems",11,316–326,Proceedings of the 16th ACM Conference on Recommender Systems,"The problem of Next Basket Recommendation (NBR) addresses the challenge of recommending items for the next basket of a user, based on her sequence of prior baskets. In this paper, we focus on a variation of this problem in which we aim to predict repurchases, i.e. we wish to recommend a user only items she had purchased before. We coin this problem Next Basket Repurchase Recommendation (NBRR). Over the years, a variety of models have been proposed to address the problem of NBR, however, the problem of NBRR has been overlooked. Although being highly related problems, which are often solved by the same methods, the problem of repurchase recommendation calls for a different approach. In this paper, we share insights from our experience of facing the challenge of NBRR. In light of these insights, we propose a novel hyper-convolutional model to leverage the behavioral patterns of repeated purchases. We demonstrate the effectiveness of the proposed model on three publicly available datasets, where it is shown to outperform other existing methods across multiple metrics.",10.1145/3523227.3546763,https://doi.org/10.1145/3523227.3546763,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Learning to Ride a Buy-Cycle: A Hyper-Convolutional Model for Next Basket Repurchase Recommendation,"Katz, Ori and Barkan, Oren and Koenigstein, Noam and Zabari, Nir",inproceedings,10.1145/3523227.3546763,
10.1145/3523227.3546766,10.1145/3523227.3546766,RecSys.bib,1,['RecSys.bib'],7,RecSys '22,"Seattle, WA, USA",,11,134–144,Proceedings of the 16th ACM Conference on Recommender Systems,"Podcasting is an increasingly popular medium for entertainment and discourse around the world, with tens of thousands of new podcasts released on a monthly basis. We consider the problem of identifying from these newly-released podcasts those with the largest potential audiences so they can be considered for personalized recommendation to users. We first study and then discard a supervised approach due to the inadequacy of either content or consumption features for this task, and instead propose a novel non-contextual bandit algorithm in the fixed-budget infinitely-armed pure-exploration setting. We demonstrate that our algorithm is well-suited to the best-arm identification task for a broad class of arm reservoir distributions, out-competing a large number of state-of-the-art algorithms. We then apply the algorithm to identifying podcasts with broad appeal in a simulated study, and show that it efficiently sorts podcasts into groups by increasing appeal while avoiding the popularity bias inherent in supervised approaches.",10.1145/3523227.3546766,https://doi.org/10.1145/3523227.3546766,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Identifying New Podcasts with High General Appeal Using a Pure Exploration Infinitely-Armed Bandit Strategy,"Aziz, Maryam and Anderton, Jesse and Jamieson, Kevin and Wang, Alice and Bouchard, Hugues and Aslam, Javed",inproceedings,10.1145/3523227.3546766,
10.1145/3523227.3546767,10.1145/3523227.3546767,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Language Modeling, Multitask Learning, Natural Language Processing, Personalized Prompt, Recommender Systems, Unified Model",17,299–315,Proceedings of the 16th ACM Conference on Recommender Systems,"For a long time, different recommendation tasks require designing task-specific architectures and training objectives. As a result, it is hard to transfer the knowledge and representations from one task to another, thus restricting the generalization ability of existing recommendation approaches. To deal with such issues, considering that language can describe almost anything and language grounding is a powerful medium to represent various problems or tasks, we present a flexible and unified text-to-text paradigm called “Pretrain, Personalized Prompt, and Predict Paradigm” (P5) for recommendation, which unifies various recommendation tasks in a shared framework. In P5, all data such as user-item interactions, user descriptions, item metadata, and user reviews are converted to a common format — natural language sequences. The rich information from natural language assists P5 to capture deeper semantics for personalization and recommendation. Specifically, P5 learns different tasks with the same language modeling objective during pretraining. Thus, it serves as the foundation model for various downstream recommendation tasks, allows easy integration with other modalities, and enables instruction-based recommendation. P5 advances recommender systems from shallow model to deep model to big model, and will revolutionize the technical form of recommender systems towards universal recommendation engine. With adaptive personalized prompt for different users, P5 is able to make predictions in a zero-shot or few-shot manner and largely reduces the necessity for extensive fine-tuning. On several benchmarks, we conduct experiments to show the effectiveness of P5. To help advance future research on Recommendation as Language Processing (RLP), Personalized Foundation Models (PFM), and Universal Recommendation Engine (URE), we release the source code, dataset, prompts, and pretrained P5 model at https://github.com/jeykigung/P5.",10.1145/3523227.3546767,https://doi.org/10.1145/3523227.3546767,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,"Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt &amp; Predict Paradigm (P5)","Geng, Shijie and Liu, Shuchang and Fu, Zuohui and Ge, Yingqiang and Zhang, Yongfeng",inproceedings,10.1145/3523227.3546767,
10.1145/3523227.3546770,10.1145/3523227.3546770,RecSys.bib,1,['RecSys.bib'],7,RecSys '22,"Seattle, WA, USA",,12,59–70,Proceedings of the 16th ACM Conference on Recommender Systems,"While sequential recommender systems achieve significant improvements on capturing user dynamics, we argue that sequential recommenders are vulnerable against substitution-based profile pollution attacks. To demonstrate our hypothesis, we propose a substitution-based adversarial attack algorithm, which modifies the input sequence by selecting certain vulnerable elements and substituting them with adversarial items. In both untargeted and targeted attack scenarios, we observe significant performance deterioration using the proposed profile pollution algorithm. Motivated by such observations, we design an efficient adversarial defense method called Dirichlet neighborhood sampling. Specifically, we sample item embeddings from a convex hull constructed by multi-hop neighbors to replace the original items in input sequences. During sampling, a Dirichlet distribution is used to approximate the probability distribution in the neighborhood such that the recommender learns to combat local perturbations. Additionally, we design an adversarial training method tailored for sequential recommender systems. In particular, we represent selected items with one-hot encodings and perform gradient ascent on the encodings to search for the worst case linear combination of item embeddings in training. As such, the embedding function learns robust item representations and the trained recommender is resistant to test-time adversarial examples. Extensive experiments show the effectiveness of both our attack and defense methods, which consistently outperform baselines by a significant margin across model architectures and datasets.",10.1145/3523227.3546770,https://doi.org/10.1145/3523227.3546770,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Defending Substitution-Based Profile Pollution Attacks on Sequential Recommenders,"Yue, Zhenrui and Zeng, Huimin and Kou, Ziyi and Shang, Lanyu and Wang, Dong",inproceedings,10.1145/3523227.3546770,
10.1145/3523227.3546771,10.1145/3523227.3546771,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Fairness, Federated Learning, Recommendation System",11,168–178,Proceedings of the 16th ACM Conference on Recommender Systems,"Achieving fairness over different user groups in recommender systems is an important problem. The majority of existing works achieve fairness through constrained optimization that combines the recommendation loss and the fairness constraint. To achieve fairness, the algorithm usually needs to know each user’s group affiliation feature such as gender or race. However, such involved user group feature is usually sensitive and requires protection. In this work, we seek a federated learning solution for the fair recommendation problem and identify the main challenge as an algorithmic conflict between the global fairness objective and the localized federated optimization process. On one hand, the fairness objective usually requires access to all users’ group information. On the other hand, the federated learning systems restrain the personal data in each user’s local space. As a resolution, we propose to communicate group statistics during federated optimization and use differential privacy techniques to avoid exposure of users’ group information when users require privacy protection. We illustrate the theoretical bounds of the noisy signal used in our method that aims to enforce privacy without overwhelming the aggregated statistics. Empirical results show that federated learning may naturally improve user group fairness and the proposed framework can effectively control this fairness with low communication overheads.",10.1145/3523227.3546771,https://doi.org/10.1145/3523227.3546771,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Fairness-aware Federated Matrix Factorization,"Liu, Shuchang and Ge, Yingqiang and Xu, Shuyuan and Zhang, Yongfeng and Marian, Amelie",inproceedings,10.1145/3523227.3546771,
10.1145/3523227.3546773,10.1145/3523227.3546773,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","e-commerce, hierarchical attention network, item attribute change, product recommendation",10,278–287,Proceedings of the 16th ACM Conference on Recommender Systems,"Traditional recommendation systems mainly focus on modeling user interests. However, the dynamics of recommended items caused by attribute modifications (e.g. changes in prices) are also of great importance in real systems, especially in the fast-growing e-commerce environment, which may cause the users’ demands to emerge, shift and disappear. Recent studies that make efforts on dynamic item representations treat the item attributes as side information but ignore its temporal dependency, or model the item evolution with a sequence of related users but do not consider item attributes. In this paper, we propose Core Attribute Evolution Network (CAEN), which partitions the user sequence according to the attribute value and thus models the item evolution over attribute dynamics with these users. Under this framework, we further devise a hierarchical attention mechanism that applies attribute-aware attention for user aggregation under each attribute, as well as personalized attention for activating similar users in assessing the matching degree between target user and item. Results from the extensive experiments over actual e-commerce datasets show that our approach outperforms the state-of-art methods and achieves significant improvements on the items with rapid changes over attributes, therefore helping the item recommendation to adapt to the growth of the e-commerce platform.",10.1145/3523227.3546773,https://doi.org/10.1145/3523227.3546773,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,CAEN: A Hierarchically Attentive Evolution Network for Item-Attribute-Change-Aware Recommendation in the Growing E-commerce Environment,"Ma, Rui and Liu, Ning and Yuan, Jingsong and Yang, Huafeng and Zhang, Jiandong",inproceedings,10.1145/3523227.3546773,
10.1145/3523227.3546777,10.1145/3523227.3546777,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Attribute-Aware Recommendation, Context-Aware Recommendation, Cross Multi-Head Attention, Sequential Recommendation",10,71–80,Proceedings of the 16th ACM Conference on Recommender Systems,"In sparse recommender settings, users’ context and item attributes play a crucial role in deciding which items to recommend next. Despite that, recent works in sequential and time-aware recommendations usually either ignore both aspects or only consider one of them, limiting their predictive performance. In this paper, we address these limitations by proposing a context and attribute-aware recommender model (CARCA) that can capture the dynamic nature of the user profiles in terms of contextual features and item attributes via dedicated multi-head self-attention blocks that extract profile-level features and predict item scores. Also, unlike many of the current state-of-the-art sequential item recommendation approaches that use a simple dot-product between the most recent item’s latent features and the target items embeddings for scoring, CARCA uses cross-attention between all profile items and the target items to predict their final scores. This cross-attention allows CARCA to harness the correlation between old and recent items in the user profile and their influence on deciding which item to recommend next. Experiments on four real-world recommender system datasets show that the proposed model significantly outperforms all state-of-the-art models in the task of item recommendation and achieving improvements of up to 53% in Normalized Discounted Cumulative Gain (NDCG) and Hit-Ratio. Results also show that CARCA outperformed several state-of-the-art dedicated image-based recommender systems by merely utilizing image attributes extracted from a pre-trained ResNet50 in a black-box fashion.",10.1145/3523227.3546777,https://doi.org/10.1145/3523227.3546777,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Context and Attribute-Aware Sequential Recommendation via Cross-Attention,"Rashed, Ahmed and Elsayed, Shereen and Schmidt-Thieme, Lars",inproceedings,10.1145/3523227.3546777,
10.1145/3523227.3547409,10.1145/3523227.3547409,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","counterfactuals, fairness in rankings, off-policy evaluation and learning, recommender systems",4,654–657,Proceedings of the 16th ACM Conference on Recommender Systems,"Recommender systems are more and more often modelled as repeated decision making processes – deciding which (ranking of) items to recommend to a given user. Each decision to recommend or rank an item has a significant impact on immediate and future user responses, long-term satisfaction or engagement with the system, and possibly valuable exposure for the item provider. This interactive and interventionist view of the recommender uncovers a plethora of unanswered research questions, as it complicates the typically adopted offline evaluation or learning procedures in the field. We need an understanding of causal inference to reason about (possibly unintended) consequences of the recommender, and a notion of counterfactuals to answer common “what if”-type questions in learning and evaluation. Advances at the intersection of these fields can foster progress in effective, efficient and fair learning and evaluation from logged data. These topics have been emerging in the Recommender Systems community for a while, but we firmly believe in the value of a dedicated forum and place to learn and exchange ideas. We welcome contributions from both academia and industry and bring together a growing community of researchers and practitioners interested in sequential decision making, offline evaluation, batch policy learning, fairness in online platforms, as well as other related tasks, such as A/B testing.",10.1145/3523227.3547409,https://doi.org/10.1145/3523227.3547409,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,"CONSEQUENCES — Causality, Counterfactuals and Sequential Decision-Making for Recommender Systems","Jeunen, Olivier and Joachims, Thorsten and Oosterhuis, Harrie and Saito, Yuta and Vasile, Flavian",inproceedings,10.1145/3523227.3547409,
10.1145/3523227.3547418,10.1145/3523227.3547418,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","multi-armed bandits, off-policy, recommender systems, reinforcement learning",2,684–685,Proceedings of the 16th ACM Conference on Recommender Systems,"Recommendation systems are increasingly modelled as a sequential decision making process, where the system decides which items to recommend to a given user. Each decision to recommend an item or slate of items has a significant impact on immediate and future user responses, long-term satisfaction or engagement with the system, and possibly valuable exposure for the item provider. The REVEAL workshop will focus on how to optimise this multi-step decision-making process, where a stream of interactions occurs between the user and the system. Deriving reward signals from these interactions, and creating a scalable, performant, and maintainable recommendation model to use for inference is a key challenge for machine learning teams, both in industry and academia. We will discuss the following challenges at the workshop: How can recommendation system models take into account the delayed effects of each recommendation? What are the right ways to reason and plan for longer-term user satisfaction? How can we leverage techniques such as Reinforcement Learning (RL) at scale?",10.1145/3523227.3547418,https://doi.org/10.1145/3523227.3547418,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,REVEAL 2022: Reinforcement Learning-Based Recommender Systems at Scale,"Liaw, Richard and Bailey, Paige and Li, Ying and Dimakopoulou, Maria and Raimond, Yves",inproceedings,10.1145/3523227.3547418,
10.1145/3523227.3548485,10.1145/3523227.3548485,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Evaluation, Incremental Updates, Reproducibility, Session-based Recommendation, Stream-based Recommendation",7,420–426,Proceedings of the 16th ACM Conference on Recommender Systems,"Frequent updates and model retraining are important in various application areas of recommender systems, e.g., news recommendation. Moreover, in such domains, we may not only face the problem of dealing with a constant stream of new data, but also with anonymous users, leading to the problem of streaming session-based recommendation (SSR). Such problem settings have attracted increased interest in recent years, and different deep learning architectures were proposed that support fast updates of the underlying prediction models when new data arrive. In a recent paper, a method based on Graph Neural Networks (GNN) was proposed as being superior than previous methods for the SSR problem. The baselines in the reported experiments included different machine learning models. However, several earlier studies have shown that often conceptually simpler methods, e.g., based on nearest neighbors, can be highly effective for session-based recommendation problems. In this work, we report a similar phenomenon for the streaming configuration. We first reproduce the results of the mentioned GNN method and then show that simpler methods are able to outperform this complex state-of-the-art neural method on two datasets. Overall, our work points to continued methodological issues in the academic community, e.g., in terms of the choice of baselines and reproducibility.1",10.1145/3523227.3548485,https://doi.org/10.1145/3523227.3548485,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Streaming Session-Based Recommendation: When Graph Neural Networks meet the Neighborhood,"Latifi, Sara and Jannach, Dietmar",inproceedings,10.1145/3523227.3548485,
10.1145/3523227.3548486,10.1145/3523227.3548486,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Benchmark, Item Recommendation, Recommender System, iALS",9,427–435,Proceedings of the 16th ACM Conference on Recommender Systems,"Matrix factorization learned by implicit alternating least squares (iALS) is a popular baseline in recommender system research publications. iALS is known to be one of the most computationally efficient and scalable collaborative filtering methods. However, recent studies suggest that its prediction quality is not competitive with the current state of the art, in particular autoencoders and other item-based collaborative filtering methods. In this work, we revisit four well-studied benchmarks where iALS was reported to perform poorly and show that with proper tuning, iALS is highly competitive and outperforms any method on at least half of the comparisons. We hope that these high quality results together with iALS’s known scalability spark new interest in applying and further improving this decade old technique.",10.1145/3523227.3548486,https://doi.org/10.1145/3523227.3548486,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,Revisiting the Performance of iALS on Item Recommendation Benchmarks,"Rendle, Steffen and Krichene, Walid and Zhang, Li and Koren, Yehuda",inproceedings,10.1145/3523227.3548486,
10.1145/3523227.3551472,10.1145/3523227.3551472,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Python, evaluation, implicit feedback data, open-source framework, top-N recommendation",4,648–651,Proceedings of the 16th ACM Conference on Recommender Systems,"RecPack is an easy-to-use, flexible and extensible toolkit for top-N recommendation with implicit feedback data. Its goal is to support researchers with the development of their recommendation algorithms, from similarity-based to deep learning algorithms, and allow for correct, reproducible and reusable experimentation. In this demo, we give an overview of the package and show how researchers can use it to their advantage when developing recommendation algorithms.",10.1145/3523227.3551472,https://doi.org/10.1145/3523227.3551472,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,RecPack: An(other) Experimentation Toolkit for Top-N Recommendation using Implicit Feedback Data,"Michiels, Lien and Verachtert, Robin and Goethals, Bart",inproceedings,10.1145/3523227.3551472,
10.1145/3523227.3551479,10.1145/3523227.3551479,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Explicit feedback granularity, Performance evaluation, Recommender systems",6,586–591,Proceedings of the 16th ACM Conference on Recommender Systems,"The main source of knowledge utilized in recommender systems (RS) is users’ feedback. While the usage of implicit feedback (i.e. user’s behavior statistics) is gaining in prominence, the explicit feedback (i.e. user’s ratings) remain an important data source. This is true especially for domains, where evaluation of an object does not require an extensive usage and users are well motivated to do so (e.g., video-on-demand services or library archives). So far, numerous rating schemes for explicit feedback have been proposed, ranging both in granularity and presentation style. There are several works studying the effect of rating’s scale and presentation on user’s rating behavior, e.g. willingness to provide feedback or various biases in rating behavior. Nonetheless, the effect of ratings granularity on RS performance remain largely under-researched. In this paper, we studied the combined effect of ratings granularity and supposed probability of feedback existence on various performance statistics of recommender systems. Results indicate that decreasing feedback granularity may lead to changes in RS’s performance w.r.t. nDCG for some recommending algorithms. Nonetheless, in most cases the effect of feedback granularity is surpassed by even a small decrease in feedback’s quantity. Therefore, our results corroborate the policy of many major real-world applications, i.e. preference of simpler rating schemes with the higher chance of feedback reception instead of finer-grained rating scenarios.",10.1145/3523227.3551479,https://doi.org/10.1145/3523227.3551479,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,The Effect of Feedback Granularity on Recommender Systems Performance,"Peska, Ladislav and Balcar, Stepan",inproceedings,10.1145/3523227.3551479,
10.1145/3523227.3552534,10.1145/3523227.3552534,RecSys.bib,1,['RecSys.bib'],8,RecSys '22,"Seattle, WA, USA","Competition, Dataset, Fashion Recommendation, Recommender Systems, Session-based",4,694–697,Proceedings of the 16th ACM Conference on Recommender Systems,"The RecSys 2022 Challenge was a session-based recommendation task in the fashion domain. The dataset was supplied by Dressipi. Given session data consisting of views and purchases, as well as content data representing the fashion characteristics of the items, the task was to predict which item was purchased at the end of the session. The challenge ran for 3 months with a public leaderboard and final result on a separate hidden test set. There were over 300 teams that submitted a solution to the leaderboard and about 50 that submitted a solution for the final test set. The winning team achieved a MRR score of 0.216 which means that the correct target item was on average ranked 5th in the list of predictions. We identify some interesting common themes among the solutions in this paper and the winning approaches are presented in the workshop.",10.1145/3523227.3552534,https://doi.org/10.1145/3523227.3552534,"New York, NY, USA",Association for Computing Machinery,9781450392785,2022,RecSys Challenge 2022: Fashion Purchase Prediction,"Landia, Nick and Cheung, Frederick and North, Donna and Kalloori, Saikishore and Srivastava, Abhishek and Ferwerda, Bruce",inproceedings,10.1145/3523227.3552534,
10.1145/3534678.3539092,10.1145/3534678.3539092,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","causal intervention, duration bias, video recommendation, watch-time prediction",10,4472–4481,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Watch-time prediction remains to be a key factor in reinforcing user engagement via video recommendations. It has become increasingly important given the ever-growing popularity of online videos. However, prediction of watch time not only depends on the match between the user and the video but is often mislead by the duration of the video itself. With the goal of improving watch time, recommendation is always biased towards videos with long duration. Models trained on this imbalanced data face the risk of bias amplification, which misguides platforms to over-recommend videos with long duration but overlook the underlying user interests. This paper presents the first work to study duration bias in watch-time prediction for video recommendation. We employ a causal graph illuminating that duration is a confounding factor that concurrently affects video exposure and watch-time prediction---the first effect on video causes the bias issue and should be eliminated, while the second effect on watch time originates from video intrinsic characteristics and should be preserved. To remove the undesired bias but leverage the natural effect, we propose a Duration-Deconfounded Quantile-based (D2Q) watch-time prediction framework, which allows for scalability to perform on industry production systems. Through extensive offline evaluation and live experiments, we showcase the effectiveness of this duration-deconfounding framework by significantly outperforming the state-of-the-art baselines. We have fully launched our approach on Kuaishou App, which has substantially improved real-time video consumption due to more accurate watch-time predictions.",10.1145/3534678.3539092,https://doi.org/10.1145/3534678.3539092,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Deconfounding Duration Bias in Watch-time Prediction for Video Recommendation,"Zhan, Ruohan and Pei, Changhua and Su, Qiang and Wen, Jianfeng and Wang, Xueliang and Mu, Guanyu and Zheng, Dong and Jiang, Peng and Gai, Kun",inproceedings,10.1145/3534678.3539092,
10.1145/3534678.3539098,10.1145/3534678.3539098,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","fin-tech, machine learning, rating migration",9,4452–4460,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Corporate credit ratings issued by third-party rating agencies are quantified assessments of a company's creditworthiness. Credit Ratings highly correlate to the likelihood of a company defaulting on its debt obligations. These ratings play critical roles in investment decision-making as one of the key risk factors. They are also central to the regulatory framework such as BASEL II in calculating necessary capital for financial institutions. Being able to predict rating changes will greatly benefit both investors and regulators alike. In this paper, we consider the corporate credit rating migration early prediction problem, which predicts the credit rating of an issuer will be upgraded, unchanged, or downgraded after 12 months based on its latest financial reporting information at the time. We investigate the effectiveness of different standard machine learning algorithms and conclude these models deliver inferior performance. As part of our contribution, we propose a new Multi-task Envisioning Transformer-based Autoencoder (META) model to tackle this challenging problem. META consists of Positional Encoding, Transformer-based Autoencoder, and Multi-task Prediction to learn effective representations for both migration prediction and rating prediction. This enables META to better explore the historical data in the training stage for one-year later prediction. Experimental results show that META outperforms all baseline models.",10.1145/3534678.3539098,https://doi.org/10.1145/3534678.3539098,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Multi-task Envisioning Transformer-based Autoencoder for Corporate Credit Rating Migration Early Prediction,"Yue, Han and Xia, Steve and Liu, Hongfu",inproceedings,10.1145/3534678.3539098,
10.1145/3534678.3539103,10.1145/3534678.3539103,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","generalized deep mixed model, neural networks, recommender systems, response prediction",9,3869–3877,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"We introduce generalized deep mixed model (GDMix), a class of machine learning models for large-scale recommender systems that combines the power of deep neural networks and the efficiency of logistic regression. GDMix leverages state-of-the-art deep neural networks (DNNs) as the global models (fixed effects), and further improves the performance by adding entity-specific personalized models (random effects). For instance, the click response from a particular user m to a job posting j may consist of contributions from a DNN model common to all users and job postings, a model specific to the user m and a model specific to the job j. GDMix models not only possess powerful modeling capabilities but also enjoy high training efficiency especially for web-scale recommender systems. We demonstrate the capabilities by detailing their use in Feed and Ads recommendation at LinkedIn. The source code for the GDMix training framework is available at https://github.com/linkedin/gdmix https://github.com/linkedin/gdmix under the BSD-2-Clause License.",10.1145/3534678.3539103,https://doi.org/10.1145/3534678.3539103,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Generalized Deep Mixed Models,"Shi, Jun and Jiang, Chengming and Gupta, Aman and Zhou, Mingzhou and Ouyang, Yunbo and Xiao, Qiang Charles and Song, Qingquan and Wu, Yi (Alice) and Wei, Haichao and Gao, Huiji",inproceedings,10.1145/3534678.3539103,
10.1145/3534678.3539161,10.1145/3534678.3539161,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","cross-platform tool, hate intensity reduction, hate normalization, online hate speech, proactive strategy, span detection",11,3524–3534,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Curbing online hate speech has become the need of the hour; however, a blanket ban on such activities is infeasible for several geopolitical and cultural reasons. To reduce the severity of the problem, in this paper, we introduce a novel task, hate speech normalization, that aims to weaken the intensity of hatred exhibited by an online post. The intention of hate speech normalization is not to support hate but instead to provide the users with a stepping stone towards non-hate while giving online platforms more time to monitor any improvement in the user's behavior. To this end, we manually curated a parallel corpus - hate texts and their normalized counterparts (a normalized text is less hateful and more benign). We introduce NACL, a simple yet efficient hate speech normalization model that operates in three stages - first, it measures the hate intensity of the original sample; second, it identifies the hate span(s) within it; and finally, it reduces hate intensity by paraphrasing the hate spans. We perform extensive experiments to measure the efficacy of NACL via three-way evaluation (intrinsic, extrinsic, and human-study). We observe that NACL outperforms six baselines - NACL yields a score of 0.1365 RMSE for the intensity prediction, 0.622 F1-score in the span identification, and 82.27 BLEU and 80.05 perplexity for the normalized text generation. We further show the generalizability of NACL across other platforms (Reddit, Facebook, Gab). An interactive prototype of NACL was put together for the user study. Further, the tool is being deployed in a real-world setting at Wipro AI as a part of its mission to tackle harmful content on online platforms.",10.1145/3534678.3539161,https://doi.org/10.1145/3534678.3539161,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Proactively Reducing the Hate Intensity of Online Posts via Hate Speech Normalization,"Masud, Sarah and Bedi, Manjot and Khan, Mohammad Aflah and Akhtar, Md Shad and Chakraborty, Tanmoy",inproceedings,10.1145/3534678.3539161,
10.1145/3534678.3539193,10.1145/3534678.3539193,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","mobile notifications, offline evaluation, reinforcement learning",9,3752–3760,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Mobile notification systems play a major role in a variety of applications to communicate, send alerts and reminders to the users to inform them about news, events or messages. In this paper, we formulate the near-real-time notification decision problem as a Markov Decision Process where we optimize for multiple objectives in the rewards. We propose an end-to-end offline reinforcement learning framework to optimize sequential notification decisions. We address the challenge of offline learning using a Double Deep Q-network method based on Conservative Q-learning that mitigates the distributional shift problem and Q-value overestimation. We illustrate our fully-deployed system and demonstrate the performance and benefits of the proposed approach through both offline and online experiments.",10.1145/3534678.3539193,https://doi.org/10.1145/3534678.3539193,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Multi-objective Optimization of Notifications Using Offline Reinforcement Learning,"Prabhakar, Prakruthi and Yuan, Yiping and Yang, Guangyu and Sun, Wensheng and Muralidharan, Ajith",inproceedings,10.1145/3534678.3539193,
10.1145/3534678.3539194,10.1145/3534678.3539194,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","backward compatibility, embeddings, graph neural networks, recommender systems",11,3018–3028,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Embeddings, low-dimensional vector representation of objects, are fundamental in building modern machine learning systems. In industrial settings, there is usually an embedding team that trains an embedding model to solve intended tasks (e.g., product recommendation). The produced embeddings are then widely consumed by consumer teams to solve their unintended tasks (e.g., fraud detection). However, as the embedding model gets updated and retrained to improve performance on the intended task, the newly-generated embeddings are no longer compatible with the existing consumer models. This means that historical versions of the embeddings can never be retired or all consumer teams have to retrain their models to make them compatible with the latest version of the embeddings, both of which are extremely costly in practice.  Here we study the problem of embedding version updates and their backward compatibility. We formalize the problem where the goal is for the embedding team to keep updating the embedding version, while the consumer teams do not have to retrain their models. We develop a solution based on learning backward compatible embeddings, which allows the embedding model version to be updated frequently, while also allowing the latest version of the embedding to be quickly transformed into any backward compatible historical version of it, so that consumer teams do not have to retrain their models. Our key idea is that whenever a new embedding model is trained, we learn it together with a light-weight backward compatibility transformation that aligns the new embedding to the previous version of it. Our learned backward transformations can then be composed to produce any historical version of embedding. Under our framework, we explore six methods and systematically evaluate them on a real-world recommender system application. We show that the best method, which we call BC-Aligner, maintains backward compatibility with existing unintended tasks even after multiple model version updates. Simultaneously, BC-Aligner achieves the intended task performance similar to the embedding model that is solely optimized for the intended task. Code is publicly available at https://github.com/snap-stanford/bc-emb",10.1145/3534678.3539194,https://doi.org/10.1145/3534678.3539194,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Learning Backward Compatible Embeddings,"Hu, Weihua and Bansal, Rajas and Cao, Kaidi and Rao, Nikhil and Subbian, Karthik and Leskovec, Jure",inproceedings,10.1145/3534678.3539194,
10.1145/3534678.3539240,10.1145/3534678.3539240,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","deconfounder, recommendation, unmeasured confounder",11,305–315,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Recommender systems should answer the intervention question ""if recommending an item to a user, what would the feedback be"", calling for estimating the causal effect of a recommendation on user feedback. Generally, this requires blocking the effect of confounders that simultaneously affect the recommendation and feedback. To mitigate the confounding bias, a strategy is incorporating propensity into model learning. However, existing methods forgo possible unmeasured confounders (e.g., user financial status), which can result in biased propensities and hurt recommendation performance. This work combats the risk of unmeasured confounders in recommender systems.  Towards this end, we propose Robust Deconfounder (RD) that accounts for the effect of unmeasured confounders on propensities, under the mild assumption that the effect is bounded. It estimates the bound with sensitivity analysis, learning a recommender model robust to unmeasured confounders within the bound by adversarial learning. However, pursuing robustness within a bound may restrict model accuracy. To avoid the trade-off between robustness and accuracy, we further propose Benchmarked RD (BRD) that incorporates a pre-trained model into the learning as the benchmark. Theoretical analyses prove the stronger robustness of our methods compared to existing propensity-based deconfounders, and also prove the no-harm property of BRD. Our methods are applicable to any propensity-based estimators, where we select three representative ones: IPS, Doubly Robust, and AutoDebias. We conduct experiments on three real-world datasets to demonstrate the effectiveness of our methods.",10.1145/3534678.3539240,https://doi.org/10.1145/3534678.3539240,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Addressing Unmeasured Confounder for Recommendation with Sensitivity Analysis,"Ding, Sihao and Wu, Peng and Feng, Fuli and Wang, Yitong and He, Xiangnan and Liao, Yong and Zhang, Yongdong",inproceedings,10.1145/3534678.3539240,
10.1145/3534678.3539269,10.1145/3534678.3539269,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","fairness, meta-learning, recommender systems",11,1989–1999,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"In recommender systems, one common challenge is the cold-start problem, where interactions are very limited for fresh users in the systems. To address this challenge, recently, many works introduce the meta-optimization idea into the recommendation scenarios, i.e. learning to learn the user preference by only a few past interaction items. The core idea is to learn global shared meta-initialization parameters for all users and rapidly adapt them into local parameters for each user respectively. They aim at deriving general knowledge across preference learning of various users, so as to rapidly adapt to the future new user with the learned prior and a small amount of training data. However, previous works have shown that recommender systems are generally vulnerable to bias and unfairness. Despite the success of meta-learning at improving the recommendation performance with cold-start, the fairness issues are largely overlooked.In this paper, we propose a comprehensive fair meta-learning framework, named CLOVER, for ensuring the fairness of meta-learned recommendation models. We systematically study three kinds of fairness - individual fairness, counterfactual fairness, and group fairness in the recommender systems, and propose to satisfy all three kinds via a multi-task adversarial learning scheme. Our framework offers a generic training paradigm that is applicable to different meta-learned recommender systems. We demonstrate the effectiveness of CLOVER on the representative meta-learned user preference estimator on three real-world data sets. Empirical results show that CLOVER achieves comprehensive fairness without deteriorating the overall cold-start recommendation performance.",10.1145/3534678.3539269,https://doi.org/10.1145/3534678.3539269,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Comprehensive Fair Meta-learned Recommender System,"Wei, Tianxin and He, Jingrui",inproceedings,10.1145/3534678.3539269,
10.1145/3534678.3539306,10.1145/3534678.3539306,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","graph neural networks, missing value imputation, neural networks, recommendation",11,773–783,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Graph representations of a target domain often project it to a set of entities (nodes) and their relations (edges). However, such projections often miss important and rich information. For example, in graph representations used in missing value imputation, items --- represented as nodes --- may contain rich textual information. However, when processing graphs with graph neural networks (GNN), such information is either ignored or summarized into a single vector representation used to initialize the GNN. Towards addressing this, we present CoRGi, a GNN that considers the rich data within nodes in the context of their neighbors. This is achieved by endowing CoRGi's message passing with a personalized attention mechanism over the content of each node. This way, CoRGi assigns user-item-specific attention scores with respect to the words that appear in an item's content. We evaluate CoRGi on two edge-value prediction tasks and show that CoRGi is better at making edge-value predictions over existing methods, especially on sparse regions of the graph.",10.1145/3534678.3539306,https://doi.org/10.1145/3534678.3539306,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,CoRGi: Content-Rich Graph Neural Networks with Attention,"Kim, Jooyeon and Lamb, Angus and Woodhead, Simon and Peyton Jones, Simon and Zhang, Cheng and Allamanis, Miltiadis",inproceedings,10.1145/3534678.3539306,
10.1145/3534678.3539342,10.1145/3534678.3539342,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","graph neural networks, hypergraph learning, multi-behavior recommendation, sequential recommendation",12,2263–2274,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Learning dynamic user preference has become an increasingly important component for many online platforms (e.g., video-sharing sites, e-commerce systems) to make sequential recommendations. Previous works have made many efforts to model item-item transitions over user interaction sequences, based on various architectures, e.g., recurrent neural networks and self-attention mechanism. Recently emerged graph neural networks also serve as useful backbone models to capture item dependencies in sequential recommendation scenarios. Despite their effectiveness, existing methods have far focused on item sequence representation with singular type of interactions, and thus are limited to capture dynamic heterogeneous relational structures between users and items (e.g., page view, add-to-favorite, purchase). To tackle this challenge, we design a Multi-Behavior Hypergraph-enhanced T ransformer framework (MBHT) to capture both short-term and long-term cross-type behavior dependencies. Specifically, a multi-scale Transformer is equipped with low-rank self-attention to jointly encode behavior-aware sequential patterns from fine-grained and coarse-grained levels. Additionally,we incorporate the global multi-behavior dependency into the hypergraph neural architecture to capture the hierarchical long-range item correlations in a customized manner. Experimental results demonstrate the superiority of our MBHT over various state-of- the-art recommendation solutions across different settings. Further ablation studies validate the effectiveness of our model design and benefits of the new MBHT framework. Our implementation code is released at: https://github.com/yuh-yang/MBHT-KDD22.",10.1145/3534678.3539342,https://doi.org/10.1145/3534678.3539342,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation,"Yang, Yuhao and Huang, Chao and Xia, Lianghao and Liang, Yuxuan and Yu, Yanwei and Li, Chenliang",inproceedings,10.1145/3534678.3539342,
10.1145/3534678.3539430,10.1145/3534678.3539430,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","cloze task, exposure bias, sequential recommender system, transformers",10,273–282,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Bidirectional Transformer architectures are state-of-the-art sequential recommendation models that use a bi-directional representation capacity based on the Cloze task, a.k.a. Masked Language Modeling. The latter aims to predict randomly masked items within the sequence. Because they assume that the true interacted item is the most relevant one, an exposure bias results, where non-interacted items with low exposure propensities are assumed to be irrelevant. The most common approach to mitigating exposure bias in recommendation has been Inverse Propensity Scoring (IPS), which consists of down-weighting the interacted predictions in the loss function in proportion to their propensities of exposure, yielding a theoretically unbiased learning. In this work, we argue and prove that IPS does not extend to sequential recommendation because it fails to account for the temporal nature of the problem. We then propose a novel propensity scoring mechanism, which can theoretically debias the Cloze task in sequential recommendation. Finally we empirically demonstrate the debiasing capabilities of our proposed approach and its robustness to the severity of exposure bias.",10.1145/3534678.3539430,https://doi.org/10.1145/3534678.3539430,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Debiasing the Cloze Task in Sequential Recommendation with Bidirectional Transformers,"Damak, Khalil and Khenissi, Sami and Nasraoui, Olfa",inproceedings,10.1145/3534678.3539430,
10.1145/3534678.3539439,10.1145/3534678.3539439,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","general debiasing, invariant preference, recommender system",10,1969–1978,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Current recommender systems have achieved great successes in online services, such as E-commerce and social media. However, they still suffer from the performance degradation in real scenarios, because various biases always occur in the generation process of user behaviors. Despite the recent development of addressing some specific type of bias, a variety of data bias, some of which are even unknown, are often mixed up in real applications. Although the uniform (or unbiased) data may help for the purpose of general debiasing, such data can either be hardly available or induce high experimental cost. In this paper, we consider a more practical setting where we aim to conduct general debiasing with the biased observational data alone. We assume that the observational user behaviors are determined by invariant preference (i.e. a user's true preference) and the variant preference (affected by some unobserved confounders). We propose a novel recommendation framework called InvPref which iteratively decomposes the invariant preference and variant preference from biased observational user behaviors by estimating heterogeneous environments corresponding to different types of latent bias. Extensive experiments, including the settings of general debiasing and specific debiasing, verify the advantages of our method.",10.1145/3534678.3539439,https://doi.org/10.1145/3534678.3539439,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Invariant Preference Learning for General Debiasing in Recommendation,"Wang, Zimu and He, Yue and Liu, Jiashuo and Zou, Wenchao and Yu, Philip S. and Cui, Peng",inproceedings,10.1145/3534678.3539439,
10.1145/3534678.3539452,10.1145/3534678.3539452,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","embedding binarization, graph convolutional network, graph representation, quantization-based, recommender system",11,168–178,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Learning vectorized embeddings is at the core of various recommender systems for user-item matching. To perform efficient online inference, representation quantization, aiming to embed the latent features by a compact sequence of discrete numbers, recently shows the promising potentiality in optimizing both memory and computation overheads. However, existing work merely focuses on numerical quantization whilst ignoring the concomitant information loss issue, which, consequently, leads to conspicuous performance degradation. In this paper, we propose a novel quantization framework to learn Binarized Graph Representations for Top-K Recommendation (BiGeaR). We introduce multi-faceted quantization reinforcement at the pre-, mid-, and post-stage of binarized representation learning, which substantially retains the informativeness against embedding binarization. In addition to saving the memory footprint, it further develops solid online inference acceleration with bitwise operations, providing alternative flexibility for the realistic deployment. The empirical results over five large real-world benchmarks show that BiGeaR achieves about 22%~40% performance improvement over the state-of-the-art quantization-based recommender system, and recovers about 95%~102% of the performance capability of the best full-precision counterpart with over 8\texttimes{} time and space reduction.",10.1145/3534678.3539452,https://doi.org/10.1145/3534678.3539452,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,Learning Binarized Graph Representations with Multi-faceted Quantization Reinforcement for Top-K Recommendation,"Chen, Yankai and Guo, Huifeng and Zhang, Yingxue and Ma, Chen and Tang, Ruiming and Li, Jingjie and King, Irwin",inproceedings,10.1145/3534678.3539452,
10.1145/3534678.3542896,10.1145/3534678.3542896,KDD.bib,1,['KDD.bib'],8,KDD '22,"Washington DC, USA","deep learning, high-dimensional, imbalanced data, sparse data",2,4860–4861,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Recently, we have witnessed that deep learning-based approaches have been widely applied. Particularly, some applications involve data that are high dimensional, sparse or imbalanced, which are different from those applications with dense data processing, such as image classification and speech recognition, where deep learning-based approaches have been extensively studied. One of the main applications is the user-centric platform that consists of great deal of users, items and user generated tabular data which are quite high-dimensional. The characteristics of such data pose unique challenges to the adoption of deep learning in these applications, including modeling, training, and online serving, etc. More and more communities from both academia and industry have initiated the endeavors to solve these challenges. This workshop will provide a venue for both the research and engineering communities to discuss and formulate the challenges, utilize opportunities, and propose new ideas in the practice and theory of deep learning on high-dimensional, sparse and imbalanced data.",10.1145/3534678.3542896,https://doi.org/10.1145/3534678.3542896,"New York, NY, USA",Association for Computing Machinery,9781450393850,2022,4th Workshop on Deep Learning Practice and Theory for High-Dimensional Sparse and Imbalanced Data with KDD 2022,"Corizzo, Roberto and Ge, Junfeng and Bellinger, Colin and Zhu, Xiaoqiang and Branco, Paula and Lee, Kuang-chih and Japkowicz, Nathalie and Tang, Ruiming and Zhuang, Tao and Zhu, Han and Jiang, Biye and Mao, Jiaxin and Zhang, Weinan",inproceedings,10.1145/3534678.3542896,
10.1145/3539597.3570393,10.1145/3539597.3570393,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","decomposing ranking de-biasing, unbiased relevance ranking",9,913–921,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"Alleviating the examination and trust bias in ranking systems is an important research line in unbiased learning-to-rank (ULTR). Current methods typically use the propensity to correct the biased user clicks and then learn ranking models based on the corrected clicks. Though successes have been achieved, directly modifying the clicks suffers from the inherent high variance because the propensities are usually involved in the denominators of corrected clicks. The problem gets even worse in the situation of mixed examination and trust bias. To address the issue, this paper proposes a novel ULTR method called Decomposed Ranking Debiasing (DRD). DRD is tailored for learning unbiased relevance models with low variance in the existence of examination and trust bias. Unlike existing methods that directly modify the original user clicks, DRD proposes to decompose each click prediction as the combination of a relevance term outputted by the ranking model and other bias terms. The unbiased relevance model, therefore, can be learned by fitting the overall click predictions to the biased user clicks. A joint learning algorithm is developed to learn the relevance and bias models' parameters alternatively. Theoretical analysis showed that, compared with existing methods, DRD has lower variance while retains unbiasedness. Empirical studies indicated that DRD can effectively reduce the variance and outperform the state-of-the-art ULTR baselines.",10.1145/3539597.3570393,https://doi.org/10.1145/3539597.3570393,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,Separating Examination and Trust Bias from Click Predictions for Unbiased Relevance Ranking,"Zhao, Haiyuan and Xu, Jun and Zhang, Xiao and Cai, Guohao and Dong, Zhenhua and Wen, Ji-Rong",inproceedings,10.1145/3539597.3570393,
10.1145/3539597.3570400,10.1145/3539597.3570400,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","collaborative filtering, contrastive learning, graph neural network, recommender system",9,69–77,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"Nowadays, it is more and more convenient for people to participate in group activities. Therefore, providing some recommendations to groups of individuals is indispensable. Group recommendation is the task of suggesting items or events for a group of users in social networks or online communities. In this work, we study group recommendation in a particular scenario, namely occasional group recommendation, which has few or no historical directly interacted items. Existing group recommendation methods mostly adopt attention-based preference aggregation strategies to capture group preferences. However, these models either ignore the complex high-order interactions between groups, users and items or greatly reduce the efficiency by introducing complex data structures. Moreover, occasional group recommendation suffers from the problem of data sparsity due to the lack of historical group-item interactions. In this work, we focus on addressing the aforementioned challenges and propose a novel group recommendation model called Self-Supervised Group Graph Collaborative Filtering (SGGCF). The goal of the model is capturing the high-order interactions between users, items and groups and alleviating the data sparsity issue in an efficient way. First, we explicitly model the complex relationships as a unified user-centered heterogeneous graph and devise a base group recommendation model. Second, we explore self-supervised learning on the graph with two kinds of contrastive learning module to capture the implicit relations between groups and items. At last, we treat the proposed contrastive learning loss as supplementary and apply a multi-task strategy to jointly train the BPR loss and the proposed contrastive learning loss. We conduct extensive experiments on three real-world datasets, and the experimental results demonstrate the superiority of our proposed model in comparison to the state-of-the-art baselines.",10.1145/3539597.3570400,https://doi.org/10.1145/3539597.3570400,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,Self-Supervised Group Graph Collaborative Filtering for Group Recommendation,"Li, Kang and Wang, Chang-Dong and Lai, Jian-Huang and Yuan, Huaqiang",inproceedings,10.1145/3539597.3570400,
10.1145/3539597.3570414,10.1145/3539597.3570414,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","causal interpretation, recommender system, repeat intention, scenario learning",9,517–525,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"Personalized recommendation has been instrumental in many real applications. Despite the great progress, the underlying multi-scenario characteristics (e.g., users may behave differently under different scenarios) are largely ignored by existing recommender systems. Intuitively, modeling different scenarios properly could significantly improve the recommendation accuracy, and some existing work has explored this direction. However, these work assumes the scenarios are explicitly given, and thus becomes less effective when such information is unavailable. To complicate things further, proper scenario modeling from data is challenging and the recommendation models may easily overfit to some scenarios. In this paper, we propose a multi-scenario learning framework, MUSENET, for personalized recommendation. The key idea of MUSENET is to learn multiple implicit scenarios from the user behaviors, with a careful design inspired by the causal interpretation of recommender systems to avoid the overfitting issue. Additionally, since users' repeat consumptions account for a large part of the user behavior data on many e-commerce platforms, a repeat-aware mechanism is integrated to handle users' repurchase intentions within each scenario. Comprehensive experimental results on both industrial and public datasets demonstrate the effectiveness of the proposed approach compared with the state-of-the-art methods.",10.1145/3539597.3570414,https://doi.org/10.1145/3539597.3570414,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,MUSENET: Multi-Scenario Learning for Repeat-Aware Personalized Recommendation,"Xu, Senrong and Li, Liangyue and Yao, Yuan and Chen, Zulong and Wu, Han and Lu, Quan and Tong, Hanghang",inproceedings,10.1145/3539597.3570414,
10.1145/3539597.3570419,10.1145/3539597.3570419,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","contrastive learning, disentanglement learning, negative sampling",9,96–104,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"Negative sampling is essential for implicit collaborative filtering to generate negative samples from massive unlabeled data. Unlike existing strategies that consider items as a whole when selecting negative items, we argue that normally user interactions are mainly driven by some relevant, but not all, factors of items, leading to a new direction of negative sampling. In this paper, we introduce a novel disentangled negative sampling (DENS) method. We first disentangle the relevant and irrelevant factors of positive and negative items using a hierarchical gating module. Next, we design a factor-aware sampling strategy to identify the best negative samples by contrasting the relevant factors while keeping irrelevant factors similar. To ensure the credibility of the disentanglement, we propose to adopt contrastive learning and introduce four pairwise contrastive tasks, which enable to learn better disentangled representations of the relevant and irrelevant factors and remove the dependency on ground truth. Extensive experiments on five real-world datasets demonstrate the superiority of DENS against several state-of-the-art competitors, achieving over 7% improvement over the strongest baseline in terms of Recall@20 and NDCG@20. Our code is publically available at https://github.com/Riwei-HEU/DENS .",10.1145/3539597.3570419,https://doi.org/10.1145/3539597.3570419,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,Disentangled Negative Sampling for Collaborative Filtering,"Lai, Riwei and Chen, Li and Zhao, Yuhan and Chen, Rui and Han, Qilong",inproceedings,10.1145/3539597.3570419,
10.1145/3539597.3570420,10.1145/3539597.3570420,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","meta learning, user engagement forecasting, user intent",9,384–392,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"User engagement prediction plays a critical role in designing interaction strategies to grow user engagement and increase revenue in online social platforms. Through the in-depth analysis of the real-world data from the world's largest professional social platforms, i.e., LinkedIn, we find that users expose diverse engagement patterns, and a major reason for the differences in user engagement patterns is that users have different intents. That is, people have different intents when using LinkedIn, e.g., applying for jobs, building connections, or checking notifications, which shows quite different engagement patterns. Meanwhile, user intents and the corresponding engagement patterns may change over time. Although such pattern differences and dynamics are essential for user engagement prediction, differentiating user engagement patterns based on user dynamic intents for better user engagement forecasting has not received enough attention in previous works. In this paper, we proposed a Dynamic Intent Guided Meta Network (DIGMN), which can explicitly model user intent varying with time and perform differentiated user engagement forecasting. Specifically, we derive some interpretable basic user intents as prior knowledge from data mining and introduce prior intents to explicitly model dynamic user intent. Furthermore, based on the dynamic user intent representations, we propose a meta-predictor to perform differentiated user engagement forecasting. Through a comprehensive evaluation of LinkedIn anonymous user data, our method outperforms state-of-the-art baselines significantly, i.e., 2.96% and 3.48% absolute error reduction, on coarse-grained and fine-grained user engagement prediction tasks, respectively, demonstrating the effectiveness of our method.",10.1145/3539597.3570420,https://doi.org/10.1145/3539597.3570420,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,DIGMN: Dynamic Intent Guided Meta Network for Differentiated User Engagement Forecasting in Online Professional Social Platforms,"Li, Feifan and Du, Lun and Fu, Qiang and Han, Shi and Du, Yushu and Lu, Guangming and Li, Zi",inproceedings,10.1145/3539597.3570420,
10.1145/3539597.3570422,10.1145/3539597.3570422,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","consensus learning, graph contrastive learning, popularity bias, recommender system",9,589–597,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"Contrastive-learning-based neural networks have recently been introduced to recommender systems, due to their unique advantage of injecting collaborative signals to model deep representations, and the self-supervision nature in the learning process. Existing contrastive learning methods for recommendations are mainly proposed through introducing augmentations to the user-item (U-I) bipartite graphs. Such a contrastive learning process, however, is susceptible to bias towards popular items and users, because higher-degree users/items are subject to more augmentations and their correlations are more captured. In this paper, we advocate a &lt;u&gt;S&lt;/u&gt;iamese &lt;u&gt;G&lt;/u&gt;raph &lt;u&gt;C&lt;/u&gt;ontrastive &lt;u&gt;C&lt;/u&gt;onsensus &lt;u&gt;L&lt;/u&gt;earning (SGCCL) framework, to explore intrinsic correlations and alleviate the bias effects for personalized recommendation. Instead of augmenting original U-I networks, we introduce siamese graphs, which are homogeneous relations of user-user (U-U) similarity and item-item (I-I) correlations. A contrastive consensus optimization process is also adopted to learn effective features for user-item ratings, user-user similarity, and item-item correlation. Finally, we employ the self-supervised learning coupled with the siamese item-item/user-user graph relationships, which ensures unpopular users/items are well preserved in the embedding space. Different from existing studies, SGCCL performs well on both overall and debiasing recommendation tasks resulting in a balanced recommender. Experiments on four benchmark datasets demonstrate that SGCCL outperforms state-of-the-art methods with higher accuracy and greater long-tail item/user exposure.",10.1145/3539597.3570422,https://doi.org/10.1145/3539597.3570422,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,SGCCL: Siamese Graph Contrastive Consensus Learning for Personalized Recommendation,"Li, Boyu and Guo, Ting and Zhu, Xingquan and Li, Qian and Wang, Yang and Chen, Fang",inproceedings,10.1145/3539597.3570422,
10.1145/3539597.3570426,10.1145/3539597.3570426,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","conversational recommender systems, knowledge graph enhancement, knowledge refinemen, variational inference",9,231–239,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"Conversational recommender systems (CRSs) often utilize external knowledge graphs (KGs) to introduce rich semantic information and recommend relevant items through natural language dialogues. However, original KGs employed in existing CRSs are often incomplete and sparse, which limits the reasoning capability in recommendation. Moreover, only few of existing studies exploit the dialogue context to dynamically refine knowledge from KGs for better recommendation. To address the above issues, we propose the Variational Reasoning over Incomplete KGs Conversational Recommender (VRICR). Our key idea is to incorporate the large dialogue corpus naturally accompanied with CRSs to enhance the incomplete KGs; and perform dynamic knowledge reasoning conditioned on the dialogue context. Specifically, we denote the dialogue-specific subgraphs of KGs as latent variables with categorical priors for adaptive knowledge graphs refactor. We propose a variational Bayesian method to approximate posterior distributions over dialogue-specific subgraphs, which not only leverages the dialogue corpus for restructuring missing entity relations but also dynamically selects knowledge based on the dialogue context. Finally, we infuse the dialogue-specific subgraphs to decode the recommendation and responses. We conduct experiments on two benchmark CRSs datasets. Experimental results confirm the effectiveness of our proposed method.",10.1145/3539597.3570426,https://doi.org/10.1145/3539597.3570426,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,Variational Reasoning over Incomplete Knowledge Graphs for Conversational Recommendation,"Zhang, Xiaoyu and Xin, Xin and Li, Dongdong and Liu, Wenxuan and Ren, Pengjie and Chen, Zhumin and Ma, Jun and Ren, Zhaochun",inproceedings,10.1145/3539597.3570426,
10.1145/3539597.3570451,10.1145/3539597.3570451,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","collaborative filtering, embedding propagation, graph convolutional network, recommendation",9,60–68,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"Graph Convolutional Networks (GCNs) are a popular type of machine learning models that use multiple layers of convolutional aggregation operations and non-linear activations to represent data. Recent studies apply GCNs to Collaborative Filtering (CF)-based recommender systems (RSs) by modeling user-item interactions as a bipartite graph and achieve superior performance. However, these models face difficulty in training with non-linear activations on large graphs. Besides, most GCN-based models could not model deeper layers due to the over-smoothing effect with the graph convolution operation. In this paper, we improve the GCN-based CF models from two aspects. First, we remove non-linearities to enhance recommendation performance, which is consistent with the theories in simple graph convolutional networks. Second, we obtain the initialization of the embedding for each node in the graph by computing the network embedding on the condensed graph, which alleviates the over smoothing problem in graph convolution aggregation operation with sparse interaction data. The proposed model is a linear model that is easy to train, scalable to large datasets, and shown to yield better efficiency and effectiveness on four real datasets.",10.1145/3539597.3570451,https://doi.org/10.1145/3539597.3570451,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,Simplifying Graph-based Collaborative Filtering for Recommendation,"He, Li and Wang, Xianzhi and Wang, Dingxian and Zou, Haoyuan and Yin, Hongzhi and Xu, Guandong",inproceedings,10.1145/3539597.3570451,
10.1145/3539597.3570477,10.1145/3539597.3570477,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","bias and debias, knowledge distillation, recommendation",9,976–984,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"As a promising solution for model compression, knowledge distillation (KD) has been applied in recommender systems (RS) to reduce inference latency. Traditional solutions first train a full teacher model from the training data, and then transfer its knowledge (iesoft labels ) to supervise the learning of a compact student model. However, we find such a standard distillation paradigm would incur serious bias issue --- popular items are more heavily recommended after the distillation. This effect prevents the student model from making accurate and fair recommendations, decreasing the effectiveness of RS.In this work, we identify the origin of the bias in KD --- it roots in the biased soft labels from the teacher, and is further propagated and intensified during the distillation. To rectify this, we propose a new KD method with a stratified distillation strategy. It first partitions items into multiple groups according to their popularity, and then extracts the ranking knowledge within each group to supervise the learning of the student. Our method is simple and teacher-agnostic --- it works on distillation stage without affecting the training of the teacher model. We conduct extensive theoretical and empirical studies to validate the effectiveness of our proposal. We release our code at: https://github.com/chengang95/UnKD.",10.1145/3539597.3570477,https://doi.org/10.1145/3539597.3570477,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,Unbiased Knowledge Distillation for Recommendation,"Chen, Gang and Chen, Jiawei and Feng, Fuli and Zhou, Sheng and He, Xiangnan",inproceedings,10.1145/3539597.3570477,
10.1145/3539597.3570486,10.1145/3539597.3570486,WSDM.bib,1,['WSDM.bib'],8,WSDM '23,"Singapore, Singapore","marketing budget allocation, offline constrained deep RL",9,186–194,Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,"We study the budget allocation problem in online marketing campaigns that utilize previously collected offline data. We first discuss the long-term effect of optimizing marketing budget allocation decisions in the offline setting. To overcome the challenge, we propose a novel game-theoretic offline value-based reinforcement learning method using mixed policies. The proposed method reduces the need to store infinitely many policies in previous methods to only constantly many policies, which achieves nearly optimal policy efficiency, making it practical and favorable for industrial usage. We further show that this method is guaranteed to converge to the optimal policy, which cannot be achieved by previous value-based reinforcement learning methods for marketing budget allocation. Our experiments on a large-scale marketing campaign with tens-of-millions users and more than one billion budget verify the theoretical results and show that the proposed method outperforms various baseline methods. The proposed method has been successfully deployed to serve all the traffic of this marketing campaign.",10.1145/3539597.3570486,https://doi.org/10.1145/3539597.3570486,"New York, NY, USA",Association for Computing Machinery,9781450394079,2023,Marketing Budget Allocation with Offline Constrained Deep Reinforcement Learning,"Cai, Tianchi and Jiang, Jiyan and Zhang, Wenpeng and Zhou, Shiji and Song, Xierui and Yu, Li and Gu, Lihong and Zeng, Xiaodong and Gu, Jinjie and Zhang, Guannan",inproceedings,10.1145/3539597.3570486,
10.1145/3543507.3583240,10.1145/3543507.3583240,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Collaborative Filtering, Graph Partitioning, Recommender System, Similarity Measuring",10,823–832,Proceedings of the ACM Web Conference 2023,"Collaborative filtering (CF) is widely searched in recommendation with various types of solutions. Recent success of Graph Convolution Networks (GCN) in CF demonstrates the effectiveness of modeling high-order relationships through graphs, while repetitive graph convolution and iterative batch optimization limit their efficiency. Instead, item similarity models attempt to construct direct relationships through efficient interaction encoding. Despite their great performance, the growing item numbers result in quadratic growth in similarity modeling process, posing critical scalability problems. In this paper, we investigate the graph sampling strategy adopted in latest GCN model for efficiency improving, and identify the potential item group structure in the sampled graph. Based on this, we propose a novel item similarity model which introduces graph partitioning to restrict the item similarity modeling within each partition. Specifically, we show that the spectral information of the original graph is well in preserving global-level information. Then, it is added to fine-tune local item similarities with a new data augmentation strategy acted as partition-aware prior knowledge, jointly to cope with the information loss brought by partitioning. Experiments carried out on 4 datasets show that the proposed model outperforms state-of-the-art GCN models with 10x speed-up and item similarity models with 95% parameter storage savings.",10.1145/3543507.3583240,https://doi.org/10.1145/3543507.3583240,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Fine-tuning Partition-aware Item Similarities for Efficient and Scalable Recommendation,"Wei, Tianjun and Ma, Jianghong and Chow, Tommy W. S.",inproceedings,10.1145/3543507.3583240,
10.1145/3543507.3583247,10.1145/3543507.3583247,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Deep Dual Clustering, Graph Neural Network, Hyperbolic Learning, Session-based Recommendation",12,165–176,Proceedings of the ACM Web Conference 2023,"Session-based Recommendation aims at predicting the next interacted item based on short anonymous behavior sessions. However, existing solutions neglect to model two inherent properties of sequential representing distributions, i.e., hierarchy structures resulted from item popularity and collaborations existing in both intra- and inter-session. Tackling with these two factors at the same time is challenging. On the one hand, traditional Euclidean space utilized in previous studies fails to capture hierarchy structures due to a restricted representation ability. On the other hand, the intuitive apply of hyperbolic geometry could extract hierarchical patterns but more emphasis on degree distribution weakens intra- and inter-session collaborations. To address the challenges, we propose a Hierarchy-Aware Dual Clustering Graph Network (HADCG) model for session-based recommendation. Towards the first challenge, we design the hierarchy-aware graph modeling module which converts sessions into hyperbolic session graphs, adopting hyperbolic geometry in propagation and attention mechanism so as to integrate chronological and hierarchical information. As for the second challenge, we introduce the deep dual clustering module which develops a two-level clustering strategy, i.e., information regularizer for intra-session clustering and contrastive learner for inter-session clustering, to enhance hyperbolic representation learning from collaborative perspectives and further promote recommendation performance. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed HADCG.",10.1145/3543507.3583247,https://doi.org/10.1145/3543507.3583247,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Enhancing Hierarchy-Aware Graph Networks with Deep Dual Clustering for Session-based Recommendation,"Su, Jiajie and Chen, Chaochao and Liu, Weiming and Wu, Fei and Zheng, Xiaolin and Lyu, Haoming",inproceedings,10.1145/3543507.3583247,
10.1145/3543507.3583260,10.1145/3543507.3583260,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Explainable Recommendation, Natural Language Explanations",11,876–886,Proceedings of the ACM Web Conference 2023,"Explainable recommendation has recently attracted increasing attention from both academic and industry communities. Among different explainable strategies, generating natural language explanations is an important method, which can deliver more informative, flexible and readable explanations to facilitate better user decisions. Despite the effectiveness, existing models are mostly optimized based on the observed datasets, which can be skewed due to the selection or exposure bias. To alleviate this problem, in this paper, we formulate the task of explainable recommendation with a causal graph, and design a causality enhanced framework to generate unbiased explanations. More specifically, we firstly define an ideal unbiased learning objective, and then derive a tractable loss for the observational data based on the inverse propensity score (IPS), where the key is a sample re-weighting strategy for equalizing the loss and ideal objective in expectation. Considering that the IPS estimated from the sparse and noisy recommendation datasets can be inaccurate, we introduce a fault tolerant mechanism by minimizing the maximum loss induced by the sample weights near the IPS. For more comprehensive modeling, we further analyze and infer the potential latent confounders induced by the complex and diverse user personalities. We conduct extensive experiments by comparing with the state-of-the-art methods based on three real-world datasets to demonstrate the effectiveness of our method.",10.1145/3543507.3583260,https://doi.org/10.1145/3543507.3583260,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Recommendation with Causality enhanced Natural Language Explanations,"Zhang, Jingsen and Chen, Xu and Tang, Jiakai and Shao, Weiqi and Dai, Quanyu and Dong, Zhenhua and Zhang, Rui",inproceedings,10.1145/3543507.3583260,
10.1145/3543507.3583280,10.1145/3543507.3583280,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Causality, Fairness, Graph Structure Learning",9,3680–3688,Proceedings of the ACM Web Conference 2023,"With ubiquitous adoption of machine learning algorithms in web technologies, such as recommendation system and social network, algorithm fairness has become a trending topic, and it has a great impact on social welfare. Among different fairness definitions, path-specific causal fairness is a widely adopted one with great potentials, as it distinguishes the fair and unfair effects that the sensitive attributes exert on algorithm predictions. Existing methods based on path-specific causal fairness either require graph structure as the prior knowledge or have high complexity in the calculation of path-specific effect. To tackle these challenges, we propose a novel casual graph based fair prediction framework which integrates graph structure learning into fair prediction to ensure that unfair pathways are excluded in the causal graph. Furthermore, we generalize the proposed framework to the scenarios where sensitive attributes can be non-root nodes and affected by other variables, which is commonly observed in real-world applications, such as recommendation system, but hardly addressed by existing works. We provide theoretical analysis on the generalization bound for the proposed fair prediction method, and conduct a series of experiments on real-world datasets to demonstrate that the proposed framework can provide better prediction performance and algorithm fairness trade-off.",10.1145/3543507.3583280,https://doi.org/10.1145/3543507.3583280,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Path-specific Causal Fair Prediction via Auxiliary Graph Structure Learning,"Yao, Liuyi and Li, Yaliang and Ding, Bolin and Zhou, Jingren and Liu, Jinduo and Huai, Mengdi and Gao, Jing",inproceedings,10.1145/3543507.3583280,
10.1145/3543507.3583296,10.1145/3543507.3583296,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Max-min Fairness, Provider Fairness, Recommender System",11,3701–3711,Proceedings of the ACM Web Conference 2023,"In this paper, we address the issue of recommending fairly from the aspect of providers, which has become increasingly essential in multistakeholder recommender systems. Existing studies on provider fairness usually focused on designing proportion fairness (PF) metrics that first consider systematic fairness. However, sociological researches show that to make the market more stable, max-min fairness (MMF) is a better metric. The main reason is that MMF aims to improve the utility of the worst ones preferentially, guiding the system to support the providers in weak market positions. When applying MMF to recommender systems, how to balance user preferences and provider fairness in an online recommendation scenario is still a challenging problem. In this paper, we proposed an online re-ranking model named Provider Max-min Fairness Re-ranking (P-MMF) to tackle the problem. Specifically, P-MMF formulates provider fair recommendation as a resource allocation problem, where the exposure slots are considered the resources to be allocated to providers and the max-min fairness is used as the regularizer during the process. We show that the problem can be further represented as a regularized online optimizing problem and solved efficiently in its dual space. During the online re-ranking phase, a momentum gradient descent method is designed to conduct the dynamic re-ranking. Theoretical analysis showed that the regret of P-MMF can be bounded. Experimental results on four public recommender datasets demonstrated that P-MMF can outperformed the state-of-the-art baselines. Experimental results also show that P-MMF can retain small computationally costs on a corpus with the large number of items.",10.1145/3543507.3583296,https://doi.org/10.1145/3543507.3583296,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,P-MMF: Provider Max-min Fairness Re-ranking in Recommender System,"Xu, Chen and Chen, Sirui and Xu, Jun and Shen, Weiran and Zhang, Xiao and Wang, Gang and Dong, Zhenhua",inproceedings,10.1145/3543507.3583296,
10.1145/3543507.3583303,10.1145/3543507.3583303,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Clustering, Collaborative Filtering, Explanability, Recommendation",11,3712–3722,Proceedings of the ACM Web Conference 2023,"Collaborative Filtering (CF) is a widely used and effective technique for recommender systems. In recent decades, there have been significant advancements in latent embedding-based CF methods for improved accuracy, such as matrix factorization, neural collaborative filtering, and LightGCN. However, the explainability of these models has not been fully explored. Adding explainability to recommendation models can not only increase trust in the decision-making process, but also have multiple benefits such as providing persuasive explanations for item recommendations, creating explicit profiles for users and items, and assisting item producers in design improvements. In this paper, we propose a neat and effective Explainable Collaborative Filtering (ECF) model that leverages interpretable cluster learning to achieve the two most demanding objectives: (1) Precise - the model should not compromise accuracy in the pursuit of explainability; and (2) Self-explainable - the model’s explanations should truly reflect its decision-making process, not generated from post-hoc methods. The core of ECF is mining taste clusters from user-item interactions and item profiles. We map each user and item to a sparse set of taste clusters, and taste clusters are distinguished by a few representative tags. The user-item preference, users/items’ cluster affiliations, and the generation of taste clusters are jointly optimized in an end-to-end manner. Additionally, we introduce a forest mechanism to ensure the model’s accuracy, explainability, and diversity. To comprehensively evaluate the explainability quality of taste clusters, we design several quantitative metrics, including in-cluster item coverage, tag utilization, silhouette, and informativeness. Our model’s effectiveness is demonstrated through extensive experiments on three real-world datasets.",10.1145/3543507.3583303,https://doi.org/10.1145/3543507.3583303,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Towards Explainable Collaborative Filtering with Taste Clusters Learning,"Du, Yuntao and Lian, Jianxun and Yao, Jing and Wang, Xiting and Wu, Mingqi and Chen, Lu and Gao, Yunjun and Xie, Xing",inproceedings,10.1145/3543507.3583303,
10.1145/3543507.3583321,10.1145/3543507.3583321,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","counterfactuals, self-supervised learning, session-based recommendation",12,971–982,Proceedings of the ACM Web Conference 2023,"Most session-based recommender systems (SBRSs) focus on extracting information from the observed items in the current session of a user to predict a next item, ignoring the causes outside the session (called outer-session causes, OSCs) that influence the user’s selection of items. However, these causes widely exist in the real world, and few studies have investigated their role in SBRSs. In this work, we analyze the causalities and correlations of the OSCs in SBRSs from the perspective of causal inference. We find that the OSCs are essentially the confounders in SBRSs, which leads to spurious correlations in the data used to train SBRS models. To address this problem, we propose a novel SBRS framework named COCO-SBRS (COunterfactual COllaborative Session-Based Recommender Systems) to learn the causality between OSCs and user-item interactions in SBRSs. COCO-SBRS first adopts a self-supervised approach to pre-train a recommendation model by designing pseudo-labels of causes for each user’s selection of the item in data to guide the training process. Next, COCO-SBRS adopts counterfactual inference to recommend items based on the outputs of the pre-trained recommendation model considering the causalities to alleviate the data sparsity problem. As a result, COCO-SBRS can learn the causalities in data, preventing the model from learning spurious correlations. The experimental results of our extensive experiments conducted on three real-world datasets demonstrate the superiority of our proposed framework over ten representative SBRSs.",10.1145/3543507.3583321,https://doi.org/10.1145/3543507.3583321,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,A Counterfactual Collaborative Session-based Recommender System,"Song, Wenzhuo and Wang, Shoujin and Wang, Yan and Liu, Kunpeng and Liu, Xueyan and Yin, Minghao",inproceedings,10.1145/3543507.3583321,
10.1145/3543507.3583337,10.1145/3543507.3583337,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","federated ego graph learning, graph neural networks, recommender systems, semi-decentralized learning",10,339–348,Proceedings of the ACM Web Conference 2023,"Collaborative filtering (CF) based recommender systems are typically trained based on personal interaction data (e.g., clicks and purchases) that could be naturally represented as ego graphs. However, most existing recommendation methods collect these ego graphs from all users to compose a global graph to obtain high-order collaborative information between users and items, and these centralized CF recommendation methods inevitably lead to a high risk of user privacy leakage. Although recently proposed federated recommendation systems can mitigate the privacy problem, they either restrict the on-device local training to an isolated ego graph or rely on an additional third-party server to access other ego graphs resulting in a cumbersome pipeline, which is hard to work in practice. In addition, existing federated recommendation systems require resource-limited devices to maintain the entire embedding tables resulting in high communication costs. In light of this, we propose a semi-decentralized federated ego graph learning framework for on-device recommendations, named SemiDFEGL, which introduces new device-to-device collaborations to improve scalability and reduce communication costs and innovatively utilizes predicted interacted item nodes to connect isolated ego graphs to augment local subgraphs such that the high-order user-item collaborative information could be used in a privacy-preserving manner. Furthermore, the proposed framework is model-agnostic, meaning that it could be seamlessly integrated with existing graph neural network-based recommendation methods and privacy protection techniques. To validate the effectiveness of the proposed SemiDFEGL, extensive experiments are conducted on three public datasets, and the results demonstrate the superiority of the proposed SemiDFEGL compared to other federated recommendation methods.",10.1145/3543507.3583337,https://doi.org/10.1145/3543507.3583337,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Semi-decentralized Federated Ego Graph Learning for Recommendation,"Qu, Liang and Tang, Ningzhi and Zheng, Ruiqi and Nguyen, Quoc Viet Hung and Huang, Zi and Shi, Yuhui and Yin, Hongzhi",inproceedings,10.1145/3543507.3583337,
10.1145/3543507.3583355,10.1145/3543507.3583355,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","BPR, Fairness, Negative Sampling., Recommender Systems",11,3723–3733,Proceedings of the ACM Web Conference 2023,"Pairwise learning strategies are prevalent for optimizing recommendation models on implicit feedback data, which usually learns user preference by discriminating between positive (i.e., clicked by a user) and negative items (i.e., obtained by negative sampling). However, the size of different item groups (specified by item attribute) is usually unevenly distributed. We empirically find that the commonly used uniform negative sampling strategy for pairwise algorithms (e.g., BPR) can inherit such data bias and oversample the majority item group as negative instances, severely countering group fairness on the item side. In this paper, we propose a Fairly adaptive Negative sampling approach (FairNeg), which improves item group fairness via adaptively adjusting the group-level negative sampling distribution in the training process. In particular, it first perceives the model’s unfairness status at each step and then adjusts the group-wise sampling distribution with an adaptive momentum update strategy for better facilitating fairness optimization. Moreover, a negative sampling distribution Mixup mechanism is proposed, which gracefully incorporates existing importance-aware sampling techniques intended for mining informative negative samples, thus allowing for achieving multiple optimization purposes. Extensive experiments on four public datasets show our proposed method’s superiority in group fairness enhancement and fairness-utility tradeoff.",10.1145/3543507.3583355,https://doi.org/10.1145/3543507.3583355,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Fairly Adaptive Negative Sampling for Recommendations,"Chen, Xiao and Fan, Wenqi and Chen, Jingfan and Liu, Haochen and Liu, Zitao and Zhang, Zhaoxiang and Li, Qing",inproceedings,10.1145/3543507.3583355,
10.1145/3543507.3583359,10.1145/3543507.3583359,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Federated Learning, Membership Inference Attack and Defense, Recommender System",10,1053–1062,Proceedings of the ACM Web Conference 2023,"The marriage of federated learning and recommender system (FedRec) has been widely used to address the growing data privacy concerns in personalized recommendation services. In FedRecs, users’ attribute information and behavior data (i.e., user-item interaction data) are kept locally on their personal devices, therefore, it is considered a fairly secure approach to protect user privacy. As a result, the privacy issue of FedRecs is rarely explored. Unfortunately, several recent studies reveal that FedRecs are vulnerable to user attribute inference attacks, highlighting the privacy concerns of FedRecs. In this paper, we further investigate the privacy problem of user behavior data (i.e., user-item interactions) in FedRecs. Specifically, we perform the first systematic study on interaction-level membership inference attacks on FedRecs. An interaction-level membership inference attacker is first designed, and then the classical privacy protection mechanism, Local Differential Privacy (LDP), is adopted to defend against the membership inference attack. Unfortunately, the empirical analysis shows that LDP is not effective against such new attacks unless the recommendation performance is largely compromised. To mitigate the interaction-level membership attack threats, we design a simple yet effective defense method to significantly reduce the attacker’s inference accuracy without losing recommendation performance. Extensive experiments are conducted with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on three real-world recommendation datasets (MovieLens-100K, Steam-200K, and Amazon Cell Phone), and the experimental results show the effectiveness of our solutions.",10.1145/3543507.3583359,https://doi.org/10.1145/3543507.3583359,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Interaction-level Membership Inference Attack Against Federated Recommender Systems,"Yuan, Wei and Yang, Chaoqun and Nguyen, Quoc Viet Hung and Cui, Lizhen and He, Tieke and Yin, Hongzhi",inproceedings,10.1145/3543507.3583359,
10.1145/3543507.3583361,10.1145/3543507.3583361,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Contrastive Learning, Popularity Bias, Sequential Recommendation",11,1063–1073,Proceedings of the ACM Web Conference 2023,"Current sequential recommender systems are proposed to tackle the dynamic user preference learning with various neural techniques, such as Transformer and Graph Neural Networks (GNNs). However, inference from the highly sparse user behavior data may hinder the representation ability of sequential pattern encoding. To address the label shortage issue, contrastive learning (CL) methods are proposed recently to perform data augmentation in two fashions: (i) randomly corrupting the sequence data (e.g., stochastic masking, reordering); (ii) aligning representations across pre-defined contrastive views. Although effective, we argue that current CL-based methods have limitations in addressing popularity bias and disentangling of user conformity and real interest. In this paper, we propose a new Debiased Contrastive learning paradigm for Recommendation (DCRec) that unifies sequential pattern encoding with global collaborative relation modeling through adaptive conformity-aware augmentation. This solution is designed to tackle the popularity bias issue in recommendation systems. Our debiased contrastive learning framework effectively captures both the patterns of item transitions within sequences and the dependencies between users across sequences. Our experiments on various real-world datasets have demonstrated that DCRec significantly outperforms state-of-the-art baselines, indicating its efficacy for recommendation. To facilitate reproducibility of our results, we make our implementation of DCRec publicly available at: https://github.com/HKUDS/DCRec.",10.1145/3543507.3583361,https://doi.org/10.1145/3543507.3583361,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Debiased Contrastive Learning for Sequential Recommendation,"Yang, Yuhao and Huang, Chao and Xia, Lianghao and Huang, Chunzhen and Luo, Da and Lin, Kangyi",inproceedings,10.1145/3543507.3583361,
10.1145/3543507.3583362,10.1145/3543507.3583362,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Embedding learning, clustering, large-scale application, recommender system, sparse data",11,1074–1084,Proceedings of the ACM Web Conference 2023,"In recent years, recommender systems have advanced rapidly, where embedding learning for users and items plays a critical role. A standard method learns a unique embedding vector for each user and item. However, such a method has two important limitations in real-world applications: 1) it is hard to learn embeddings that generalize well for users and items with rare interactions; and 2) it may incur unbearably high memory costs when the number of users and items scales up. Existing approaches either can only address one of the limitations or have flawed overall performances. In this paper, we propose Clustered Embedding Learning (CEL) as an integrated solution to these two problems. CEL is a plug-and-play embedding learning framework that can be combined with any differentiable feature interaction model. It is capable of achieving improved performance, especially for cold users and items, with reduced memory cost. CEL enables automatic and dynamic clustering of users and items in a top-down fashion, where clustered entities jointly learn a shared embedding. The accelerated version of CEL has an optimal time complexity, which supports efficient online updates. Theoretically, we prove the identifiability and the existence of a unique optimal number of clusters for CEL in the context of nonnegative matrix factorization. Empirically, we validate the effectiveness of CEL on three public datasets and one business dataset, showing its consistently superior performance against current state-of-the-art methods. In particular, when incorporating CEL into the business model, it brings an improvement of in AUC, which translates into a significant revenue gain; meanwhile, the size of the embedding table gets 2650 times smaller.1",10.1145/3543507.3583362,https://doi.org/10.1145/3543507.3583362,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Clustered Embedding Learning for Recommender Systems,"Chen, Yizhou and Huzhang, Guangda and Zeng, Anxiang and Yu, Qingtao and Sun, Hui and Li, Heng-Yi and Li, Jingyi and Ni, Yabo and Yu, Han and Zhou, Zhiming",inproceedings,10.1145/3543507.3583362,
10.1145/3543507.3583363,10.1145/3543507.3583363,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Adaptiveness, Recommendation system, Temperature",12,1085–1096,Proceedings of the ACM Web Conference 2023,"Recent years have witnessed the great successes of embedding-based methods in recommender systems. Despite their decent performance, we argue one potential limitation of these methods — the embedding magnitude has not been explicitly modulated, which may aggravate popularity bias and training instability, hindering the model from making a good recommendation. It motivates us to leverage the embedding normalization in recommendation. By normalizing user/item embeddings to a specific value, we empirically observe impressive performance gains (9% on average) on four real-world datasets. Although encouraging, we also reveal a serious limitation when applying normalization in recommendation — the performance is highly sensitive to the choice of the temperature τ which controls the scale of the normalized embeddings. To fully foster the merits of the normalization while circumvent its limitation, this work studied on how to adaptively set the proper τ. Towards this end, we first make a comprehensive analyses of τ to fully understand its role on recommendation. We then accordingly develop an adaptive fine-grained strategy Adap-τ for the temperature with satisfying four desirable properties including adaptivity, personalized, efficiency and model-agnostic. Extensive experiments have been conducted to validate the effectiveness of the proposal. The code is available at https://github.com/junkangwu/Adap_tau.",10.1145/3543507.3583363,https://doi.org/10.1145/3543507.3583363,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Adap-τ : Adaptively Modulating Embedding Magnitude for Recommendation,"Chen, Jiawei and Wu, Junkang and Wu, Jiancan and Cao, Xuezhi and Zhou, Sheng and He, Xiangnan",inproceedings,10.1145/3543507.3583363,
10.1145/3543507.3583366,10.1145/3543507.3583366,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Domain Adaptation, Recommendation, Sequential Modelling",12,383–394,Proceedings of the ACM Web Conference 2023,"Sequential Cross-Domain Recommendation (CDR) has been popularly studied to utilize different domain knowledge and users’ historical behaviors for the next-item prediction. In this paper, we focus on the cross-domain sequential recommendation problem. This commonly exist problem is rather challenging from two perspectives, i.e., the implicit user historical rating sequences are difficult in modeling and the users/items on different domains are mostly non-overlapped. Most previous sequential CDR approaches cannot solve the cross-domain sequential recommendation problem well, since (1) they cannot sufficiently depict the users’ actual preferences, (2) they cannot leverage and transfer useful knowledge across domains. To tackle the above issues, we propose joint Internal multi-interest exploration and External domain alignment for cross domain Sequential Recommendation model (IESRec). IESRec&nbsp;includes two main modules, i.e., internal multi-interest exploration module and external domain alignment module. To reflect the users’ diverse characteristics with multi-interests evolution, we first propose internal temporal optimal transport method in the internal multi-interest exploration module. We further propose external alignment optimal transport method in the external domain alignment module to reduce domain discrepancy for the item embeddings. Our empirical studies on Amazon datasets demonstrate that IESRec&nbsp;significantly outperforms the state-of-the-art models.",10.1145/3543507.3583366,https://doi.org/10.1145/3543507.3583366,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Joint Internal Multi-Interest Exploration and External Domain Alignment for Cross Domain Sequential Recommendation,"Liu, Weiming and Zheng, Xiaolin and Chen, Chaochao and Su, Jiajie and Liao, Xinting and Hu, Mengling and Tan, Yanchao",inproceedings,10.1145/3543507.3583366,
10.1145/3543507.3583374,10.1145/3543507.3583374,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Graph Denoising, Preference Learning, Social Recommendation",12,1097–1108,Proceedings of the ACM Web Conference 2023,"Graph Neural Network&nbsp;(GNN) based social recommendation models improve the prediction accuracy of user preference by leveraging GNN in exploiting preference similarity contained in social relations. However, in terms of both effectiveness and efficiency of recommendation, a large portion of social relations can be redundant or even noisy, e.g., it is quite normal that friends share no preference in a certain domain. Existing models do not fully solve this problem of relation redundancy and noise, as they directly characterize social influence over the full social network. In this paper, we instead propose to improve graph based social recommendation by only retaining the informative social relations to ensure an efficient and effective influence diffusion, i.e., graph denoising. Our designed denoising method is preference-guided to model social relation confidence and benefits user preference learning in return by providing a denoised but more informative social graph for recommendation models. Moreover, to avoid interference of noisy social relations, it designs a self-correcting curriculum learning module and an adaptive denoising strategy, both favoring highly-confident samples. Experimental results on three public datasets demonstrate its consistent capability of improving three state-of-the-art social recommendation models by robustly removing 10-40% of original relations. We release the source code at https://github.com/tsinghua-fib-lab/Graph-Denoising-SocialRec.",10.1145/3543507.3583374,https://doi.org/10.1145/3543507.3583374,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Robust Preference-Guided Denoising for Graph based Social Recommendation,"Quan, Yuhan and Ding, Jingtao and Gao, Chen and Yi, Lingling and Jin, Depeng and Li, Yong",inproceedings,10.1145/3543507.3583374,
10.1145/3543507.3583461,10.1145/3543507.3583461,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Collaborative Filtering, Debiasing, Popularity Distribution Shift",12,1240–1251,Proceedings of the ACM Web Conference 2023,"Collaborative Filtering (CF) models, despite their great success, suffer from severe performance drops due to popularity distribution shifts, where these changes are ubiquitous and inevitable in real-world scenarios. Unfortunately, most leading popularity debiasing strategies, rather than tackling the vulnerability of CF models to varying popularity distributions, require prior knowledge of the test distribution to identify the degree of bias and further learn the popularity-entangled representations to mitigate the bias. Consequently, these models result in significant performance benefits in the target test set, while dramatically deviating the recommendation from users’ true interests without knowing the popularity distribution in advance. In this work, we propose a novel learning framework, Invariant Collaborative Filtering (InvCF), to discover disentangled representations that faithfully reveal the latent preference and popularity semantics without making any assumption about the popularity distribution. At its core is the distillation of unbiased preference representations (i.e., user preference on item property), which are invariant to the change of popularity semantics, while filtering out the popularity feature that is unstable or outdated. Extensive experiments on five benchmark datasets and four evaluation settings (i.e., synthetic long-tail, unbiased, temporal split, and out-of-distribution evaluations) demonstrate that InvCF outperforms the state-of-the-art baselines in terms of popularity generalization ability on real recommendations. Visualization studies shed light on the advantages of InvCF for disentangled representation learning. Our codes are available at https://github.com/anzhang314/InvCF.",10.1145/3543507.3583461,https://doi.org/10.1145/3543507.3583461,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Invariant Collaborative Filtering to Popularity Distribution Shift,"Zhang, An and Zheng, Jingnan and Wang, Xiang and Yuan, Yancheng and Chua, Tat-Seng",inproceedings,10.1145/3543507.3583461,
10.1145/3543507.3583481,10.1145/3543507.3583481,TheWebConf.bib,1,['TheWebConf.bib'],7,WWW '23,"Austin, TX, USA",,9,1813–1821,Proceedings of the ACM Web Conference 2023,"Social media is being increasingly weaponized by state-backed actors to elicit reactions, push narratives and sway public opinion. These are known as Information Operations (IO). The covert nature of IO makes their detection difficult. This is further amplified by missing data due to the user and content removal and privacy requirements. This work advances the hypothesis that the very reactions that Information Operations seek to elicit within the target social systems can be used to detect them. We propose an Interval-censored Transformer Hawkes (IC-TH) architecture and a novel data encoding scheme to account for both observed and missing data. We derive a novel log-likelihood function that we deploy together with a contrastive learning procedure. We showcase the performance of IC-TH on three real-world Twitter datasets and two learning tasks: future popularity prediction and item category prediction. The latter is particularly significant. Using the retweeting timing and patterns solely, we can predict the category of YouTube videos, guess whether news publishers are reputable or controversial and, most importantly, identify state-backed IO agent accounts. Additional qualitative investigations uncover that the automatically discovered clusters of Russian-backed agents appear to coordinate their behavior, activating simultaneously to push specific narratives.",10.1145/3543507.3583481,https://doi.org/10.1145/3543507.3583481,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Interval-censored Transformer Hawkes: Detecting Information Operations using the Reaction of Social Systems,"Kong, Quyu and Calderon, Pio and Ram, Rohit and Boichak, Olga and Rizoiu, Marian-Andrei",inproceedings,10.1145/3543507.3583481,
10.1145/3543507.3583495,10.1145/3543507.3583495,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Bias, Debias, Recommender Systems, Unobserved Confounding",9,1305–1313,Proceedings of the ACM Web Conference 2023,"Recommender systems are seen as an effective tool to address information overload, but it is widely known that the presence of various biases makes direct training on large-scale observational data result in sub-optimal prediction performance. In contrast, unbiased ratings obtained from randomized controlled trials or A/B tests are considered to be the golden standard, but are costly and small in scale in reality. To exploit both types of data, recent works proposed to use unbiased ratings to correct the parameters of the propensity or imputation models trained on the biased dataset. However, the existing methods fail to obtain accurate predictions in the presence of unobserved confounding or model misspecification. In this paper, we propose a theoretically guaranteed model-agnostic balancing approach that can be applied to any existing debiasing method with the aim of combating unobserved confounding and model misspecification. The proposed approach makes full use of unbiased data by alternatively correcting model parameters learned with biased data, and adaptively learning balance coefficients of biased samples for further debiasing. Extensive real-world experiments are conducted along with the deployment of our proposal on four representative debiasing methods to demonstrate the effectiveness.",10.1145/3543507.3583495,https://doi.org/10.1145/3543507.3583495,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Balancing Unobserved Confounding with a Few Unbiased Ratings in Debiased Recommendations,"Li, Haoxuan and Xiao, Yanghao and Zheng, Chunyuan and Wu, Peng",inproceedings,10.1145/3543507.3583495,
10.1145/3543507.3583529,10.1145/3543507.3583529,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Mutual Information, Self-supervised Learning, Sequential Recommendation, Wasserstein Distance",11,1375–1385,Proceedings of the ACM Web Conference 2023,"Self-supervised sequential recommendation significantly improves recommendation performance by maximizing mutual information with well-designed data augmentations. However, the mutual information estimation is based on the calculation of Kullback–Leibler divergence with several limitations, including asymmetrical estimation, the exponential need of the sample size, and training instability. Also, existing data augmentations are mostly stochastic and can potentially break sequential correlations with random modifications. These two issues motivate us to investigate an alternative robust mutual information measurement capable of modeling uncertainty and alleviating KL divergence’s limitations. To this end, we propose a novel self-supervised learning framework based on the Mutual WasserStein discrepancy minimization&nbsp;(MStein) for the sequential recommendation. We propose the Wasserstein Discrepancy Measurement to measure the mutual information between augmented sequences. Wasserstein Discrepancy Measurement builds upon the 2-Wasserstein distance, which is more robust, more efficient in small batch sizes, and able to model the uncertainty of stochastic augmentation processes. We also propose a novel contrastive learning loss based on Wasserstein Discrepancy Measurement. Extensive experiments on four benchmark datasets demonstrate the effectiveness of MStein over baselines. More quantitative analyses show the robustness against perturbations and training efficiency in batch size. Finally, improvements analysis indicates better representations of popular users/items with significant uncertainty. The source code is in https://github.com/zfan20/MStein.",10.1145/3543507.3583529,https://doi.org/10.1145/3543507.3583529,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Mutual Wasserstein Discrepancy Minimization for Sequential Recommendation,"Fan, Ziwei and Liu, Zhiwei and Peng, Hao and Yu, Philip S",inproceedings,10.1145/3543507.3583529,
10.1145/3543507.3583538,10.1145/3543507.3583538,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","Attribute Bias, Counterfactual Reasoning, Data Augmentation, Recommender Systems",9,1396–1404,Proceedings of the ACM Web Conference 2023,"Embedding-based methods currently achieved impressive success in recommender systems. However, such methods are more likely to suffer from bias in data distribution, especially the attribute bias problem. For example, when a certain type of user, like the elderly, occupies the mainstream, the recommendation results of minority users would be seriously affected by the mainstream users’ attributes. To address this problem, most existing methods are proposed from the perspective of fairness, which focuses on eliminating unfairness but deteriorates the recommendation performance. Unlike these methods, in this paper, we focus on improving the recommendation performance for minority users of biased attributes. Along this line, we propose a novel attribute-aware Counterfactual Augmentation framework for Minority Users(CAMUS). Specifically, the CAMUS consists of a counterfactual augmenter, a confidence estimator, and a recommender. The counterfactual augmenter conducts data augmentation for the minority group by utilizing the interactions of mainstream users based on a universal counterfactual assumption. Besides, a tri-training-based confidence estimator is applied to ensure the effectiveness of augmentation. Extensive experiments on three real-world datasets have demonstrated the superior performance of the proposed methods. Further case studies verify the universality of the proposed CAMUS framework on different data sparsity, attributes, and models.",10.1145/3543507.3583538,https://doi.org/10.1145/3543507.3583538,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,CAMUS: Attribute-Aware Counterfactual Augmentation for Minority Users in Recommendation,"Ying, Yuxin and Zhuang, Fuzhen and Zhu, Yongchun and Wang, Deqing and Zheng, Hongwei",inproceedings,10.1145/3543507.3583538,
10.1145/3543507.3583866,10.1145/3543507.3583866,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23,"Austin, TX, USA","AI in education, auxiliary learning, deep learning, knowledge tracing, student modeling",10,4178–4187,Proceedings of the ACM Web Conference 2023,"Knowledge tracing (KT) is the problem of predicting students’ future performance based on their historical interactions with intelligent tutoring systems. Recent studies have applied multiple types of deep neural networks to solve the KT problem. However, there are two important factors in real-world educational data that are not well represented. First, most existing works augment input representations with the co-occurrence matrix of questions and knowledge components1 (KCs) but fail to explicitly integrate such intrinsic relations into the final response prediction task. Second, the individualized historical performance of students has not been well captured. In this paper, we proposed AT-DKT to improve the prediction performance of the original deep knowledge tracing model with two auxiliary learning tasks, i.e., question tagging (QT) prediction task and individualized prior knowledge (IK) prediction task. Specifically, the QT task helps learn better question representations by predicting whether questions contain specific KCs. The IK task captures students’ global historical performance by progressively predicting student-level prior knowledge that is hidden in students’ historical learning interactions. We conduct comprehensive experiments on three real-world educational datasets and compare the proposed approach to both deep sequential KT models and non-sequential models. Experimental results show that AT-DKT outperforms all sequential models with more than 0.9% improvements of AUC for all datasets, and is almost the second best compared to non-sequential models. Furthermore, we conduct both ablation studies and quantitative analysis to show the effectiveness of auxiliary tasks and the superior prediction outcomes of AT-DKT. To encourage reproducible research, we make our data and code publicly available at https://github.com/pykt-team/pykt-toolkit&nbsp; 2.",10.1145/3543507.3583866,https://doi.org/10.1145/3543507.3583866,"New York, NY, USA",Association for Computing Machinery,9781450394161,2023,Enhancing Deep Knowledge Tracing with Auxiliary Tasks,"Liu, Zitao and Liu, Qiongqiong and Chen, Jiahao and Huang, Shuyan and Gao, Boyu and Luo, Weiqi and Weng, Jian",inproceedings,10.1145/3543507.3583866,
10.1145/3543873.3584637,10.1145/3543873.3584637,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23 Companion,"Austin, TX, USA","causal embedding, contrastive learning, recommender systems",5,406–410,Companion Proceedings of the ACM Web Conference 2023,"Recommender systems usually rely on observed user interaction data to build personalized recommendation models, assuming that the observed data reflect user interest. However, user interacting with an item may also due to conformity, the need to follow popular items. Most previous studies neglect user’s conformity and entangle interest with it, which may cause the recommender systems fail to provide satisfying results. Therefore, from the cause-effect view, disentangling these interaction causes is a crucial issue. It also contributes to OOD problems, where training and test data are out-of-distribution. Nevertheless, it is quite challenging as we lack the signal to differentiate interest and conformity. The data sparsity of pure cause and the items’ long-tail problem hinder disentangled causal embedding. In this paper, we propose DCCL, a framework that adopts contrastive learning to disentangle these two causes by sample augmentation for interest and conformity respectively. Futhermore, DCCL is model-agnostic, which can be easily deployed in any industrial online system. Extensive experiments are conducted over two real-world datasets and DCCL outperforms state-of-the-art baselines on top of various backbone models in various OOD environments. We also demonstrate the performance improvements by online A/B testing on Kuaishou, a billion-user scale short-video recommender system.",10.1145/3543873.3584637,https://doi.org/10.1145/3543873.3584637,"New York, NY, USA",Association for Computing Machinery,9781450394192,2023,Disentangled Causal Embedding With Contrastive Learning For Recommender System,"Zhao, Weiqi and Tang, Dian and Chen, Xin and Lv, Dawei and Ou, Daoli and Li, Biao and Jiang, Peng and Gai, Kun",inproceedings,10.1145/3543873.3584637,
10.1145/3543873.3584657,10.1145/3543873.3584657,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23 Companion,"Austin, TX, USA","Causal embedding, Conformity bias, Multi-task learning, Recommender system",5,513–517,Companion Proceedings of the ACM Web Conference 2023,"Learning large-scale industrial recommender system models by fitting them to historical user interaction data makes them vulnerable to conformity bias. This may be due to a number of factors, including the fact that user interests may be difficult to determine and that many items are often interacted with based on ecosystem factors other than their relevance to the individual user. In this work, we introduce CAM2, a conformity-aware multi-task ranking model to serve relevant items to users on one of the largest industrial recommendation platforms. CAM2 addresses these challenges systematically by leveraging causal modeling to disentangle users’ conformity to popular items from their true interests. This framework is generalizable and can be scaled to support multiple representations of conformity and user relevance in any large-scale recommender system. We provide deeper practical insights and demonstrate the effectiveness of the proposed model through improvements in offline evaluation metrics compared to our production multi-task ranking model. We also show through online experiments that the CAM2 model results in a significant 0.50% increase in aggregated user engagement, coupled with a 0.21% increase in daily active users on Facebook Watch, a popular video discovery and sharing platform serving billions of users.",10.1145/3543873.3584657,https://doi.org/10.1145/3543873.3584657,"New York, NY, USA",Association for Computing Machinery,9781450394192,2023,CAM2: Conformity-Aware Multi-Task Ranking Model for Large-Scale Recommender Systems,"Raul, Ameya and Porobo Dharwadker, Amey and Schumitsch, Brad",inproceedings,10.1145/3543873.3584657,
10.1145/3543873.3587374,10.1145/3543873.3587374,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23 Companion,"Austin, TX, USA","language model, negative sampling, recommender system, search-based prediction, transformer",4,318–321,Companion Proceedings of the ACM Web Conference 2023,"Recommender systems have achieved impressive results on benchmark datasets. However, the numbers are often influenced by assumptions made on the data and evaluation mode. This work questions and revises these assumptions, to study and improve the quality, particularly for the difficult case of search-based recommendations. Users start with a personally liked item as a query and look for similar items that match their tastes. User satisfaction requires discovering truly unknown items: new authors of books rather than merely more books of known writers. We propose a unified system architecture that combines interaction-based and content-based signals and leverages language models for Transformer-powered predictions. We present new techniques for selecting negative training samples, and investigate their performance in the underexplored search-based evaluation mode.",10.1145/3543873.3587374,https://doi.org/10.1145/3543873.3587374,"New York, NY, USA",Association for Computing Machinery,9781450394192,2023,Search-based Recommendation: the Case for Difficult Predictions,"Haratinezhad Torbati, Ghazaleh and Weikum, Gerhard and Yates, Andrew",inproceedings,10.1145/3543873.3587374,
10.1145/3543873.3587657,10.1145/3543873.3587657,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '23 Companion,"Austin, TX, USA","conversational preference elicitation, conversational recommender systems, intent prediction",6,886–891,Companion Proceedings of the ACM Web Conference 2023,"Structured interviews are used in many settings, importantly in market research on topics such as brand perception, customer habits, or preferences, which are critical to product development, marketing, and e-commerce at large. Such interviews generally consist of a series of questions that are asked to a participant. These interviews are typically conducted by skilled interviewers, who interpret the responses from the participants and can adapt the interview accordingly. Using automated conversational agents to conduct such interviews would enable reaching a much larger and potentially more diverse group of participants than currently possible. However, the technical challenges involved in building such a conversational system are relatively unexplored. To learn more about these challenges, we convert a market research multiple-choice questionnaire to a conversational format and conduct a user study. We address the key task of conducting structured interviews, namely interpreting the participant’s response, for example, by matching it to one or more predefined options. Our findings can be applied to improve response interpretation for the information elicitation phase of conversational recommender systems.",10.1145/3543873.3587657,https://doi.org/10.1145/3543873.3587657,"New York, NY, USA",Association for Computing Machinery,9781450394192,2023,Contextual Response Interpretation for Automated Structured Interviews: A Case Study in Market Research,"Sahijwani, Harshita and Dhole, Kaustubh and Purwar, Ankur and Vasudevan, Venugopal and Agichtein, Eugene",inproceedings,10.1145/3543873.3587657,
10.1145/3556702.3556792,10.1145/3556702.3556792,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '22,"Seattle, WA, USA","Fashion Recommendation, Ranking, RecSys Challenge, Retrieval",6,4–9,Proceedings of the Recommender Systems Challenge 2022,"In this technical report, we present our solution of RecSys Challenge 2022 focusing on the fashion recommendation. We produce recommendations in two steps: (i) the retrieval step, which generates a candidate item set based on multiple cheap-to-compute strategies; (ii) the ranking step: which rearranges the candidate items with a richer set of features. Specifically, we conduct various strategies to retrieve as many positive samples as possible in retrieval step and obtain the retrieval scores from these retrieval channels meanwhile. Then these scores along with some extracted features are involved in the ranking stage for modeling to generate the purchase prediction. In the final submission, we use six effective retrieval strategies in retrieval step and ensemble five ranking models by taking average of their outputs. Using our method, our team doubleQ achieved MRR 0.2013 on final test set which wins the 10 place, and the solution codes are available via https://github.com/doubleQ2018/recsys-challenge-2022.",10.1145/3556702.3556792,https://doi.org/10.1145/3556702.3556792,"New York, NY, USA",Association for Computing Machinery,9781450398565,2022,Fashion Recommendation with a real Recommender System Flow,"Zhang, Qi and Cai, Guohao and Guo, Wei and Han, Yi and Dong, Zhenhua and Tang, Ruiming and Li, Liangbi",inproceedings,10.1145/3556702.3556792,
10.1145/3556702.3556829,10.1145/3556702.3556829,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '22,"Seattle, WA, USA","boosting, feature engineering, neural networks, recommender systems, recsys challenge",6,18–23,Proceedings of the Recommender Systems Challenge 2022,"This paper presents the solution designed by the team “Boston Team Party” for the ACM RecSys Challenge 2022. The competition was organized by Dressipi and was framed under the session-based fashion recommendations domain. Particularly, the task was to predict the purchased item at the end of each anonymous session. Our proposed two-stage solution is effective, lightweight, and scalable. First, it leverages the expertise of several strong recommendation models to produce a pool of candidate items. Then, a Gradient-Boosting Decision Tree model aggregates these candidates alongside several hand-crafted features to produce the final ranking. Our model achieved a score of 0.18800 in the public leaderboard. To aid in the reproducibility of our findings, we open-source our materials.",10.1145/3556702.3556829,https://doi.org/10.1145/3556702.3556829,"New York, NY, USA",Association for Computing Machinery,9781450398565,2022,Lightweight Model for Session-Based Recommender Systems with Seasonality Information in the Fashion Domain,"Della Volpe, Nicola and Mainetti, Lorenzo and Martignetti, Alessio and Menta, Andrea and Pala, Riccardo and Polvanesi, Giacomo and Sammarco, Francesco and Perez Maurera, Fernando Benjamin and Bernardis, Cesare and Ferrari Dacrema, Maurizio",inproceedings,10.1145/3556702.3556829,
10.1145/3556702.3556844,10.1145/3556702.3556844,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '22,"Seattle, WA, USA","Deep Learning, Recommender Systems, Session-based Recommendation",5,29–33,Proceedings of the Recommender Systems Challenge 2022,"Large item catalogs and constantly changing preference trends make recommendations a critically important component of every fashion e-commerce platform. However, since most users browse anonymously, historical preference data is rarely available and recommendations have to be made using only information from within the session. In the 2022 ACM RecSys challenge, Dressipi released a dataset with 1.1 million online retail sessions in the fashion domain that span an 18-month period. The goal is to predict the item purchased at the end of each session. To simulate a common production scenario all sessions are anonymous and no previous user preference information is available. In this paper, we present our approach to this challenge. We leverage the Transformer architecture with two different learning objectives inspired by the self-supervised learning techniques to improve generalization. Our team, LAYER 6, achieves strong results placing 2’nd on the final leaderboard out of over 300 teams.",10.1145/3556702.3556844,https://doi.org/10.1145/3556702.3556844,"New York, NY, USA",Association for Computing Machinery,9781450398565,2022,Session-based Recommendation with Transformers,"Lu, Yichao and Gao, Zhaolin and Cheng, Zhaoyue and Sun, Jianing and Brown, Bradley and Yu, Guangwei and Wong, Anson and P\'{e}rez, Felipe and Volkovs, Maksims",inproceedings,10.1145/3556702.3556844,
10.1145/3556702.3556845,10.1145/3556702.3556845,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '22,"Seattle, WA, USA","collaborative filtering, content based filtering, graph recommenders, neural networks, re-ranking",5,34–38,Proceedings of the Recommender Systems Challenge 2022,"In this paper we provide an overview of the approach we used as team Surricchi1 for the ACM RecSys Challenge 20221. The competition, sponsored and organized by Dressipi, involves a typical session-based recommendation task in the fashion industry domain. Our proposed method2 leverages an ensemble of multiple recommenders selected to capture diverse facets of the input data. Such a modular approach allowed our team to achieve competitive results with a score of 0.1994 Mean Reciprocal Rank at 100 (∼ 7.6% less than the first qualified team). We obtained this result by leveraging only publicly and freely available computational resources 3 and our own laptops. Part of the merit also lies in the size of this year’s dataset (∼ 5 million data points), which democratized the challenge to a larger public and allowed us to join the challenge as independent researchers.",10.1145/3556702.3556845,https://doi.org/10.1145/3556702.3556845,"New York, NY, USA",Association for Computing Machinery,9781450398565,2022,"United We Stand, Divided We Fall: Leveraging Ensembles of Recommenders to Compete with Budget Constrained Resources","Maldini, Pietro and Sanvito, Alessandro and Surricchio, Mattia",inproceedings,10.1145/3556702.3556845,
10.1145/3556702.3556851,10.1145/3556702.3556851,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '22,"Seattle, WA, USA","Cold-Start Problem, RecSys Challenge 2022, Recommender Systems, Session-based Recommendation",5,50–54,Proceedings of the Recommender Systems Challenge 2022,"In this paper, we describe our approach for the RecSys 2022 Challenge organized by Dressipi. The goal of the challenge is to predict which item is purchased next given sessions of users as well as metadata of items from fashion e-commerce service. One key characteristic of this problem is that most sessions only have few (lower than 3) previous views. Furthermore, a large number of sessions (about 19%) contain views and purchases of items that did not appear before. We propose the following approaches to overcome these problems. First, we introduce a simple, yet strong sequence-aware MLP that outperforms recently proposed sequential recommenders such as BERT4Rec and GRU4Rec in the given dataset. Secondly, we propose a similarity metric that captures not only item metadata but also item popularity. Lastly, we predict recommendations for different types of sessions with different serving models.",10.1145/3556702.3556851,https://doi.org/10.1145/3556702.3556851,"New York, NY, USA",Association for Computing Machinery,9781450398565,2022,Simple and Efficient Recommendation Strategy for Warm/Cold Sessions for RecSys Challenge 2022,"Lee, Hyunsung and Yoo, Sungwook and Yang, Andrew and Jang, Wonjun and Park, Chiwan",inproceedings,10.1145/3556702.3556851,
10.1145/3580305.3599281,10.1145/3580305.3599281,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","community detection, dynamic graph learning, popularity prediction",11,930–940,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Popularity prediction, which aims to forecast how many users would like to interact with a target item or online content in the future, can help online shopping or social media platforms to identify popular items or digital contents. Many efforts have been made to study how the multi-faceted factors, such as item features, user preferences, and social influence, affect user-item interactions, but little work has focused on the evolutionary dynamics of these factors for individuals or groups. In that light, this paper develops a community-based dynamic graph learning method for popularity prediction. First, a dynamic graph learning framework is proposed to maintain a dynamic representation for each item or user entity and update the representations according to the newly observed user-item interactions. Second, a community detection module is designed to capture the evolving community structures and identify the most influential nodes. More importantly, our framework leverages a community-level message passing during the learning process to balance local and global information propagation. Finally, we predict the popularity of the target item or online content based on the learned representations. Our experimental results based on three real-world datasets demonstrate that the proposed method achieves better performance than the baselines. Our method could not only model the changes in a user's preferences, but also capture how the communities evolve over time.",10.1145/3580305.3599281,https://doi.org/10.1145/3580305.3599281,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Community-based Dynamic Graph Learning for Popularity Prediction,"Ji, Shuo and Lu, Xiaodong and Liu, Mingzhe and Sun, Leilei and Liu, Chuanren and Du, Bowen and Xiong, Hui",inproceedings,10.1145/3580305.3599281,
10.1145/3580305.3599296,10.1145/3580305.3599296,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","deconfounder, recommendation, unmeasured confounder",11,3353–3363,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Recommendation systems aim to predict users' feedback on items not exposed to them yet. Confounding bias arises due to the presence of unmeasured variables (e.g., the socio-economic status of a user) that can affect both a user's exposure and feedback. Existing methods either (1) make untenable assumptions about these unmeasured variables or (2) directly infer latent confounders from users' exposure. However, they cannot guarantee the identification of counterfactual feedback, which can lead to biased predictions. In this work, we propose a novel method, i.e., identifiable deconfounder (iDCF), which leverages a set of proxy variables (e.g., observed user features) to resolve the aforementioned non-identification issue. The proposed iDCF is a general deconfounded recommendation framework that applies proximal causal inference to infer the unmeasured confounders and identify the counterfactual feedback with theoretical guarantees. Extensive experiments on various real-world and synthetic datasets verify the proposed method's effectiveness and robustness.",10.1145/3580305.3599296,https://doi.org/10.1145/3580305.3599296,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Debiasing Recommendation by Learning Identifiable Latent Confounders,"Zhang, Qing and Zhang, Xiaoying and Liu, Yang and Wang, Hongning and Gao, Min and Zhang, Jiheng and Guo, Ruocheng",inproceedings,10.1145/3580305.3599296,
10.1145/3580305.3599428,10.1145/3580305.3599428,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","graph learning, long-tail recommendation, meta-learning",11,2512–2522,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Highly skewed long-tail item distribution commonly hurts model performance on tail items in recommendation systems, especially for graph-based recommendation models. We propose a novel idea to learn relations among items as an auxiliary graph to enhance the graph-based representation learning and make recommendations collectively in a coupled framework. This raises two challenges, 1) the long-tail downstream information may also bias the auxiliary graph learning, and 2) the learned auxiliary graph may cause negative transfer to the original user-item bipartite graph. We innovatively propose a novel Meta Graph Learning framework for long-tail recommendation (MGL) for solving both challenges. The meta-learning strategy is introduced to the learning of an edge generator, which is first tuned to reconstruct a debiased item co-occurrence matrix, and then virtually evaluated on generating item relations for recommendation. Moreover, we propose a popularity-aware contrastive learning strategy to prevent negative transfer by aligning the confident head item representations with those of the learned auxiliary graph. Experiments on public datasets demonstrate that our proposed model significantly outperforms strong baselines for tail items without compromising the overall performance.",10.1145/3580305.3599428,https://doi.org/10.1145/3580305.3599428,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Meta Graph Learning for Long-tail Recommendation,"Wei, Chunyu and Liang, Jian and Liu, Di and Dai, Zehui and Li, Mang and Wang, Fei",inproceedings,10.1145/3580305.3599428,
10.1145/3580305.3599487,10.1145/3580305.3599487,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","causal inference, unbiased recommendation",12,2764–2775,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"This work studies the problem of learning unbiased algorithms from biased feedback for recommendation. We address this problem from a novel distribution shift perspective. Recent works in unbiased recommendation have advanced the state-of-the-art with various techniques such as re-weighting, multi-task learning, and meta-learning. Despite their empirical successes, most of them lack theoretical guarantees, forming non-negligible gaps between theories and recent algorithms. In this paper, we propose a theoretical understanding of why existing unbiased learning objectives work for unbiased recommendation. We establish a close connection between unbiased recommendation and distribution shift, which shows that existing unbiased learning objectives implicitly align biased training and unbiased test distributions. Built upon this connection, we develop two generalization bounds for existing unbiased learning methods and analyze their learning behavior. Besides, as a result of the distribution shift, we further propose a principled framework, Adversarial Self-Training (AST), for unbiased recommendation. Extensive experiments on real-world and semi-synthetic datasets demonstrate the effectiveness of AST.",10.1145/3580305.3599487,https://doi.org/10.1145/3580305.3599487,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Reconsidering Learning Objectives in Unbiased Recommendation: A Distribution Shift Perspective,"Xiao, Teng and Chen, Zhengyu and Wang, Suhang",inproceedings,10.1145/3580305.3599487,
10.1145/3580305.3599516,10.1145/3580305.3599516,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","continual learning, recommender system, universal user representation",13,1107–1119,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"User modeling, which learns to represent users into a low-dimensional representation space based on their past behaviors, got a surge of interest from the industry for providing personalized services to users. Previous efforts in user modeling mainly focus on learning a task-specific user representation that is designed for a single task. However, since learning task-specific user representations for every task is infeasible, recent studies introduce the concept of universal user representation, which is a more generalized representation of a user that is relevant to a variety of tasks. Despite their effectiveness, existing approaches for learning universal user representations are impractical in real-world applications due to the data requirement, catastrophic forgetting and the limited learning capability for continually added tasks. In this paper, we propose a novel continual user representation learning method, called TERACON, whose learning capability is not limited as the number of learned tasks increases while capturing the relationship between the tasks. The main idea is to introduce an embedding for each task, i.e., task embedding, which is utilized to generate task-specific soft masks that not only allow the entire model parameters to be updated until the end of training sequence, but also facilitate the relationship between the tasks to be captured. Moreover, we introduce a novel knowledge retention module with pseudo-labeling strategy that successfully alleviates the long-standing problem of continual learning, i.e., catastrophic forgetting. Extensive experiments on public and proprietary real-world datasets demonstrate the superiority and practicality of TERACON. Our code is available at https://github.com/Sein-Kim/TERACON.",10.1145/3580305.3599516,https://doi.org/10.1145/3580305.3599516,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Task Relation-aware Continual User Representation Learning,"Kim, Sein and Lee, Namkyeong and Kim, Donghyun and Yang, Minchul and Park, Chanyoung",inproceedings,10.1145/3580305.3599516,
10.1145/3580305.3599550,10.1145/3580305.3599550,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","counterfactual, optimal treatment regime, recommender system.",13,1235–1247,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Effective personalized incentives can improve user experience and increase platform revenue, resulting in a win-win situation between users and e-commerce companies. Previous studies have used uplift modeling methods to estimate the conditional average treatment effects of users' incentives, and then placed the incentives by maximizing the sum of estimated treatment effects under a limited budget. However, some users will always buy whether incentives are given or not, and they will actively collect and use incentives if provided, named ""Always Buyers"". Identifying and predicting these ""Always Buyers"" and reducing incentive delivery to them can lead to a more rational incentive allocation. In this paper, we first divide users into five strata from an individual counterfactual perspective, and reveal the failure of previous uplift modeling methods to identify and predict the ""Always Buyers"". Then, we propose principled counterfactual identification and estimation methods and prove their unbiasedness. We further propose a counterfactual entire-space multi-task learning approach to accurately perform personalized incentive policy learning with a limited budget. We also theoretically derive a lower bound on the reward of the learned policy. Extensive experiments are conducted on three real-world datasets with two common incentive scenarios, and the results demonstrate the effectiveness of the proposed approaches.",10.1145/3580305.3599550,https://doi.org/10.1145/3580305.3599550,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Who Should Be Given Incentives? Counterfactual Optimal Treatment Regimes Learning for Recommendation,"Li, Haoxuan and Zheng, Chunyuan and Wu, Peng and Kuang, Kun and Liu, Yue and Cui, Peng",inproceedings,10.1145/3580305.3599550,
10.1145/3580305.3599764,10.1145/3580305.3599764,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","bonus allocation, convex constraint, e-commerce, monotonic constraint, multi-treatment effect estimation",11,5028–5038,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"With the explosive development of e-commerce for service, tens of millions of orders are generated every day on the Meituan platform. By allocating bonuses to new customers when they pay, the Meituan platform encourages them to use its own payment service for a better experience in the future. It can be formulated as a multi-choice knapsack problem (MCKP), and the mainstream solution is usually a two-stage method. The first stage is user intent detection, predicting the effect for each bonus treatment. Then, it serves as the objective of the MCKP, and the problem is solved in the second stage to obtain the optimal allocation strategy. However, this solution usually faces the following challenges: (1) In the user intent detection stage, due to the sparsity of interaction and noise, the traditional multi-treatment effect estimation methods lack interpretability, which may violate the domain knowledge that the marginal gain is non-negative with the increase of the bonus amount in economic theory. (2) There is an optimality gap between the two stages, which limits the upper bound of the optimal value obtained in the second stage. (3) Due to changes in the distribution of orders online, the actual cost consumption often violates the given budget limit. To solve the above challenges, we propose a framework that consists of three modules, i.e., User Intent Detection Module, Online Allocation Module, and Feedback Control Module. In the User Intent Detection Module, we implicitly model the treatment increment based on deep representation learning and constrain it to be non-negative to achieve monotonicity constraints. Then, in order to reduce the optimality gap, we further propose a convex constrained model to increase the upper bound of the optimal value. For the third challenge, to cope with the fluctuation of online bonus consumption, we leverage a feedback control strategy in the framework to make the actual cost more accurately approach the given budget limit. Finally, we conduct extensive offline and online experiments, demonstrating the superiority of our proposed framework, which reduced customer acquisition costs by 5.07% and is still running online.",10.1145/3580305.3599764,https://doi.org/10.1145/3580305.3599764,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,A Multi-stage Framework for Online Bonus Allocation Based on Constrained User Intent Detection,"Wang, Chao and Shi, Xiaowei and Xu, Shuai and Wang, Zhe and Fan, Zhiqiang and Feng, Yan and You, An and Chen, Yu",inproceedings,10.1145/3580305.3599764,
10.1145/3580305.3599774,10.1145/3580305.3599774,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","causal inference, covid analysis, deep latent variable models, generative ai, machine learning for healthcare, representation learning, semi-supervised learning, treatment effect estimation, variational autoencoder",12,5360–5371,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting modality for COVID-19 patients who are refractory to conventional therapies. However, the proper treatment decision has been the subject of significant debate and it remains controversial about who benefits from this scarcely available and technically complex treatment option. To support clinical decisions, it is a critical need to predict the treatment need and the potential treatment and no-treatment responses. Targeting this clinical challenge, we propose Treatment Variational AutoEncoder (TVAE), a novel approach for individualized treatment analysis. TVAE is specifically designed to address the modeling challenges like ECMO with strong treatment selection bias and scarce treatment cases. TVAE conceptualizes the treatment decision as a multi-scale problem. We model a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics that can be represented by a deep latent variable model. The factual and counterfactual prediction errors are alleviated via a reconstruction regularization scheme together with semi-supervision, and the selection bias and the scarcity of treatment cases are mitigated by the disentangled and distribution-matched latent space and the label-balancing generative strategy. We evaluate TVAE on two real-world COVID-19 datasets: an international dataset collected from 1651 hospitals across 63 countries, and a institutional dataset collected from 15 hospitals. The results show that TVAE outperforms state-of-the-art treatment effect models in predicting both the propensity scores and factual outcomes on heterogeneous COVID-19 datasets. Additional experiments also show TVAE outperforms the best existing models in individual treatment effect estimation on the synthesized IHDP benchmark dataset.",10.1145/3580305.3599774,https://doi.org/10.1145/3580305.3599774,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation,"Xue, Bing and Said, Ahmed Sameh and Xu, Ziqi and Liu, Hanyang and Shah, Neel and Yang, Hanqing and Payne, Philip and Lu, Chenyang",inproceedings,10.1145/3580305.3599774,
10.1145/3580305.3599814,10.1145/3580305.3599814,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","decoupling, memorization and generalization, recommendation",10,5608–5617,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Industry recommender systems usually suffer from highly-skewed long-tail item distributions where a small fraction of the items receives most of the user feedback. This skew hurts recommender quality especially for the item slices without much user feedback. While there have been many research advances made in academia, deploying these methods in production is very difficult and very few improvements have been made in industry. One challenge is that these methods often hurt overall performance; additionally, they could be complex and expensive to train and serve.In this work, we aim to improve tail item recommendations while maintaining the overall performance with less training and serving cost. We first find that the predictions of user preferences are biased under long-tail distributions. The bias comes from the differences between training and serving data in two perspectives: 1) the item distributions, and 2) user's preference given an item. Most existing methods mainly attempt to reduce the bias from the item distribution perspective, ignoring the discrepancy from user preference given an item. This leads to a severe forgetting issue and results in sub-optimal performance.To address the problem, we design a novel Cross Decoupling Network (CDN) to reduce the two differences. Specifically, CDN (i) decouples the learning process of memorization and generalization on the item side through a mixture-of-expert architecture; (ii) decouples the user samples from different distributions through a regularized bilateral branch network. Finally, a new adapter is introduced to aggregate the decoupled vectors, and softly shift the training attention to tail items. Extensive experimental results show that CDN significantly outperforms state-of-the-art approaches on popular benchmark datasets. We also demonstrate its effectiveness by a case study of CDN in a large-scale recommendation system at Google.",10.1145/3580305.3599814,https://doi.org/10.1145/3580305.3599814,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Empowering Long-tail Item Recommendation through Cross Decoupling Network (CDN),"Zhang, Yin and Wang, Ruoxi and Cheng, Derek Zhiyuan and Yao, Tiansheng and Yi, Xinyang and Hong, Lichan and Caverlee, James and Chi, Ed H.",inproceedings,10.1145/3580305.3599814,
10.1145/3580305.3599826,10.1145/3580305.3599826,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","cold-start recommendation, content generalization, hybrid recommendation systems, real-time learning",10,5082–5091,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Recommendation system serves as a conduit connecting users to an incredibly large, diverse and ever growing collection of contents. In practice, missing information on fresh (and tail) contents needs to be filled in order for them to be exposed and discovered by their audience. We here share our success stories in building a dedicated fresh content recommendation stack on a large commercial platform. To nominate fresh contents, we built a multi-funnel nomination system that combines (i) a two-tower model with strong generalization power for coverage, and (ii) a sequence model with near real-time update on user feedback for relevance. The multi-funnel setup effectively balances between coverage and relevance. An in-depth study uncovers the relationship between user activity level and their proximity toward fresh contents, which further motivates a contextual multi-funnel setup. Nominated fresh candidates are then scored and ranked by systems considering prediction uncertainty to further bootstrap content with less exposure. We evaluate the benefits of the dedicated fresh content recommendation stack, and the multi-funnel nomination system in particular, through user corpus co-diverted live experiments. We conduct multiple rounds of live experiments on a commercial platform serving billion of users demonstrating efficacy of our proposed methods.",10.1145/3580305.3599826,https://doi.org/10.1145/3580305.3599826,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Fresh Content Needs More Attention: Multi-funnel Fresh Content Recommendation,"Wang, Jianling and Lu, Haokai and Zhang, Sai and Locanthi, Bart and Wang, Haoting and Greaves, Dylan and Lipshitz, Benjamin and Badam, Sriraj and Chi, Ed H. and Goodrow, Cristos J. and Wu, Su-Lin and Baugher, Lexi and Chen, Minmin",inproceedings,10.1145/3580305.3599826,
10.1145/3580305.3599834,10.1145/3580305.3599834,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","data subsampling, network analysis, recommender systems",12,3865–3876,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Data subsampling is widely used to speed up the training of large-scale recommendation systems. Most subsampling methods are model-based and often require a pre-trained pilot model to measure data importance via e.g. sample hardness. However, when the pilot model is misspecified, model-based subsampling methods deteriorate. Since model misspecification is persistent in real recommendation systems, we instead propose model-agnostic data subsampling methods by only exploring input data structure represented by graphs. Specifically, we study the topology of the user-item graph to estimate the importance of each user-item interaction (an edge in the user-item graph) via graph conductance, followed by a propagation step on the network to smooth out the estimated importance value. Since our proposed method is model-agnostic, we can marry the merits of both model-agnostic and model-based subsampling methods. Empirically, we show that combing the two consistently improves over any single method on the used datasets. Experimental results on KuaiRec and MIND datasets demonstrate that our proposed methods achieve superior results compared to baseline approaches.",10.1145/3580305.3599834,https://doi.org/10.1145/3580305.3599834,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Graph-Based Model-Agnostic Data Subsampling for Recommendation Systems,"Chen, Xiaohui and Sun, Jiankai and Wang, Taiqing and Guo, Ruocheng and Liu, Li-Ping and Zhang, Aonan",inproceedings,10.1145/3580305.3599834,
10.1145/3580305.3599919,10.1145/3580305.3599919,KDD.bib,1,['KDD.bib'],8,KDD '23,"Long Beach, CA, USA","ordinal regression, recommender system, tree based model, watch time prediction",10,4497–4506,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"An accurate prediction of watch time has been of vital importance to enhance user engagement in video recommender systems. To achieve this, there are four properties that a watch time prediction framework should satisfy: first, despite its continuous value, watch time is also an ordinal variable and the relative ordering between its values reflects the differences in user preferences. Therefore the ordinal relations should be reflected in watch time predictions. Second, the conditional dependence between the video-watching behaviors should be captured in the model. For instance, one has to watch half of the video before he/she finishes watching the whole video. Third, modeling watch time with a point estimation ignores the fact that models might give results with high uncertainty and this could cause bad cases in recommender systems. Therefore the framework should be aware of prediction uncertainty. Forth, the real-life recommender systems suffer from severe bias amplifications thus an estimation without bias amplification is expected.How to design a framework that solves these four issues simultaneously remain unexplored. Therefore we propose TPM (Tree-based Progressive regression Model) for watch time prediction. Specifically, the ordinal ranks of watch time are introduced into TPM and the problem is decomposed into a series of conditional dependent classification tasks which are organized into a tree structure. The expectation of watch time can be generated by traversing the tree and the variance of watch time predictions is explicitly introduced into the objective function as a measurement for uncertainty. Moreover, we illustrate that backdoor adjustment can be seamlessly incorporated into TPM, which alleviates bias amplifications.Extensive offline evaluations have been conducted in public datasets and TPM have been deployed in a real-world video app Kuaishou with over 300 million DAUs. The results indicate that TPM outperforms state-of-the-art approaches and indeed improves video consumption significantly.",10.1145/3580305.3599919,https://doi.org/10.1145/3580305.3599919,"New York, NY, USA",Association for Computing Machinery,9798400701030,2023,Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation,"Lin, Xiao and Chen, Xiaokai and Song, Linfeng and Liu, Jingwei and Li, Biao and Jiang, Peng",inproceedings,10.1145/3580305.3599919,
10.1145/3583780.3614651,10.1145/3583780.3614651,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","multi-task learning, multi-scenario learning, meta learning",7,4945–4951,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Recommender systems are widely applied on web. For example, online advertising systems rely on recommender systems to accurately estimate the value of display opportunities, which is critical to maximize the profits of advertisers. To reduce computational resource consumption, the core tactic of Multi-Scenario Multi-Task Learning (MSMTL) is to devise a single recommder system that is adapted to all contexts instead of implementing multiple scenario-oriented or task-oriented recommender systems. However, MSMTL is challenging because there are complicated task-task, scenario-scenario, and task-scenario interrelations; the characteristic of different tasks in different scenarios also largely varies; and samples of each context are often unevenly distributed. Previous MSMTL solutions focus on applying scenario knowledge to improve the performance of multi-task learning, while neglecting the complicated interrelations among tasks and scenarios. Moreover, samples derived from different scenarios are transferred into the latent embedding with the same dimension. This static embedding strategy impedes the practicality of model expressiveness, since the scenarios with sufficient samples are underrepresented and those with insufficient samples are over-represented.In this paper, we propose a novel three meta networks-based solution (3MN) to MSMTL that addresses all the limitations discussed above. Specifically, we innovatively bind the meta network with scenario-related input in bottom embedding layer, so that the embedding layer is capable of learning the scenario-related knowledge explicitly. To counteract the imbalanced scenario-related data distributions, our flexible embedding layer adaptively learns the representation of samples. This innovative embedding layer is also able to boost other solutions as a plug-in. Moreover, to fully capture the interrelations among scenarios and tasks, we enforce the task and scenario information into the other two meta networks, and transfer the resulted meta-knowledge into the top components (i.e., backbone network and classifier) of the recommender system, respectively. These three meta networks contribute to the superiority of our 3MN solution over state-of-the-art MSMTL solutions, which is demonstrated by extensive offline experiments. 3MN has been successfully deployed in our industrial online advertising system.",10.1145/3583780.3614651,https://doi.org/10.1145/3583780.3614651,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,3MN: Three Meta Networks for Multi-Scenario and Multi-Task Learning in Online Advertising Recommender Systems,"Zhang, Yifei and Hua, Hua and Guo, Hui and Wang, Shuangyang and Zhong, Chongyu and Zhang, Shijie",inproceedings,10.1145/3583780.3614651,
10.1145/3583780.3614749,10.1145/3583780.3614749,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","self-supervised learning, probabilistic meta-learning, neural processes",5,5123–5127,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Neural Processes (NPs) are a family of supervised density estimators devoted to probabilistic function approximation with meta-learning. Despite extensive research on the subject, the absence of a unified framework for NPs leads to varied architectural solutions across diverse studies. This non-consensus poses challenges to reproducing and benchmarking different NPs. Moreover, existing codebases mainly prioritize generative density estimation, yet rarely consider expanding the capability of NPs to self-supervised representation learning, which however has gained growing importance in data mining applications. To this end, we present NP-SSL, a modular and configurable framework with built-in support, requiring minimal effort to 1) implement classical NPs architectures; 2) customize specific components; 3) integrate hybrid training scheme (e.g., contrastive); and 4) extend NPs to act as a self-supervised learning toolkit, producing latent representations of data, and facilitating diverse downstream predictive tasks. To illustrate, we discuss a case study that applies NP-SSL to model time-series data. We interpret that NP-SSL can handle different predictive tasks such as imputation and forecasting, by a simple switch in data samplings, without significant change to the underlying structure. We hope this study can reduce the workload of future research on leveraging NPs to tackle more a broader range of real-world data mining applications. Code and documentation are at https://github.com/zyecs/NP-SSL.",10.1145/3583780.3614749,https://doi.org/10.1145/3583780.3614749,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,NP-SSL: A Modular and Extensible Self-supervised Learning Library with Neural Processes,"Ye, Zesheng and Du, Jing and Liu, Yao and Zhang, Yihong and Yao, Lina",inproceedings,10.1145/3583780.3614749,
10.1145/3583780.3614770,10.1145/3583780.3614770,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","shared embedding, review-based recommendation, recommender systems",11,2928–2938,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Reviews are valuable resources that have been widely researched and used to improve the quality of recommendation services. Recent methods use multiple full embedding layers to model various levels of individual preferences, increasing the risk of the data sparsity issue. Although it is a potential way to deal with this issue that models homophily among users who have similar behaviors, the existing approaches are implemented in a coarse-grained way. They calculate user similarities by considering the homophily in their global behaviors but ignore their local behaviors under a specific context. In this paper, we propose a two-tier shared embedding model (TSE), which fuses coarse- and fine-grained ways of modeling homophily. It considers global behaviors to model homophily in a coarse-grained way, and the high-level feature in the process of each user-item interaction to model homophily in a fine-grained way. TSE designs a whole-to-part principle-based process to fuse these ways in the review-based recommendation. Experiments on five real-world datasets demonstrate that TSE significantly outperforms state-of-the-art models. It outperforms the best baseline by 20.50% on the root-mean-square error (RMSE) and 23.96% on the mean absolute error (MAE), respectively. The source code is available at https://github.com/dianziliu/TSE.git.",10.1145/3583780.3614770,https://doi.org/10.1145/3583780.3614770,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,A Two-tier Shared Embedding Method for Review-based Recommender Systems,"Yang, Zhen and Liu, Junrui and Li, Tong and Wu, Di and Yang, Shiqiu and Liu, Huan",inproceedings,10.1145/3583780.3614770,
10.1145/3583780.3614776,10.1145/3583780.3614776,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","time series forecasting, social media popularity, retrieval, angle feature",10,2606–2615,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Social media popularity forecasting has become a hot research topic in recent years. It is of great significance in assisting public opinion monitoring and advertising placement. Time series prediction is one of the simple and commonly used methods for popularity forecasting, which takes the popularity of the first few time steps in the observed data as inputs. However, the complete popularity trend of each social media is known in the training dataset, while the historical time series information except for the first few time steps is neglected in the existing models. In order to utilize the complete historical information from the observed data, a retrieval method is introduced in this paper. Therefore, how to retrieve similar social media based on the first few steps time series and how to integrate the similar historical information have become two challenges. A two-stage prediction method named Angle Feature Retrieval based Forecasting (AFRF) is proposed in this paper to solve the upper two problems. In the first stage, based on the angle features of series, we retrieve K similar series from the historical posts and concatenate them with the target series as the model's input. In the second stage, an attention mechanism is used to learn the temporal relationships among the series and generate future popularity forecasts. We evaluated the multi-step and single-point forecasting performance of AFRF on three real-world datasets and compared it with state-of-the-art popularity forecasting methods, such as temporal feature-based and cascade-based methods, verifying the effectiveness of AFRF.",10.1145/3583780.3614776,https://doi.org/10.1145/3583780.3614776,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,AFRF: Angle Feature Retrieval Based Popularity Forecasting,"Wang, Haoyu and Xie, Zongxia and Liu, Meiyao and Guan, Canhua",inproceedings,10.1145/3583780.3614776,
10.1145/3583780.3614785,10.1145/3583780.3614785,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","transformer, sequential recommendation, attention mechanism",11,3595–3605,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Transformer-based sequential recommendation (SR) has been booming in recent years, with the self-attention mechanism as its key component. Self-attention has been widely believed to be able to effectively select those informative and relevant items from a sequence of interacted items for next-item prediction via learning larger attention weights for these items. However, this may not always be true in reality. Our empirical analysis of some representative Transformer-based SR models reveals that it is not uncommon for large attention weights to be assigned to less relevant items, which can result in inaccurate recommendations. Through further in-depth analysis, we find two factors that may contribute to such inaccurate assignment of attention weights:sub-optimal position encoding andnoisy input. To this end, in this paper, we aim to address this significant yet challenging gap in existing works. To be specific, we propose a simple yet effective framework called Attention Calibration for Transformer-based Sequential Recommendation (AC-TSR). In AC-TSR, a novel spatial calibrator and adversarial calibrator are designed respectively to directly calibrates those incorrectly assigned attention weights. The former is devised to explicitly capture the spatial relationships (i.e., order and distance) among items for more precise calculation of attention weights. The latter aims to redistribute the attention weights based on each item's contribution to the next-item prediction. AC-TSR is readily adaptable and can be seamlessly integrated into various existing transformer-based SR models. Extensive experimental results on four benchmark real-world datasets demonstrate the superiority of our proposed AC-TSR via significant recommendation performance enhancements. The source code is available at https://github.com/AIM-SE/AC-TSR.",10.1145/3583780.3614785,https://doi.org/10.1145/3583780.3614785,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Attention Calibration for Transformer-based Sequential Recommendation,"Zhou, Peilin and Ye, Qichen and Xie, Yueqi and Gao, Jingqi and Wang, Shoujin and Kim, Jae Boum and You, Chenyu and Kim, Sunghun",inproceedings,10.1145/3583780.3614785,
10.1145/3583780.3614789,10.1145/3583780.3614789,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","recommender systems, negative sampling, information retrieval",10,494–503,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Recommendation retrievers commonly retrieve user potentially preferred items from numerous items, where the query and item representation are learned according to the dual encoders with the log-softmax loss. Under real scenarios, the number of items becomes considerably large, making it exceedingly difficult to calculate the partition function with the whole item corpus. Negative sampling, which samples a subset from the item corpus, is widely used to accelerate the model training. Among different samplers, the in-batch sampling is commonly adopted for online recommendation retrievers, which regards the other items within the mini-batch as the negative samples for the given query, owing to its time and memory efficiency. However, the sample selection bias occurs due to the skewed feedback, harming the retrieval quality. In this paper, we propose a negative sampling approach named Batch-Mix Negative Sampling (BMNS), which adopts batch mixing operation to generate additional negatives for model training. Concretely, BMNS first generates new negative items with the sampled mix coefficient from the Beta distribution, after which a tailored correct strategy guided by frequency is designed to match the sampled softmax loss. In this way, the effort of re-encoding items out of the mini-batch is reduced while also improving the representation space of the negative set. The empirical experiments on four real-world datasets demonstrate BMNS is superior to the competitive negative inbatch sampling method.",10.1145/3583780.3614789,https://doi.org/10.1145/3583780.3614789,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Batch-Mix Negative Sampling for Learning Recommendation Retrievers,"Fan, Yongfu and Chen, Jin and Jiang, Yongquan and Lian, Defu and Guo, Fangda and Zheng, Kai",inproceedings,10.1145/3583780.3614789,
10.1145/3583780.3614801,10.1145/3583780.3614801,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","recommender system, popularity trends, non-personalized recommender",11,1014–1024,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Recommender systems have been gaining increasing research attention over the years. Most existing recommendation methods focus on capturing users' personalized preferences through historical user-item interactions, which may potentially violate user privacy. Additionally, these approaches often overlook the significance of the temporal fluctuation in item popularity that can sway users' decision-making. To bridge this gap, we propose Popularity-Aware Recommender (PARE), which makes non-personalized recommendations by predicting the items that will attain the highest popularity. PARE consists of four modules, each focusing on a different aspect: popularity history, temporal impact, periodic impact, and side information. Finally, an attention layer is leveraged to fuse the outputs of four modules. To our knowledge, this is the first work to explicitly model item popularity in recommendation systems. Extensive experiments show that PARE performs on par or even better than sophisticated state-of-the-art recommendation methods. Since PARE prioritizes item popularity over personalized user preferences, it can enhance existing recommendation methods as a complementary component. Our experiments demonstrate that integrating PARE with existing recommendation methods significantly surpasses the performance of standalone models, highlighting PARE's potential as a complement to existing recommendation methods. Furthermore, the simplicity of PARE makes it immensely practical for industrial applications and a valuable baseline for future research.",10.1145/3583780.3614801,https://doi.org/10.1145/3583780.3614801,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation,"Jing, Jiazheng and Zhang, Yinan and Zhou, Xin and Shen, Zhiqi",inproceedings,10.1145/3583780.3614801,
10.1145/3583780.3614805,10.1145/3583780.3614805,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","selection bias, recommender systems, doubly robust",10,2321–2330,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"In recommendation systems (RS), user behavior data is observational rather than experimental, resulting in widespread bias in the data. Consequently, tackling bias has emerged as a major challenge in the field of recommendation systems. Recently, Doubly Robust Learning (DR) has gained significant attention due to its remarkable performance and robust properties. However, our experimental findings indicate that existing DR methods are severely impacted by the presence of so-called Poisonous Imputation, where the imputation significantly deviates from the truth and becomes counterproductive.To address this issue, this work proposes Conservative Doubly Robust strategy (CDR) which filters imputations by scrutinizing their mean and variance. Theoretical analyses show that CDR offers reduced variance and improved tail bounds.In addition, our experimental investigations illustrate that CDR significantly enhances performance and can indeed reduce the frequency of poisonous imputation.",10.1145/3583780.3614805,https://doi.org/10.1145/3583780.3614805,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,CDR: Conservative Doubly Robust Learning for Debiased Recommendation,"Song, Zijie and Chen, Jiawei and Zhou, Sheng and Shi, Qihao and Feng, Yan and Chen, Chun and Wang, Can",inproceedings,10.1145/3583780.3614805,
10.1145/3583780.3614822,10.1145/3583780.3614822,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","personalization, online learning, learner modeling, knowledge tracing, intelligent education",10,2616–2625,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"With the advance of online education systems, accessibility to learning materials has increased. In these systems, students can practice independently and learn from different learning materials over long periods of time. As a result, it is essential to trace students' knowledge states over long learning sequences while maintaining a personalized model of each individual student's progress. However, the existing deep learning-based knowledge tracing models are either not personalized or not tailored for handling long sequences. Handling long sequences are especially essential in the online education environments, in where models are preferred to be updated with the newly collected user data in a timely manner as students could acquire knowledge on each learning activity. In this paper, we propose a knowledge tracing model, Continuous Personalized Knowledge Tracing (CPKT), that can mimic the real-world long-term continuous learning scenario by incorporating a novel online model training paradigm that is suitable for the knowledge tracing problem. To achieve personalized knowledge tracing, we propose two model components: 1) personalized memory slots to maintain learner's knowledge in a lifelong manner, and 2) personalized user embeddings that help to accurately predict the individual responses, correctly detect the personalized knowledge acquisition and forgetting patterns, and better interpret and analyze the learner's progress. Additionally, we propose transition-aware stochastic shared embedding according to the learning transition matrix to regularize the online model training. Extensive experiments on four real-world datasets showcase the effectiveness and superiority of CPKT, especially for students with longer sequences.",10.1145/3583780.3614822,https://doi.org/10.1145/3583780.3614822,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Continuous Personalized Knowledge Tracing: Modeling Long-Term Learning in Online Environments,"Wang, Chunpai and Sahebi, Shaghayegh",inproceedings,10.1145/3583780.3614822,
10.1145/3583780.3614823,10.1145/3583780.3614823,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","recommender systems, propensity scores, contrastive counterfactual learning, causal inference",10,3564–3573,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"The field of generating recommendations within the framework of causal inference has seen a recent surge.This approach enhances insights into the influence of recommendations on user behavior and helps in identifying the underlying factors. Existing research has often leveraged propensity scores to mitigate bias, albeit at the risk of introducing additional variance. Others have explored the use of unbiased data from randomized controlled trials, although this comes with assumptions that may prove challenging in practice. In this paper, we first present the causality-aware interpretation of recommendations and reveal how the underlying exposure mechanism can bias the maximum likelihood estimation (MLE) of observational feedback. Recognizing that confounders may be elusive, we propose a contrastive self-supervised learning to minimize exposure bias, employing inverse propensity scores and expanding the positive sample set. Building on this foundation, we present a novel contrastive counterfactual learning method (CCL) that incorporates three unique positive sampling strategies grounded in estimated exposure probability or random counterfactual samples. Through extensive experiments on two real-world datasets, we demonstrate that our CCL outperforms the state-of-the-art methods.",10.1145/3583780.3614823,https://doi.org/10.1145/3583780.3614823,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Contrastive Counterfactual Learning for Causality-aware Interpretable Recommender Systems,"Zhou, Guanglin and Huang, Chengkai and Chen, Xiaocong and Xu, Xiwei and Wang, Chen and Zhu, Liming and Yao, Lina",inproceedings,10.1145/3583780.3614823,
10.1145/3583780.3614845,10.1145/3583780.3614845,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","recommendation system, negative sample, Mixup",10,2785–2794,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Collaborative filtering (CF) is a widely employed technique that predicts user preferences based on past interactions. Negative sampling plays a vital role in training CF-based models with implicit feedback. In this paper, we propose a novel perspective based on the sampling area to revisit existing sampling methods. We point out that current sampling methods mainly focus on Point-wise or Line-wise sampling, lacking flexibility and leaving a significant portion of the hard sampling area un-explored. To address this limitation, we propose Dimension Independent Mixup for Hard Negative Sampling (DINS), which is the first Area-wise sampling method for training CF-based models. DINS comprises three modules: Hard Boundary Definition, Dimension Independent Mixup, and Multi-hop Pooling. Experiments with real-world datasets on both matrix factorization and graph-based models demonstrate that DINS outperforms other negative sampling methods, establishing its effectiveness and superiority. Our work contributes a new perspective, introduces Area-wise sampling, and presents DINS as a novel approach that achieves state-of-the-art performance for negative sampling. Our implementations are available in PyTorch.",10.1145/3583780.3614845,https://doi.org/10.1145/3583780.3614845,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Dimension Independent Mixup for Hard Negative Sample in Collaborative Filtering,"Wu, Xi and Yang, Liangwei and Gong, Jibing and Zhou, Chao and Lin, Tianyu and Liu, Xiaolong and Yu, Philip S.",inproceedings,10.1145/3583780.3614845,
10.1145/3583780.3614854,10.1145/3583780.3614854,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","semantic commonality, multiple relations, contrastive learning, auction recommendation",10,2146–2155,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Recommendation systems in auction platforms like eBay function differently in comparison to those found in traditional trading platforms. The bidding process involves multiple users competing for a product, with the highest bidder winning the item. As a result, each transaction is independent and characterized by varying transaction prices. The individual nature of auction items means that users cannot purchase identical items, adding to the uniqueness of the purchasing history. Bidders in auction systems rely on their judgment to determine the value of a product, as bidding prices reflect preferences rather than cost-free actions like clicking or collecting. Conventional methodologies that heavily rely on user-item purchase history are ill-suited to handle these unique and extreme product features. Unfortunately, prior recommendation approaches have failed to give due attention to the contextual intricacies of auction items, thereby missing out on the full potential of the invaluable bidding record at hand.This paper introduces a novel contrastive learning approach for auction recommendation, addressing the challenges of data sparsity and uniqueness in auction recommendation. Our method focuses on capturing multiple behavior relations and item context through contrastive pairs construction, contrastive embedding, and contrastive optimization techniques from both user and item perspectives. By overcoming the limitations of previous approaches, our method delivers promising results on two auction datasets, highlighting the practicality and effectiveness of our model.",10.1145/3583780.3614854,https://doi.org/10.1145/3583780.3614854,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Dual-view Contrastive Learning for Auction Recommendation,"Ren, Dan Ni and U, Leong Hou and Liu, Wei",inproceedings,10.1145/3583780.3614854,
10.1145/3583780.3614879,10.1145/3583780.3614879,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","transformer, sequential tabular data, field and time aware",10,3247–3256,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Sequential tabular data is one of the most commonly used data types in real-world applications. Different from conventional tabular data, where rows in a table are independent, sequential tabular data contains rich contextual and sequential information, where some fields aredynamically changing over time and others arestatic. Existing transformer-based approaches analyzing sequential tabular data overlook the differences between dynamic and static fields by replicating and filling static fields into each record, and ignore temporal information between rows, which leads to three major disadvantages: (1) computational overhead, (2) artificially simplified data for masked language modeling pre-training task that may yield less meaningful representations, and (3) disregarding the temporal behavioral patterns implied by time intervals. In this work, we propose FATA-Trans, a model with two field transformers for modeling sequential tabular data, where each processes static and dynamic field information separately. FATA-Trans isfield - andtime -aware for sequential tabular data. Thefield -type embedding in the method enables FATA-Trans to capture differences between static and dynamic fields. Thetime -aware position embedding exploits both order and time interval information between rows, which helps the model detect underlying temporal behavior in a sequence. Our experiments on three benchmark datasets demonstrate that the learned representations from FATA-Trans consistently outperform state-of-the-art solutions in the downstream tasks. We also present visualization studies to highlight the insights captured by the learned representations, enhancing our understanding of the underlying data. Our codes are available at https://github.com/zdy93/FATA-Trans.",10.1145/3583780.3614879,https://doi.org/10.1145/3583780.3614879,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,FATA-Trans: Field And Time-Aware Transformer for Sequential Tabular Data,"Zhang, Dongyu and Wang, Liang and Dai, Xin and Jain, Shubham and Wang, Junpeng and Fan, Yujie and Yeh, Chin-Chia Michael and Zheng, Yan and Zhuang, Zhongfang and Zhang, Wei",inproceedings,10.1145/3583780.3614879,
10.1145/3583780.3614929,10.1145/3583780.3614929,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","recommender system, long-tail distribution, graph augmentation",10,1707–1716,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"The ubiquitous long-tail distribution of inherent user behaviors results in worse recommendation performance for the items with fewer user records (i.e., tail items) than those with richer ones (i.e., head items). Graph-based recommendation methods (e.g., using graph neural networks) have recently emerged as a powerful tool for recommender systems, often outperforming traditional methods. However, existing techniques for alleviating the long-tail problem mainly focus on traditional methods. There is a lack of graph-based methods that can efficiently deal with the long-tail problem.In this paper, we propose a novel approach, Graph Augmentation for Long-tail Recommendation (GALORE), which can be plugged into any graph-based recommendation models to improve the performance for tail items. GALORE incorporates an edge addition module that enriches the graph's connectivity for tail items by injecting additional item-to-item edges. To further balance the graph structure, GALORE utilizes a degree-aware edge dropping strategy, preserving the more valuable edges from the tail items while selectively discarding less informative edges from the head items. Beyond structural augmentation, we synthesize new data samples, thereby addressing the data scarcity issue for tail items. We further introduce a two-stage training strategy to facilitate the learning for both head and tail items. Comprehensive empirical studies conducted on four datasets show that GALORE outperforms existing methods in terms of the performance for tail items as well as the overall performance.",10.1145/3583780.3614929,https://doi.org/10.1145/3583780.3614929,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Improving Long-Tail Item Recommendation with Graph Augmentation,"Luo, Sichun and Ma, Chen and Xiao, Yuanzhang and Song, Linqi",inproceedings,10.1145/3583780.3614929,
10.1145/3583780.3614949,10.1145/3583780.3614949,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","large language model, datasets, conversational recommendation",11,720–730,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"In this paper, we present empirical studies on conversational recommendation tasks using representative large language models in a zero-shot setting with three primary contributions. (1) Data: To gain insights into model behavior in ""in-the-wild"" conversational recommendation scenarios, we construct a new dataset of recommendation-related conversations by scraping a popular discussion website. This is the largest public real-world conversational recommendation dataset to date. (2) Evaluation: On the new dataset and two existing conversational recommendation datasets, we observe that even without fine-tuning, large language models can outperform existing fine-tuned conversational recommendation models. (3) Analysis: We propose various probing tasks to investigate the mechanisms behind the remarkable performance of large language models in conversational recommendation. We analyze both the large language models' behaviors and the characteristics of the datasets, providing a holistic understanding of the models' effectiveness, limitations and suggesting directions for the design of future conversational recommenders.",10.1145/3583780.3614949,https://doi.org/10.1145/3583780.3614949,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Large Language Models as Zero-Shot Conversational Recommenders,"He, Zhankui and Xie, Zhouhang and Jha, Rahul and Steck, Harald and Liang, Dawen and Feng, Yesu and Majumder, Bodhisattwa Prasad and Kallus, Nathan and Mcauley, Julian",inproceedings,10.1145/3583780.3614949,
10.1145/3583780.3614965,10.1145/3583780.3614965,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","sequential recommender systems, meta-learning, loss function, imbalanced data, cold-start recommendation",10,1077–1086,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Sequential recommenders have made great strides in capturing a user's preferences. Nevertheless, the cold-start recommendation remains a fundamental challenge as they typically involve limited user-item interactions for personalization. Recently, gradient-based meta-learning approaches have emerged in the sequential recommendation field due to their fast adaptation and easy-to-integrate abilities. The meta-learning algorithms formulate the cold-start recommendation as a few-shot learning problem, where each user is represented as a task to be adapted. While meta-learning algorithms generally assume that task-wise samples are evenly distributed over classes or values, user-item interactions in real-world applications do not conform to such a distribution (e.g., watching favorite videos multiple times, leaving only positive ratings without any negative ones). Consequently, imbalanced user feedback, which accounts for the majority of task training data, may dominate the user adaptation process and prevent meta-learning algorithms from learning meaningful meta-knowledge for personalized recommendations. To alleviate this limitation, we propose a novel sequential recommendation framework based on gradient-based meta-learning that captures the imbalanced rating distribution of each user and computes adaptive loss for user-specific learning. Our work is the first to tackle the impact of imbalanced ratings in cold-start sequential recommendation scenarios. Through extensive experiments conducted on real-world datasets, we demonstrate the effectiveness of our framework.",10.1145/3583780.3614965,https://doi.org/10.1145/3583780.3614965,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start Recommendation,"Kim, Minchang and Yang, Yongjin and Ryu, Jung Hyun and Kim, Taesup",inproceedings,10.1145/3583780.3614965,
10.1145/3583780.3615009,10.1145/3583780.3615009,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","sample bias, popularity bias, debiased contrastive learning, collaborative filtering",11,1482–1492,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Collaborative filtering (CF) is the basic method for recommendation with implicit feedback. Recently, various state-of-the-art CF integrates graph neural networks. However, they often suffer from popularity bias, causing recommendations to deviate from users' genuine preferences. Additionally, several contrastive learning methods based on the in-batch sample strategy have been proposed to train the CF model effectively, but they are prone to suffering from sample bias. To address this problem, debiased contrastive loss has been employed in the recommendation, but instead of personalized debiasing, it treats each user equally. In this paper, we propose a popularity-aware debiased contrastive loss for CF, which can adaptively correct the positive and negative scores based on the popularity of users and items. Our approach aims to reduce the negative impact of popularity and sample bias simultaneously. We theoretically analyze the effectiveness of the proposed method and reveal the relationship between popularity and gradient, which justifies the correction strategy. We extensively evaluate our method on three public benchmarks over balanced and imbalanced settings. The results demonstrate its superiority over the existing debiased strategies, not only on the entire datasets but also when segmenting the datasets based on item popularity.",10.1145/3583780.3615009,https://doi.org/10.1145/3583780.3615009,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,PopDCL: Popularity-aware Debiased Contrastive Loss for Collaborative Filtering,"Liu, Zhuang and Li, Haoxuan and Chen, Guanming and Ouyang, Yuanxin and Rong, Wenge and Xiong, Zhang",inproceedings,10.1145/3583780.3615009,
10.1145/3583780.3615010,10.1145/3583780.3615010,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","recommender systems, pareto optimality, information retrieval",11,2013–2023,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Information Retrieval (IR) and Recommender Systems (RSs) tasks are moving from computing a ranking of final results based on a single metric to multi-objective problems. Solving these problems leads to a set of Pareto-optimal solutions, known as Pareto frontier, in which no objective can be further improved without hurting the others. In principle, all the points on the Pareto frontier are potential candidates to represent the best model selected with respect to the combination of two, or more, metrics. To our knowledge, there are no well-recognized strategies to decide which point should be selected on the frontier in IR and RSs. In this paper, we propose a novel, post-hoc, theoretically-justified technique, named ""Population Distance from Utopia"" (PDU), to identify and select the one-best Pareto-optimal solution. PDU considers fine-grained utopia points, and measures how far each point is from its utopia point, allowing to select solutions tailored to user preferences, a novel feature we call ""calibration"". We compare PDU against state-of-the-art strategies through extensive experiments on tasks from both IR and RS, showing that PDU combined with calibration notably impacts the solution selection.",10.1145/3583780.3615010,https://doi.org/10.1145/3583780.3615010,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Post-hoc Selection of Pareto-Optimal Solutions in Search and Recommendation,"Paparella, Vincenzo and Anelli, Vito Walter and Nardini, Franco Maria and Perego, Raffaele and Di Noia, Tommaso",inproceedings,10.1145/3583780.3615010,
10.1145/3583780.3615012,10.1145/3583780.3615012,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","user review, textual content, recommender system, image content, graph convolutional network, dimension-based attention, collaborative filtering",10,1431–1440,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Nowadays, modern recommender systems usually leverage textual and visual contents as auxiliary information to predict user preference. For textual information, review texts are one of the most popular contents to model user behaviors. Nevertheless, reviews usually lose their shine when it comes to top-N recommender systems because those that solely utilize textual reviews as features struggle to adequately capture the interaction relationships between users and items. For visual one, it is usually modeled with naive convolutional networks and also hard to capture high-order relationships between users and items. Moreover, previous works did not collaboratively use both texts and images in a proper way. In this paper, we propose printf, preference modeling based on user reviews with item images and textual information via graph learning, to address the above challenges. Specifically, the dimension-based attention mechanism directs relations between user reviews and interacted items, allowing each dimension to contribute different importance weights to derive user representations. Extensive experiments are conducted on three publicly available datasets. The experimental results demonstrate that our proposed printf consistently outperforms baseline methods with the relative improvements for NDCG@5 of 26.80%, 48.65%, and 25.74% on Amazon-Grocery, Amazon-Tools, and Amazon-Electronics datasets, respectively. The in-depth analysis also indicates the dimensions of review representations definitely have different topics and aspects, assisting the validity of our model design.",10.1145/3583780.3615012,https://doi.org/10.1145/3583780.3615012,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,printf: Preference Modeling Based on User Reviews with Item Images and Textual Information via Graph Learning,"Lin, Hao-Lun and Jiang, Jyun-Yu and Juan, Ming-Hao and Cheng, Pu-Jen",inproceedings,10.1145/3583780.3615012,
10.1145/3583780.3615035,10.1145/3583780.3615035,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","collaborative filtering, graph neural networks, meta-learning, neural architecture search",10,1379–1388,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Graph Neural Networks (GNNs) have been widely used in Collaborative Filtering (CF). However, when given a new recommendation scenario, the current options are either selecting from existing GNN architectures or employing Neural Architecture Search (NAS) to obtain a well-performing GNN model, both of which are expensive in terms of human expertise or computational resources.To address the problem, in this work,we propose a novel neural retrieval approach, dubbed RGCF, to search a well-performing architecture for GNN-based CF rapidly when handling new scenarios. Specifically, we design the neural retrieval approach based on meta-learning by developing two-level meta-features, ranking loss, and task-level data augmentation, and in a retrieval paradigm, RGCF can directly return a well-performing architecture given a new dataset (query), thus being efficient inherently. Experimental results on two mainstream tasks, i.e., rating prediction and item ranking, show that RGCF outperforms all models either by human-designed or NAS on two new datasets in terms of effectiveness and efficiency. Particularly, the efficiency improvement is significant, taking as an example that RGCF is 61.7-206.3x faster than a typical reinforcement learning based NAS approach on the two new datasets. Code and data are available at https://github.com/BUPT-GAMMA/RGCF.",10.1145/3583780.3615035,https://doi.org/10.1145/3583780.3615035,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Retrieving GNN Architecture for Collaborative Filtering,"Liang, Fengqi and Zhao, Huan and Wang, Zhenyi and Fang, Wei and Shi, Chuan",inproceedings,10.1145/3583780.3615035,
10.1145/3583780.3615056,10.1145/3583780.3615056,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","sentiment classification, recommender system, pre-trained language models, personalized review summarization",10,2826–2835,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Personalized review summarization is a challenging task in recommender systems, which aims to generate condensed and readable summaries for product reviews. Recently, some methods propose to adopt the sentiment signals of reviews to enhance the review summarization. However, most previous works only share the semantic features of reviews via preliminary multi-task learning, while ignoring the rich personalized information of users and products, which is crucial to both sentiment identification and comprehensive review summarization. In this paper, we propose a sentiment-aware review summarization method with an elaborately designed multi-task fine-tuning framework to make full use of personalized information of users and products effectively based on Pretrained Language Models (PLMs). We first denote two types of personalized information including IDs and historical summaries to indicate their identification and semantics information respectively. Subsequently, we propose to incorporate the IDs of the user/product into the PLMs-based encoder to learn the personalized representations of input reviews and their historical summaries in a fine-tuning way. Based on this, an auxiliary context-aware review sentiment classification task and a further sentiment-guided personalized review summarization task are jointly learned. Specifically, the sentiment representation of input review is used to identify relevant historical summaries, which are then treated as additional semantic context features to enhance the summary generation process. Extensive experimental results show our approach could generate sentiment-consistent summaries and outperforms many competitive baselines on both review summarization and sentiment classification tasks.",10.1145/3583780.3615056,https://doi.org/10.1145/3583780.3615056,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Sentiment-aware Review Summarization with Personalized Multi-task Fine-tuning,"Xu, Hongyan and Liu, Hongtao and Lv, Zhepeng and Yang, Qing and Wang, Wenjun",inproceedings,10.1145/3583780.3615056,
10.1145/3583780.3615062,10.1145/3583780.3615062,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","shilling attack, recommender system, adversarial attack",10,864–873,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Recommendation systems (RS) are crucial for alleviating the information overload problem. Due to its pivotal role in guiding users to make decisions, unscrupulous parties are lured to launch attacks against RS to affect the decisions of normal users and gain illegal profits. Among various types of attacks, shilling attack is one of the most subsistent and profitable attacks. In shilling attack, an adversarial party injects a number of well-designed fake user profiles into the system to mislead RS so that the attack goal can be achieved. Although existing shilling attack methods have achieved promising results, they all adopt the attack paradigm of multi-user injection, where some fake user profiles are required. This paper provides the first study of shilling attack in an extremely limited scenario: only one fake user profile is injected into the victim RS to launch shilling attacks (i.e., single-user injection). We propose a novel single-user injection method SUI-Attack for invisible shilling attack. SUI-Attack is a graph based attack method that models shilling attack as a node generation task over the user-item bipartite graph of the victim RS, and it constructs the fake user profile by generating user features and edges that link the fake user to items. Extensive experiments demonstrate that SUI-Attack can achieve promising attack results in single-user injection. In addition to its attack power, SUI-Attack increases the stealthiness of shilling attack and reduces the risk of being detected. We provide our implementation at: https://github.com/KDEGroup/SUI-Attack.",10.1145/3583780.3615062,https://doi.org/10.1145/3583780.3615062,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Single-User Injection for Invisible Shilling Attack against Recommender Systems,"Huang, Chengzhi and Li, Hui",inproceedings,10.1145/3583780.3615062,
10.1145/3583780.3615073,10.1145/3583780.3615073,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","targeted shilling attacks, recommender systems, graph neural networks",10,649–658,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"GNN-based recommender systems have shown their vulnerability to shilling attacks in recent studies. By conducting shilling attacks on recommender systems, the attackers aim to have homogeneous impacts on all users. However, such indiscriminate attacks suffer from a waste of resources because even if the target item is promoted to users who are not interested, they are unlikely to click on them. In this paper, we conduct targeted shilling attacks in GNN-based recommender systems. By automatically constructing the features and edges of the fake users, our proposed framework AutoAttack achieves accurate attacks on a specific group of users while minimizing the impact on non-target users. Specifically, the features of fake users are generated based on a similarity function, which is optimized according to the features of target users. The structure of fake users is learned by conducting spectral clustering on the target users based on their graph Laplacian matrix, which contains the degree and adjacency information that provides guidance to the edge generation of fake users. We conduct extensive experiments on four real-world datasets in different GNN-based RS and evaluate the performance of our method on the shilling attack and recommendation tasks comprehensively, showing the effectiveness and flexibility of our framework.",10.1145/3583780.3615073,https://doi.org/10.1145/3583780.3615073,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Targeted Shilling Attacks on GNN-based Recommender Systems,"Guo, Sihan and Bai, Ting and Deng, Weihong",inproceedings,10.1145/3583780.3615073,
10.1145/3583780.3615074,10.1145/3583780.3615074,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","user cold-start problem, recommendation, meta-learning",10,3484–3493,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"User cold-start recommendation is one of the most challenging problems that limit the effectiveness of recommender systems. Meta-learning-based methods are introduced to address this problem by learning initialization parameters for cold-start tasks. Recent studies attempt to enhance the initialization methods. They first represent each task by the cold-start user and interacted items. Then they distinguish tasks based on the task relevance to learn adaptive initialization. However, this manner is based on the assumption that user preferences can be reflected by the interacted items saliently, which is not always true in reality. In addition, we argue that previous approaches suffer from their adaptive framework (e.g., adaptive initialization), which reduces the adaptability in the process of transferring meta-knowledge to personalized RSs. In response to the issues, we propose a task-difficulty-aware meta-learning with adaptive update strategies (TDAS) for user cold-start recommendation. First, we design a task difficulty encoder, which can represent user preference salience, task relevance, and other task characteristics by modeling task difficulty information. Second, we adopt a novel framework with task-adaptive local update strategies by optimizing the initialization parameters with task-adaptive per-step and per-layer hyperparameters. Extensive experiments based on three real-world datasets demonstrate that our TDAS outperforms the state-of-the-art methods. The source code is available at https://github.com/XuHao-bit/TDAS.",10.1145/3583780.3615074,https://doi.org/10.1145/3583780.3615074,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Task-Difficulty-Aware Meta-Learning with Adaptive Update Strategies for User Cold-Start Recommendation,"Zhao, Xuhao and Zhu, Yanmin and Wang, Chunyang and Jing, Mengyuan and Yu, Jiadi and Tang, Feilong",inproceedings,10.1145/3583780.3615074,
10.1145/3583780.3615077,10.1145/3583780.3615077,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","text matching, sequential recommendation, popularity bias, long user-item interaction modeling",11,1534–1544,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"This paper proposes Text mAtching based SequenTial rEcommenda-tion model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users. All codes are available at https://github.com/OpenMatch/TASTE.",10.1145/3583780.3615077,https://doi.org/10.1145/3583780.3615077,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Text Matching Improves Sequential Recommendation by Reducing Popularity Biases,"Liu, Zhenghao and Mei, Sen and Xiong, Chenyan and Li, Xiaohua and Yu, Shi and Liu, Zhiyuan and Gu, Yu and Yu, Ge",inproceedings,10.1145/3583780.3615077,
10.1145/3583780.3615086,10.1145/3583780.3615086,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","theoretical analysis, loss function, collaborative filtering, alignment and uniformity",10,2034–2043,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Collaborative filtering (CF) is a pivotal technique in modern recommender systems. The learning process of CF models typically consists of three components: interaction encoder, loss function, and negative sampling. Although many existing studies have proposed various CF models to design sophisticated interaction encoders, recent work shows that simply reformulating the loss functions can achieve significant performance gains. This paper delves into analyzing the relationship among existing loss functions. Our mathematical analysis reveals that the previous loss functions can be interpreted as alignment and uniformity functions: (i) the alignment matches user and item representations, and (ii) the uniformity disperses user and item distributions. Inspired by this analysis, we propose a novel loss function that improves the design of alignment and uniformity considering the unique patterns of datasets called Margin-aware Alignment and Weighted Uniformity (MAWU). The key novelty of MAWU is two-fold: (i) margin-aware alignment (MA) mitigates user/item-specific popularity biases, and (ii) weighted uniformity (WU) adjusts the significance between user and item uniformities to reflect the inherent characteristics of datasets. Extensive experimental results show that MF and LightGCN equipped with MAWU are comparable or superior to state-of-the-art CF models with various loss functions on three public datasets.",10.1145/3583780.3615086,https://doi.org/10.1145/3583780.3615086,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Toward a Better Understanding of Loss Functions for Collaborative Filtering,"Park, Seongmin and Yoon, Mincheol and Lee, Jae-woong and Park, Hogun and Lee, Jongwuk",inproceedings,10.1145/3583780.3615086,
10.1145/3583780.3615110,10.1145/3583780.3615110,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","zero-shot recommendation, product knowledge graph, multi-task pre-training",11,483–493,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Existing recommender systems face difficulties with zero-shot items, i.e. items that have no historical interactions with users during the training stage. Though recent works extract universal item representation via pre-trained language models (PLMs), they ignore the crucial item relationships. This paper presents a novel paradigm for the Zero-Shot Item-based Recommendation (ZSIR) task, which pre-trains a model on product knowledge graph (PKG) to refine the item features from PLMs. We identify three challenges for pre-training PKG, which are multi-type relations in PKG, semantic divergence between item generic information and relations and domain discrepancy from PKG to downstream ZSIR task. We address the challenges by proposing four pre-training tasks and novel task-oriented adaptation (ToA) layers. Moreover, this paper discusses how to fine-tune the model on new recommendation task such that the ToA layers are adapted to ZSIR task. Comprehensive experiments on 18 markets dataset are conducted to verify the effectiveness of the proposed MPKG model.",10.1145/3583780.3615110,https://doi.org/10.1145/3583780.3615110,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Zero-shot Item-based Recommendation via Multi-task Product Knowledge Graph Pre-Training,"Fan, Ziwei and Liu, Zhiwei and Heinecke, Shelby and Zhang, Jianguo and Wang, Huan and Xiong, Caiming and Yu, Philip S.",inproceedings,10.1145/3583780.3615110,
10.1145/3583780.3615165,10.1145/3583780.3615165,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","recommender systems, mitigation, gnn, fairness, explainability",5,3753–3757,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"In recommendation literature, explainability and fairness are becoming two prominent perspectives to consider. However, prior works have mostly addressed them separately, for instance by explaining to consumers why a certain item was recommended or mitigating disparate impacts in recommendation utility. None of them has leveraged explainability techniques to inform unfairness mitigation. In this paper, we propose an approach that relies on counterfactual explanations to augment the set of user-item interactions, such that using them while inferring recommendations leads to fairer outcomes. Modeling user-item interactions as a bipartite graph, our approach augments the latter by identifying new user-item edges that not only can explain the original unfairness by design, but can also mitigate it. Experiments on two public data sets show that our approach effectively leads to a better trade-off between fairness and recommendation utility compared with state-of-the-art mitigation procedures. We further analyze the characteristics of added edges to highlight key unfairness patterns. Source code available at https://github.com/jackmedda/RS-BGExplainer/tree/cikm2023.",10.1145/3583780.3615165,https://doi.org/10.1145/3583780.3615165,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Counterfactual Graph Augmentation for Consumer Unfairness Mitigation in Recommender Systems,"Boratto, Ludovico and Fabbri, Francesco and Fenu, Gianni and Marras, Mirko and Medda, Giacomo",inproceedings,10.1145/3583780.3615165,
10.1145/3583780.3615230,10.1145/3583780.3615230,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","self-supervised learning, information diffusion prediction, hypergraph representation, disentangled representation learning",5,3808–3812,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Accurately predicting information diffusion is critical for a vast range of applications. Existing methods generally consider user re-sharing behaviors to be driven by a single intent, and/or assume cascade temporal influence to be unchanged, which might not be consistent with real-world scenarios. To address these issues, we propose a self-supervised disentanglement framework (DisenIDP) for information diffusion prediction. First, we construct intent-aware hypergraphs to capture users' potential intents from different perspectives, and then perform the light hypergraph convolution to adaptively activate disentangled intents. Second, we extract long-term and short-term cascade influence via independent attention-based encoders. Finally, we set a self-supervised disentanglement task to alleviate the information loss and learn better-disentanglement representations. Extensive experiments conducted on two real-world social datasets demonstrate that DisenIDP outperforms state-of-the-art models across several settings.",10.1145/3583780.3615230,https://doi.org/10.1145/3583780.3615230,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Enhancing Information Diffusion Prediction with Self-Supervised Disentangled User and Cascade Representations,"Cheng, Zhangtao and Ye, Wenxue and Liu, Leyuan and Tai, Wenxin and Zhou, Fan",inproceedings,10.1145/3583780.3615230,
10.1145/3583780.3615281,10.1145/3583780.3615281,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","recommender systems, popularity bias, fairness",5,4023–4027,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Popularity bias is a widespread problem in the field of recommender systems, where popular items tend to dominate recommendation results. In this work, we propose 'Test Time Embedding Normalization' as a simple yet effective strategy for mitigating popularity bias, which surpasses the performance of the previous mitigation approaches by a significant margin. Our approach utilizes the normalized item embedding during the inference stage to control the influence of embedding magnitude, which is highly correlated with item popularity. Through extensive experiments, we show that our method combined with the sampled softmax loss effectively reduces popularity bias compare to previous approaches for bias mitigation. We further investigate the relationship between user and item embeddings and find that the angular similarity between embeddings distinguishes preferable and non-preferable items regardless of their popularity. The analysis explains the mechanism behind the success of our approach in eliminating the impact of popularity bias. Our code is available at https://github.com/ml-postech/TTEN.",10.1145/3583780.3615281,https://doi.org/10.1145/3583780.3615281,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Test-Time Embedding Normalization for Popularity Bias Mitigation,"Kim, Dain and Park, Jinhyeok and Kim, Dongwoo",inproceedings,10.1145/3583780.3615281,
10.1145/3583780.3615476,10.1145/3583780.3615476,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","sequential preferences, recommender systems, optimisation-based sequencing",7,4759–4765,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Users in music streaming platforms typically consume tracks sequentially in sessions by interacting with personalised playlists. To satisfy users, music platforms usually rely on recommender systems that learn users' preferences over individual tracks and rank the tracks within each playlist according to the learned preferences. However, such rankings often do not fully exploit the sequential nature of the users' consumption, which may result in a lower within-a-session consumption. In this paper, we model the sequential within-a-session preferences of users and propose an optimisation-based sequencing approach that allows for optimally incorporating such preferences into the rankings. To this end, we rely on interaction data of a major music streaming service to identify two most common aspects of the users' sequential preferences: (1) Position-Aware preferences, and (2) Local-Sequential preferences. We propose a sequencing model that can leverage each of these aspects optimally to maximise the expected total consumption from the session. We further perform an extensive offline and off-policy evaluation of our model, and carry out a large scale online randomised control trial with 7M users across 80 countries. Our findings confirm that we can effectively incorporate sequential preferences of users into our sequencer to make users complete more and skip less tracks within their listening sessions.",10.1145/3583780.3615476,https://doi.org/10.1145/3583780.3615476,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Exploiting Sequential Music Preferences via Optimisation-Based Sequencing,"Moor, Dmitrii and Yuan, Yi and Mehrotra, Rishabh and Dai, Zhenwen and Lalmas, Mounia",inproceedings,10.1145/3583780.3615476,
10.1145/3583780.3615492,10.1145/3583780.3615492,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","distributionally robust optimization, popularity, recommendation",7,4967–4973,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Collaborative Filtering (CF) has been widely applied for personalized recommendations in various industrial applications. However, due to the training strategy of Empirical Risk Minimization, CF models tend to favor popular items, resulting in inferior performance on sparse users and items. To enhance the CF representation learning of sparse users and items without sacrificing the performance of popular items, we propose a novel Popularity- aware Distributionally Robust Optimization (PDRO) framework. In particular, PDRO emphasizes the optimization of sparse users/items, while incorporating item popularity to preserve the performance of popular items through two modules. First, an implicit module develops a new popularity-aware DRO objective, paying more attention to items that will potentially become popular over time. Second, an explicit module that directly predicts the popularity of items to help the estimation of user-item matching scores. We apply PDRO to a micro-video recommendation scenario and implement it on two representative backend models. Extensive experiments on a real-world industrial dataset, as well as two public benchmark datasets, validate the efficacy of our proposed PDRO. Additionally, we perform an offline A/B test on the industrial dataset, further demonstrating the superiority of PDRO in real-world application scenarios.",10.1145/3583780.3615492,https://doi.org/10.1145/3583780.3615492,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Popularity-aware Distributionally Robust Optimization for Recommendation System,"Zhao, Jujia and Wang, Wenjie and Lin, Xinyu and Qu, Leigang and Zhang, Jizhi and Chua, Tat-Seng",inproceedings,10.1145/3583780.3615492,
10.1145/3583780.3615496,10.1145/3583780.3615496,CIKM.bib,1,['CIKM.bib'],8,CIKM '23,"Birmingham, United Kingdom","sample selection bias, online advertising, CTR prediction",7,4574–4580,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Click-Through Rate (CTR) prediction serves as a fundamental component in online advertising. A common practice is to train a CTR model on advertisement (ad) impressions with user feedback. Since ad impressions are purposely selected by the model itself, their distribution differs from the inference distribution and thus exhibits sample selection bias (SSB) that affects model performance. Existing studies on SSB mainly employ sample re-weighting techniques which suffer from high variance and poor model calibration. Another line of work relies on costly uniform data that is inadequate to train industrial models. Thus mitigating SSB in industrial models with a uniform-data-free framework is worth exploring. Fortunately, many platforms display mixed results of organic items (i.e., recommendations) and sponsored items (i.e., ads) to users, where impressions of ads and recommendations are selected by different systems but share the same user decision rationales. Based on the above characteristics, we propose to leverage recommendations samples as a free lunch to mitigate SSB for ads CTR model (Rec4Ad). After elaborating data augmentation, Rec4Ad learns disentangled representations with alignment and decorrelation modules for enhancement. When deployed in Taobao display advertising system, Rec4Ad achieves substantial gains in key business metrics, with a lift of up to +6.6% CTR and +2.9% RPM.",10.1145/3583780.3615496,https://doi.org/10.1145/3583780.3615496,"New York, NY, USA",Association for Computing Machinery,9798400701245,2023,Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR Prediction in Taobao,"Gao, Jingyue and Han, Shuguang and Zhu, Han and Yang, Siran and Jiang, Yuning and Xu, Jian and Zheng, Bo",inproceedings,10.1145/3583780.3615496,
10.1145/3589334.3645324,10.1145/3589334.3645324,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","data sampling, multi-objective learning, recommender system",10,3129–3138,Proceedings of the ACM Web Conference 2024,"Recommendation systems guide users in locating their desired information within extensive content repositories. Usually, a recommendation model is optimized to enhance accuracy metrics from a user utility standpoint, such as click-through rate or matching relevance. However, a responsible industrial recommendation model must address not only user utility (responsibility to users) but also other objectives, including increasing platform revenue (responsibility to platforms), ensuring fairness (responsibility to content creators), and maintaining unbiasedness (responsibility to long-term healthy development). Multi-objective learning is a promising approach for achieving responsible recommendation models. Nevertheless, current methods encounter two challenges: difficulty in scaling to heterogeneous objectives within a unified framework, and inadequate controllability over objective priority during optimization, leading to uncontrollable solutions.In this paper, we present a data-centric optimization framework, MoRec, which unifies the learning of diverse objectives. MoRec is a tri-level framework: the outer level manages the balance between different objectives, utilizing a proportional-integral-derivative (PID)-based controller to ensure a preset regularization on the primary objective. The middle level transforms objective-aware optimization into data sampling weights using sign gradients. The inner level employs a standard optimizer to update model parameters with the sampled data. Consequently, MoRec can flexibly support various objectives while maintaining the original model intact. Comprehensive experiments on two public datasets and one industrial dataset showcase the effectiveness, controllability, flexibility, and Pareto efficiency of MoRec, making it highly suitable for real-world implementation.",10.1145/3589334.3645324,https://doi.org/10.1145/3589334.3645324,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,A Data-Centric Multi-Objective Learning Framework for Responsible Recommendation Systems,"Huang, Xu and Lian, Jianxun and Wang, Hao and Liao, Hao and Lian, Defu and Xie, Xing",inproceedings,10.1145/3589334.3645324,
10.1145/3589334.3645331,10.1145/3589334.3645331,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","cross domain recommendation, domain adaptation, optimal transport, recommendation",10,334–343,Proceedings of the ACM Web Conference 2024,"User cold-start recommendation aims to provide accurate items for the newly joint users and is a hot and challenging problem. Nowadays as people participant in different domains, how to recommend items in the new domain for users in an old domain has become more urgent. In this paper, we focus on the Dual Cold-Start Cross Domain Recommendation (Dual-CSCDR) problem. That is, providing the most relevant items for new users on the source and target domains. The prime task in Dual-CSCDR is to properly model user-item rating interactions and map user expressive embeddings across domains. However, previous approaches cannot solve Dual-CSCDR well, since they separate the collaborative filtering and distribution mapping process, leading to the error superimposition issue. Moreover, most of these methods fail to fully exploit the cross-domain relationship among large number of non-overlapped users, which strongly limits their performance. To fill this gap, we propose User Distribution Mapping model with Collaborative Filtering (UDMCF), a novel end-to-end cold-start cross-domain recommendation framework for the Dual-CSCDR problem. UDMCF includes two main modules, i.e., rating prediction module and distribution alignment module. The former module adopts one-hot ID vectors and multi-hot historical ratings for collaborative filtering via a contrastive loss. The latter module contains overlapped user embedding alignment and general user subgroup distribution alignment. Specifically, we innovatively propose unbalance distribution optimal transport with typical subgroup discovering algorithm to map the whole user distributions. Our empirical study on several datasets demonstrates that UDMCF significantly outperforms the state-of-the-art models under the Dual-CSCDR setting.",10.1145/3589334.3645331,https://doi.org/10.1145/3589334.3645331,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,User Distribution Mapping Modelling with Collaborative Filtering for Cross Domain Recommendation,"Liu, Weiming and Chen, Chaochao and Liao, Xinting and Hu, Mengling and Su, Jiajie and Tan, Yanchao and Wang, Fan",inproceedings,10.1145/3589334.3645331,
10.1145/3589334.3645354,10.1145/3589334.3645354,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","conformity, hawkes process, recommendations, temporal graph attention network, user interest",10,3185–3194,Proceedings of the ACM Web Conference 2024,"Many existing recommender systems (RSs) assume user behavior is governed solely by their interests. However, the peer effect often influences individual decision-making, which leads to conformity behavior. Conventional solutions that eliminate indiscriminately such bias may cause RSs to neglect valuable information and depersonalize the recommendation results. Also, conformity can transform into user interest, e.g., discovering new tastes after a glance at popular music. By better representing different forms of conformity influence, we can do a better job at interest mining and debiasing. In certain extreme circumstances, the herd effect may be exacerbated by user anxiety with uncertainty (e.g., panic buying during the COVID-19 pandemic). RSs may thus fail to respond in time due to sudden and dramatic changes. Moreover, many existing studies potentially conflate conformity bias with popularity bias and lump together various factors responsible for differences in popularity. In this paper, we identify two distinct types of conformity behavior: informational conformity and normative conformity. To address this, we introduce the TCHN model, which utilizes attentional Hawkes processes to disentangle user self-interest and conformity in a personalized manner. Our approach incorporates temporal graph attention networks to capture users' stable and volatile dynamics. We conduct experiments on three real-world datasets, which uncover diverse levels of conformity among users. The results show that TCHN excels in recommendation accuracy, diversity, and fairness across various user groups.",10.1145/3589334.3645354,https://doi.org/10.1145/3589334.3645354,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Temporal Conformity-aware Hawkes Graph Network for Recommendations,"Ma, Chenglong and Ren, Yongli and Castells, Pablo and Sanderson, Mark",inproceedings,10.1145/3589334.3645354,
10.1145/3589334.3645369,10.1145/3589334.3645369,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","adaptive sampling, fairness, meta-learning, user modeling",12,3241–3252,Proceedings of the ACM Web Conference 2024,"Meta-learning has been widely employed to tackle the cold-start problem in user modeling. Similar to a guidebook for a new traveler, meta-learning significantly affects decision-making for new users in crucial scenarios, such as career recommendations. Consequently, the issue of fairness in meta-learning has gained paramount importance. Several methods have been proposed to mitigate unfairness in meta-learning and have shown promising results. However, a fundamental question remains unexplored: What is the critical factor leading to unfairness in meta-learned user modeling? Through the theoretical analysis that integrates the meta-learning paradigm with group fairness metrics, we identify group proportion imbalance as a critical factor. Subsequently, in order to mitigate the impact of this factor, we introduce a novel Fairness-aware Adaptive Sampling framework for meTa-learning, abbreviated as FAST. Its core concept involves adaptively adjusting the sampling distribution for different user groups during the interleaved training process of meta-learning. Furthermore, we provide theoretical guarantees demonstrating the convergence of FAST. Finally, empirical experiments conducted on three datasets reveal that FAST effectively enhances fairness while maintaining high accuracy. The code for FAST is available at https://github.com/zhengz99/FAST.",10.1145/3589334.3645369,https://doi.org/10.1145/3589334.3645369,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Enhancing Fairness in Meta-learned User Modeling via Adaptive Sampling,"Zhang, Zheng and Liu, Qi and Hu, Zirui and Zhan, Yi and Huang, Zhenya and Gao, Weibo and Mao, Qingyang",inproceedings,10.1145/3589334.3645369,
10.1145/3589334.3645421,10.1145/3589334.3645421,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","causal inference, item popularity, recommendation",10,3400–3409,Proceedings of the ACM Web Conference 2024,"Global popularity (GP) bias is the phenomenon that popular items are recommended much more frequently than they should be, which goes against the goal of providing personalized recommendations and harms user experience and recommendation accuracy. Many methods have been proposed to reduce GP bias but they fail to notice the fundamental problem of GP, i.e., it considers popularity from a global perspective of all users and uses a single set of popular items, and thus cannot capture the interests of individual users. As such, we propose a user-aware version of item popularity named personal popularity (PP), which identifies different popular items for each user by considering the users that share similar interests. As PP models the preferences of individual users, it naturally helps to produce personalized recommendations and mitigate GP bias. To integrate PP into recommendation, we design a general personal popularity aware counterfactual (PPAC) framework, which adapts easily to existing recommendation models. In particular, PPAC recognizes that PP and GP have both direct and indirect effects on recommendations and controls direct effects with counterfactual inference techniques for unbiased recommendations. All codes and datasets are available at https://github.com/Stevenn9981/PPAC.",10.1145/3589334.3645421,https://doi.org/10.1145/3589334.3645421,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Debiasing Recommendation with Personal Popularity,"Ning, Wentao and Cheng, Reynold and Yan, Xiao and Kao, Ben and Huo, Nan and Haldar, Nur Al Hasan and Tang, Bo",inproceedings,10.1145/3589334.3645421,
10.1145/3589334.3645473,10.1145/3589334.3645473,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","EM-algorithm, temporal dynamics of web systems, time-series",12,2464–2475,Proceedings of the ACM Web Conference 2024,"We propose the Burst-Induced Poisson Process (BPoP), a model designed to analyze time series data such as feeds or search queries. BPoP can distinguish between the slowly-varying regular activity of a stable audience and the bursty activity of a curious audience, often seen in viral threads. Our model consists of two hidden, interacting processes: a self-feeding process (SFP) that generates bursty behavior related to viral threads, and a non-homogeneous Poisson process (NHPP) with step function intensity that is influenced by the bursts from the SFP. The NHPP models the normal background behavior, driven solely by the overall popularity of the topic among the stable audience. Through extensive empirical work, we have demonstrated that our model fits and characterizes a large number of real datasets more effectively than state-of-the-art models. Most importantly, BPoP can quantify the stable audience of media channels over time, serving as a valuable indicator of their popularity.",10.1145/3589334.3645473,https://doi.org/10.1145/3589334.3645473,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Unraveling the Dynamics of Stable and Curious Audiences in Web Systems,"Alves, Rodrigo and Ledent, Antoine and Assun\c{c}\~{a}o, Renato and Vaz-De-Melo, Pedro and Kloft, Marius",inproceedings,10.1145/3589334.3645473,
10.1145/3589334.3645485,10.1145/3589334.3645485,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","depolarization, fairness, recommender system",12,1126–1137,Proceedings of the ACM Web Conference 2024,"Repeated risk minimization is a popular choice in real-world recommender systems driving their recommendation algorithms to adapt to user preferences and trends. However, numerous studies have shown that it exacerbates retention disparities among user groups, resulting in polarization within the user population. Given the primary objective of improving long-term user engagement in most industrial recommender systems and the significant commercial benefits from a diverse user population, enforcing retention fairness across user population is therefore crucial. Nonetheless, this goal is highly challenging due to the unknown dynamics of user retention (e.g., when a user would abandon the system) and the simultaneous aim to maximize the experience of every user. In this paper, we propose ReFair, the first computational framework that continuously improves recommendation algorithms while ensuring long-term retention fairness in the entire user population. ReFair alternates between environment learning (i.e., estimate the user retention dynamics) and fairness constrained policy improvement with respect to the estimated environment, while effectively handling uncertainties in the estimation. Our solution provides strong theoretical guarantees for long-term recommendation performance and retention fairness violation. Empirical experiments on two real-world recommendation datasets also demonstrate its effectiveness in realizing these two goals.",10.1145/3589334.3645485,https://doi.org/10.1145/3589334.3645485,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Retention Depolarization in Recommender System,"Zhang, Xiaoying and Wang, Hongning and Liu, Yang",inproceedings,10.1145/3589334.3645485,
10.1145/3589334.3645492,10.1145/3589334.3645492,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","fake users, federated recommender systems, poisoning attacks",11,3555–3565,Proceedings of the ACM Web Conference 2024,"Federated recommendation is a prominent use case within federated learning, yet it remains susceptible to various attacks, from user to server-side vulnerabilities. Poisoning attacks are particularly notable among user-side attacks, as participants upload malicious model updates to deceive the global model, often intending to promote or demote specific targeted items. This study investigates strategies for executing promotion attacks in federated recommender systems.Current poisoning attacks on federated recommender systems often rely on additional information, such as the local training data of genuine users or item popularity. However, such information is challenging for the potential attacker to obtain. Thus, there is a need to develop an attack that requires no extra information apart from item embeddings obtained from the server. In this paper, we introduce a novel fake user based poisoning attack named PoisonFRS to promote the attacker-chosen targeted item in federated recommender systems without requiring knowledge about user-item rating data, user attributes, or the aggregation rule used by the server. Extensive experiments on multiple real-world datasets demonstrate that PoisonFRS can effectively promote the attacker-chosen targeted item to a large portion of genuine users and outperform current benchmarks that rely on additional information about the system. We further observe that the model updates from both genuine and fake users are indistinguishable within the latent space.",10.1145/3589334.3645492,https://doi.org/10.1145/3589334.3645492,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Poisoning Federated Recommender Systems with Fake Users,"Yin, Ming and Xu, Yichang and Fang, Minghong and Gong, Neil Zhenqiang",inproceedings,10.1145/3589334.3645492,
10.1145/3589334.3645518,10.1145/3589334.3645518,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","fairness, intersectional group, recommendation",12,3609–3620,Proceedings of the ACM Web Conference 2024,"Fairness of recommender systems (RS) has attracted increasing attention recently. Based on the involved stakeholders, the fairness of RS can be divided into user fairness, item fairness, and two-sided fairness which considers both user and item fairness simultaneously. However, we argue that the intersectional two-sided unfairness may still exist even if the RS is two-sided fair, which is observed and shown by empirical studies on real-world data in this paper, and has not been well-studied previously. To mitigate this problem, we propose a novel approach called Intersectional Two-sided Fairness Recommendation (ITFR). Our method utilizes a sharpness-aware loss to perceive disadvantaged groups, and then uses collaborative loss balance to develop consistent distinguishing abilities for different intersectional groups. Additionally, predicted score normalization is leveraged to align positive predicted scores to fairly treat positives in different intersectional groups. Extensive experiments and analyses on three public datasets show that our proposed approach effectively alleviates the intersectional two-sided unfairness and consistently outperforms previous state-of-the-art methods.",10.1145/3589334.3645518,https://doi.org/10.1145/3589334.3645518,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Intersectional Two-sided Fairness in Recommendation,"Wang, Yifan and Sun, Peijie and Ma, Weizhi and Zhang, Min and Zhang, Yuan and Jiang, Peng and Ma, Shaoping",inproceedings,10.1145/3589334.3645518,
10.1145/3589334.3645525,10.1145/3589334.3645525,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","cold-start, federated learning, recommendation systems",11,3632–3642,Proceedings of the ACM Web Conference 2024,"Federated recommendation system usually trains a global model on the server without direct access to users' private data on their own devices. However, this separation of the recommendation model and users' private data poses a challenge in providing quality service, particularly when it comes to new items, namely cold-start recommendations in federated settings. This paper introduces a novel method called Item-aligned Federated Aggregation (IFedRec) to address this challenge. It is the first research work in federated recommendation to specifically study the cold-start scenario. The proposed method learns two sets of item representations by leveraging item attributes and interaction records simultaneously. Additionally, an item representation alignment mechanism is designed to align two item representations and learn the meta attribute network at the server within a federated learning framework. Experiments on four benchmark datasets demonstrate IFedRec's superior performance for cold-start scenarios. Furthermore, we also verify IFedRec owns good robustness when the system faces limited client participation and noise injection, which brings promising practical application potential in privacy-protection enhanced federated recommendation systems. The implementation code is available",10.1145/3589334.3645525,https://doi.org/10.1145/3589334.3645525,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,When Federated Recommendation Meets Cold-Start Problem: Separating Item Attributes and User Interactions,"Zhang, Chunxu and Long, Guodong and Zhou, Tianyi and Zhang, Zijian and Yan, Peng and Yang, Bo",inproceedings,10.1145/3589334.3645525,
10.1145/3589334.3645536,10.1145/3589334.3645536,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","dynamic updates, recommender systems, user-side fairness",12,3667–3678,Proceedings of the ACM Web Conference 2024,"User-side group fairness is crucial for modern recommender systems, alleviating performance disparities among user groups defined by sensitive attributes like gender, race, or age. In the everevolving landscape of user-item interactions, continual adaptation to newly collected data is crucial for recommender systems to stay aligned with the latest user preferences. However, we observe that such continual adaptation often worsen performance disparities. This necessitates a thorough investigation into user-side fairness in dynamic recommender systems. This problem is challenging due to distribution shifts, frequent model updates, and nondifferentiability of ranking metrics. To our knowledge, this paper presents the first principled study on ensuring user-side fairness in dynamic recommender systems. We start with theoretical analyses on fine-tuning v.s. retraining, showing that the best practice is incremental fine-tuning with restart. Guided by our theoretical analyses, we propose FAir Dynamic rEcommender (FADE), an end-to-end fine-tuning framework to dynamically ensure user-side fairness over time. To overcome the non-differentiability of recommendation metrics in the fairness loss, we further introduce Differentiable Hit (DH) as an improvement over the recent NeuralNDCG method, not only alleviating its gradient vanishing issue but also achieving higher efficiency. Besides that, we also address the instability issue of the fairness loss by leveraging the competing nature between the recommendation loss and the fairness loss. Through extensive experiments on real-world datasets, we demonstrate that FADE effectively and efficiently reduces performance disparities with little sacrifice in the overall recommendation performance.",10.1145/3589334.3645536,https://doi.org/10.1145/3589334.3645536,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Ensuring User-side Fairness in Dynamic Recommender Systems,"Yoo, Hyunsik and Zeng, Zhichen and Kang, Jian and Qiu, Ruizhong and Zhou, David and Liu, Zhining and Wang, Fei and Xu, Charlie and Chan, Eunice and Tong, Hanghang",inproceedings,10.1145/3589334.3645536,
10.1145/3589334.3645573,10.1145/3589334.3645573,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","accuracy and diversity, item category and popularity, long-tail games, video game recommendation",11,3734–3744,Proceedings of the ACM Web Conference 2024,"In recent years, the video game industry has experienced substantial growth, presenting players with a vast array of game choices. This surge in options has spurred the need for a specialized recommender system tailored for video games. However, current video game recommendation approaches tend to prioritize accuracy over diversity, potentially leading to unvaried game suggestions. In addition, the existing game recommendation methods commonly lack the ability to establish strict connections between games to enhance accuracy. Furthermore, many existing diversity-focused methods fail to leverage crucial item information, such as item category and popularity during neighbor modeling and message propagation. To address these challenges, we introduce a novel framework, called CPGRec, comprising three modules, namely accuracy-driven, diversity-driven, and comprehensive modules. The first module extends the state-of-the-art accuracy-focused game recommendation method by connecting games in a more stringent manner to enhance recommendation accuracy. The second module connects neighbors with diverse categories within the proposed game graph and harnesses the advantages of popular game nodes to amplify the influence of long-tail games within the player-game bipartite graph, thereby enriching recommendation diversity. The third module combines the above two modules and employs a new negative-sample rating score reweighting method to balance accuracy and diversity. Experimental results on the Steam dataset demonstrate the effectiveness of our proposed method in improving game recommendations. The dataset and source codes are anonymously released at: https://github.com/CPGRec2024/CPGRec.git.",10.1145/3589334.3645573,https://doi.org/10.1145/3589334.3645573,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Category-based and Popularity-guided Video Game Recommendation: A Balance-oriented Framework,"Li, Xiping and Ma, Jianghong and Liu, Kangzhe and Feng, Shanshan and Zhang, Haijun and Wang, Yutong",inproceedings,10.1145/3589334.3645573,
10.1145/3589334.3645589,10.1145/3589334.3645589,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","cognitive diagnosis, inductive learning, web-based online intelligent education systems",12,4260–4271,Proceedings of the ACM Web Conference 2024,"Cognitive diagnosis aims to gauge students' mastery levels based on their response logs. Serving as a pivotal module in web-based online intelligent education systems (WOIESs), it plays an upstream and fundamental role in downstream tasks like learning item recommendation and computerized adaptive testing. WOIESs are open learning environment where numerous new students constantly register and complete exercises. In WOIESs, efficient cognitive diagnosis is crucial to fast feedback and accelerating student learning. However, the existing cognitive diagnosis methods always employ intrinsically transductive student-specific embeddings, which become slow and costly due to retraining when dealing with new students who are unseen during training. To this end, this paper proposes an inductive cognitive diagnosis model (ICDM) for fast new students' mastery levels inference in WOIESs. Specifically, in ICDM, we propose a novel student-centered graph (SCG). Rather than inferring mastery levels through updating student-specific embedding, we derive the inductive mastery levels as the aggregated outcomes of students' neighbors in SCG. Namely, SCG enables to shift the task from finding the most suitable student-specific embedding that fits the response logs to finding the most suitable representations for different node types in SCG, and the latter is more efficient since it no longer requires retraining. To obtain this representation, ICDM consists of a construction-aggregation-generation-transformation process to learn the final representation of students, exercises and concepts. Extensive experiments across real-world datasets show that, compared with the existing cognitive diagnosis methods that are always transductive, ICDM is much more faster while maintains the competitive inference performance for new students.",10.1145/3589334.3645589,https://doi.org/10.1145/3589334.3645589,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Inductive Cognitive Diagnosis for Fast Student Learning in Web-Based Intelligent Education Systems,"Liu, Shuo and Shen, Junhao and Qian, Hong and Zhou, Aimin",inproceedings,10.1145/3589334.3645589,
10.1145/3589334.3645598,10.1145/3589334.3645598,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","graph recommendation, out of distribution, robust",12,3777–3788,Proceedings of the ACM Web Conference 2024,"With the capacity to capture high-order collaborative signals, Graph Neural Networks (GNNs) have emerged as powerful methods in Recommender Systems (RS). However, their efficacy often hinges on the assumption that training and testing data share the same distribution (aka IID assumption), and exhibits significant declines under distribution shifts. Distribution shifts commonly arises in RS, often attributed to the dynamic nature of user preferences or ubiquitous biases during data collection in RS. Despite its significance, researches on GNN-based recommendation against distribution shift are still sparse. To bridge this gap, we propose Distributionally Robust GNN (DR-GNN) that incorporates Distributional Robust Optimization (DRO) into the GNN-based recommendation. DR-GNN addresses two core challenges: 1) To enable DRO to cater to graph data intertwined with GNN, we reinterpret GNN as a graph smoothing regularizer, thereby facilitating the nuanced application of DRO; 2) Given the typically sparse nature of recommendation data, which might impede robust optimization, we introduce slight perturbations in the training distribution to expand its support. Notably, while DR-GNN involves complex optimization, it can be implemented easily and efficiently. Our extensive experiments validate the effectiveness of DR-GNN against three typical distribution shifts. The code is available at https://github.com/WANGBohaO-jpg/DR-GNN.",10.1145/3589334.3645598,https://doi.org/10.1145/3589334.3645598,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Distributionally Robust Graph-based Recommendation System,"Wang, Bohao and Chen, Jiawei and Li, Changdong and Zhou, Sheng and Shi, Qihao and Gao, Yang and Feng, Yan and Chen, Chun and Wang, Can",inproceedings,10.1145/3589334.3645598,
10.1145/3589334.3645601,10.1145/3589334.3645601,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","graph neural networks, link prediction, variational graph autoencoder",11,839–849,Proceedings of the ACM Web Conference 2024,"Link prediction is an important learning task for graph-structured data, and has become increasingly popular due to its wide application areas. Graph Neural Network (GNN)-based approaches including Variational Graph Autoencoder (VGAE) have achieved promising performance on link prediction outperforming conventional models which use hand-crafted features. VGAE learns latent node representations and predicts links based on the similarities between nodes. While the inner product based decoder effectively utilizes the node representations for link prediction, it exhibits sub-optimal performance due to the intrinsic limitation of the inner product. We found that the the cosine similarity and norm simultaneously try to explain the link probability, which hinders the gradient flow during training. We also point out the message passing scheme is unexpectedly dominated by the nodes with large norm values. In this paper, we propose a stochastic VGAE-based method that can effectively decouple the norm and angle in the embeddings. Specifically, we relate the cosine similarity and norm to two fundamental principles in graph: homophily and node popularity respectively. Our learning scheme is based on a hard expectation maximization learning method; we infer which of the two has been exerted for link formation, and subsequently optimize based on this guess. Through extensive experiments on real-world datasets, we demonstrate our model outperforms the existing state-of-the-art methods on link prediction and achieves comparable performances on other downstream tasks such as node classification and clustering. Our code is at https://github.com/yoonsikcho/d-vgae.",10.1145/3589334.3645601,https://doi.org/10.1145/3589334.3645601,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Decoupled Variational Graph Autoencoder for Link Prediction,"Cho, Yoon-Sik",inproceedings,10.1145/3589334.3645601,
10.1145/3589334.3645626,10.1145/3589334.3645626,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","co-clustering, federated recommendation, supervised contrastive learning",12,3821–3832,Proceedings of the ACM Web Conference 2024,"As data privacy and security attract increasing attention, Federated Recommender System (FRS) offers a solution that strikes a balance between providing high-quality recommendations and preserving user privacy. However, the presence of statistical heterogeneity in FRS, commonly observed due to personalized decision-making patterns, can pose challenges. To address this issue and maximize the benefit of collaborative filtering (CF) in FRS, it is intuitive to consider clustering clients (users) as well as items into different groups and learning group-specific models. Existing methods either resort to client clustering via user representations-risking privacy leakage, or employ classical clustering strategies on item embeddings or gradients, which we found are plagued by the curse of dimensionality. In this paper, we delve into the inefficiencies of the K-Means method in client grouping, attributing failures due to the high dimensionality as well as data sparsity occurring in FRS, and propose CoFedRec, a novel Co-clustering Federated Recommendation mechanism, to address clients heterogeneity and enhance the collaborative filtering within the federated framework. Specifically, the server initially formulates an item membership from the client-provided item networks. Subsequently, clients are grouped regarding a specific item category picked from the item membership during each communication round, resulting in an intelligently aggregated group model. Meanwhile, to comprehensively capture the global inter-relationships among items, we incorporate an additional supervised contrastive learning term based on the server-side generated item membership into the local training phase for each client. Extensive experiments on four datasets are provided, which verify the effectiveness of the proposed CoFedRec.",10.1145/3589334.3645626,https://doi.org/10.1145/3589334.3645626,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Co-clustering for Federated Recommender System,"He, Xinrui and Liu, Shuo and Keung, Jacky and He, Jingrui",inproceedings,10.1145/3589334.3645626,
10.1145/3589334.3645661,10.1145/3589334.3645661,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","contrastive learning, data augmentation, sequential recommendation",10,3854–3863,Proceedings of the ACM Web Conference 2024,"Sequential recommender systems (SRS) are designed to predict users' future behaviors based on their historical interaction data. Recent research has increasingly utilized contrastive learning (CL) to leverage unsupervised signals to alleviate the data sparsity issue in SRS. In general, CL-based SRS first augments the raw sequential interaction data by using data augmentation strategies and employs a contrastive training scheme to enforce the representations of those sequences from the same raw interaction data to be similar. Despite the growing popularity of CL, data augmentation, as a basic component of CL, has not received sufficient attention. This raises the question: Is it possible to achieve superior recommendation results solely through data augmentation? To answer this question, we benchmark eight widely used data augmentation strategies, as well as state-of-the-art CL-based SRS methods, on four real-world datasets under both warm- and cold-start settings. Intriguingly, the conclusion drawn from our study is that, certain data augmentation strategies can achieve similar or even superior performance compared with some CL-based methods, demonstrating the potential to significantly alleviate the data sparsity issue with fewer computational overhead. We hope that our study can further inspire more fundamental studies on the key functional components of complex CL techniques. Our processed datasets and codes are available at https://github.com/AIM-SE/DA4Rec.",10.1145/3589334.3645661,https://doi.org/10.1145/3589334.3645661,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Is Contrastive Learning Necessary? A Study of Data Augmentation vs Contrastive Learning in Sequential Recommendation,"Zhou, Peilin and Huang, You-Liang and Xie, Yueqi and Gao, Jingqi and Wang, Shoujin and Kim, Jae Boum and Kim, Sunghun",inproceedings,10.1145/3589334.3645661,
10.1145/3589334.3645667,10.1145/3589334.3645667,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","collaborative filtering, debiasing, distribution shift",12,3864–3875,Proceedings of the ACM Web Conference 2024,"Graph neural networks (GNNs) have shown impressive performance in recommender systems, particularly in collaborative filtering (CF). The key lies in aggregating neighborhood information on a user-item interaction graph to enhance user/item representations. However, we have discovered that this aggregation mechanism comes with a drawback - it amplifies biases present in the interaction graph. For instance, a user's interactions with items can be driven by both unbiased true interest and various biased factors like item popularity or exposure. However, the current aggregation approach combines all information, both biased and unbiased, leading to biased representation learning. Consequently, graph-based recommenders can learn distorted views of users/items, hindering the modeling of their true preferences and generalizations.To address this issue, we introduce a novel framework called Adversarial Graph Dropout (AdvDrop). It differentiates between unbiased and biased interactions, enabling unbiased representation learning. For each user/item, AdvDrop employs adversarial learning to split the neighborhood into two views: one with bias-mitigated interactions and the other with bias-aware interactions. After view-specific aggregation, AdvDrop ensures that the bias-mitigated and bias-aware representations remain invariant, shielding them from the influence of bias. We validate AdvDrop's effectiveness on five public datasets that cover both general and specific biases, demonstrating significant improvements. Furthermore, our method exhibits meaningful separation of subgraphs and achieves unbiased representations for graph-based CF models, as revealed by in-depth analysis. Our code is publicly available at https://github.com/Arthurma71/AdvDrop/tree/main.",10.1145/3589334.3645667,https://doi.org/10.1145/3589334.3645667,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,General Debiasing for Graph-based Collaborative Filtering via Adversarial Graph Dropout,"Zhang, An and Ma, Wenchang and Wei, Pengbo and Sheng, Leheng and Wang, Xiang",inproceedings,10.1145/3589334.3645667,
10.1145/3589334.3645702,10.1145/3589334.3645702,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","communication efficiency, federated learning, recommendation system",12,3940–3951,Proceedings of the ACM Web Conference 2024,"Federated Recommendation (FedRec) systems have emerged as a solution to safeguard users' data in response to growing regulatory concerns. However, one of the major challenges in these systems lies in the communication costs that arise from the need to transmit neural network models between user devices and a central server. Prior approaches to these challenges often lead to issues such as computational overheads, model specificity constraints, and compatibility issues with secure aggregation protocols. In response, we propose a novel framework, called Correlated Low-rank Structure (CoLR), which leverages the concept of adjusting lightweight trainable parameters while keeping most parameters frozen. Our approach substantially reduces communication overheads without introducing additional computational burdens. Critically, our framework remains fully compatible with secure aggregation protocols, including the robust use of Homomorphic Encryption. The approach resulted in a reduction of up to 93.75% in payload size, with only an approximate 8% decrease in recommendation performance across datasets. Code for reproducing our experiments can be found at https://github.com/NNHieu/CoLR-FedRec.",10.1145/3589334.3645702,https://doi.org/10.1145/3589334.3645702,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Towards Efficient Communication and Secure Federated Recommendation System via Low-rank Training,"Nguyen, Ngoc-Hieu and Nguyen, Tuan-Anh and Nguyen, Tuan and Hoang, Vu Tien and Le, Dung D. and Wong, Kok-Seng",inproceedings,10.1145/3589334.3645702,
10.1145/3589334.3645711,10.1145/3589334.3645711,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","multimodal interaction, personalized content generation, user preference modeling, video comments dataset, video to text generation",12,3952–3963,Proceedings of the ACM Web Conference 2024,"While previous video to text models have achieved remarkable successes, they mostly focus on how to understand the video contents in a general sense, but fail to capture the human personalized preferences, which is highly demanded for an engaging multimodal chatbots. Different from user modeling in collaborative filtering, there is no other user behaviors in inference as a real-time video stream is coming. In this paper, we formally define the task of personalized video commenting task and design an end-to-end personalized framework for solving this task. In specific, we argue that the personalization for video comment generation can be reflected in two aspects, that is, (1) for the same video, different users may comment on different clips, and (2) for the same clip, different people may also express various opinions with diverse commentary styles. Motivated by these considerations, we design our framework based on two components. The first one is a clip selector, which is responsible for predicting the clips that the user may comment in the video. The second one is a text generator, which aims to produce the comment based on the above predicted clips and the user's preference. In our framework, these two components are optimized in an end-to-end manner to mutually enhance each other, where we design confidence-aware scheduled sampling and iterative inference strategies to solve the problem that the ground truth clips are absent in the inference phase. As the absence of personalized video to text dataset, we collect and release a new dataset for studying this problem. We conduct extensive experiments to demonstrate the effectiveness of our model.",10.1145/3589334.3645711,https://doi.org/10.1145/3589334.3645711,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Understanding Human Preferences: Towards More Personalized Video to Text Generation,"Wu, Yihan and Song, Ruihua and Chen, Xu and Jiang, Hao and Cao, Zhao and Yu, Jin",inproceedings,10.1145/3589334.3645711,
10.1145/3589334.3648158,10.1145/3589334.3648158,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","item-side fairness, large language model, recommendation",10,4717–4726,Proceedings of the ACM Web Conference 2024,"Recommendation systems for Web content distribution intricately connect to the information access and exposure opportunities for vulnerable populations. The emergence of Large Language Models-based Recommendation System (LRS) may introduce additional societal challenges to recommendation systems due to the inherent biases in Large Language Models (LLMs). From the perspective of item-side fairness, there remains a lack of comprehensive investigation into the item-side fairness of LRS given the unique characteristics of LRS compared to conventional recommendation systems. To bridge this gap, this study examines the property of LRS with respect to item-side fairness and reveals the influencing factors of both historical users' interactions and inherent semantic biases of LLMs, shedding light on the need to extend conventional item-side fairness methods for LRS. Towards this goal, we develop a concise and effective framework called IFairLRS to enhance the item-side fairness of an LRS. IFairLRS covers the main stages of building an LRS with specifically adapted strategies to calibrate the recommendations of LRS. We utilize IFairLRS to fine-tune LLaMA, a representative LLM, on MovieLens and Steam datasets, and observe significant item-side fairness improvements. The code can be found in https://github.com/JiangM-C/IFairLRS.git.",10.1145/3589334.3648158,https://doi.org/10.1145/3589334.3648158,"New York, NY, USA",Association for Computing Machinery,9798400701719,2024,Item-side Fairness of Large Language Model-based Recommendation System,"Jiang, Meng and Bao, Keqin and Zhang, Jizhi and Wang, Wenjie and Yang, Zhengyi and Feng, Fuli and He, Xiangnan",inproceedings,10.1145/3589334.3648158,
10.1145/3589335.3648310,10.1145/3589335.3648310,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","ads allocation, reinforcement learning, user response modeling",10,131–140,Companion Proceedings of the ACM Web Conference 2024,"User response modeling can enhance the learning of user representations and further improve the reinforcement learning (RL) recommender agent. However, as users' behaviors are influenced by their long-term preferences and short-term stochastic factors (e.g., weather, mood, or fashion trends), it remains challenging for previous works focusing on recurrent neural network-based user response modeling. Meanwhile, due to the dynamic interests of users, it is often unrealistic to assume the dynamics of users are stationary. Drawing inspiration from opponent modeling, we propose a novel network structure, Deep User Q-Network (DUQN), incorporating a user response probabilistic model into the Q-learning ads allocation strategy to capture the effect of the non-stationary user policy on Q-values. Moreover, we utilize the Recurrent State-Space Model (RSSM) to develop the user response model, which includes deterministic and stochastic components, enabling us to fully consider user long-term preferences and short-term stochastic factors. In particular, we design a RetNet version of RSSM (R-RSSM) to support parallel computation. The R-RSSM model can be further used for multi-step predictions to enable bootstrapping over multiple steps simultaneously. Finally, we conduct extensive experiments on a large-scale offline dataset from the Meituan food delivery platform and a public benchmark. Experimental results show that our method yields superior performance to state-of-the-art (SOTA) baselines. Moreover, our model demonstrates a significant improvement in the online A/B test and has been fully deployed on the industrial Meituan platform, serving more than 500 million customers.",10.1145/3589335.3648310,https://doi.org/10.1145/3589335.3648310,"New York, NY, USA",Association for Computing Machinery,9798400701726,2024,User Response Modeling in Reinforcement Learning for Ads Allocation,"Zhang, Zhiyuan and Zhang, Qichao and Wu, Xiaoxu and Shi, Xiaowen and Liao, Guogang and Wang, Yongkang and Wang, Xingxing and Zhao, Dongbin",inproceedings,10.1145/3589335.3648310,
10.1145/3589335.3648312,10.1145/3589335.3648312,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","hierarchical clustering, popularity bias, recommender systems",10,151–160,Companion Proceedings of the ACM Web Conference 2024,"Recommender systems are essential for finding personalized content for users on online platforms. These systems are often trained on historical user interaction data, which collects user feedback on system recommendations. This creates a feedback loop leading to popularity bias; popular content is over-represented in the data, better learned, and thus recommended even more. Less popular content struggles to reach its potential audiences. Popularity bias limits the diversity of content that users are exposed to, and makes it harder for new creators to gain traction. Existing methods to alleviate popularity bias tend to trade off the performance of popular items. In this work, we propose a new method for alleviating popularity bias in recommender systems, called the cluster anchor regularization, which partitions the large item corpus into hierarchical clusters, and then leverages the cluster information of each item to facilitate transfer learning from head items to tail items. Our results demonstrate the effectiveness of the proposed method with offline analyses and live experiments on a large-scale industrial recommendation platform, where it significantly increases tail recommendation without hurting the overall user experience.",10.1145/3589335.3648312,https://doi.org/10.1145/3589335.3648312,"New York, NY, USA",Association for Computing Machinery,9798400701726,2024,Cluster Anchor Regularization to Alleviate Popularity Bias in Recommender Systems,"Chang, Bo and Meng, Changping and Ma, He and Chang, Shuo and Gu, Yang and Peng, Yajun and Feng, Jingchen and Zhang, Yaping and Bi, Shuchao and Chi, Ed H. and Chen, Minmin",inproceedings,10.1145/3589335.3648312,
10.1145/3589335.3648340,10.1145/3589335.3648340,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","recommender systems, sequential recommender, target attention, user interest model",10,413–422,Companion Proceedings of the ACM Web Conference 2024,"User response prediction is essential in industrial recommendation systems, such as online display advertising. Among all the features in recommendation models, user behaviors are among the most critical. Many works have revealed that a user's behavior reflects her interest in the candidate item, owing to the semantic or temporal correlation between behaviors and the candidate. While the literature has individually examined each of these correlations, researchers have yet to analyze them in combination, that is, the semantic-temporal correlation. We empirically measure this correlation and observe intuitive yet robust patterns. We then examine several popular user interest models and find that, surprisingly, none of them learn such correlation well.To fill this gap, we propose a Temporal Interest Network (TIN) to capture the semantic-temporal correlation simultaneously between behaviors and the target. We achieve this by incorporating target-aware temporal encoding, in addition to semantic encoding, to represent behaviors and the target. Furthermore, we conduct explicit 4-way interaction by deploying target-aware attention and target-aware representation to capture both semantic and temporal correlation. We conduct comprehensive evaluations on two popular public datasets, and our proposed TIN outperforms the best-performing baselines by 0.43% and 0.29% on GAUC, respectively. During online A/B testing in Tencent's advertising platform, TIN achieves 1.65% cost lift and 1.93% GMV lift over the base model. It has been successfully deployed in production since October 2023, serving the WeChat Moments traffic. We have released our code at https://github.com/zhouxy1003/TIN.",10.1145/3589335.3648340,https://doi.org/10.1145/3589335.3648340,"New York, NY, USA",Association for Computing Machinery,9798400701726,2024,Temporal Interest Network for User Response Prediction,"Zhou, Haolin and Pan, Junwei and Zhou, Xinyi and Chen, Xihua and Jiang, Jie and Gao, Xiaofeng and Chen, Guihai",inproceedings,10.1145/3589335.3648340,
10.1145/3589335.3651552,10.1145/3589335.3651552,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","data augmentation, personalization, sequential recommendation",5,641–645,Companion Proceedings of the ACM Web Conference 2024,"Predicting customer preferences for each item is a prerequisite module for most recommender systems in e-commerce. However, the sparsity of behavioral data is often a challenge to learn accurate prediction models. Given millions of items, each customer may only be able to interact with a small subset of them over time. This sparse behavioral data is insufficient to represent item-customer and item-item relations for a machine learning model to digest, resulting in limited prediction accuracy that hinders recommendation performance. To mitigate this issue, this study introduces an inter-sequence data augmentation method, SDAinter, that enhances data density by leveraging cross-customer behavioral patterns to enrich item relations. Tested on three public and one proprietary e-commerce dataset, SDAinter significantly increases data density, leading to notable improvements in both evaluation and business metrics. Our findings demonstrate SDAinter's effectiveness and its potential to complement existing data augmentation strategies in recommender systems. See https://github.com/ML-apollo/SDA_inter.",10.1145/3589335.3651552,https://doi.org/10.1145/3589335.3651552,"New York, NY, USA",Association for Computing Machinery,9798400701726,2024,Rethinking Sequential Relationships: Improving Sequential Recommenders with Inter-Sequence Data Augmentation,"Jiao, Yang and Yang, Fan and Chen, Yetian and Gao, Yan and Liu, Jia and Sun, Yi",inproceedings,10.1145/3589335.3651552,
10.1145/3589335.3651896,10.1145/3589335.3651896,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '24,"Singapore, Singapore","bias alleviation, causality learning, sequential recommendation",7,1400–1406,Companion Proceedings of the ACM Web Conference 2024,"Contemporary sequential recommendation systems predominantly leverage statistical correlations derived from user interaction histories to predict future preferences. However, these correlations often mask implicit challenges. On the one hand, user data is frequently plagued by implicit, noisy feedback, misdirecting users towards items that fail to align with their actual interests, which is magnified in sequential recommendation contexts. On the other hand, prevalent methods tend to over-rely on similarity-based attention mechanisms across item pairs, which are prone to utilizing heuristic shortcuts, thereby leading to suboptimal recommendation.To tackle these issues, we put forward a causality-driven user modeling approach for sequential recommendation, which pivots towards a causal perspective. Specifically, we involves the application of a causal graph to identify confounding factors that give rise to spurious correlations and to isolate conceptual variables that causally encapsulate user preferences. By learning the representation of these disentangled causal variables at the conceptual level, we can distinguish between causal and non-causal associations while preserving the inherent sequential nature of user behaviors. This enables us to ascertain which elements are critical and which may induce unintended biases. The framework of our method can be compatible with various mainstream sequential models, which offers a robust foundation for reconstructing more accurate and meaningful user and item representations driven by causality.",10.1145/3589335.3651896,https://doi.org/10.1145/3589335.3651896,"New York, NY, USA",Association for Computing Machinery,9798400701726,2024,Causality-driven User Modeling for Sequential Recommendations over Time,"Chen, Xingming and Li, Qing",inproceedings,10.1145/3589335.3651896,
10.1145/3604915.3608765,10.1145/3604915.3608765,RecSys.bib,1,['RecSys.bib'],6,RecSys '23,"Singapore, Singapore",,5,1276–1280,Proceedings of the 17th ACM Conference on Recommender Systems,,10.1145/3604915.3608765,https://doi.org/10.1145/3604915.3608765,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,International Workshop on Deep Learning Practice for High-Dimensional Sparse Data with RecSys 2023,"Tang, Ruiming and Zhu, Xiaoqiang and Ge, Junfeng and Lee, Kuang-chih and Jiang, Biye and Wang, Xingxing and Zhu, Han and Zhuang, Tao and Liu, Weiwen and Ren, Kan and Zhang, Weinan and Zhao, Xiangyu",inproceedings,10.1145/3604915.3608765,
10.1145/3604915.3608770,10.1145/3604915.3608770,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","fairness aware recommendation, recommendation system",11,200–210,Proceedings of the 17th ACM Conference on Recommender Systems,"Fairness in the recommendation domain has recently attracted increasing attention due to more and more concerns about the algorithm discrimination and ethics. While recent years have witnessed many promising fairness aware recommender models, an important problem has been largely ignored, that is, the fairness can be biased due to the user personalized selection tendencies or the non-uniform item exposure probabilities. To study this problem, in this paper, we formally define a novel task named as unbiased fairness aware Top-N recommendation. For solving this task, we firstly define an ideal loss function based on all the user-item pairs. Considering that, in real-world datasets, only a small number of user-item interactions can be observed, we then approximate the above ideal loss with a more tractable objective based on the inverse propensity score (IPS). Since the recommendation datasets can be noisy and quite sparse, which brings difficulties for accurately estimating the IPS, we propose to optimize the objective in an IPS range instead of a specific point, which improves the model fault tolerance capability. In order to make our model more applicable to the commonly studied Top-N recommendation, we soften the ranking metrics such as Precision, Hit-Ratio, and NDCG to derive a fully differentiable framework. We conduct extensive experiments to demonstrate the effectiveness of our model based on four real-world datasets.",10.1145/3604915.3608770,https://doi.org/10.1145/3604915.3608770,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,When Fairness meets Bias: a Debiased Framework for Fairness aware Top-N Recommendation,"Tang, Jiakai and Shen, Shiqi and Wang, Zhipeng and Gong, Zhi and Zhang, Jingsen and Chen, Xu",inproceedings,10.1145/3604915.3608770,
10.1145/3604915.3608780,10.1145/3604915.3608780,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Contrastive Learning, Cross-Domain, Decouple Representation, Sequential Recommendation System",12,479–490,Proceedings of the 17th ACM Conference on Recommender Systems,"Cross-Domain Sequential Recommendation(CDSR) aims to generate accurate predictions for future interactions by leveraging users’ cross-domain historical interactions. One major challenge of CDSR is how to jointly learn the single- and cross-domain user preferences efficiently. To enhance the target domain’s performance, most existing solutions start by learning the single-domain user preferences within each domain and then transferring the acquired knowledge from the rich domain to the target domain. However, this approach ignores the inter-sequence item relationship and also limits the opportunities for target domain knowledge to enhance the rich domain performance. Moreover, it also ignores the information within the cross-domain sequence. Despite cross-domain sequences being generally noisy and hard to learn directly, they contain valuable user behavior patterns with great potential to enhance performance. Another key challenge of CDSR is data sparsity, which also exists in other recommendation system problems. In the real world, the data distribution of the recommendation system is highly skewed to the popular products, especially on the large-scale dataset with millions of users and items. One more challenge is the class imbalance problem, inherited by the sequential recommendation problem. Generally, each sample only has one positive and thousands of negative samples. To address the above problems together, an innovative Decoupled Representation via Extraction Attention Module (DREAM) is proposed for CDSR to simultaneously learn single- and cross-domain user preference via decoupled representations. A novel Supervised Contrastive Learning framework is introduced to model the inter-sequence relationship as well as address the data sparsity via data augmentations. DREAM also leverages Focal Loss to put more weight on misclassified samples to address the class-imbalance problem, with another uplift on the overall model performance. Extensive experiments had been conducted on two cross-domain recommendation datasets, demonstrating DREAM outperforms various SOTA cross-domain recommendation algorithms achieving up to a 75% uplift in Movie-Book Scenarios.",10.1145/3604915.3608780,https://doi.org/10.1145/3604915.3608780,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,DREAM: Decoupled Representation via Extraction Attention Module and Supervised Contrastive Learning for Cross-Domain Sequential Recommender,"Ye, Xiaoxin and Li, Yun and Yao, Lina",inproceedings,10.1145/3604915.3608780,
10.1145/3604915.3608782,10.1145/3604915.3608782,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Gaussian Distribution, Learnable Filter, Sequential Recommendation, Side Information",11,78–88,Proceedings of the 17th ACM Conference on Recommender Systems,"Sequential Recommendation aims to predict the next item by mining out the dynamic preference from user previous interactions. However, most methods represent each item as a single fixed vector, which is incapable of capturing the uncertainty of item-item transitions that result from time-dependent and multifarious interests of users. Besides, they struggle to effectively exploit side information that helps to better express user preferences. Finally, the noise in user’s access sequence, which is due to accidental clicks, can interfere with the next item prediction and lead to lower recommendation performance. To deal with these issues, we propose DLFS-Rec, a simple and novel model that combines Distribution-based Learnable Filters with Side information for sequential Recommendation. Specifically, items and their side information are represented by stochastic Gaussian distribution, which is described by mean and covariance embeddings, and then the corresponding embeddings are fused to generate a final representation for each item. To attenuate noise, stacked learnable filter layers are applied to smooth the fused embeddings. Extensive experiments on four public real-world datasets demonstrate the superiority of the proposed model over state-of-the-art baselines, especially on cold start users and items. Codes are available at https://github.com/zxiang30/DLFS-Rec.",10.1145/3604915.3608782,https://doi.org/10.1145/3604915.3608782,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Distribution-based Learnable Filters with Side Information for Sequential Recommendation,"Liu, Haibo and Deng, Zhixiang and Wang, Liang and Peng, Jinjia and Feng, Shi",inproceedings,10.1145/3604915.3608782,
10.1145/3604915.3608784,10.1145/3604915.3608784,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","fairness aware recommendation, recommendation system",12,211–222,Proceedings of the 17th ACM Conference on Recommender Systems,"Due to the progressive advancement of trustworthy machine learning algorithms, fairness in recommender systems is attracting increasing attention and is often considered from the perspective of users. Conventional fairness-aware recommendation models assume that user preferences remain the same between the training set and the testing set. However, this assumption is arguable in reality, where user preference can shift in the testing set due to the natural spatial or temporal heterogeneity. It is concerning that conventional fairness-aware models may be unaware of such distribution shifts, leading to a sharp decline in the model performance. To address the distribution shift problem, we propose a robust fairness-aware recommendation framework based on Distributionally Robust Optimization (DRO) technique. In specific, we assign learnable weights for each sample to approximate the distributions that leads to the worst-case model performance, and then optimize the fairness-aware recommendation model to improve the worst-case performance in terms of both fairness and recommendation accuracy. By iteratively updating the weights and the model parameter, our framework can be robust to unseen testing sets. To ease the learning difficulty of DRO, we use a hard clustering technique to reduce the number of learnable sample weights. To optimize our framework in a full differentiable manner, we soften the above clustering strategy. Empirically, we conduct extensive experiments based on four real-world datasets to verify the effectiveness of our proposed framework.",10.1145/3604915.3608784,https://doi.org/10.1145/3604915.3608784,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Towards Robust Fairness-aware Recommendation,"Yang, Hao and Liu, Zhining and Zhang, Zeyu and Zhuang, Chenyi and Chen, Xu",inproceedings,10.1145/3604915.3608784,
10.1145/3604915.3608788,10.1145/3604915.3608788,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Confidence, Recommender Systems, Uncertainty",12,306–317,Proceedings of the 17th ACM Conference on Recommender Systems,"Most recommender systems (RecSys) do not provide an indication of confidence in their decisions. Therefore, they do not distinguish between recommendations of which they are certain, and those where they are not. Existing confidence methods for RecSys are either inaccurate heuristics, conceptually complex or computationally very expensive. Consequently, real-world RecSys applications rarely adopt these methods, and thus, provide no confidence insights in their behavior. In this work, we propose learned beta distributions (LBD) as a simple and practical recommendation method with an explicit measure of confidence. Our main insight is that beta distributions predict user preferences as probability distributions that naturally model confidence on a closed interval, yet can be implemented with the minimal model-complexity. Our results show that LBD maintains competitive accuracy to existing methods while also having a significantly stronger correlation between its accuracy and confidence. Furthermore, LBD has higher performance when applied to a high-precision targeted recommendation task. Our work thus shows that confidence in RecSys is possible without sacrificing simplicity or accuracy, and without introducing heavy computational complexity. Thereby, we hope it enables better insight into real-world RecSys and opens the door for novel future applications.",10.1145/3604915.3608788,https://doi.org/10.1145/3604915.3608788,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,A Lightweight Method for Modeling Confidence in Recommendations with Learned Beta Distributions,"Knyazev, Norman and Oosterhuis, Harrie",inproceedings,10.1145/3604915.3608788,
10.1145/3604915.3608791,10.1145/3604915.3608791,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Cross-domain Recommendation, Negative Sampling, Recommender System",13,502–514,Proceedings of the 17th ACM Conference on Recommender Systems,"Negative Sampling in recommendation aims to capture informative negative instances for the sparse user-item interactions to improve the performance. Conventional negative sampling methods tend to select informative hard negative samples (HNS) besides the default random samples. However, these hard negative sampling methods usually struggle with false hard negative samples (FHNS), which happens when a user-item interaction has not been observed yet and is picked as a negative sample, while the user will actually interact with this item once exposed to it. Such FHNS issues may seriously confuse the model training, while most conventional hard negative sampling methods do not systematically explore and distinguish FHNS from HNS. To address this issue, we propose a novel model-agnostic Real Hard Negative Sampling (RealHNS) framework specially for cross-domain recommendation (CDR), which aims to discover the false and refine the real from all HNS via both general and cross-domain real hard negative sample selectors. For the general part, we conduct the coarse- and fine-grained real HNS selectors sequentially, armed with a dynamic item-based FHNS filter to find high-quality HNS. For the cross-domain part, we further design a new cross-domain HNS for alleviating negative transfer in CDR and discover its corresponding FHNS via a dynamic user-based FHNS filter to keep its power. We conduct experiments on four datasets based on three representative hard negative sampling methods, along with extensive model analyses, ablation studies, and universality analyses. The consistent improvements indicate the effectiveness, robustness, and universality of RealHNS, which is also easy-to-deploy in real-world systems as a plug-and-play strategy. The source code is avaliable in https://github.com/hulkima/RealHNS.",10.1145/3604915.3608791,https://doi.org/10.1145/3604915.3608791,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Exploring False Hard Negative Sample in Cross-Domain Recommendation,"Ma, Haokai and Xie, Ruobing and Meng, Lei and Chen, Xin and Zhang, Xu and Lin, Leyu and Zhou, Jie",inproceedings,10.1145/3604915.3608791,
10.1145/3604915.3608809,10.1145/3604915.3608809,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","item response theory, offline evaluation, recommender systems, user preferences",13,658–670,Proceedings of the 17th ACM Conference on Recommender Systems,"Current practices in offline evaluation use rank-based metrics to measure the quality of top-n recommendation lists. This approach has practical benefits as it centres assessment on the output of the recommender system and, therefore, measures performance from the perspective of end-users. However, this methodology neglects how recommender systems more broadly model user preferences, which is not captured by only considering the top-n recommendations. In this article, we use item response theory (IRT), a family of latent variable models used in psychometric assessment, to gain a comprehensive understanding of offline evaluation. We use IRT to jointly estimate the latent abilities of 51 recommendation algorithms and the characteristics of 3 commonly used benchmark data sets. For all data sets, the latent abilities estimated by IRT suggest that higher scores from traditional rank-based metrics do not reflect improvements in modeling user preferences. Furthermore, we show that the top-n recommendations with the most discriminatory power are biased towards lower difficulty items, leaving much room for improvement. Lastly, we highlight the role of popularity in evaluation by investigating how user engagement and item popularity influence recommendation difficulty.",10.1145/3604915.3608809,https://doi.org/10.1145/3604915.3608809,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,What We Evaluate When We Evaluate Recommender Systems: Understanding Recommender Systems’ Performance using Item Response Theory,"Liu, Yang and Medlar, Alan and Glowacka, Dorota",inproceedings,10.1145/3604915.3608809,
10.1145/3604915.3608810,10.1145/3604915.3608810,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Bayesian Deep Learning, Recommender Systems, Trend Recommendation",12,294–305,Proceedings of the 17th ACM Conference on Recommender Systems,"Modern recommender systems usually include separate recommendation carousels such as ‘trending now’ to list trending items and further boost their popularity, thereby attracting active users. Though widely useful, such ‘trending now’ carousels typically generate item lists based on simple heuristics, e.g., the number of interactions within a time interval, and therefore still leave much room for improvement. This paper aims to systematically study this under-explored but important problem from the new perspective of time series forecasting. We first provide a set of rigorous definitions related to item trendiness and formulate the trend recommendation task as a one-step time series forecasting problem. We then propose a deep latent variable model, dubbed Trend Recommender (TrendRec), to forecast items’ future trends and generate trending item lists. Furthermore, we design associated evaluation protocols for trend recommendation. Experiments on real-world datasets from various domains show that our TrendRec significantly outperforms the baselines, verifying our model’s effectiveness.",10.1145/3604915.3608810,https://doi.org/10.1145/3604915.3608810,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Trending Now: Modeling Trend Recommendations,"Ding, Hao and Kveton, Branislav and Ma, Yifei and Park, Youngsuk and Kini, Venkataramana and Gu, Yupeng and Divvela, Ravi and Wang, Fei and Deoras, Anoop and Wang, Hao",inproceedings,10.1145/3604915.3608810,
10.1145/3604915.3608823,10.1145/3604915.3608823,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Next-basket recommendation, autoregressive generative model.",7,737–743,Proceedings of the 17th ACM Conference on Recommender Systems,"Next-basket Recommendation (NBR) refers to the task of predicting a set of items that a user will purchase in the next basket. However, most of existing works merely focus on the correlations between user preferences and predicted items, ignoring the essential correlations among items in the next basket, which often results in over-homogenization of predicted items. In this work, we presents a Generative next-basket Recommendation model (GenRec), a novel NBR paradigm that generates the recommended items one by one to form the next basket via an autoregressive decoder. This generative NBR paradigm contributes to capturing and considering item correlations inside each baskets in both training and serving. Moreover, we jointly consider user’s both item- and basket-level contextual information to better capture user’s multi-granularity preferences. Extensive experiments on three real-world datasets demonstrate the effectiveness of our model.",10.1145/3604915.3608823,https://doi.org/10.1145/3604915.3608823,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Generative Next-Basket Recommendation,"Sun, Wenqi and Xie, Ruobing and Zhang, Junjie and Zhao, Wayne Xin and Lin, Leyu and Wen, Ji-Rong",inproceedings,10.1145/3604915.3608823,
10.1145/3604915.3608825,10.1145/3604915.3608825,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","algorithmic fairness, performance variation, user features",7,750–756,Proceedings of the 17th ACM Conference on Recommender Systems,"Collaborative filtering has been a dominant approach in the recommender systems community since the early 1990s. Collaborative filtering (and other) algorithms, however, have been predominantly evaluated by aggregating results across users or user groups. These performance averages hide large disparities: an algorithm may perform very well for some users (or groups) and poorly for others. We show that performance variation is large and systematic. In experiments on three large-scale datasets and using an array of collaborative filtering algorithms, we demonstrate large performance disparities across algorithms, datasets and metrics for different users. We then show that two key features that characterize users, their mean taste similarity and dispersion in taste similarity with other users, can systematically explain performance variation better than previously identified features. We use these two features to visualize algorithm performance for different users and we point out that this mapping can capture different categories of users that have been proposed before. Our results demonstrate an extensive mainstream-taste bias in collaborative filtering algorithms, which implies a fundamental fairness limitation that needs to be mitigated.",10.1145/3604915.3608825,https://doi.org/10.1145/3604915.3608825,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Collaborative filtering algorithms are prone to mainstream-taste bias,"Pipergias Analytis, Pantelis and Hager, Philipp",inproceedings,10.1145/3604915.3608825,
10.1145/3604915.3608833,10.1145/3604915.3608833,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","differential privacy, matrix factorization, recommendation system, side features",8,805–812,Proceedings of the 17th ACM Conference on Recommender Systems,"We consider the problem of training private recommendation models with access to public item features. Training with Differential Privacy (DP) offers strong privacy guarantees, at the expense of loss in recommendation quality. We show that incorporating public item features during training can help mitigate this loss in quality. We propose a general approach based on collective matrix factorization (CMF), that works by simultaneously factorizing two matrices: the user feedback matrix (representing sensitive data) and an item feature matrix that encodes publicly available (non-sensitive) item information. The method is conceptually simple, easy to tune, and highly scalable. It can be applied to different types of public item data, including: (1) categorical item features; (2) item-item similarities learned from public sources; and (3) publicly available user feedback. Furthermore, these data modalities can be collectively utilized to fully leverage public data. Evaluating our method on a standard DP recommendation benchmark, we find that using public item features significantly narrows the quality gap between private models and their non-private counterparts. As privacy constraints become more stringent, models rely more heavily on public side features for recommendation. This results in a smooth transition from collaborative filtering to item-based contextual recommendations.",10.1145/3604915.3608833,https://doi.org/10.1145/3604915.3608833,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Private Matrix Factorization with Public Item Features,"Curmei, Mihaela and Krichene, Walid and Zhang, Li and Sundararajan, Mukund",inproceedings,10.1145/3604915.3608833,
10.1145/3604915.3608835,10.1145/3604915.3608835,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Long-tail problem, Multi-interest Learning, Recommender Systems",6,820–825,Proceedings of the 17th ACM Conference on Recommender Systems,"Multi-interest recommendation methods extract multiple interest vectors to represent the user comprehensively. Despite their success in the matching stage, previous works overlook the long-tail problem. This results in the model excelling at suggesting head items, while the performance for tail items, which make up more than 70% of all items, remains suboptimal. Hence, enhancing the tail item recommendation capability holds great potential for improving the performance of the multi-interest model. Through experimental analysis, we reveal that the insufficient context for embedding learning is the reason behind the underperformance of tail items. Meanwhile, we face two challenges in addressing this issue: the absence of supplementary item features and the need to maintain head item performance. To tackle these challenges, we propose a CoLT module (Co-occurrence embedding enhancement for Long-Tail problem) that replaces the embedding layer of existing multi-interest frameworks. By linking co-occurring items to establish ""assistance relationships"", CoLT aggregates information from relevant head items into tail item embeddings and enables joint gradient updates. Experiments on three datasets show our method outperforms SOTA models by 21.86% Recall@50 and improves the Recall@50 of tail items by 14.62% on average.",10.1145/3604915.3608835,https://doi.org/10.1145/3604915.3608835,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Co-occurrence Embedding Enhancement for Long-tail Problem in Multi-Interest Recommendation,"Liu, Yaokun and Zhang, Xiaowang and Zou, Minghui and Feng, Zhiyong",inproceedings,10.1145/3604915.3608835,
10.1145/3604915.3608839,10.1145/3604915.3608839,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","evaluation flaws, evaluation setups, offline evaluation, recommender systems",8,848–855,Proceedings of the 17th ACM Conference on Recommender Systems,"Even though offline evaluation is just an imperfect proxy of online performance – due to the interactive nature of recommenders – it will probably remain the primary way of evaluation in recommender systems research for the foreseeable future, since the proprietary nature of production recommenders prevents independent validation of A/B test setups and verification of online results. Therefore, it is imperative that offline evaluation setups are as realistic and as flawless as they can be. Unfortunately, evaluation flaws are quite common in recommender systems research nowadays, due to later works copying flawed evaluation setups from their predecessors without questioning their validity. In the hope of improving the quality of offline evaluation of recommender systems, we discuss four of these widespread flaws and why researchers should avoid them.",10.1145/3604915.3608839,https://doi.org/10.1145/3604915.3608839,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Widespread Flaws in Offline Evaluation of Recommender Systems,"Hidasi, Bal\'{a}zs and Czapp, \'{A}d\'{a}m Tibor",inproceedings,10.1145/3604915.3608839,
10.1145/3604915.3608844,10.1145/3604915.3608844,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","BERT, Consistency Regularization, Social Recommendation",7,883–889,Proceedings of the 17th ACM Conference on Recommender Systems,"In the real world, when we seek our friends’ opinions on various items or events, we request verbal social recommendations. It has been observed that we often turn to our friends for recommendations on a daily basis. The emergence of online social platforms has enabled users to share their opinion with their social connections. Therefore, we should consider users’ social connections to enhance online recommendation performance. The social recommendation aims to fuse social links with user-item interactions to offer more relevant recommendations. Several efforts have been made to develop an effective social recommendation system. However, there are two significant limitations to current methods: First, they haven’t thoroughly explored the intricate relationships between the diverse influences of neighbours on users’ preferences. Second, existing models are vulnerable to overfitting due to the relatively low number of user-item interaction records in the interaction space. For the aforementioned problems, this paper offers a novel framework called CR-SoRec, an effective recommendation model based on BERT and consistency regularization. This model incorporates Bidirectional Encoder Representations from Transformer(BERT) to learn bidirectional context-aware user and item embeddings with neighbourhood sampling. The neighbourhood Sampling technique samples the most influential neighbours for all the users/ items. Further, to effectively use the available user-item interaction data and social ties, we leverage diverse perspectives via consistency regularization to harness the underlying information. The main objective of our model is to predict the next item that a user would interact with based on its interaction behaviour and social connections. Experimental results show that our model defines a new state-of-the-art on various datasets and outperforms previous work by a significant margin. Extensive experiments are also conducted to analyze the proposed method.",10.1145/3604915.3608844,https://doi.org/10.1145/3604915.3608844,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,CR-SoRec: BERT driven Consistency Regularization for Social Recommendation,"Prakash, Tushar and Jalan, Raksha and Singh, Brijraj and Onoe, Naoyuki",inproceedings,10.1145/3604915.3608844,
10.1145/3604915.3608847,10.1145/3604915.3608847,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","explainability, natural language generation, sequence-aware recommender systems",8,904–911,Proceedings of the 17th ACM Conference on Recommender Systems,"Self-explaining models are becoming an important perk of recommender systems, as they help users understand the reason behind certain recommendations, which encourages them to interact more often with the platform. In order to personalize recommendations, modern approaches make the model aware of the user behavior history for interest evolution representation. However, existing explainable recommender systems do not consider the past user history to further personalize the explanation based on the user interest fluctuation. In this work, we propose a SEQuence-Aware Explainable Recommendation model (SEQUER) that is able to leverage the sequence of user-item review interactions to generate better explanations while maintaining recommendation performance. Experiments validate the effectiveness of our proposal on multiple recommendation scenarios. Our source code and preprocessed datasets are available at https://github.com/alarca94/sequer-recsys23.",10.1145/3604915.3608847,https://doi.org/10.1145/3604915.3608847,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Towards Self-Explaining Sequence-Aware Recommendation,"Ariza-Casabona, Alejandro and Salam\'{o}, Maria and Boratto, Ludovico and Fenu, Gianni",inproceedings,10.1145/3604915.3608847,
10.1145/3604915.3608881,10.1145/3604915.3608881,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","change detection, recommender systems, temporal evolution, trust",2,1342–1343,Proceedings of the 17th ACM Conference on Recommender Systems,"Trust-based recommender systems emerged as a solution to different limitations of traditional recommender systems. These social systems rely on the assumption that users will adopt the preferences of users they deem trustworthy in an online social setting. However, most trust-based recommender systems consider trust to be a static notion, thereby disregarding crucial dynamic factors that influence the value of trust between users and the performance of the recommender system. In this work, we intend to address several challenges regarding the dynamics of trust within a social recommender system. These issues include the temporal evolution of trust between users and change detection and prediction in users’ interactions. By exploring the factors that influence the evolution of human trust, a complex and abstract concept, this work will contribute to a better understanding of how trust operates in recommender systems.",10.1145/3604915.3608881,https://doi.org/10.1145/3604915.3608881,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Acknowledging Dynamic Aspects of Trust in Recommender Systems,"Akdim, Imane",inproceedings,10.1145/3604915.3608881,
10.1145/3604915.3608886,10.1145/3604915.3608886,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","AutoRecSys, Automation, Recommender Systems",6,1355–1360,Proceedings of the 17th ACM Conference on Recommender Systems,"Recommender systems have become essential in domains like streaming services, social media platforms, and e-commerce websites. However, the development of a recommender system involves a complex pipeline with preprocessing, data splitting, algorithm and model selection, and postprocessing stages. Every stage of the recommender systems pipeline requires design decisions that influence the performance of the recommender system. To ease design decisions, automated machine learning (AutoML) techniques have been adapted to the field of recommender systems, resulting in various AutoRecSys libraries. Nevertheless, these libraries limit flexibility in integrating automation techniques. In response, our research aims to enhance the usability of AutoML techniques for design decisions in recommender system pipelines. We focus on developing flexible and library-independent automation techniques for algorithm selection, model selection, and postprocessing steps. By enabling developers to make informed choices and ease the recommender system development process, we decrease the developer’s effort while improving the performance of the recommender systems. Moreover, we want to analyze the cost-to-benefit ratio of automation techniques in recommender systems, evaluating the computational overhead and the resulting improvements in predictive performance. Our objective is to leverage AutoML concepts to automate design decisions in recommender system pipelines, reduce manual effort, and enhance the overall performance and usability of recommender systems.",10.1145/3604915.3608886,https://doi.org/10.1145/3604915.3608886,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Advancing Automation of Design Decisions in Recommender System Pipelines,"Vente, Tobias",inproceedings,10.1145/3604915.3608886,
10.1145/3604915.3609489,10.1145/3604915.3609489,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Graph Collaborative Filtering, Recommendation, Reproducibility",12,350–361,Proceedings of the 17th ACM Conference on Recommender Systems,"The success of graph neural network-based models (GNNs) has significantly advanced recommender systems by effectively modeling users and items as a bipartite, undirected graph. However, many original graph-based works often adopt results from baseline papers without verifying their validity for the specific configuration under analysis. Our work addresses this issue by focusing on the replicability of results. We present a code that successfully replicates results from six popular and recent graph recommendation models (NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmark datasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare these graph models with traditional collaborative filtering models that historically performed well in offline evaluations. Furthermore, we extend our study to two new datasets (Allrecipes and BookCrossing) that lack established setups in existing literature. As the performance on these datasets differs from the previous benchmarks, we analyze the impact of specific dataset characteristics on recommendation accuracy. By investigating the information flow from users’ neighborhoods, we aim to identify which models are influenced by intrinsic features in the dataset structure. The code to reproduce our experiments is available at:&nbsp;https://github.com/sisinflab/Graph-RSs-Reproducibility.",10.1145/3604915.3609489,https://doi.org/10.1145/3604915.3609489,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis,"Anelli, Vito Walter and Malitesta, Daniele and Pomo, Claudio and Bellogin, Alejandro and Di Sciascio, Eugenio and Di Noia, Tommaso",inproceedings,10.1145/3604915.3609489,
10.1145/3604915.3609494,10.1145/3604915.3609494,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Foundation Models, Large Language Models, Recommendation",3,1281–1283,Proceedings of the 17th ACM Conference on Recommender Systems,"Foundation Models such as Large Language Models (LLMs) have significantly advanced many research areas. In particular, LLMs offer significant advantages for recommender systems, making them valuable tools for personalized recommendations. For example, by formulating various recommendation tasks such as rating prediction, sequential recommendation, straightforward recommendation, and explanation generation into language instructions, LLMs make it possible to build universal recommendation engines that can handle different recommendation tasks. Additionally, LLMs have a remarkable capacity for understanding natural language, enabling them to comprehend user preferences, item descriptions, and contextual information to generate more accurate and relevant recommendations, leading to improved user satisfaction and engagement. This tutorial introduces Foundation Models such as LLMs for recommendation. We will introduce how recommender system advanced from shallow models to deep models and to large models, how LLMs enable generative recommendation in contrast to traditional discriminative recommendation, and how to build LLM-based recommender systems. We will cover multiple perspectives of LLM-based recommendation, including data preparation, model design, model pre-training, fine-tuning and prompting, multi-modality and multi-task learning, as well as trustworthy perspectives of LLM-based recommender systems such as fairness and transparency.",10.1145/3604915.3609494,https://doi.org/10.1145/3604915.3609494,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Tutorial on Large Language Models for Recommendation,"Hua, Wenyue and Li, Lei and Xu, Shuyuan and Chen, Li and Zhang, Yongfeng",inproceedings,10.1145/3604915.3609494,
10.1145/3604915.3610637,10.1145/3604915.3610637,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","A/B Testing, Long-tail, Online Evaluation, Popularity Bias, Recommender Systems",6,1084–1089,Proceedings of the 17th ACM Conference on Recommender Systems,"Despite their proven various benefits, Recommender Systems can cause or amplify certain undesired effects. In this paper, we focus on Popularity Bias, i.e., the tendency of a recommender system to utilize the effect of recommending popular items to the user. Prior research has studied the negative impact of this type of bias on individuals and society as a whole and proposed various approaches to mitigate this in various domains. However, almost all works adopted offline methodologies to evaluate the effectiveness of the proposed approaches. Unfortunately, such offline simulations can potentially be rather simplified and unable to capture the full picture. To contribute to this line of research and given a particular lack of knowledge about how debiasing approaches work not only offline, but online as well, we present in this paper the results of user study on a national broadcaster movie streaming platform in Norway, i.e., TV 2, following the A/B testing methodology. We deployed an effective mitigation approach for popularity bias, called Calibrated Popularity (CP), and monitored its performance in comparison to the platform’s existing collaborative filtering recommendation approach as a baseline over a period of almost four months. The results obtained from a large user base interacting in real-time with the recommendations indicate that the evaluated debiasing approach can be effective in addressing popularity bias while still maintaining the level of user interest and engagement.",10.1145/3604915.3610637,https://doi.org/10.1145/3604915.3610637,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Evaluating The Effects of Calibrated Popularity Bias Mitigation: A Field Study,"Klimashevskaia, Anastasiia and Elahi, Mehdi and Jannach, Dietmar and Skj\ae{}rven, Lars and Tessem, Astrid and Trattner, Christoph",inproceedings,10.1145/3604915.3610637,
10.1145/3604915.3610638,10.1145/3604915.3610638,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Carousel interfaces, Choice overload, Multi-list recommendations, User Experience.",6,1090–1095,Proceedings of the 17th ACM Conference on Recommender Systems,"Multi-list interfaces are widely used in recommender systems, especially in industry, showing collections of recommendations, one below the other, with items that have certain commonalities. The composition and order of these “carousels” are usually optimized by simulating user interaction based on probabilistic models learned from item click data. Research that actually involves users is rare, with only few studies investigating general user experience in comparison to conventional recommendation lists. Hence, it is largely unknown how specific design aspects such as carousel type and length influence the individual perception and usage of carousel-based interfaces. This paper seeks to fill this gap through an exploratory user study. The results confirm previous assumptions about user behavior and provide first insights into the differences in decision making in the presence of multiple recommendation carousels.",10.1145/3604915.3610638,https://doi.org/10.1145/3604915.3610638,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,How Users Ride the Carousel: Exploring the Design of Multi-List Recommender Interfaces From a User Perspective,"Loepp, Benedikt and Ziegler, J\""{u}rgen",inproceedings,10.1145/3604915.3610638,
10.1145/3604915.3610639,10.1145/3604915.3610639,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Evaluation, Large Language Models, Recommender Systems, Sequential Recommendation",7,1096–1102,Proceedings of the 17th ACM Conference on Recommender Systems,"Sequential recommendation problems have received increasing attention in research during the past few years, leading to the inception of a large variety of algorithmic approaches. In this work, we explore how large language models (LLMs), which are nowadays introducing disruptive effects in many AI-based applications, can be used to build or improve sequential recommendation approaches. Specifically, we devise and evaluate three approaches to leverage the power of LLMs in different ways. Our results from experiments on two datasets show that initializing the state-of-the-art sequential recommendation model BERT4Rec with embeddings obtained from an LLM improves NDCG by 15-20% compared to the vanilla BERT4Rec model. Furthermore, we find that a simple approach that leverages LLM embeddings for producing recommendations, can provide competitive performance by highlighting semantically related items. We publicly share the code and data of our experiments to ensure reproducibility.1",10.1145/3604915.3610639,https://doi.org/10.1145/3604915.3610639,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Leveraging Large Language Models for Sequential Recommendation,"Harte, Jesse and Zorgdrager, Wouter and Louridas, Panos and Katsifodimos, Asterios and Jannach, Dietmar and Fragkoulis, Marios",inproceedings,10.1145/3604915.3610639,
10.1145/3604915.3610645,10.1145/3604915.3610645,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","long-tail recommendation, music recommendation, popularity bias",4,1200–1203,Proceedings of the 17th ACM Conference on Recommender Systems,"Cities with strong local music scenes enjoy many social and economic benefits. To this end, we are interested in developing a locally-focused artist and event recommendation system called Localify.org that supports and promotes local music scenes. In this demo paper, we describe both the overall system architecture as well as our core recommendation algorithm. This algorithm uses artist-artist similarity information, as opposed to user-artist preference information, to bootstrap recommendation while we grow the number of users. The overall design of Localify was chosen based on the fact that local artists tend to be relatively obscure and reside in the long tail of the artist popularity distribution. We discuss the role of popularity bias and how we attempt to ameliorate it in the context of local music recommendation.",10.1145/3604915.3610645,https://doi.org/10.1145/3604915.3610645,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Localify.org: Locally-focus Music Artist and Event Recommendation,"Turnbull, Douglas and Trainor, April and Turnbull, Douglas R and Richards, Elizabeth and Bentley, Kieran and Conrad, Victoria and Gagliano, Paul and Raineault, Cassandra and Joachims, Thorsten",inproceedings,10.1145/3604915.3610645,
10.1145/3604915.3610648,10.1145/3604915.3610648,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","collaborative filtering, continual learning, gradient alignment, recommendation systems",6,1133–1138,Proceedings of the 17th ACM Conference on Recommender Systems,"A recommender system operates in a dynamic environment where new items emerge and new users join the system, resulting in ever-growing user-item interactions over time. Existing works either assume a model trained offline on a static dataset (requiring periodic re-training with ever larger datasets); or an online learning setup that favors recency over history. As privacy-aware users could hide their histories, the loss of older information means that periodic retraining may not always be feasible, while online learning may lose sight of users’ long-term preferences. In this work, we adopt a continual learning perspective to collaborative filtering, by compartmentalizing users and items over time into a notion of tasks. Of particular concern is to mitigate catastrophic forgetting that occurs when the model would reduce performance for older users and items in prior tasks even as it tries to fit the newer users and items in the current task. To alleviate this, we propose a method that leverages gradient alignment to deliver a model that is more compatible across tasks and maximizes user agreement for better user representations to improve long-term recommendations.",10.1145/3604915.3610648,https://doi.org/10.1145/3604915.3610648,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Continual Collaborative Filtering Through Gradient Alignment,"Do, Jaime Hieu and Lauw, Hady W.",inproceedings,10.1145/3604915.3610648,
10.1145/3604915.3610654,10.1145/3604915.3610654,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","anomaly detection, graph neural network, matrix completion, uncertainty",6,1169–1174,Proceedings of the 17th ACM Conference on Recommender Systems,"We propose a robust recommender systems model which performs matrix completion and a ratings-wise uncertainty estimation jointly. Whilst the prediction module is purely based on an implicit low-rank assumption imposed via nuclear norm regularization, our loss function is augmented by an uncertainty estimation module which learns an anomaly score for each individual rating via a Graph Neural Network: data points deemed more anomalous by the GNN are downregulated in the loss function used to train the low-rank module. The whole model is trained in an end-to-end fashion, allowing the anomaly detection module to tap on the supervised information available in the form of ratings. Thus, our model’s predictors enjoy the favourable generalization properties that come with being chosen from small function space (i.e., low-rank matrices), whilst exhibiting the robustness to outliers and flexibility that comes with deep learning methods. Furthermore, the anomaly scores themselves contain valuable qualitative information. Experiments on various real-life datasets demonstrate that our model outperforms standard matrix completion and other baselines, confirming the usefulness of the anomaly detection module.",10.1145/3604915.3610654,https://doi.org/10.1145/3604915.3610654,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Uncertainty-adjusted Inductive Matrix Completion with Graph Neural Networks,"Kasalicky, Petr and Ledent, Antoine and Alves, Rodrigo",inproceedings,10.1145/3604915.3610654,
10.1145/3604915.3610656,10.1145/3604915.3610656,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Algorithm Selection, AutoRecSys, Automated Recommender Systems, CASH, Hyperparameter Optimization, Recommender Systems",5,1212–1216,Proceedings of the 17th ACM Conference on Recommender Systems,"LensKit is one of the first and most popular Recommender System libraries. While LensKit offers a wide variety of features, it does not include any optimization strategies or guidelines on how to select and tune LensKit algorithms. LensKit developers have to manually include third-party libraries into their experimental setup or implement optimization strategies by hand to optimize hyperparameters. We found that 63.6% (21 out of 33) of papers using LensKit algorithms for their experiments did not select algorithms or tune hyperparameters. Non-optimized models represent poor baselines and produce less meaningful research results. This demo introduces LensKit-Auto. LensKit-Auto automates the entire Recommender System pipeline and enables LensKit developers to automatically select, optimize, and ensemble LensKit algorithms.",10.1145/3604915.3610656,https://doi.org/10.1145/3604915.3610656,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,"Introducing LensKit-Auto, an Experimental Automated Recommender System (AutoRecSys) Toolkit","Vente, Tobias and Ekstrand, Michael and Beel, Joeran",inproceedings,10.1145/3604915.3610656,
10.1145/3604915.3610659,10.1145/3604915.3610659,RecSys.bib,1,['RecSys.bib'],8,RecSys '23,"Singapore, Singapore","Fairness, Food recommendation, Healthy recommendation, Recommender systems",6,1184–1189,Proceedings of the 17th ACM Conference on Recommender Systems,"Food recommendation systems play a crucial role in promoting personalized recommendations designed to help users find food and recipes that align with their preferences. However, many existing food recommendation systems have overlooked the important aspect of healthy-food and nutritional value of recommended foods, thereby limiting their effectiveness in generating truly healthy recommendations. Our preliminary analysis indicates that users tend to respond positively to unhealthy food and recipes. As a result, existing food recommender systems that neglect health considerations often assign high scores to popular items, inadvertently encouraging unhealthy choices among users. In this study, we propose the development of a fairness-based model that prioritizes health considerations. Our model incorporates fairness constraints from both the user and item perspectives, integrating them into a joint objective framework. Experimental results conducted on real-world food datasets demonstrate that the proposed system not only maintains the ability of food recommendation systems to suggest users’ favorite foods but also improves the health factor compared to unfair models, with an average enhancement of approximately 35%.",10.1145/3604915.3610659,https://doi.org/10.1145/3604915.3610659,"New York, NY, USA",Association for Computing Machinery,9798400702419,2023,Towards Health-Aware Fairness in Food Recipe Recommendation,"Rostami, Mehrdad and Aliannejadi, Mohammad and Oussalah, Mourad",inproceedings,10.1145/3604915.3610659,
10.1145/3616855.3635760,10.1145/3616855.3635760,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","recommender systems, sequential recommendation",9,930–938,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"State-of-the-art sequential recommendation relies heavily on self-attention-based recommender models. Yet such models are computationally expensive and often too slow for real-time recommendation. Furthermore, the self-attention operation is performed at a sequence-level, thereby making low-cost incremental inference challenging. Inspired by recent advances in efficient language modeling, we propose linear recurrent units for sequential recommendation (LRURec). Similar to recurrent neural networks, LRURec offers rapid inference and can achieve incremental inference on sequential inputs. By decomposing the linear recurrence operation and designing recursive parallelization in our framework, LRURec provides the additional benefits of reduced model size and parallelizable training. Moreover, we optimize the architecture of LRURec by implementing a series of modifications to address the lack of non-linearity and improve training dynamics. To validate the effectiveness of our proposed LRURec, we conduct extensive experiments on multiple real-world datasets and compare its performance against state-of-the-art sequential recommenders. Experimental results demonstrate the effectiveness of LRURec, which consistently outperforms baselines by a significant margin. Results also highlight the efficiency of LRURec with our parallelized training paradigm and fast inference on long sequences, showing its potential to further enhance user experience in sequential recommendation.",10.1145/3616855.3635760,https://doi.org/10.1145/3616855.3635760,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,Linear Recurrent Units for Sequential Recommendation,"Yue, Zhenrui and Wang, Yueqi and He, Zhankui and Zeng, Huimin and Mcauley, Julian and Wang, Dong",inproceedings,10.1145/3616855.3635760,
10.1145/3616855.3635762,10.1145/3616855.3635762,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","knowledge graph, sequential recommendation",10,266–275,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"Knowledge Graphs (KGs) enhance recommendations by providing external connectivity between items. However, there is limited research on distilling relevant knowledge in sequential recommendation, where item connections can change over time. To address this, we introduce the Temporal Knowledge Graph (TKG), which incorporates such dynamic features of user behaviors into the original KG while emphasizing sequential relationships. The TKG captures both patterns of entity dynamics (nodes) and structural dynamics (edges). Considering real-world applications with large-scale and rapidly evolving user behavior patterns, we propose an efficient two-phase framework called TKG-SRec, which strengthens Sequential Recommendation with Temporal KGs. In the first phase, we learn dynamic entity embeddings using our novel Knowledge Evolution Network (KEN) that brings together pretrained static knowledge with evolving temporal knowledge. In the second stage, downstream sequential recommender models utilize these time-specific dynamic entity embeddings with compatible neural backbones like GRUs, Transformers, and MLPs. From our extensive experiments over four datasets, TKG-SRec outperforms the current state-of-the-art by a statistically significant 5% on average. Detailed analysis validates that such filtered temporal knowledge better adapts entity embedding for sequential recommendation. In summary, TKG-SRec provides an effective and efficient approach.",10.1145/3616855.3635762,https://doi.org/10.1145/3616855.3635762,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,User Behavior Enriched Temporal Knowledge Graphs for Sequential Recommendation,"Hu, Hengchang and Guo, Wei and Liu, Xu and Liu, Yong and Tang, Ruiming and Zhang, Rui and Kan, Min-Yen",inproceedings,10.1145/3616855.3635762,
10.1145/3616855.3635779,10.1145/3616855.3635779,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","bayesian inference, causality, pre-trained models, probabilistic methods, recommender systems",10,424–433,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"Recent studies on pre-trained vision/language models have demonstrated the practical benefit of a new, promising solution-building paradigm in AI where models can be pre-trained on broad data describing a generic task space and then adapted successfully to solve a wide range of downstream tasks, even when training data is severely limited (e.g., in zero- or few-shot learning scenarios). Inspired by such progress, we investigate in this paper the possibilities and challenges of adapting such a paradigm to the context of recommender systems, which is less investigated from the perspective of pre-trained model. In particular, we propose to develop a generic recommender that captures universal interaction patterns by training on generic user-item interaction data extracted from different domains, which can then be fast adapted to improve few-shot learning performance in unseen new domains (with limited data).  However, unlike vision/language data which share strong conformity in the semantic space, universal patterns underlying recommendation data collected across different domains (e.g., different countries or different E-commerce platforms) are often occluded by both in-domain and cross-domain biases implicitly imposed by the cultural differences in their user and item bases, as well as their uses of different e-commerce platforms. As shown in our experiments, such heterogeneous biases in the data tend to hinder the effectiveness of the pre-trained model. To address this challenge, we further introduce and formalize a causal debiasing perspective, which is substantiated via a hierarchical Bayesian deep learning model, named model. Our empirical studies on real-world data show that the proposed model could significantly improve the recommendation performance in zero- and few-shot learning settings under both cross-market and cross-platform scenarios.",10.1145/3616855.3635779,https://doi.org/10.1145/3616855.3635779,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,Pre-trained Recommender Systems: A Causal Debiasing Perspective,"Lin, Ziqian and Ding, Hao and Hoang, Nghia Trong and Kveton, Branislav and Deoras, Anoop and Wang, Hao",inproceedings,10.1145/3616855.3635779,
10.1145/3616855.3635794,10.1145/3616855.3635794,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","cold-start recommendation, cross-domain recommendation, meta learning, neural process",9,378–386,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"Cross-domain recommendation (CDR) has been proven as a promising way to tackle the user cold-start problem, which aims to make recommendations for users in the target domain by transferring the user preference derived from the source domain. Traditional CDR studies follow the embedding and mapping (EMCDR) paradigm, which transfers user representations from the source to target domain by learning a user-shared mapping function, neglecting the user-specific preference. Recent CDR studies attempt to learn user-specific mapping functions in meta-learning paradigm, which regards each user's CDR as an individual task, but neglects the preference correlations among users, limiting the beneficial information for user representations. Moreover, both of the paradigms neglect the explicit user-item interactions from both domains during the mapping process. To address the above issues, this paper proposes a novel CDR framework with neural process (NP), termed as CDRNP. Particularly, it develops the meta-learning paradigm to leverage user-specific preference, and further introduces a stochastic process by NP to capture the preference correlations among the overlapping and cold-start users, thus generating more powerful mapping functions by mapping the user-specific preference and common preference correlations to a predictive probability distribution. In addition, we also introduce a preference remainer to enhance the common preference from the overlapping users, and finally devises an adaptive conditional decoder with preference modulation to make prediction for cold-start users with items in the target domain. Experimental results demonstrate that CDRNP outperforms previous SOTA methods in three real-world CDR scenarios.",10.1145/3616855.3635794,https://doi.org/10.1145/3616855.3635794,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process,"Li, Xiaodong and Sheng, Jiawei and Cao, Jiangxia and Zhang, Wenyuan and Li, Quangang and Liu, Tingwen",inproceedings,10.1145/3616855.3635794,
10.1145/3616855.3635811,10.1145/3616855.3635811,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","hypergraph learning., multitask pretraining, recommender system",10,891–900,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"Although pretraining has garnered significant attention and popularity in recent years, its application in graph-based recommender systems is relatively limited. It is challenging to exploit prior knowledge by pretraining in widely used ID-dependent datasets. On the one hand, user-item interaction history in one dataset can hardly be transferred to other datasets through pretraining, where IDs are different. On the other hand, pretraining and finetuning on the same dataset leads to a high risk of overfitting. In this paper, we propose a novel multitask pretraining framework named Unified Pretraining for Recommendation via Task Hypergraphs. For a unified learning pattern to handle diverse requirements and nuances of various pretext tasks, we design task hypergraphs to generalize pretext tasks to hyperedge prediction. A novel transitional attention layer is devised to discriminatively learn the relevance between each pretext task and recommendation. Experimental results on three benchmark datasets verify the superiority of UPRTH. Additional detailed investigations are conducted to demonstrate the effectiveness of the proposed framework.",10.1145/3616855.3635811,https://doi.org/10.1145/3616855.3635811,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,Unified Pretraining for Recommendation via Task Hypergraphs,"Yang, Mingdai and Liu, Zhiwei and Yang, Liangwei and Liu, Xiaolong and Wang, Chen and Peng, Hao and Yu, Philip S.",inproceedings,10.1145/3616855.3635811,
10.1145/3616855.3635833,10.1145/3616855.3635833,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","experiment design, exploration, recommendation systems",9,636–644,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"Effective exploration is believed to positively influence the long-term user experience on recommendation platforms. Determining its exact benefits, however, has been challenging. Regular A/B tests on exploration often measure neutral or even negative engagement metrics while failing to capture its long-term benefits. We here introduce new experiment designs to formally quantify the long-term value of exploration by examining its effects on content corpus, and connecting content corpus growth to the long-term user experience from real-world experiments. Once established the values of exploration, we investigate the Neural Linear Bandit algorithm as a general framework to introduce exploration into any deep learning based ranking systems. We conduct live experiments on one of the largest short-form video recommendation platforms that serves billions of users to validate the new experiment designs, quantify the long-term values of exploration, and to verify the effectiveness of the adopted neural linear bandit algorithm for exploration.",10.1145/3616855.3635833,https://doi.org/10.1145/3616855.3635833,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,"Long-Term Value of Exploration: Measurements, Findings and Algorithms","Su, Yi and Wang, Xiangyu and Le, Elaine Ya and Liu, Liang and Li, Yuening and Lu, Haokai and Lipshitz, Benjamin and Badam, Sriraj and Heldt, Lukasz and Bi, Shuchao and Chi, Ed H. and Goodrow, Cristos and Wu, Su-Lin and Baugher, Lexi and Chen, Minmin",inproceedings,10.1145/3616855.3635833,
10.1145/3616855.3635848,10.1145/3616855.3635848,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","distributionally robust optimization, exposure bias, recommendation debiasing, sequential recommendation",9,882–890,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"Sequential recommendation (SR) models are typically trained on user-item interactions which are affected by the system exposure bias, leading to the user preference learned from the biased SR model not being fully consistent with the true user preference. Exposure bias refers to the fact that user interactions are dependent upon the partial items exposed to the user. Existing debiasing methods do not make full use of the system exposure data and suffer from sub-optimal recommendation performance and high variance.In this paper, we propose to debias sequential recommenders through Distributionally Robust Optimization (DRO) over system exposure data. The key idea is to utilize DRO to optimize the worst-case error over an uncertainty set to safeguard the model against distributional discrepancy caused by the exposure bias. The main challenge to apply DRO for exposure debiasing in sequential recommendation lies in how to construct the uncertainty set and avoid the overestimation of user preference on biased samples. Moreover, since the test set could also be affected by the exposure bias, how to evaluate the debiasing effect is also an open question. To this end, we first introduce an exposure simulator trained upon the system exposure data to calculate the exposure distribution, which is then regarded as the nominal distribution to construct the uncertainty set of DRO. Then, we introduce a penalty to items with high exposure probability to avoid the overestimation of user preference for biased samples. Finally, we design a debiased self-normalized inverse propensity score (SNIPS) evaluator for evaluating the debiasing effect on the biased offline test set. We conduct extensive experiments on two real-world datasets to verify the effectiveness of the proposed methods. Experimental results demonstrate the superior exposure debiasing performance of proposed methods. Codes and data are available at https://github.com/nancheng58/DebiasedSR_DRO.",10.1145/3616855.3635848,https://doi.org/10.1145/3616855.3635848,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,Debiasing Sequential Recommenders through Distributionally Robust Optimization over System Exposure,"Yang, Jiyuan and Ding, Yue and Wang, Yidan and Ren, Pengjie and Chen, Zhumin and Cai, Fei and Ma, Jun and Zhang, Rui and Ren, Zhaochun and Xin, Xin",inproceedings,10.1145/3616855.3635848,
10.1145/3616855.3635853,10.1145/3616855.3635853,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","bias in recommender system, collaborative filtering, content-based recommendation, data augmentation, data sparsity, graph learning, large language models, multi-modal recommendation",10,806–815,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"The problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information. However, this approach often introduces side effects such as noise, availability issues, and low data quality, which in turn hinder the accurate modeling of user preferences and adversely impact recommendation performance. In light of the recent advancements in large language models (LLMs), which possess extensive knowledge bases and strong reasoning capabilities, we propose a novel framework called LLMRec that enhances recommender systems by employing three simple yet effective LLM-based graph augmentation strategies. Our approach leverages the rich content available within online platforms (e.g., Netflix, MovieLens) to augment the interaction graph in three ways: (i) reinforcing user-item interaction egde, (ii) enhancing the understanding of item node attributes, and (iii) conducting user node profiling, intuitively from the natural language perspective. By employing these strategies, we address the challenges posed by sparse implicit feedback and low-quality side information in recommenders. Besides, to ensure the quality of the augmentation, we develop a denoised data robustification mechanism that includes techniques of noisy implicit feedback pruning and MAE-based feature enhancement that help refine the augmented data and improve its reliability. Furthermore, we provide theoretical analysis to support the effectiveness of LLMRec and clarify the benefits of our method in facilitating model optimization. Experimental results on benchmark datasets demonstrate the superiority of our LLM-based augmentation approach over state-of-the-art techniques. To ensure reproducibility, we have made our code and augmented data publicly available at: https://github.com/HKUDS/LLMRec.git.",10.1145/3616855.3635853,https://doi.org/10.1145/3616855.3635853,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,LLMRec: Large Language Models with Graph Augmentation for Recommendation,"Wei, Wei and Ren, Xubin and Tang, Jiabin and Wang, Qinyong and Su, Lixin and Cheng, Suqi and Wang, Junfeng and Yin, Dawei and Huang, Chao",inproceedings,10.1145/3616855.3635853,
10.1145/3616855.3635855,10.1145/3616855.3635855,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","causal reasoning, debiased recommendation, explainable recommendation system",10,472–481,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"In recent years, the field of recommendation systems has witnessed significant advancements, with explainable recommendation systems gaining prominence as a crucial area of research. These systems aim to enhance user experience by providing transparent and compelling recommendations, accompanied by explanations. However, a persistent challenge lies in addressing biases that can influence the recommendations and explanations offered by these systems. Such biases often stem from a tendency to favor popular items and generate explanations that highlight their common attributes, thereby deviating from the objective of delivering personalized recommendations and explanations. While existing debiasing methods have been applied in explainable recommendation systems, they often overlook the model-generated explanations in tackling biases. Consequently, biases in model-generated explanations may persist, potentially compromising system performance and user satisfaction.To address biases in both model-generated explanations and recommended items, we discern the impact of model-generated explanations in recommendation through a formulated causal graph. Inspired by this causal perspective, we propose a novel approach termed Causal Explainable Recommendation System (CERS), which incorporates model-generated explanations into the debiasing process and enacts causal interventions based on user feedback on the explanations. By utilizing model-generated explanations as intermediaries between user-item interactions and recommendation results, we adeptly mitigate the biases via targeted causal interventions. Experimental results demonstrate the efficacy of CERS in reducing popularity bias while simultaneously improving recommendation performance, leading to more personalized and tailored recommendations. Human evaluation further affirms that CERS generates explanations tailored to individual users, thereby enhancing the persuasiveness of the system.",10.1145/3616855.3635855,https://doi.org/10.1145/3616855.3635855,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,Interact with the Explanations: Causal Debiased Explainable Recommendation System,"Liu, Xu and Yu, Tong and Xie, Kaige and Wu, Junda and Li, Shuai",inproceedings,10.1145/3616855.3635855,
10.1145/3616855.3635858,10.1145/3616855.3635858,WSDM.bib,1,['WSDM.bib'],8,WSDM '24,"Merida, Mexico","disentangled representation learning, search and recommendation, visual preference modeling",10,816–825,Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"In the world of E-Commerce, the core task is to understand the personalized preference from various kinds of heterogeneous information, such as textual reviews, item images and historical behaviors. In current systems, these heterogeneous information are mainly exploited to generate better item or user representations. For example, in scenario of visual search, the importance of modeling query image has been widely acknowledged. But, these existing solutions focus on improving the representation quality of the query image, overlooking the personalized visual preference of the user. Note that the visual features affect the user's decision significantly, e.g., the user could be more likely to click the items with her preferred design. Hence, it is fruitful to exploit the visual preference to deliver better capacity for personalization. To this end, we propose a simple yet effective target-aware visual preference learning framework (named Tavern) for both item recommendation and search. The proposed Tavern works as an individual and generic model that can be smoothly plugged into different downstream systems. Specifically, for visual preference learning, we utilize the image of the target item to derive the visual preference signals for each historical clicked item. This procedure is modeled as a form of representation disentanglement, where the visual preference signals are extracted by taking off the noisy information irrelevant to visual preference from the shared visual information between the target and historical items. During this process, a novel selective orthogonality disentanglement is proposed to avoid the significant information loss. Then, a GRU network is utilized to aggregate these signals to form the final visual preference representation. Extensive experiments over three large-scale real-world datasets covering visual search, product search and recommendation well demonstrate the superiority of our proposed Tavern against existing technical alternatives. Further ablation study also confirms the validity of each design choice.",10.1145/3616855.3635858,https://doi.org/10.1145/3616855.3635858,"New York, NY, USA",Association for Computing Machinery,9798400703713,2024,Unified Visual Preference Learning for User Intent Understanding,"Wen, Yihua and Chen, Si and Tian, Yu and Guan, Wanxian and Wang, Pengjie and Deng, Hongbo and Xu, Jian and Zheng, Bo and Li, Zihao and Zou, Lixin and Li, Chenliang",inproceedings,10.1145/3616855.3635858,
10.1145/3625007.3627486,10.1145/3625007.3627486,KDD.bib,1,['KDD.bib'],8,ASONAM '23,"Kusadasi, Turkiye","latent factor models, visualization, topic models",5,335–339,Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Latent factor models are widely used in recommender systems. In these models, users and items are represented as vectors in a joint latent factor space. The inner products of user vectors and item vectors are used to model the user-item interactions (e.g., ratings). A review is often posted by the user to explain the given rating. Therefore, reviews can be used to understand how users rate the items and to interpret the latent dimensions of user and item vectors. In this paper, we propose a probabilistic model that learns latent vectors of users and items in a two- or three-dimensional space for visualization. Our proposed model also extracts review topics and visualizes them in the same visualization space for interpreting the ratings. We model the user-item interactions by using the distances between users and items in the visualization space. Extensive experiments using several real-world datasets demonstrate the effectiveness of our proposed model in recommendation and visualization tasks.",10.1145/3625007.3627486,https://doi.org/10.1145/3625007.3627486,"New York, NY, USA",Association for Computing Machinery,9798400704093,2024,Utilizing Textual Reviews for Visualizing and Understanding User Preferences,"Pham, Dang and Le, Tuan",inproceedings,10.1145/3625007.3627486,
10.1145/3625007.3627517,10.1145/3625007.3627517,KDD.bib,1,['KDD.bib'],8,ASONAM '23,"Kusadasi, Turkiye","anomaly detection, event reconstruction, cascade prediction, social media",5,300–304,Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Due to their high volume and data recency, communications from social media platforms have become an excellent source for monitoring information diffusion. The insights leveraged are invaluable for social media analysts in the areas of event analysis and emergency management. Existing work ranges from the initial detection of incidents over information enrichment to determining an incident's relevance and life span. Until now, individual parts of this process have been considered separately, but never in combination.In this work, we address this crucial need and present an approach for detecting the onset and context of emerging events and predicting their popularity two weeks after emergence on Twitter in real time. Our contribution is threefold. We first present an online learning anomaly detection method refined with temporal clustering to identify abnormal conversational volumes of keywords. Second, we reconstruct potentially underlying events causing the anomaly through the enrichment of contextual and temporal information. Third, we assess an event's relevance and life span by predicting the resonance corresponding tweets receive shortly after their publication.",10.1145/3625007.3627517,https://doi.org/10.1145/3625007.3627517,"New York, NY, USA",Association for Computing Machinery,9798400704093,2024,Real-Time Anomaly Detection and Popularity Prediction for Emerging Events on Twitter,"Steuber, Florian and Schneider, Sinclair and Schneider, Jo\~{a}o A. G. and Rodosek, Gabi Dreo",inproceedings,10.1145/3625007.3627517,
10.1145/3625007.3627520,10.1145/3625007.3627520,KDD.bib,1,['KDD.bib'],7,ASONAM '23,"Kusadasi, Turkiye",,8,17–24,Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"The significant impact of Twitter in news dissemination underscores the need to understand what drives tweet popularity. While the content of an article plays a role, several ""content-agnostic"" factors also influence tweet popularity. Previous studies have faced challenges in differentiating the effects of content-agnostic factors from content variations. To address this, the paper presents a comprehensive analysis of tweet popularity using a ""clone-based"" approach. The methodology involves identifying tweets linking the same or similar articles (clones) and studying the factors that make some tweets within clone sets more successful in attracting retweets. The analysis reveals insights into clone set characteristics, winners' success patterns, retweet dynamics over time, domain-based competition, and predictors of success. The findings shed light on the complex nature of popularity and success in social media, providing a deeper understanding of the content-agnostic factors that influence tweet popularity.",10.1145/3625007.3627520,https://doi.org/10.1145/3625007.3627520,"New York, NY, USA",Association for Computing Machinery,9798400704093,2024,A Clone-based Analysis of the Content-Agnostic Factors Driving News Article Popularity on Twitter,"Mohammadinodooshan, Alireza and Holmgren, William and Christensson, Martin and Carlsson, Niklas",inproceedings,10.1145/3625007.3627520,
10.1145/3625007.3627724,10.1145/3625007.3627724,KDD.bib,1,['KDD.bib'],8,ASONAM '23,"Kusadasi, Turkiye","auditing, exposure bias, recommendations",5,379–383,Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Online social platforms employ personalized feed algorithms to gather and prioritize messages from accounts followed by users, which distorts content's perceived popularity prior to personalization. We call this ""exposure bias,"" and our research focuses on quantifying it using diverse exposure bias metrics, and we evaluate recommendation algorithms through various content ranking heuristics. Similarly we simulate activity in a network to assess the influence of such ranking heuristics on exposure bias. Furthermore, we are working on agent-based model simulations to comprehend the impact of ranking schemes, with the ultimate goal of exploring intervention effects over time. Our empirical findings reveal that users exposed to popularity-based feeds experience significantly lower exposure bias compared to chronologically-ordered feeds.",10.1145/3625007.3627724,https://doi.org/10.1145/3625007.3627724,"New York, NY, USA",Association for Computing Machinery,9798400704093,2024,Evaluating Content Exposure Bias in Social Networks,"Bartley, Nathan and Burghardt, Keith and Lerman, Kristina",inproceedings,10.1145/3625007.3627724,
10.1145/3626221.3626223,10.1145/3626221.3626223,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '23,"Singapore, Singapore","Feature Interaction Models, Online Ad Installation Forecasting, Recommender Systems",5,4–8,Proceedings of the Recommender Systems Challenge 2023,"We present our solution for the RecSys Challenge 2023 in this paper, which focuses on online advertising and deep funnel optimization, emphasizing user privacy. The dataset provided for the challenge includes user and ad features, as well as click and install information from the ShareChat apps. The objective is to predict the probabilities of ad installations in the test set. Our solution primarily leverages the xDeepFM model, which combines explicit and implicit feature interactions to capture complex relationships. Additionally, we employ various techniques such as feature engineering, feature crossing, cross-validation, and model integration to enhance the performance of our solution. Through extensive experimentation and fine-tuning, our team BUAA_BIGSCity achieved a score of 6.282142 in the final submission, demonstrating the effectiveness of our approach. To promote reproducibility and further research, our code is available on GitHub&nbsp;1. This paper provides insights into our solution for this challenge, showcasing advancements in online advertising and deep funnel optimization.",10.1145/3626221.3626223,https://doi.org/10.1145/3626221.3626223,"New York, NY, USA",Association for Computing Machinery,9798400716133,2023,Integrating Explicit and Implicit Feature Interactions for Online Ad Installation Forecasting,"Jiang, Jiawei and Wang, Bing and Wang, Jingyuan",inproceedings,10.1145/3626221.3626223,
10.1145/3626221.3626225,10.1145/3626221.3626225,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '23,"Singapore, Singapore","ACM RecSys Challenge 2023, Adversarial Validation, CTR Prediction, Gradient Boosting Decision Trees, User Response Prediction",5,9–13,Proceedings of the Recommender Systems Challenge 2023,"The ACM RecSys Challenge 2023, organized by ShareChat, aims to predict the probability of the app being installed. This paper describes the lightweight solution to this challenge. We formulate the task as a user response prediction task. For rapid prototyping for the task, we propose a lightweight solution including the following steps: 1) using adversarial validation, we effectively eliminate uninformative features from a dataset; 2) to address noisy continuous features and categorical features with a large number of unique values, we employ feature engineering techniques.; 3) we leverage Gradient Boosted Decision Trees (GBDT) for their exceptional performance and scalability. The experiments show that a single LightGBM model, without additional ensembling, performs quite well. Our team achieved ninth place in the challenge with the final leaderboard score of 6.059065. Code for our approach can be found here: https://github.com/choco9966/recsys-challenge-2023.",10.1145/3626221.3626225,https://doi.org/10.1145/3626221.3626225,"New York, NY, USA",Association for Computing Machinery,9798400716133,2023,Lightweight Boosting Models for User Response Prediction Using Adversarial Validation,"Kim, Hyeonwoo and Lee, Wonsung",inproceedings,10.1145/3626221.3626225,
10.1145/3627673.3679536,10.1145/3627673.3679536,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","personalized ranking, recommender system, triplet importance",10,809–818,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Personalized item ranking has been a crucial component contributing to the performance of recommender systems. As a representative approach, pairwise ranking directly optimizes the ranking with user implicit feedback by constructing ( user, positive item, negative item ) triplets. Several recent works have noticed that treating all triplets equally may hardly achieve the best effects. They assign different importance scores to negative items, user-item pairs, or triplets, respectively. However, almost all the generated importance scores are groundless and hard to interpret, thus far from trustworthy and transparent. To tackle these, we propose the Triplet Shapley ---a Shapely value-based method to measure the triplet importance in an interpretable manner. Due to the huge number of triplets, we transform the original Shapley value calculation to the Monte Carlo (MC) approximation. To stabilize the MC approximation, we adopt a control covariates-based scheme. Finally, we utilize the triplet Shapley values to guide the resampling of important triplets for facilitating the model learning. Extensive experiments are conducted on six public datasets involving classical matrix factorization- and graph neural network-based recommendation models to demonstrate the superiority of our method.",10.1145/3627673.3679536,https://doi.org/10.1145/3627673.3679536,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,Interpretable Triplet Importance for Personalized Ranking,"He, Bowei and Ma, Chen",inproceedings,10.1145/3627673.3679536,
10.1145/3627673.3679558,10.1145/3627673.3679558,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","collaborative filtering, large language models",11,2178–2188,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Recent advancements in Large Language Models (LLMs) have attracted considerable interest among researchers to leverage these models to enhance Recommender Systems (RSs). Existing work predominantly utilizes LLMs to generate knowledge-rich texts or utilizes LLM-derived embeddings as features to improve RSs. Although the extensive world knowledge embedded in LLMs generally benefits RSs, the application can only take a limited number of users and items as inputs, without adequately exploiting collaborative filtering information. Considering its crucial role in RSs, one key challenge in enhancing RSs with LLMs lies in providing better collaborative filtering information through LLMs. In this paper, drawing inspiration from the in-context learning and chain of thought reasoning in LLMs, we propose the Large Language Models enhanced Collaborative Filtering (LLM-CF) framework, which distills the world knowledge and reasoning capabilities of LLMs into collaborative filtering. We also explored a concise and efficient instruction-tuning method, which improves the recommendation capabilities of LLMs while preserving their general functionalities (e.g., not decreasing on the LLM benchmark). Comprehensive experiments on three real-world datasets demonstrate that LLM-CF significantly enhances several backbone recommendation models and consistently outperforms competitive baselines, showcasing its effectiveness in distilling the world knowledge and reasoning capabilities of LLM into collaborative filtering.",10.1145/3627673.3679558,https://doi.org/10.1145/3627673.3679558,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,Large Language Models Enhanced Collaborative Filtering,"Sun, Zhongxiang and Si, Zihua and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Zhang, Xiao and Xu, Jun",inproceedings,10.1145/3627673.3679558,
10.1145/3627673.3679581,10.1145/3627673.3679581,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","popularity bias, sequential recommendation, text-based recommendation",10,2240–2249,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Recently, the item textual information has been exploited with pre-trained language models (PLMs) to enrich the representations of tail items. The underlying idea is to align the hot items and tail items in terms of the external semantic knowledge covered by the PLM. However, it is non-trivial to eliminate the popularity bias by exploiting the textual semantics. One major obstacle is that the model supervision still counts on the sparse yet binary user behaviors. In the preliminary investigation, we discover that text-based recommendations also suffer from the popularity bias.To this end, we propose a novel self-distillation framework based on a pre-trained language model, named Staple. The proposed Staple consists of two main components: ranker model and recommender model, which are both instantiated as a PLM towards exploiting the item textual semantics. Motivated by the recent success of reinforcement learning with human feedback (RLHF), the proposed Staple aims to recover the relative preference by learning a fair ranker model that can successfully distinguish the preference levels for uninteracted items. Specifically, analogous to the training of large language models (LLMs), we introduce a pre-training and a fair supervised fine-tuning with a decoupled layer to build the ranker model. Then, similar to RLHF for LLM training, we utilize the relative preference information estimated by the ranker over candidate items to complement the learning of the recommender model. We show that this RLHF process can be reformed as an efficient distillation learning process. We conduct extensive experiments on three real-world datasets. In addition to the performance metrics, we employ two additional metrics to measure fairness and debiased performance. The experiments show that our method can significantly improve the item exposure fairness of recommendation and mitigate popularity bias, while also improving the recommendation performance. The source code is available at https://github.com/WHUIR/STAPLE.",10.1145/3627673.3679581,https://doi.org/10.1145/3627673.3679581,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,TEXT CAN BE FAIR: Mitigating Popularity Bias with PLMs by Learning Relative Preference,"Tang, Zuoli and Huan, Zhaoxin and Li, Zihao and Hu, Shirui and Zhang, Xiaolu and Zhou, Jun and Zou, Lixin and Li, Chenliang",inproceedings,10.1145/3627673.3679581,
10.1145/3627673.3679638,10.1145/3627673.3679638,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","neural architecture search, recommender system, reinforcement learning",10,1941–1950,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Recommender systems typically represent users and items by learning their embeddings, which are usually set to uniform dimensions and dominate the model parameters. However, real-world recommender systems often operate in streaming recommendation scenarios, where the number of users and items continues to grow, leading to substantial storage resource consumption for these embeddings. Although a few methods attempt to mitigate this by employing embedding size search strategies to assign different embedding dimensions in streaming recommendations, they assume that the embedding size grows with the frequency of users/items, which eventually still exceeds the predefined memory budget over time. To address this issue, this paper proposes to learn Scalable Lightweight Embeddings for streaming recommendation, called SCALL, which can adaptively adjust the embedding sizes of users/items within a given memory budget over time. Specifically, we propose to sample embedding sizes from a probabilistic distribution, with the guarantee to meet any predefined memory budget. By fixing the memory budget, the proposed embedding size sampling strategy can increase and decrease the embedding sizes in accordance to the frequency of the corresponding users or items. Furthermore, we develop a reinforcement learning-based search paradigm that models each state with mean pooling to keep the length of the state vectors fixed, invariant to the changing number of users and items. As a result, the proposed method can provide embedding sizes to unseen users and items. Comprehensive empirical evaluations on two public datasets affirm the advantageous effectiveness of our proposed method.",10.1145/3627673.3679638,https://doi.org/10.1145/3627673.3679638,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,Scalable Dynamic Embedding Size Search for Streaming Recommendation,"Qu, Yunke and Qu, Liang and Chen, Tong and Zhao, Xiangyu and Nguyen, Quoc Viet Hung and Yin, Hongzhi",inproceedings,10.1145/3627673.3679638,
10.1145/3627673.3679663,10.1145/3627673.3679663,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","alignment with rating and feature, explainable recommendation, maximizing mutual information, natural language-based explanation",10,3374–3383,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Providing natural language-based explanations to justify recommendations helps to improve users' satisfaction and gain users' trust. However, as current explanation generation methods are commonly trained with an objective to mimic existing user reviews, the generated explanations are often not aligned with the predicted ratings or some important features of the recommended items, and thus, are suboptimal in helping users make informed decision on the recommendation platform. To tackle this problem, we propose a flexible model-agnostic method named MMI (Maximizing Mutual Information) framework to enhance the alignment between the generated natural language explanations and the predicted rating/important item features. Specifically, we propose to use mutual information (MI) as a measure for the alignment and train a neural MI estimator. Then, we treat a well-trained explanation generation model as the backbone model and further fine-tune it through reinforcement learning with guidance from the MI estimator, which rewards a generated explanation that is more aligned with the predicted rating or a pre-defined feature of the recommended item. Experiments on three datasets demonstrate that our MMI framework can boost different backbone models, enabling them to outperform existing baselines in terms of alignment with predicted ratings and item features. Additionally, user studies verify that MI-enhanced explanations indeed facilitate users' decisions and are favorable compared with other baselines due to their better alignment properties.",10.1145/3627673.3679663,https://doi.org/10.1145/3627673.3679663,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,Aligning Explanations for Recommendation with Rating and Feature via Maximizing Mutual Information,"Zhao, Yurou and Sun, Yiding and Han, Ruidong and Jiang, Fei and Guan, Lu and Li, Xiang and Lin, Wei and Ma, Weizhi and Mao, Jiaxin",inproceedings,10.1145/3627673.3679663,
10.1145/3627673.3679674,10.1145/3627673.3679674,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","causal state representation, recommendation, reinforcement learning",10,2390–2399,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"In Reinforcement Learning-based Recommender Systems (RLRS), the complexity and dynamism of user interactions often result in high-dimensional and noisy state spaces, making it challenging to discern which aspects of the state are truly influential in driving the decision-making process. This issue is exacerbated by the evolving nature of user preferences and behaviors, requiring the recommender system to adaptively focus on the most relevant information for decision-making while preserving generaliability. To tackle this problem, we introduce an innovative causal approach for decomposing the state and extracting Causal-InDispensable State Representations (CIDS) in RLRS. Our method concentrates on identifying the Directly Action-Influenced State Variables (DAIS) and Action-Influence Ancestors (AIA), which are essential for making effective recommendations. By leveraging conditional mutual information, we develop a framework that not only discerns the causal relationships within the generative process but also isolates critical state variables from the typically dense and high-dimensional state representations. We provide theoretical evidence for the identifiability of these variables. Then, by making use of the identified causal relationship, we construct causal-indispensable state representations, enabling the training of policies over a more advantageous subset of the agent's state space. We demonstrate the efficacy of our approach through extensive experiments, showcasing our method outperforms state-of-the-art methods.",10.1145/3627673.3679674,https://doi.org/10.1145/3627673.3679674,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,On Causally Disentangled State Representation Learning for Reinforcement Learning based Recommender Systems,"Wang, Siyu and Chen, Xiaocong and Yao, Lina",inproceedings,10.1145/3627673.3679674,
10.1145/3627673.3679689,10.1145/3627673.3679689,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","feature enhancement, item frequency, sequence uniformity, sequential recommendation",10,1483–1492,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Representation learning in sequential recommendation is critical for accurately modeling user interaction patterns and improving recommendation precision. However, existing approaches predominantly emphasize item-to-item transitions, often neglecting the time intervals between interactions, which are closely related to behavior pattern changes. Additionally, broader interaction attributes, such as item frequency, are frequently overlooked. We found that both sequences with more uniform time intervals and items with higher frequency yield better prediction performance. Conversely, non-uniform sequences exacerbate user interest drift and less-frequent items are difficult to model due to sparse sampling, presenting unique challenges inadequately addressed by current methods. In this paper, we propose UniRec, a novel bidirectional enhancement sequential recommendation method. UniRec leverages sequence uniformity and item frequency to enhance performance, particularly improving the representation of non-uniform sequences and less-frequent items. These two branches mutually reinforce each other, driving comprehensive performance optimization in complex sequential recommendation scenarios. Additionally, we present a multidimensional time module to further enhance adaptability. To the best of our knowledge, UniRec is the first method to utilize the characteristics of uniformity and frequency for feature augmentation. Comparing with eleven advanced models across four datasets, we demonstrate that UniRec outperforms SOTA models significantly. The code is available at https://github.com/Linxi000/UniRec.",10.1145/3627673.3679689,https://doi.org/10.1145/3627673.3679689,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,UniRec: A Dual Enhancement of Uniformity and Frequency in Sequential Recommendations,"Liu, Yang and Wang, Yitong and Feng, Chenyue",inproceedings,10.1145/3627673.3679689,
10.1145/3627673.3679756,10.1145/3627673.3679756,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","classifier-free guidance, diffusion model, schrodinger bridge, sequential recommendation",11,2618–2628,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Sequential recommendation has attracted increasing attention due to its ability to accurately capture the dynamic changes in user interests. We have noticed that generative models, especially diffusion models, which have achieved significant results in fields like image and audio, hold considerable promise in the field of sequential recommendation. However, existing sequential recommendation methods based on diffusion models are constrained by a prior distribution limited to Gaussian distribution, hindering the possibility of introducing user-specific information for each recommendation and leading to information loss. To address these issues, we introduce the Schr\""{o}dinger Bridge into diffusion-based sequential recommendation models, creating the SdifRec model. This allows us to replace the Gaussian prior of the diffusion model with the user's current state, directly modeling the process from a user's current state to the target recommendation. Additionally, to better utilize collaborative information in recommendations, we propose an extended version of SdifRec called con-SdifRec, which utilizes user clustering information as a guiding condition to further enhance the posterior distribution. Finally, extensive experiments on multiple public benchmark datasets have demonstrated the effectiveness of SdifRec and con-SdifRec through comparison with several state-of-the-art methods. Further in-depth analysis has validated their efficiency and robustness.",10.1145/3627673.3679756,https://doi.org/10.1145/3627673.3679756,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,"Bridging User Dynamics: Transforming Sequential Recommendations with Schr\""{o}dinger Bridge and Diffusion Models","Xie, Wenjia and Zhou, Rui and Wang, Hao and Shen, Tingjia and Chen, Enhong",inproceedings,10.1145/3627673.3679756,
10.1145/3627673.3679760,10.1145/3627673.3679760,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","inductive learning, knowledge tracing, online education",11,632–642,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Knowledge Tracing (KT) aims to determine whether students will respond correctly to the next question, which is a crucial task in intelligent tutoring systems (ITS). In educational KT scenarios, transductive ID-based methods often face severe data sparsity and cold start problems, where interactions between individual students and questions are sparse, and new questions and concepts consistently arrive in the database. In addition, existing KT models only implicitly consider the correlation between concepts and questions, lacking direct modeling of the more complex relationships in the heterogeneous graph of concepts and questions. In this paper, we propose a &lt;u&gt;S&lt;/u&gt;tructure-aware &lt;u&gt;IN&lt;/u&gt;ductive &lt;u&gt;K&lt;/u&gt;nowledge &lt;u&gt;T&lt;/u&gt;racing model with large language model (dubbed SINKT), which, for the first time, introduces large language models (LLMs) and realizes inductive knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural relationships between concepts and constructs a hetero- geneous graph for concepts and questions. Secondly, by encoding concepts and questions with LLMs, SINKT incorporates semantic information to aid prediction. Finally, SINKT predicts the student's response to the target question by interacting with the student's knowledge state and the question representation. Experiments on four real-world datasets demonstrate that SINKT achieves state-of-the-art performance among 12 existing transductive KT models. Additionally, we explore the performance of SINKT on the inductive KT task and provide insights into various modules.",10.1145/3627673.3679760,https://doi.org/10.1145/3627673.3679760,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model,"Fu, Lingyue and Guan, Hao and Du, Kounianhua and Lin, Jianghao and Xia, Wei and Zhang, Weinan and Tang, Ruiming and Wang, Yasheng and Yu, Yong",inproceedings,10.1145/3627673.3679760,
10.1145/3627673.3679803,10.1145/3627673.3679803,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","causal intervention, counterfactual thinking, sequential recommendation",10,249–258,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Sequential recommendation has been receiving increasing attention from researchers. Existing sequential recommendation models leverage deep learning models to capture sequential features. However, these methods ignore confounders in the recommendation process, which can lead the model to learn incorrect correlations and fail to accurately capture users' true preferences. Moreover, these methods rely on extensive interaction sequences, but sequential data often suffers from sparsity issues. To address these limitations, this paper proposes a &lt;u&gt; P &lt;/u&gt;reference-&lt;u&gt; a &lt;/u&gt;ware &lt;u&gt; C &lt;/u&gt;ausal &lt;u&gt; I &lt;/u&gt;ntervention and Counter&lt;u&gt; f &lt;/u&gt;a&lt;u&gt; c &lt;/u&gt;tual Data Augmentation ( Pacific ) framework to enhance sequential recommendation. Initially, we model the causal graph of sequential recommendation and categorize user preferences into global long-term preferences, local long-term preferences, and short-term preferences. Then, we introduce the front-door criterion to eliminate the interference of confounders and design different self-attention mechanisms to estimate the causal effects, aiming to capture users' true preferences. In addition, based on counterfactual thinking, we design a counterfactual data augmentation module to generate enriched sequences. Experimental results on four real-world datasets demonstrate the superiority of our proposed approach over state-of-the-art sequential recommendation methods.",10.1145/3627673.3679803,https://doi.org/10.1145/3627673.3679803,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,PACIFIC: Enhancing Sequential Recommendation via Preference-aware Causal Intervention and Counterfactual Data Augmentation,"Chen, Jinpeng and Guan, Huachen and Li, Huan and Zhang, Fan and Huang, Liwei and Pang, Guangyao and Jin, Xiongnan",inproceedings,10.1145/3627673.3679803,
10.1145/3627673.3679818,10.1145/3627673.3679818,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","collaborative filtering, federated learning, importance sampling, variational autoencoder",10,3176–3185,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Federated recommender systems are used to address privacy issues in recommendations. Among them, FedVAE extends the representative non-linear recommendation method MultVAE. However, the bottleneck of FedVAE lies in its communication load during training, as the parameter volume of its first and last layers is correlated with the number of items. This leads to significant communication cost during the model's transmission phases (distribution and upload), making FedVAE's implementation extremely challenging. To address these challenges, we propose an Efficient Federated Variational AutoEncoder for collaborative filtering, EFVAE, which core is the Federated Collaborative Importance Sampling (FCIS) method. FCIS reduces communication costs through a client-to-server collaborative sampling mechanism and provides satisfactory recommendation performance through dynamic multi-stage approximation of the decoding distribution. Extensive experiments and analyses on real-world datasets confirm that EFVAE significantly reduces communication costs by up to 94.51% while maintaining the recommendation performance. Moreover, its recommendation performance is better on sparse datasets, with improvements reaching up to 13.79%.",10.1145/3627673.3679818,https://doi.org/10.1145/3627673.3679818,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,EFVAE: Efficient Federated Variational Autoencoder for Collaborative Filtering,"Zhang, Lu and Rong, Qian and Ding, Xuanang and Li, Guohui and Yuan, Ling",inproceedings,10.1145/3627673.3679818,
10.1145/3627673.3679913,10.1145/3627673.3679913,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","contrastive learning, llm, recommender system",5,4153–4157,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"In real-world applications, users express different behaviors when they interact with different items, including implicit click/like interactions, and explicit comments/reviews interactions. Nevertheless, almost all recommender works are focused on how to describe user preferences by the implicit click/like interactions, to find the synergy of people. For the content-based explicit comments/reviews interactions, some works attempt to utilize them to mine the semantic knowledge to enhance recommender models. However, they still neglect the following two points: (1) The content semantic is a universal world knowledge; how do we extract the multi-aspect semantic information to empower different domains? (2) The user/item ID feature is a fundamental element for recommender models; how do we align the ID and content semantic feature space? In this paper, we propose a 'plugin' semantic knowledge transferring method LoID, which includes two major components: (1) LoRA-based large language model pretraining to extract multi-aspect semantic information; (2) ID-based contrastive objective to align their feature spaces. We conduct extensive experiments with SOTA baselines to demonstrate superiority of our method LoID.",10.1145/3627673.3679913,https://doi.org/10.1145/3627673.3679913,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,Enhancing Content-based Recommendation via Large Language Model,"Xu, Wentao and Xie, Qianqian and Yang, Shuo and Cao, Jiangxia and Pang, Shuchao",inproceedings,10.1145/3627673.3679913,
10.1145/3627673.3679920,10.1145/3627673.3679920,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","loss functions, sequential recommendation, transitivity",5,3704–3708,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"A choice of optimization objective is immensely pivotal in the design of a recommender system as it affects the general modeling process of a user's intent from previous interactions. Existing approaches mainly adhere to three categories of loss functions: pairwise, pointwise, and setwise loss functions. Despite their effectiveness, a critical and common drawback of such objectives is viewing the next observed item as a unique positive while considering all remaining items equally negative. Such a binary label assignment is generally limited to assuring a higher recommendation score of the positive item, neglecting potential structures induced by varying preferences between other unobserved items. To alleviate this issue, we propose a novel method that extends original objectives to explicitly leverage the different levels of preferences as relative orders between their scores. Finally, we demonstrate the superior performance of our method compared to baseline objectives.",10.1145/3627673.3679920,https://doi.org/10.1145/3627673.3679920,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,Exploiting Preferences in Loss Functions for Sequential Recommendation via Weak Transitivity,"Chung, Hyunsoo and Kim, Jungtaek and Jo, Hyungeun and Choi, Hyungwon",inproceedings,10.1145/3627673.3679920,
10.1145/3627673.3679943,10.1145/3627673.3679943,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","implicit feedback, item recommendation, negative item sampling",5,4066–4070,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"In recommendation systems, there has been a growth in the number of recommendable items (# of movies, music, products). When the set of recommendable items is large, training and evaluation of item recommendation models becomes computationally expensive. To lower this cost, it has become common to sample negative items. However, the recommendation quality can suffer from biases introduced by traditional negative sampling mechanisms.In this work, we demonstrate the benefits from correcting the bias introduced by sampling of negatives. We first provide sampled batch version of the well-studied WARP and LambdaRank methods. Then, we present how these methods can benefit from improved ranking estimates. Finally, we evaluate the recommendation quality as a result of correcting rank estimates and demonstrate that WARP and LambdaRank can be learned efficiently with negative sampling and our proposed correction technique.",10.1145/3627673.3679943,https://doi.org/10.1145/3627673.3679943,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,Improved Estimation of Ranks for Learning Item Recommenders with Negative Sampling,"Subbiah, Anushya and Rendle, Steffen and Aggarwal, Vikram",inproceedings,10.1145/3627673.3679943,
10.1145/3627673.3679978,10.1145/3627673.3679978,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","long-tail recommendation, post-training, recommender systems",5,3857–3861,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Item popularity in real-world data follows a long-tail distribution, where a few items attract most of the attention, while the majority receive much less. This disparity results in high-quality embeddings for popular (head) items, but lower-quality embeddings for unpopular (tail) items, leading to less accurate recommendations for the latter. Our observations confirm that embeddings of tail items often exhibit (1) magnitudes (i.e., norms) that are less reflective of actual popularity and (2) directions that are less effective in capturing user preferences, compared to those of head items.To address this issue, we propose EDGE, a post-training embedding enhancement method for long-tail recommendations. EDGE employs two key strategies: (1) refining embedding magnitudes to better reflect item popularity and (2) adjusting embedding directions by leveraging knowledge from head items. Importantly, EDGE is model-agnostic and can be applied to embeddings learned from any trained recommender system. Experimental results show that EDGE significantly improves tail item recommendation performance and overall system performance, achieving up to an improvement of 211.23% in NDCG@20 over the state-of-the-art method. Our code and datasets are available at https://github.com/geon0325/EDGE.",10.1145/3627673.3679978,https://doi.org/10.1145/3627673.3679978,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,Post-Training Embedding Enhancement for Long-Tail Recommendation,"Lee, Geon and Kim, Kyungho and Shin, Kijung",inproceedings,10.1145/3627673.3679978,
10.1145/3627673.3679986,10.1145/3627673.3679986,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","cross-entropy loss, negative sampling, sequential recommendation",5,3772–3776,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Scalability is a major challenge in modern recommender systems. In sequential recommendations, full Cross-Entropy (CE) loss achieves state-of-the-art recommendation quality but consumes excessive GPU memory with large item catalogs, limiting its practicality. Using a GPU-efficient locality-sensitive hashing-like algorithm for approximating large tensor of logits, this paper introduces a novel RECE (REduced Cross-Entropy) loss. RECE significantly reduces memory consumption while allowing one to enjoy the state-of-the-art performance of full CE loss. Experimental results on various datasets show that RECE cuts training peak memory usage by up to 12 times compared to existing methods while retaining or exceeding performance metrics of CE loss. The approach also opens up new possibilities for large-scale applications in other domains.",10.1145/3627673.3679986,https://doi.org/10.1145/3627673.3679986,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,RECE: Reduced Cross-Entropy Loss for Large-Catalogue Sequential Recommenders,"Gusak, Danil and Mezentsev, Gleb and Oseledets, Ivan and Frolov, Evgeny",inproceedings,10.1145/3627673.3679986,
10.1145/3627673.3680034,10.1145/3627673.3680034,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","hash-table, key-value storage, recommender system",8,5078–5085,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"In industrial recommendation systems on websites and apps, it is essential to recall and predict top-n results relevant to user interests from a content pool of billions within milliseconds. To cope with continuous data growth and improve real-time recommendation performance, we have designed and implemented a high-performance batch query architecture for real-time recommendation systems. Our contributions include optimizing hash structures with a cacheline-aware probing method to enhance coalesced hashing, as well as the implementation of a hybrid storage key-value service built upon it. Our experiments indicate this approach significantly surpasses conventional hash tables in batch query throughput, achieving up to 90% of the query throughput of random memory access when incorporating parallel optimization. The support for NVMe, integrating two-tier storage for hot and cold data, notably reduces resource consumption. Additionally, the system facilitates dynamic updates, automated sharding of attributes and feature embedding tables, and introduces innovative protocols for consistency in batch queries, thereby enhancing the effectiveness of real-time incremental learning updates. This architecture has been deployed and in use in the bilibili recommendation system for over a year, a video content community with hundreds of millions of users, supporting 10x increase in model computation with minimal resource growth, improving outcomes while preserving the system's real-time performance.",10.1145/3627673.3680034,https://doi.org/10.1145/3627673.3680034,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,An Enhanced Batch Query Architecture in Real-time Recommendation,"Zhang, Qiang and Teng, Zhipeng and Wu, Disheng and Wang, Jiayin",inproceedings,10.1145/3627673.3680034,
10.1145/3627673.3680048,10.1145/3627673.3680048,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","ctr prediction, large language models, multimodal embedding, recommender systems, semantic embedding",9,4819–4827,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Recent studies highlight the potential of large language models (LLMs) to enhance content integration in recommender systems by leveraging their semantic understanding capabilities. However, directly incorporating LLMs into an online inference pipeline significantly increases computation costs for large-scale deployment, posing a practical challenge in balancing their benefits and costs. In this work, we propose the EASE framework, which enriches and aligns semantic feature embeddings using LLMs during the training phase while establishing a lightweight inference pipeline that does not directly involve LLMs. Specifically, we train a semantic adapter to align item features with LLMs and simultaneously enrich semantic embeddings through reconstruction tasks from LLMs. During inference, we retain only the item feature encoder and lightweight semantic adapter, thereby eliminating the computation overhead of resource-intensive LLMs. Our EASE framework is flexible, supporting not only text and visual features but also other pre-processed embedding features. Extensive experiments on both public and industrial datasets demonstrate that enriching semantic feature embeddings with our EASE framework yields consistent improvements in downstream click-through rate prediction tasks.",10.1145/3627673.3680048,https://doi.org/10.1145/3627673.3680048,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,EASE: Learning Lightweight Semantic Feature Adapters from Large Language Models for CTR Prediction,"Qiu, Zexuan and Zhu, Jieming and Chen, Yankai and Cai, Guohao and Liu, Weiwen and Dong, Zhenhua and King, Irwin",inproceedings,10.1145/3627673.3680048,
10.1145/3627673.3680061,10.1145/3627673.3680061,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","exploration and exploitation, graph-based recommender systems, online advertising",8,4579–4586,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Graph-based Recommendation Systems (GRSs) have gained prominence for their ability to enhance the accuracy and effectiveness of recommender systems by exploiting structural relationships in user-item interaction data. Despite their advanced capabilities, we find GRSs are susceptible to feedback-loop phenomena that disproportionately diminish the visibility of new and long-tail items, leading to a homogenization of recommendations and the potential emergence of echo chambers. To mitigate this feedback-loop issue, exploration and exploitation (E&amp;E) strategies have been extensively researched. However, conventional E&amp;E methods rest on the assumption that recommendations are independent and identically distributed-an assumption that is not valid for GRSs. To forge an effective E&amp;E approach tailored to GRSs, we introduce a novel framework, the &lt;u&gt;GRAD&lt;/u&gt;ient-informed &lt;u&gt;E&lt;/u&gt;xploration and Exploitation (GRADE), designed to adaptively seek out underrepresented or new items with promising rewards. Our method evaluates the potential benefit of exploring an item by assessing the change in the system's empirical risk error pre- and post-exposure. For practical implementation, we approximate this measure using the gradients of potential edges and model parameters, alongside their associated uncertainties. We then orchestrate the balance between exploration and exploitation utilizing Thompson sampling and the Upper Confidence Bound (UCB) strategy. Empirical tests on datasets from two industrial environments demonstrate that GRADE consistently outperforms existing state-of-the-art methods. Additionally, our approach has been successfully integrated into actual industrial systems.",10.1145/3627673.3680061,https://doi.org/10.1145/3627673.3680061,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,To Explore or Exploit? A Gradient-informed Framework to Address the Feedback Loop for Graph based Recommendation,"Huangfu, Zhigang and Hu, Binbin and Wu, Zhengwei and Han, Fengyu and Zhang, Gong-Duo and Zhang, Gong-Duo and Gu, Lihong and Gu, Lihong and Zhang, Zhiqiang and Zhang, Zhiqiang",inproceedings,10.1145/3627673.3680061,
10.1145/3627673.3680099,10.1145/3627673.3680099,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","fairness constraint, recommender system, self-adaptive",8,4726–4733,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"Achieving fairness among different individuals or groups is an essential task for industrial recommender systems. Due to the group's personalized selection tendencies and the non-uniform population distributions, existing industrial recommenders tend to make unfair predictions towards the preferences of minority groups. To alleviate this unfairness, we propose a model-agnostic self-adaptive fairness constraint framework (SaFair) based on the posterior preferences of different groups. We construct group-level and individual-level fairness constraints. The former measures consistency between group-level posterior preferences and predicted interests, and the latter relies on the degree of consistency in interests between a user and their associated group to perform self-adaptive constraints. In particular, to balance effectiveness and fairness, we utilize uncertainty estimation to adjust the intensity of constraints according to the model's learning status called self-adaptive constraints. Extensive offline experiments and online A/B Testing are conducted and the results validate the superiority of our proposed method over the baselines. SaFair has been successfully deployed in Kuaishou, one of China's most popular short-video streaming platforms with hundreds of millions of active users.",10.1145/3627673.3680099,https://doi.org/10.1145/3627673.3680099,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,A Self-Adaptive Fairness Constraint Framework for Industrial Recommender System,"Liu, Zhiqiang and Xu, Xiaoxiao and Yu, Jiaqi and Xu, Han and Hu, Lantao and Li, Han and Gai, Kun",inproceedings,10.1145/3627673.3680099,
10.1145/3627673.3680270,10.1145/3627673.3680270,CIKM.bib,1,['CIKM.bib'],8,CIKM '24,"Boise, ID, USA","content understanding, personalization, recommendation, representation learning, user understanding",4,5459–5462,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"In the realm of personalized recommendation systems, accurately capturing user preferences and item characteristics is important for delivering relevant and satisfying recommendations. This study introduces innovative approaches using Large Language Models (LLMs) to generate detailed textual descriptions that enhance both user and item representations. We propose a dual strategy: for user representation, we employ supervised fine-tuning coupled with Retrieval-Augmented Generation (RAG) to keep the model current with dynamic user preferences; for item representation, we leverage the extensive knowledge base of LLMs to enrich item descriptions and infer traits from user interactions. These methods promise a deeper, more nuanced understanding of both users and items, potentially leading to superior recommendation accuracy. We adopt a rigorous evaluation methodology, ensuring the reliability of our results and the effectiveness of our proposed system. This paper discusses these methodologies, presents our preliminary findings, and highlights the potential of text-augmented profiles in advancing recommendation systems.",10.1145/3627673.3680270,https://doi.org/10.1145/3627673.3680270,"New York, NY, USA",Association for Computing Machinery,9798400704369,2024,Towards Advancing Text-Based User and Item Representation in Personalized Recommendation,"Lyu, Hanjia",inproceedings,10.1145/3627673.3680270,
10.1145/3637528.3671474,10.1145/3637528.3671474,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","ethical and societal considerations, gans, generative models, llms, multimodal, recommender systems, vaes, vllms",11,6448–6458,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Traditional recommender systems typically use user-item rating histories as their main data source. However, deep generative models now have the capability to model and sample from complex data distributions, including user-item interactions, text, images, and videos, enabling novel recommendation tasks. This comprehensive, multidisciplinary survey connects key advancements in RS using Generative Models (Gen-RecSys), covering: interaction-driven generative models; the use of large language models (LLM) and textual data for natural language recommendation; and the integration of multimodal models for generating and processing images/videos in RS. Our work highlights necessary paradigms for evaluating the impact and harm of Gen-RecSys and identifies open challenges. This survey accompanies a ""tutorial"" presented at ACM KDD'24, with supporting materials provided at: https://encr.pw/vDhLq.",10.1145/3637528.3671474,https://doi.org/10.1145/3637528.3671474,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys),"Deldjoo, Yashar and He, Zhankui and McAuley, Julian and Korikov, Anton and Sanner, Scott and Ramisa, Arnau and Vidal, Ren\'{e} and Sathiamoorthy, Maheswaran and Kasirzadeh, Atoosa and Milano, Silvia",inproceedings,10.1145/3637528.3671474,
10.1145/3637528.3671516,10.1145/3637528.3671516,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","online marketing, rankability, revenue uplift modeling",12,5093–5104,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Uplift modeling has been widely employed in online marketing by predicting the response difference between the treatment and control groups, so as to identify the sensitive individuals toward interventions like coupons or discounts. Compared with traditional conversion uplift modeling,revenue uplift modeling exhibits higher potential due to its direct connection with the corporate income. However, previous works can hardly handle the continuous long-tail response distribution in revenue uplift modeling. Moreover, they have neglected to optimize the uplift ranking among different individuals, which is actually the core of uplift modeling. To address such issues, in this paper, we first utilize the zero-inflated lognormal (ZILN) loss to regress the responses and customize the corresponding modeling network, which can be adapted to different existing uplift models. Then, we study the ranking-related uplift modeling error from the theoretical perspective and propose two tighter error bounds as the additional loss terms to the conventional response regression loss. Finally, we directly model the uplift ranking error for the entire population with a listwise uplift ranking loss. The experiment results on offline public and industrial datasets validate the effectiveness of our method for revenue uplift modeling. Furthermore, we conduct large-scale experiments on a prominent online fintech marketing platform, Tencent FiT, which further demonstrates the superiority of our method in real-world applications.",10.1145/3637528.3671516,https://doi.org/10.1145/3637528.3671516,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Rankability-enhanced Revenue Uplift Modeling Framework for Online Marketing,"He, Bowei and Weng, Yunpeng and Tang, Xing and Cui, Ziqiang and Sun, Zexu and Chen, Liang and He, Xiuqiang and Ma, Chen",inproceedings,10.1145/3637528.3671516,
10.1145/3637528.3671523,10.1145/3637528.3671523,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","e-commerce, multi-task learning, ranking system, residual learning",12,4974–4985,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Modern e-commerce platforms rely heavily on modeling diverse user feedback to provide personalized services. Consequently, multi-task learning has become an integral part of their ranking systems. However, existing multi-task learning methods encounter two main challenges: some lack explicit modeling of task relationships, resulting in inferior performance, while others have limited applicability due to being computationally intensive, having scalability issues, or relying on strong assumptions. To address these limitations and better fit our real-world scenario, pre-rank in Shopee Search, we introduce in this paper ResFlow, a lightweight multi-task learning framework that enables efficient cross-task information sharing via residual connections between corresponding layers of task networks. Extensive experiments on datasets from various scenarios and modalities demonstrate its superior performance and adaptability over state-of-the-art methods. The online A/B tests in Shopee Search showcase its practical value in large-scale industrial applications, evidenced by a 1.29% increase in OPU (order-per-user) without additional system latency. ResFlow is now fully deployed in the pre-rank module of Shopee Search. To facilitate efficient online deployment, we propose a novel offline metric Weighted Recall@K, which aligns well with our online metric OPU, addressing the longstanding online-offline metric misalignment issue. Besides, we propose to fuse scores from the multiple tasks additively when ranking items, which outperforms traditional multiplicative fusion.",10.1145/3637528.3671523,https://doi.org/10.1145/3637528.3671523,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Residual Multi-Task Learner for Applied Ranking,"Fu, Cong and Wang, Kun and Wu, Jiahua and Chen, Yizhou and Huzhang, Guangda and Ni, Yabo and Zeng, Anxiang and Zhou, Zhiming",inproceedings,10.1145/3637528.3671523,
10.1145/3637528.3671652,10.1145/3637528.3671652,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","auxiliary information, cancer drug response prediction, clinical deployment, personalized treatment recommendation, survival prediction, transformers",12,5138–5149,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Cancer remains a global challenge due to its growing clinical and economic burden. Its uniquely personal manifestation, which makes treatment difficult, has fuelled the quest for personalized treatment strategies. Thus, genomic profiling is increasingly becoming part of clinical diagnostic panels. Effective use of such panels requires accurate drug response prediction (DRP) models, which are challenging to build due to limited labelled patient data. Previous methods to address this problem have used various forms of transfer learning. However, they do not explicitly model the variable length sequential structure of the list of mutations in such diagnostic panels. Further, they do not utilize auxiliary information (like patient survival) for model training. We address these limitations through a novel transformer-based method, which surpasses the performance of state-of-the-art DRP models on benchmark data. Code for our method is available at https://github.com/CDAL-SOC/PREDICT-AI.We also present the design of a treatment recommendation system (TRS), which is currently deployed at the National University Hospital, Singapore and is being evaluated in a clinical trial. We discuss why the recommended drugs and their predicted scores alone, obtained from DRP models, are insufficient for treatment planning. Treatment planning for complex cancer cases, in the face of limited clinical validation, requires assessment of many other factors, including several indirect sources of evidence on drug efficacy. We discuss key lessons learnt on model validation and use of indirect supporting evidence to build clinicians' trust and aid their decision making.",10.1145/3637528.3671652,https://doi.org/10.1145/3637528.3671652,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Personalised Drug Identifier for Cancer Treatment with Transformers using Auxiliary Information,"Jayagopal, Aishwarya and Xue, Hansheng and He, Ziyang and Walsh, Robert J. and Hariprasannan, Krishna Kumar and Tan, David Shao Peng and Tan, Tuan Zea and Pitt, Jason J. and Jeyasekharan, Anand D. and Rajan, Vaibhav",inproceedings,10.1145/3637528.3671652,
10.1145/3637528.3671661,10.1145/3637528.3671661,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","adversarial learning, graph contrastive learning, recommender robustness",12,2854–2865,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"In recent years, graph contrastive learning (GCL) has received increasing attention in recommender systems due to its effectiveness in reducing bias caused by data sparsity. However, most existing GCL models rely on heuristic approaches and usually assume entity independence when constructing contrastive views. We argue that these methods struggle to strike a balance between semantic invariance and view hardness across the dynamic training process, both of which are critical factors in graph contrastive learning.To address the above issues, we propose a novel GCL-based recommendation framework RGCL, which effectively maintains the semantic invariance of contrastive pairs and dynamically adapts as the model capability evolves through the training process. Specifically, RGCL first introduces decision boundary-aware adversarial perturbations to constrain the exploration space of contrastive augmented views, avoiding the decrease of task-specific information. Furthermore, to incorporate global user-user and item-item collaboration relationships for guiding on the generation of hard contrastive views, we propose an adversarial-contrastive learning objective to construct a relation-aware view-generator. Besides, considering that unsupervised GCL could potentially narrower margins between data points and the decision boundary, resulting in decreased model robustness, we introduce the adversarial examples based on maximum perturbations to achieve margin maximization. We also provide theoretical analyses on the effectiveness of our designs. Through extensive experiments on five public datasets, we demonstrate the superiority of RGCL compared against twelve baseline models.",10.1145/3637528.3671661,https://doi.org/10.1145/3637528.3671661,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Towards Robust Recommendation via Decision Boundary-aware Graph Contrastive Learning,"Tang, Jiakai and Dai, Sunhao and Sun, Zexu and Chen, Xu and Xu, Jun and Yu, Wenhui and Hu, Lantao and Jiang, Peng and Li, Han",inproceedings,10.1145/3637528.3671661,
10.1145/3637528.3671698,10.1145/3637528.3671698,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","cross-market recommendation, pre-training, self-attention, sequential recommendation",10,2970–2979,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Cross-market recommendation (CMR) involves selling the same set of items across multiple nations or regions within a transfer learning framework. However, CMR's distinctive characteristics, including limited data sharing due to privacy policies, absence of user overlap, and a shared item set between markets present challenges for traditional recommendation methods. Moreover, CMR experiences market shifts, leading to differences in item popularity and user preferences among different markets. This study focuses on cross-market sequential recommendation (CMSR) and proposes the Cross-market Attention Transferring with Sequential Recommendation (CAT-SR) framework to address these challenges and market shifts. CAT-SR incorporates a pre-training strategy emphasizing item-item correlation, selective self-attention transferring for effective transfer learning, and query and key adapters for market-specific user preferences. Experimental results on real-world cross-market datasets demonstrate the superiority of CAT-SR, and ablation studies validate the benefits of its components across different geographical continents. CAT-SR offers a robust and adaptable solution for cross-market sequential recommendation. The code is available at https://github.com/ChenMetanoia/CATSR-KDD/.",10.1145/3637528.3671698,https://doi.org/10.1145/3637528.3671698,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Pre-Training with Transferable Attention for Addressing Market Shifts in Cross-Market Sequential Recommendation,"Wang, Chen and Fan, Ziwei and Yang, Liangwei and Yang, Mingdai and Liu, Xiaolong and Liu, Zhiwei and Yu, Philip",inproceedings,10.1145/3637528.3671698,
10.1145/3637528.3671781,10.1145/3637528.3671781,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","adversarial learning, explainable recommendation, natural language explanations",10,4203–4212,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Natural language explainable recommendation has become a promising direction to facilitate more efficient and informed user decisions. Previous models mostly focus on how to enhance the explanation accuracy. However, the robustness problem has been largely ignored, which requires the explanations generated for similar user-item pairs should not be too much different. Different from traditional classification problems, improving the robustness of natural languages has two unique characteristics: (1) Different token importances, that is, different tokens play various roles in representing the complete sentence, and the robustness requirements for predicting them should also be different. (2) Continuous token semantics, that is, the similarity of the output should be judged based on semantics, and the sequences without any token-level overlap may also be highly similar. Based on these characteristics, we formulate and solve a novel problem in the recommendation domain, that is, robust natural language explainable recommendation. To the best of our knowledge, it is the first time in this field. Specifically, we base our modeling on adversarial robust optimization and design four types of heuristic methods to modify the adversarial outputs with weighted token probabilities and synonym replacements. Furthermore, to consider the mutual influence between the above characteristics, we regard language generation as a decision-making problem and design a dual-policy reinforcement learning framework to improve the robustness of the generated languages. We conduct extensive experiments to demonstrate the effectiveness of our framework.",10.1145/3637528.3671781,https://doi.org/10.1145/3637528.3671781,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Natural Language Explainable Recommendation with Robustness Enhancement,"Zhang, Jingsen and Tang, Jiakai and Chen, Xu and Yu, Wenhui and Hu, Lantao and Jiang, Peng and Li, Han",inproceedings,10.1145/3637528.3671781,
10.1145/3637528.3671795,10.1145/3637528.3671795,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","contrastive learning, poisoning attacks, recommender systems, self-supervised learning",12,3311–3322,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Contrastive learning (CL) has recently gained prominence in the domain of recommender systems due to its great ability to enhance recommendation accuracy and improve model robustness. Despite its advantages, this paper identifies a vulnerability of CL-based recommender systems that they are more susceptible to poisoning attacks aiming to promote individual items. Our analysis indicates that this vulnerability is attributed to the uniform spread of representations caused by the InfoNCE loss. Furthermore, theoretical and empirical evidence shows that optimizing this loss favors smooth spectral values of representations. This finding suggests that attackers could facilitate this optimization process of CL by encouraging a more uniform distribution of spectral values, thereby enhancing the degree of representation dispersion. With these insights, we attempt to reveal a potential poisoning attack against CL-based recommender systems, which encompasses a dual-objective framework: one that induces a smoother spectral value distribution to amplify the InfoNCE loss's inherent dispersion effect, named dispersion promotion; and the other that directly elevates the visibility of target items, named rank promotion. We validate the threats of our attack model through extensive experimentation on four datasets. By shedding light on these vulnerabilities, our goal is to advance the development of more robust CL-based recommender systems. The code is available at https://github.com/CoderWZW/ARLib.",10.1145/3637528.3671795,https://doi.org/10.1145/3637528.3671795,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Unveiling Vulnerabilities of Contrastive Recommender Systems to Poisoning Attacks,"Wang, Zongwei and Yu, Junliang and Gao, Min and Yin, Hongzhi and Cui, Bin and Sadiq, Shazia",inproceedings,10.1145/3637528.3671795,
10.1145/3637528.3671802,10.1145/3637528.3671802,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","large language models, model explainability, recommender systems",12,1530–1541,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Recommender systems are widely used in online services, with embedding-based models being particularly popular due to their expressiveness in representing complex signals. However, these models often function as a black box, making them less transparent and reliable for both users and developers. Recently, large language models (LLMs) have demonstrated remarkable intelligence in understanding, reasoning, and instruction following. This paper presents the initial exploration of using LLMs as surrogate models to explaining black-box recommender models. The primary concept involves training LLMs to comprehend and emulate the behavior of target recommender models. By leveraging LLMs' own extensive world knowledge and multi-step reasoning abilities, these aligned LLMs can serve as advanced surrogates, capable of reasoning about observations. Moreover, employing natural language as an interface allows for the creation of customizable explanations that can be adapted to individual user preferences. To facilitate an effective alignment, we introduce three methods: behavior alignment, intention alignment, and hybrid alignment. Behavior alignment operates in the language space, representing user preferences and item information as text to mimic the target model's behavior; intention alignment works in the latent space of the recommendation model, using user and item representations to understand the model's behavior; hybrid alignment combines both language and latent spaces. Comprehensive experiments conducted on three public datasets show that our approach yields promising results in understanding and mimicking target models, producing high-quality, high-fidelity, and distinct explanations. Our code is available at https://github.com/microsoft/RecAI.",10.1145/3637528.3671802,https://doi.org/10.1145/3637528.3671802,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,RecExplainer: Aligning Large Language Models for Explaining Recommendation Models,"Lei, Yuxuan and Lian, Jianxun and Yao, Jing and Huang, Xu and Lian, Defu and Xie, Xing",inproceedings,10.1145/3637528.3671802,
10.1145/3637528.3671824,10.1145/3637528.3671824,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","collaborative filtering, contrastive learning, popularity bias, re-weighting, supervised alignment",12,187–198,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Collaborative Filtering~(CF) typically suffers from the significant challenge of popularity bias due to the uneven distribution of items in real-world datasets. This bias leads to a significant accuracy gap between popular and unpopular items. It not only hinders accurate user preference understanding but also exacerbates the Matthew effect in recommendation systems. To alleviate popularity bias, existing efforts focus on emphasizing unpopular items or separating the correlation between item representations and their popularity. Despite the effectiveness, existing works still face two persistent challenges: (1) how to extract common supervision signals from popular items to improve the unpopular item representations, and (2) how to alleviate the representation separation caused by popularity bias. In this work, we conduct an empirical analysis of popularity bias and propose &lt;u&gt;P&lt;/u&gt;opularity-&lt;u&gt;A&lt;/u&gt;ware &lt;u&gt;A&lt;/u&gt;lignment and &lt;u&gt;C&lt;/u&gt;ontrast (PAAC) to address two challenges. Specifically, we use the common supervisory signals modeled in popular item representations and propose a novel popularity-aware supervised alignment module to learn unpopular item representations. Additionally, we suggest re-weighting the contrastive learning loss to mitigate the representation separation from a popularity-centric perspective. Finally, we validate the effectiveness and rationale of PAAC in mitigating popularity bias through extensive experiments on three real-world datasets. Our code is available at https://github.com/miaomiao-cai2/KDD2024-PAAC.",10.1145/3637528.3671824,https://doi.org/10.1145/3637528.3671824,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Popularity-Aware Alignment and Contrast for Mitigating Popularity Bias,"Cai, Miaomiao and Chen, Lei and Wang, Yifan and Bai, Haoyue and Sun, Peijie and Wu, Le and Zhang, Min and Wang, Meng",inproceedings,10.1145/3637528.3671824,
10.1145/3637528.3671837,10.1145/3637528.3671837,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","adversarial attacks, large language models, llm-empowered recommender systems, llms-based agent, recommender systems",12,2284–2295,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.",10.1145/3637528.3671837,https://doi.org/10.1145/3637528.3671837,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent,"Ning, Liang-bo and Wang, Shijie and Fan, Wenqi and Li, Qing and Xu, Xin and Chen, Hao and Huang, Feiran",inproceedings,10.1145/3637528.3671837,
10.1145/3637528.3671901,10.1145/3637528.3671901,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","collaborative filtering, large language models, long-tail recommendation",11,3391–3401,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"The long-tail recommendation is a challenging task for traditional recommender systems, due to data sparsity and data imbalance issues. The recent development of large language models (LLMs) has shown their abilities in complex reasoning, which can help to deduce users' preferences based on very few previous interactions. However, since most LLM-based systems rely on items' semantic meaning as the sole evidence for reasoning, the collaborative information of user-item interactions is neglected, which can cause the LLM's reasoning to be misaligned with task-specific collaborative information of the dataset. To further align LLMs' reasoning to task-specific user-item interaction knowledge, we introduce collaborative retrieval-augmented LLMs, CoRAL, which directly incorporate collaborative evidence into the prompts. Based on the retrieved user-item interactions, the LLM can analyze shared and distinct preferences among users, and summarize the patterns indicating which types of users would be attracted by certain items. The retrieved collaborative evidence prompts the LLM to align its reasoning with the user-item interaction patterns in the dataset. However, since the capacity of the input prompt is limited, finding the minimally-sufficient collaborative information for recommendation tasks can be challenging. We propose to find the optimal interaction set through a sequential decision-making process and develop a retrieval policy learned through a reinforcement learning (RL) framework, CoRAL. Our experimental results show that CoRAL can significantly improve LLMs' reasoning abilities on specific recommendation tasks. Our analysis also reveals that CoRAL can more efficiently explore collaborative information through reinforcement learning.",10.1145/3637528.3671901,https://doi.org/10.1145/3637528.3671901,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation,"Wu, Junda and Chang, Cheng-Chun and Yu, Tong and He, Zhankui and Wang, Jianing and Hou, Yupeng and McAuley, Julian",inproceedings,10.1145/3637528.3671901,
10.1145/3637528.3671915,10.1145/3637528.3671915,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","bias, debias, noisy feedback, recommender systems",11,1576–1586,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Ratings of a user to most items in recommender systems are usually missing not at random (MNAR), largely because users are free to choose which items to rate. To achieve unbiased learning of the prediction model under MNAR data, three typical solutions have been proposed, including error-imputation-based (EIB), inverse-propensity-scoring (IPS), and doubly robust (DR) methods. However, these methods ignore an alternative form of bias caused by the inconsistency between the observed ratings and the users' true preferences, also known as noisy feedback or outcome measurement errors (OME), e.g., due to public opinion or low-quality data collection process. In this work, we study intersectional threats to the unbiased learning of the prediction model from data MNAR and OME in the collected data. First, we design OME-EIB, OME-IPS, and OME-DR estimators, which largely extend the existing estimators to combat OME in real-world recommendation scenarios. Next, we theoretically prove the unbiasedness and generalization bound of the proposed estimators. We further propose an alternate denoising training approach to achieve unbiased learning of the prediction model under MNAR data with OME. Extensive experiments are conducted on three real-world datasets and one semi-synthetic dataset to show the effectiveness of our proposed approaches. The code is available at https://github.com/haoxuanli-pku/KDD24-OME-DR.",10.1145/3637528.3671915,https://doi.org/10.1145/3637528.3671915,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Debiased Recommendation with Noisy Feedback,"Li, Haoxuan and Zheng, Chunyuan and Wang, Wenjie and Wang, Hao and Feng, Fuli and Zhou, Xiao-Hua",inproceedings,10.1145/3637528.3671915,
10.1145/3637528.3671958,10.1145/3637528.3671958,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","graph denoising, independent cascade, self-supervised learning, social recommender system",12,2806–2817,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Social Recommendation (SR) typically exploits neighborhood influence in the social network to enhance user preference modeling. However, users' intricate social behaviors may introduce noisy social connections for user modeling and harm the models' robustness. Existing solutions to alleviate social noise either filter out the noisy connections or generate new potential social connections. Due to the absence of labels, the former approaches may retain uncertain connections for user preference modeling while the latter methods may introduce additional social noise. Through data analysis, we discover that (1) social noise likely comes from the connected users with low preference similarity; and (2) Opinion Leaders (OLs) play a pivotal role in influence dissemination, surpassing high-similarity neighbors, regardless of their preference similarity with trusting peers. Guided by these observations, we propose a novel Self-Supervised Denoising approach through Independent Cascade Graph Augmentation, for more robust SR. Specifically, we employ the independent cascade diffusion model to generate an augmented graph view, which traverses the social graph and activates the edges in sequence to simulate the cascading influence spread. To steer the augmentation towards a denoised social graph, we (1) introduce a hierarchical contrastive loss to prioritize the activation of OLs first, followed by high-similarity neighbors, while weakening the low-similarity neighbors; and (2) integrate an information bottleneck based contrastive loss, aiming to minimize mutual information between original and augmented graphs yet preserve sufficient information for improved SR. Experiments conducted on two public datasets demonstrate that our model outperforms the state-of-the-art while also exhibiting higher robustness to different extents of social noise.",10.1145/3637528.3671958,https://doi.org/10.1145/3637528.3671958,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Self-Supervised Denoising through Independent Cascade Graph Augmentation for Robust Social Recommendation,"Sun, Youchen and Sun, Zhu and Du, Yingpeng and Zhang, Jie and Ong, Yew Soon",inproceedings,10.1145/3637528.3671958,
10.1145/3637528.3671966,10.1145/3637528.3671966,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","deep learning, heterogeneous graph, multi-source information, popularity prediction, social networks",12,3460–3471,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Predicting information diffusion is a fundamental task in online social networks (OSNs). Recent studies mainly focus on the popularity prediction of specific content but ignore the correlation between multiple pieces of information. The topic is often used to correlate such information and can correspond to multi-source information. The popularity of a topic relies not only on information diffusion time but also on users' followership. Current solutions concentrate on hard time partition, lacking versatility. Meanwhile, the hop-based sampling adopted in state-of-the-art (SOTA) methods encounters redundant user followership. Moreover, many SOTA methods are not designed with good modularity and lack evaluation for each functional module and enlightening discussion. This paper presents a novel extensible framework, coined as HIF, for effective popularity prediction in OSNs with four original contributions. First, HIF adopts a soft partition of users and time intervals to better learn users' behavioral preferences over time. Second, HIF utilizes weighted sampling to optimize the construction of heterogeneous graphs and reduce redundancy. Furthermore, HIF supports multi-task collaborative optimization to improve its learning capability. Finally, as an extensible framework, HIF provides generic module slots to combine different submodules (e.g., RNNs, Transformer encoders). Experiments show that HIF significantly improves performance and interpretability compared to SOTAs.",10.1145/3637528.3671966,https://doi.org/10.1145/3637528.3671966,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,A Deep Prediction Framework for Multi-Source Information via Heterogeneous GNN,"Wu, Zhen and Zhou, Jingya and Zhang, Jinghui and Liu, Ling and Huang, Chizhou",inproceedings,10.1145/3637528.3671966,
10.1145/3637528.3671976,10.1145/3637528.3671976,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","causal inference, conformal prediction, uncertainty quantification",12,397–408,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Personalized decision making requires the knowledge of potential outcomes under different treatments, and confidence intervals about the potential outcomes further enrich this decision-making process and improve its reliability in high-stakes scenarios. Predicting potential outcomes along with its uncertainty in a counterfactual world poses the foundamental challenge in causal inference. Existing methods that construct confidence intervals for counterfactuals either rely on the assumption of strong ignorability that completely ignores hidden confounders, or need access to un-identifiable lower and upper bounds that characterize the difference between observational and interventional distributions. In this paper, to overcome these limitations, we first propose a novel approach wTCP-DR based on transductive weighted conformal prediction, which provides confidence intervals for counterfactual outcomes with marginal converage guarantees, even under hidden confounding. With less restrictive assumptions, our approach requires access to a fraction of interventional data (from randomized controlled trials) to account for the covariate shift from observational distributoin to interventional distribution. Theoretical results explicitly demonstrate the conditions under which our algorithm is strictly advantageous to the naive method that only uses interventional data. Since transductive conformal prediction is notoriously costly, we propose wSCP-DR, a two-stage variant of wTCP-DR, based on split conformal prediction with same marginal coverage guarantees but at a significantly lower computational cost. After ensuring valid intervals on counterfactuals, it is straightforward to construct intervals for individual treatment effects (ITEs). We demonstrate our method across synthetic and real-world data, including recommendation systems, to verify the superiority of our methods compared against state-of-the-art baselines in terms of both coverage and efficiency. Our code can be found at https://github.com/rguo12/KDD24-Conformal.",10.1145/3637528.3671976,https://doi.org/10.1145/3637528.3671976,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Conformal Counterfactual Inference under Hidden Confounding,"Chen, Zonghao and Guo, Ruocheng and Ton, Jean-Francois and Liu, Yang",inproceedings,10.1145/3637528.3671976,
10.1145/3637528.3672041,10.1145/3637528.3672041,KDD.bib,1,['KDD.bib'],8,KDD '24,"Barcelona, Spain","hypergraph, multimedia popularity, retrieval augmentation",11,445–455,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"Accurately predicting the popularity of multimodal user-generated content (UGC) is fundamental for many real-world applications such as online advertising and recommendation. Existing approaches generally focus on limited contextual information within individual UGCs, yet overlook the potential benefit of exploiting meaningful knowledge in relevant UGCs. In this work, we propose RAGTrans, an aspect-aware retrieval-augmented multi-modal hypergraph transformer that retrieves pertinent knowledge from a multi-modal memory bank and enhances UGC representations via neighborhood knowledge aggregation on multi-model hypergraphs. In particular, we initially retrieve relevant multimedia instances from a large corpus of UGCs via the aspect information and construct a knowledge-enhanced hypergraph based on retrieved relevant instances. This allows capturing meaningful contextual information across the data. We then design a novel bootstrapping hypergraph transformer on multimodal hypergraphs to strengthen UGC representations across modalities via customizing a propagation algorithm to effectively diffuse information across nodes and edges. Additionally, we propose a user-aware attention-based fusion module to comprise the enriched UGC representations for popularity prediction. Extensive experiments on real-world social media datasets demonstrate that RAGTrans outperforms state-of-the-art popularity prediction models across settings.",10.1145/3637528.3672041,https://doi.org/10.1145/3637528.3672041,"New York, NY, USA",Association for Computing Machinery,9798400704901,2024,Retrieval-Augmented Hypergraph for Multimodal Social Media Popularity Prediction,"Cheng, Zhangtao and Zhang, Jienan and Xu, Xovee and Trajcevski, Goce and Zhong, Ting and Zhou, Fan",inproceedings,10.1145/3637528.3672041,
10.1145/3640457.3687108,10.1145/3640457.3687108,RecSys.bib,1,['RecSys.bib'],7,RecSys '24,"Bari, Italy","long-term optimization, multi-objective recommendation, multi-stakeholder recommendation, value-aware recommendation",3,1210–1212,Proceedings of the 18th ACM Conference on Recommender Systems,,10.1145/3640457.3687108,https://doi.org/10.1145/3640457.3687108,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,SURE 2024: Workshop on Strategic and Utility-aware REcommendation,"Abdollahpouri, Himan and Danylenko, Tonia and Mansoury, Masoud and Loni, Babak and Russo, Daniel and Grbovic, Mihajlo",inproceedings,10.1145/3640457.3687108,
10.1145/3640457.3688013,10.1145/3640457.3688013,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Auxiliary Information, Collaborative Filtering, Graph Neural Network, Non Negative Matrix Factorization, Recommender Systems",4,1314–1317,Proceedings of the 18th ACM Conference on Recommender Systems,"Graph based Recommender models make use of user-item rating and user-user social relationships to elicit recommendation performance by extracting inherent geometrical knowledge. In a social graph scenario, user-user trust plays a significant role in reducing sparsity and has varied characteristics that can be exploited. Existing models limit themselves to learning from either a high-order interaction graph of user-item ratings or a user-user social graph from trust value. They explore other trust characteristics in a very limited setting. The graph based model, designed using entire user-user social information, impacts performance and escalates complexities in model learning. To alleviate these issues of graph learning, graph recommender seeks assistance from matrix factorization techniques. Incorporating graph based model with matrix factorization brings its own set of challenges of model integration, leveraging trust, graph learning, and optimization. This article presents the existing work in that line and future possibilities and challenges to be catered to through novel developments",10.1145/3640457.3688013,https://doi.org/10.1145/3640457.3688013,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Integrating Matrix Factorization with Graph based Models,"Mehta, Rachana",inproceedings,10.1145/3640457.3688013,
10.1145/3640457.3688024,10.1145/3640457.3688024,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Fairness, Human-Centered Computing, Music Recommender Systems, Transparency",8,1368–1375,Proceedings of the 18th ACM Conference on Recommender Systems,"Music streaming services have become one of the main sources of music consumption in the last decade, with recommender systems playing a crucial role. Since these systems partially determine which songs listeners hear, they significantly influence the artists behind the music. However, when assessing the performance and fairness of music recommender systems, the perspectives of artists and others working in the music industry are often overlooked. Additionally, artists express a desire for greater transparency regarding why certain songs are recommended while others are not. This research project adopts a multi-stakeholder approach to close the gap between music recommender systems and the artists whose music they recommend. First, we gather insights from artists and music industry professionals through interviews and questionnaires. Building on those insights, we then aim to improve matching between end users and music from lesser-known artists by generating rich item and user representations. Results will be evaluated both quantitatively and qualitatively. Lastly, we plan to effectively communicate music recommender system fairness by increasing transparency for both end users and artists.",10.1145/3640457.3688024,https://doi.org/10.1145/3640457.3688024,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Fairness and Transparency in Music Recommender Systems: Improvements for Artists,"Dinnissen, Karlijn",inproceedings,10.1145/3640457.3688024,
10.1145/3640457.3688025,10.1145/3640457.3688025,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Bias, Books, Recommender Systems, Reproducibility",6,1376–1381,Proceedings of the 18th ACM Conference on Recommender Systems,"Recommender systems are prevalent in many applications, but hide risks; issues like bias propagation have been on the focus of related studies in recent years. My own research revolves around tracking bias in the book recommendation domain. Specifically, I am interested in whether the incorporation of recommender systems in a library’s loaning system serves their social responsibility and purpose, with bias being the main point of concern. To this end, I engage with the topic in three ways; by mapping the area of ethics in book recommendation, by investigating and reflecting on challenges with studying bias in recommender systems in general, and by showcasing a set of social implication of statistical bias in the book recommendation domain in particular. In this doctoral symposium paper, I further elaborate on the problem at hand, the outline of my thesis, the progress I have made so far, as well as my plans for future work along with specific questions that have arisen from my research efforts.",10.1145/3640457.3688025,https://doi.org/10.1145/3640457.3688025,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Bias in Book Recommendation,"Daniil, Savvina",inproceedings,10.1145/3640457.3688025,
10.1145/3640457.3688056,10.1145/3640457.3688056,RecSys.bib,1,['RecSys.bib'],7,RecSys '24,"Bari, Italy","XGBoost, autoencoders, experimentation, offline evaluation",3,844–846,Proceedings of the 18th ACM Conference on Recommender Systems,,10.1145/3640457.3688056,https://doi.org/10.1145/3640457.3688056,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Towards Understanding The Gaps of Offline And Online Evaluation Metrics: Impact of Series vs. Movie Recommendations,"Edizel, Bora and Sweetser, Tim and Chandrashekar, Ashok and Ahmadi, Kamilia and Das, Puja",inproceedings,10.1145/3640457.3688056,
10.1145/3640457.3688057,10.1145/3640457.3688057,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Conditional Retrieval, Learned Retrieval, Topic Feed Generation, Two Tower Model",3,755–757,Proceedings of the 18th ACM Conference on Recommender Systems,"User-to-item retrieval has been an active research area in recommendation system, and two tower models are widely adopted due to model simplicity and serving efficiency. In this work, we focus on a variant called conditional retrieval, where we expect retrieved items to be relevant to a condition (e.g. topic). We propose a method that uses the same training data as standard two tower models but incorporates item-side information as conditions in query. This allows us to bootstrap new conditional retrieval use cases and encourages feature interactions between user and condition. Experiments show that our method can retrieve highly relevant items and outperforms standard two tower models with filters on engagement metrics. The proposed model is deployed to power a topic-based notification feed at Pinterest and led to +0.26% weekly active users.",10.1145/3640457.3688057,https://doi.org/10.1145/3640457.3688057,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Bootstrapping Conditional Retrieval for User-to-Item Recommendations,"Lin, Hongtao and Chen, Haoyu and Yang, Jaewon and Xu, Jiajing",inproceedings,10.1145/3640457.3688057,
10.1145/3640457.3688061,10.1145/3640457.3688061,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Conversational Recommender System, E-commerce, Multi-Agent",3,745–747,Proceedings of the 18th ACM Conference on Recommender Systems,"Multi-agent collaboration is the latest trending method to build conversational recommender systems (CRS), especially with the widespread use of Large Language Models (LLMs) recently. Typically, these systems employ several LLM agents, each serving distinct roles to meet user needs. In an industrial setting, it’s essential for a CRS to exhibit low first token latency (i.e., the time taken from a user’s input until the system outputs its first response token.) and high scalability—for instance, minimizing the number of LLM inferences per user request—to enhance user experience and boost platform profit. For example, JD.com’s baseline CRS features two LLM agents and a search API but suffers from high first token latency and requires two LLM inferences per request (LIPR), hindering its performance. To address these issues, we introduce a Hybrid Multi-Agent Collaborative Recommender System (Hybrid-MACRS). It includes a central agent powered by a fine-tuned proprietary LLM and a search agent combining a related search module with a search engine. This hybrid system notably reduces first token latency by about 70% and cuts the LIPR from 2 to 1. We conducted thorough online A/B testing to confirm this approach’s efficiency.",10.1145/3640457.3688061,https://doi.org/10.1145/3640457.3688061,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,A Hybrid Multi-Agent Conversational Recommender System with LLM and Search Engine in E-commerce,"Nie, Guangtao and Zhi, Rong and Yan, Xiaofan and Du, Yufan and Zhang, Xiangyang and Chen, Jianwei and Zhou, Mi and Chen, Hongshen and Li, Tianhao and Cheng, Ziguang and Xu, Sulong and Hu, Jinghe",inproceedings,10.1145/3640457.3688061,
10.1145/3640457.3688067,10.1145/3640457.3688067,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Dataset, Fairness, Music Information Retrieval, Music recommendation",11,137–147,Proceedings of the 18th ACM Conference on Recommender Systems,"Nowadays a recommendation model should exploit additional information from both the user and item perspectives, in addition to utilizing user-item interaction data. Datasets are central in offering the required information for evaluating new models or algorithms. Although there are many datasets in the literature with user and item properties, there are several issues not covered yet: (i) it is difficult to perform cross-analysis of properties at user and item level as they are not related in most cases; and (ii) on top of that, in many occasions datasets do not allow analysis at different granularity levels. In this paper, we propose a new dataset in the music domain, named AMBAR, that tackles the above-mentioned issues. Besides detailing in depth the structure of the new dataset, we also show its application in contexts (i.e., multi-objective, fair, and calibrated recommendations) where both the effectiveness and the beyond-accuracy perspectives of recommendation are assessed.",10.1145/3640457.3688067,https://doi.org/10.1145/3640457.3688067,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,AMBAR: A dataset for Assessing Multiple Beyond-Accuracy Recommenders,"G\'{o}mez, Elizabeth and Contreras, David and Boratto, Ludovico and Salamo, Maria",inproceedings,10.1145/3640457.3688067,
10.1145/3640457.3688069,10.1145/3640457.3688069,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Explainable Recommendation, Feature Hallucination, Natural Language Explanations, Reproducibility",11,105–115,Proceedings of the 18th ACM Conference on Recommender Systems,"One way to increase trust among users towards recommender systems is to provide the recommendation along with a textual explanation. In the literature, extraction-based, generation-based, and, more recently, hybrid solutions based on retrieval-augmented generation have been proposed to tackle the problem of text-based explainable recommendation. However, the use of different datasets, preprocessing steps, target explanations, baselines, and evaluation metrics complicates the reproducibility and state-of-the-art assessment of previous work among different model categories for successful advancements in the field. Our aim is to provide a comprehensive analysis of text-based explainable recommender systems by setting up a well-defined benchmark that accommodates generation-based, extraction-based, and hybrid approaches. Also, we enrich the existing evaluation of explainability and text quality of the explanations with a novel definition of feature hallucination. Our experiments on three real-world datasets unveil hidden behaviors and confirm several claims about model patterns. Our source code and preprocessed datasets are available at https://github.com/alarca94/text-exp-recsys24.",10.1145/3640457.3688069,https://doi.org/10.1145/3640457.3688069,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,A Comparative Analysis of Text-Based Explainable Recommender Systems,"Ariza-Casabona, Alejandro and Boratto, Ludovico and Salam\'{o}, Maria",inproceedings,10.1145/3640457.3688069,
10.1145/3640457.3688070,10.1145/3640457.3688070,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Graph Neural Networks, Recommender Systems, Topology",11,549–559,Proceedings of the 18th ACM Conference on Recommender Systems,"Recently, graph neural networks (GNNs)-based recommender systems have encountered great success in recommendation. As the number of GNNs approaches rises, some works have started questioning the theoretical and empirical reasons behind their superior performance. Nevertheless, this investigation still disregards that GNNs treat the recommendation data as a topological graph structure. Building on this assumption, in this work, we provide a novel evaluation perspective on GNNs-based recommendation, which investigates the impact of the graph topology on the recommendation performance. To this end, we select some (topological) properties of the recommendation data and three GNNs-based recommender systems (i.e., LightGCN, DGCF, and SVD-GCN). Then, starting from three popular recommendation datasets (i.e., Yelp2018, Gowalla, and Amazon-Book) we sample them to obtain 1,800 size-reduced datasets that still resemble the original ones but can encompass a wider range of topological structures. We use this procedure to build a large pool of samples for which data characteristics and recommendation performance of the selected GNNs models are measured. Through an explanatory framework, we find strong correspondences between graph topology and GNNs performance, offering a novel evaluation perspective on these models.",10.1145/3640457.3688070,https://doi.org/10.1145/3640457.3688070,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,A Novel Evaluation Perspective on GNNs-based Recommender Systems through the Topology of the User-Item Graph,"Malitesta, Daniele and Pomo, Claudio and Anelli, Vito Walter and Mancino, Alberto Carlo Maria and Di Noia, Tommaso and Di Sciascio, Eugenio",inproceedings,10.1145/3640457.3688070,
10.1145/3640457.3688072,10.1145/3640457.3688072,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","LLMs, Large Language Models, Recommendation Frameworks, Recommender Systems, Reproducibility Analysis",10,116–125,Proceedings of the 18th ACM Conference on Recommender Systems,"Recommender systems can significantly benefit from the availability of pre-trained large language models (LLMs), which can serve as a basic mechanism for generating recommendations based on detailed user and item data, such as text descriptions, user reviews, and metadata. On the one hand, this new generation of LLM-based recommender systems paves the way for dealing with traditional limitations, such as cold-start and data sparsity. Still, on the other hand, this poses fundamental challenges for their accountability. Reproducing experiments in the new context of LLM-based recommender systems is challenging for several reasons. New approaches are published at an unprecedented pace, which makes difficult to have a clear picture of the main protocols and good practices in the experimental evaluation. Moreover, the lack of proper frameworks for LLM-based recommendation development and evaluation makes the process of benchmarking models complex and uncertain. In this work, we discuss the main issues encountered when trying to reproduce P5 (Pretrain, Personalized Prompt, and Prediction Paradigm), one of the first works unifying different recommendation tasks in a shared language modeling and natural language generation framework. Starting from this study, we have developed LaikaLLM, a framework for training and evaluating LLMs, specifically for the recommendation task. It has been used to perform several experiments to assess the impact of using different LLMs, different personalization strategies, and a novel set of more informative prompts on the overall performance of recommendations in a fully reproducible environment.",10.1145/3640457.3688072,https://doi.org/10.1145/3640457.3688072,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Reproducibility of LLM-based Recommender Systems: the Case Study of P5 Paradigm,"Lops, Pasquale and Silletti, Antonio and Polignano, Marco and Musto, Cataldo and Semeraro, Giovanni",inproceedings,10.1145/3640457.3688072,
10.1145/3640457.3688074,10.1145/3640457.3688074,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Carbon Footprint, Deep Learning, Energy Consumption, Green Computing, GreenRecSys, Recommender Systems, Reproducibility",11,580–590,Proceedings of the 18th ACM Conference on Recommender Systems,"As global warming soars, the need to assess the environmental impact of research is becoming increasingly urgent. Despite this, few recommender systems research papers address their environmental impact. In this study, we estimate the environmental impact of recommender systems research by reproducing typical experimental pipelines. Our analysis spans 79 full papers from the 2013 and 2023 ACM RecSys conferences, comparing traditional “good old-fashioned AI’’ algorithms with modern deep learning algorithms. We designed and reproduced representative experimental pipelines for both years, measuring energy consumption with a hardware energy meter and converting it to CO2 equivalents. Our results show that papers using deep learning algorithms emit approximately 42 times more CO2 equivalents than papers using traditional methods. On average, a single deep learning-based paper generates 3,297 kilograms of CO2 equivalents—more than the carbon emissions of one person flying from New York City to Melbourne or the amount of CO2 one tree sequesters over 300 years.",10.1145/3640457.3688074,https://doi.org/10.1145/3640457.3688074,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,From Clicks to Carbon: The Environmental Toll of Recommender Systems,"Vente, Tobias and Wegmeth, Lukas and Said, Alan and Beel, Joeran",inproceedings,10.1145/3640457.3688074,
10.1145/3640457.3688100,10.1145/3640457.3688100,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","collaborative filtering, implicit feedback, matrix factorization, recommender system",9,219–227,Proceedings of the 18th ACM Conference on Recommender Systems,"Matrix factorization is a well-known and effective methodology for top-k list recommendation. It became widely known during the Netflix challenge in 2006, and since then, many adapted and improved versions have been published. A particularly interesting matrix factorization algorithm called iALS (for implicit Alternating Least Squares) adapts the method for implicit feedback, i.e. a setting where only a very small amount of positive labels are available along with a majority of unknown labels. Compared to the classical task of rating prediction, learning from implicit feedback is applicable to many more domains, as the data is more abundant and requires less effort to elicit from users. However, the sparsity, imbalance, and implicit nature of the signal also pose unique challenges to retrieving the most relevant items to recommend. We revisit the role of unknown interactions in implicit matrix factorization. Traditionally, all unknowns are interpreted as negative samples and their importance in the training objective is then down-weighted to balance them out with the known, positive interactions. Interestingly, by adapting a probabilistic view of matrix factorization, we can retain the unknown nature of these interactions by modelling them as either positive or negative. With this new formulation that better fits the underlying data, we gain improved performance on the downstream recommendation task without any computational overhead compared to the popular iALS method.This paper outlines the key insights needed to adapt iALS to use logistic regression. Furthermore, a logistic version of the popular full-rank EASE model is introduced in a similar fasion. An extensive experimental evaluation on several real-world datasets demonstrates the effectiveness of our approach. Additionally, a discrepancy between the need for weighting between factorization and autoencoder models is discovered, leading towards a better understanding of these methods.",10.1145/3640457.3688100,https://doi.org/10.1145/3640457.3688100,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,The Role of Unknown Interactions in Implicit Matrix Factorization — A Probabilistic View,"De Pauw, Joey and Goethals, Bart",inproceedings,10.1145/3640457.3688100,
10.1145/3640457.3688102,10.1145/3640457.3688102,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Bias Mitigation, Fairness, Music, Popularity Bias, Recommender Systems, User-Centric Evaluation",10,169–178,Proceedings of the 18th ACM Conference on Recommender Systems,"Popularity bias is a prominent phenomenon in recommender systems (RS), especially in the music domain. Although popularity bias mitigation techniques are known to enhance the fairness of RS while maintaining their high performance, there is a lack of understanding regarding users’ actual perception of the suggested music. To address this gap, we conducted a user study (n=40) exploring user satisfaction and perception of personalized music recommendations generated by algorithms that explicitly mitigate popularity bias. Specifically, we investigate item-centered and user-centered bias mitigation techniques, aiming to ensure fairness for artists or users, respectively. Results show that neither mitigation technique harms the users’ satisfaction with the recommendation lists despite promoting underrepresented items. However, the item-centered mitigation technique impacts user perception; by promoting less popular items, it reduces users’ familiarity with the items. Lower familiarity evokes discovery—the feeling that the recommendations enrich the user’s taste. We demonstrate that this can ultimately lead to higher satisfaction, highlighting the potential of less-popular recommendations to improve the user experience.",10.1145/3640457.3688102,https://doi.org/10.1145/3640457.3688102,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Putting Popularity Bias Mitigation to the Test: A User-Centric Evaluation in Music Recommenders,"Ungruh, Robin and Dinnissen, Karlijn and Volk, Anja and Pera, Maria Soledad and Hauptmann, Hanna",inproceedings,10.1145/3640457.3688102,
10.1145/3640457.3688104,10.1145/3640457.3688104,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Knowledge Augmentation, Large Language Model, Recommender System",11,12–22,Proceedings of the 18th ACM Conference on Recommender Systems,"Recommender system plays a vital role in various online services. However, its insulated nature of training and deploying separately within a specific closed domain limits its access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capabilities. Nevertheless, previous attempts to directly use LLMs as recommenders cannot meet the inference latency demand of industrial recommender systems. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs — the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM. Extensive experiments show that KAR significantly outperforms the state-of-the-art baselines and is compatible with a wide range of recommendation algorithms. We deploy KAR to Huawei’s news and music recommendation platforms and gain a 7% and 1.7% improvement in the online A/B test, respectively.",10.1145/3640457.3688104,https://doi.org/10.1145/3640457.3688104,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models,"Xi, Yunjia and Liu, Weiwen and Lin, Jianghao and Cai, Xiaoling and Zhu, Hong and Zhu, Jieming and Chen, Bo and Tang, Ruiming and Zhang, Weinan and Yu, Yong",inproceedings,10.1145/3640457.3688104,
10.1145/3640457.3688105,10.1145/3640457.3688105,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Contextual Bandits, Off-policy Learning, Recommender Systems",11,722–732,Proceedings of the 18th ACM Conference on Recommender Systems,"The off-policy learning paradigm allows for recommender systems and general ranking applications to be framed as decision-making problems, where we aim to learn decision policies that optimize an unbiased offline estimate of an online reward metric. With unbiasedness comes potentially high variance, and prevalent methods exist to reduce estimation variance. These methods typically make use of control variates, either additive (i.e., baseline corrections or doubly robust methods) or multiplicative (i.e., self-normalisation). Our work unifies these approaches by proposing a single framework built on their equivalence in learning scenarios. The foundation of our framework is the derivation of an equivalent baseline correction for all of the existing control variates. Consequently, our framework enables us to characterize the variance-optimal unbiased estimator and provide a closed-form solution for it. This optimal estimator brings significantly improved performance in both evaluation and learning, and minimizes data requirements. Empirical observations corroborate our theoretical findings.",10.1145/3640457.3688105,https://doi.org/10.1145/3640457.3688105,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Optimal Baseline Corrections for Off-Policy Contextual Bandits,"Gupta, Shashank and Jeunen, Olivier and Oosterhuis, Harrie and de Rijke, Maarten",inproceedings,10.1145/3640457.3688105,
10.1145/3640457.3688112,10.1145/3640457.3688112,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Federated Learning, Personalized Federated Recommendation, Recommendation System",11,690–700,Proceedings of the 18th ACM Conference on Recommender Systems,"Privacy protection in recommendation systems is gaining increasing attention, for which federated learning has emerged as a promising solution. Current federated recommendation systems grapple with high communication overhead due to sharing dense global embeddings, and also poorly reflect user preferences due to data heterogeneity. To overcome these challenges, we propose a two-stage Federated Low-rank Coordinated Adaptation (FedLoCA) framework to decouple global and client-specific knowledge into low-rank embeddings, which significantly reduces communication overhead while enhancing the system’s ability to capture individual user preferences amidst data heterogeneity. Further, to tackle gradient estimation inaccuracies stemming from data sparsity in federated recommendation systems, we introduce an adversarial gradient projected descent approach in low-rank spaces, which significantly boosts model performance while maintaining robustness. Remarkably, FedLoCA also alleviates performance loss even under the stringent constraints of differential privacy. Extensive experiments on various real-world datasets demonstrate that FedLoCA significantly outperforms existing methods in both recommendation accuracy and communication efficiency.",10.1145/3640457.3688112,https://doi.org/10.1145/3640457.3688112,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,FedLoCA: Low-Rank Coordinated Adaptation with Knowledge Decoupling for Federated Recommendations,"Ding, Yuchen and Zhang, Siqing and Fan, Boyu and Sun, Wei and Liao, Yong and Zhou, Peng Yuan",inproceedings,10.1145/3640457.3688112,
10.1145/3640457.3688113,10.1145/3640457.3688113,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Causal Inference, Recommender System, Release Interval Bias",10,179–188,Proceedings of the 18th ACM Conference on Recommender Systems,"Short-video recommender systems often exhibit a biased preference to recently released videos. However, not all videos become outdated; certain classic videos can still attract user’s attention. Such bias along temporal dimension can be further aggravated by the matching model between users and videos, because the model learns from preexisting interactions. From real data, we observe that different videos have varying sensitivities to recency in attracting users’ attention. Our analysis, based on a causal graph modeling short-video recommendation, suggests that the release interval serves as a confounder, establishing a backdoor path between users and videos. To address this confounding effect, we propose a model-agnostic causal architecture called Learning to Deconfound the Release Interval Bias (LDRI). LDRI enables jointly learning of the matching model and the video recency sensitivity perceptron. In the inference stage, we apply a backdoor adjustment, effectively blocking the backdoor path by intervening on each video. Extensive experiments on two benchmarks demonstrate that LDRI consistently outperforms backbone models and exhibits superior performance against state-of-the-art models. Additional comprehensive analyses confirm the deconfounding capability of LDRI.",10.1145/3640457.3688113,https://doi.org/10.1145/3640457.3688113,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Not All Videos Become Outdated: Short-Video Recommendation by Learning to Deconfound Release Interval Bias,"Dong, Lulu and He, Guoxiu and Sun, Aixin",inproceedings,10.1145/3640457.3688113,
10.1145/3640457.3688123,10.1145/3640457.3688123,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Generative Recommendation, Generative Retrieval, Joint Search and Recommendation, Multi-task Learning",10,340–349,Proceedings of the 18th ACM Conference on Recommender Systems,"Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the breakthroughs of Large Language Models (LLMs), these generative systems can play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items learned by generative recommenders are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item’s representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item’s popularity, and [H2] the joint training regularizes the item’s latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.",10.1145/3640457.3688123,https://doi.org/10.1145/3640457.3688123,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other?,"Penha, Gustavo and Vardasbi, Ali and Palumbo, Enrico and De Nadai, Marco and Bouchard, Hugues",inproceedings,10.1145/3640457.3688123,
10.1145/3640457.3688129,10.1145/3640457.3688129,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Scaling Law, Sequential Recommendation",10,444–453,Proceedings of the 18th ACM Conference on Recommender Systems,"Scaling of neural networks has recently shown great potential to improve the model capacity in various fields. Specifically, model performance has a power-law relationship with model size or data size, which provides important guidance for the development of large-scale models. However, there is still limited understanding on the scaling effect of user behavior models in recommender systems, where the unique data characteristics (e.g., data scarcity and sparsity) pose new challenges in recommendation tasks. In this work, we focus on investigating the scaling laws in large sequential recommendation models. Specifically, we consider a pure ID-based task formulation, where the interaction history of a user is formatted as a chronological sequence of item IDs. We don’t incorporate any side information (e.g., item text), to delve into the scaling law’s applicability from the perspective of user behavior. We successfully scale up the model size to 0.8B parameters, making it feasible to explore the scaling effect in a diverse range of model sizes. As the major findings, we empirically show that the scaling law still holds for these trained models, even in data-constrained scenarios. We then fit the curve for scaling law, and successfully predict the test loss of the two largest tested model scales. Furthermore, we examine the performance advantage of scaling effect on five challenging recommendation tasks, considering the unique issues (e.g., cold start, robustness, long-term preference) in recommender systems. We find that scaling up the model size can greatly boost the performance on these challenging tasks, which again verifies the benefits of large recommendation models.",10.1145/3640457.3688129,https://doi.org/10.1145/3640457.3688129,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Scaling Law of Large Sequential Recommendation Models,"Zhang, Gaowei and Hou, Yupeng and Lu, Hongyu and Chen, Yu and Zhao, Wayne Xin and Wen, Ji-Rong",inproceedings,10.1145/3640457.3688129,
10.1145/3640457.3688135,10.1145/3640457.3688135,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Contrastive Learning, Large Language Model, Recommendation System",10,23–32,Proceedings of the 18th ACM Conference on Recommender Systems,"Click-Through Rate (CTR) prediction is crucial for Recommendation System(RS), aiming to provide personalized recommendation services for users in many aspects such as food delivery, e-commerce and so on. However, traditional RS relies on collaborative signals, which lacks semantic understanding to real-time scenes. We also noticed that a major challenge in utilizing Large Language Models (LLMs) for practical recommendation purposes is their efficiency in dealing with long text input. To break through the problems above, we propose Large Language Model Aided Real-time Scene Recommendation(LARR), adopt LLMs for semantic understanding, utilizing real-time scene information in RS without requiring LLM to process the entire real-time scene text directly, thereby enhancing the efficiency of LLM-based CTR modeling. Specifically, recommendation domain-specific knowledge is injected into LLM and then RS employs an aggregation encoder to build real-time scene information from separate LLM’s outputs. Firstly, a LLM is continual pretrained on corpus built from recommendation data with the aid of special tokens. Subsequently, the LLM is fine-tuned via contrastive learning on three kinds of sample construction strategies. Through this step, LLM is transformed into a text embedding model. Finally, LLM’s separate outputs for different scene features are aggregated by an encoder, aligning to collaborative signals in RS, enhancing the performance of recommendation model.",10.1145/3640457.3688135,https://doi.org/10.1145/3640457.3688135,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding,"Wan, Zhizhong and Yin, Bin and Xie, Junjie and Jiang, Fei and Li, Xiang and Lin, Wei",inproceedings,10.1145/3640457.3688135,
10.1145/3640457.3688137,10.1145/3640457.3688137,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Cross-domain Recommendations, Instruction Tuning, Large Language Models, Recommender Systems",11,298–308,Proceedings of the 18th ACM Conference on Recommender Systems,"In this paper, we present a strategy to provide users with explainable cross-domain recommendations (CDR) that exploits large language models (LLMs). Generally speaking, CDR is a task that is hard to tackle, mainly due to data sparsity issues. Indeed, CDR models require a large amount of data labeled in both source and target domains, which are not easy to collect. Accordingly, our approach relies on the intuition that the knowledge that is already encoded in LLMs can be used to more easily bridge the domains and seamlessly provide users with personalized cross-domain suggestions. To this end, we designed a pipeline to: (a) instruct a LLM to handle a CDR task; (b) design a personalized prompt, based on the preferences of the user in a source domain, and a list of items to be ranked in target domain; (c) feed the LLM with the prompt, in both zero-shot and one-shot settings, and process the answer in order to extract the recommendations and a natural language explanation. As shown in the experimental evaluation, our approach beats several established state-of-the-art baselines for CDR in most of the experimental settings, thus showing the effectiveness of LLMs also in this novel and scarcely investigated scenario.",10.1145/3640457.3688137,https://doi.org/10.1145/3640457.3688137,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Instructing and Prompting Large Language Models for Explainable Cross-domain Recommendations,"Petruzzelli, Alessandro and Musto, Cataldo and Laraspata, Lucrezia and Rinaldi, Ivan and de Gemmis, Marco and Lops, Pasquale and Semeraro, Giovanni",inproceedings,10.1145/3640457.3688137,
10.1145/3640457.3688140,10.1145/3640457.3688140,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Sequential recommendation, cross-entropy loss, negative sampling",11,475–485,Proceedings of the 18th ACM Conference on Recommender Systems,"Scalability issue plays a crucial role in productionizing modern recommender systems. Even lightweight architectures may suffer from high computational overload due to intermediate calculations, limiting their practicality in real-world applications. Specifically, applying full Cross-Entropy (CE) loss often yields state-of-the-art performance in terms of recommendations quality. Still, it suffers from excessive GPU memory utilization when dealing with large item catalogs. This paper introduces a novel Scalable Cross-Entropy (SCE) loss function in the sequential learning setup. It approximates the CE loss for datasets with large-size catalogs, enhancing both time efficiency and memory usage without compromising recommendations quality. Unlike traditional negative sampling methods, our approach utilizes a selective GPU-efficient computation strategy, focusing on the most informative elements of the catalog, particularly those most likely to be false positives. This is achieved by approximating the softmax distribution over a subset of the model outputs through the maximum inner product search. Experimental results on multiple datasets demonstrate the effectiveness of SCE in reducing peak memory usage by a factor of up to 100 compared to the alternatives, retaining or even exceeding their metrics values. The proposed approach also opens new perspectives for large-scale developments in different domains, such as large language models.",10.1145/3640457.3688140,https://doi.org/10.1145/3640457.3688140,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Scalable Cross-Entropy Loss for Sequential Recommendations with Large Item Catalogs,"Mezentsev, Gleb and Gusak, Danil and Oseledets, Ivan and Frolov, Evgeny",inproceedings,10.1145/3640457.3688140,
10.1145/3640457.3688145,10.1145/3640457.3688145,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Recommender System, Zero-shot Sequential Recommendation",11,433–443,Proceedings of the 18th ACM Conference on Recommender Systems,"This paper proposes a novel pre-trained framework for zero-shot cross-domain sequential recommendation without auxiliary information. While using auxiliary information (e.g.,&nbsp;item descriptions) seems promising for cross-domain transfer, a cross-domain adaptation of sequential recommenders can be challenging when the target domain differs from the source domain—item descriptions are in different languages; metadata modalities (e.g.,&nbsp;audio, image, and text) differ across source and target domains. If we can learn universal item representations independent of the domain type (e.g.,&nbsp;groceries, movies), we can achieve zero-shot cross-domain transfer without auxiliary information. Our critical insight is that user interaction sequences highlight shifting user preferences via the popularity dynamics of interacted items. We present a pre-trained sequential recommendation framework: PrepRec, which utilizes a novel popularity dynamics-aware transformer architecture. Through extensive experiments on five real-world datasets, we show that PrepRec, without any auxiliary information, can zero-shot adapt to new application domains and achieve competitive performance compared to state-of-the-art sequential recommender models. In addition, we show that PrepRec&nbsp;complements existing sequential recommenders. With a simple post-hoc interpolation, PrepRec&nbsp;improves the performance of existing sequential recommenders on average by 11.8% in Recall@10 and 22% in NDCG@10. We provide an anonymized implementation of PrepRec&nbsp;at https://github.com/CrowdDynamicsLab/preprec.",10.1145/3640457.3688145,https://doi.org/10.1145/3640457.3688145,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,A Pre-trained Zero-shot Sequential Recommendation Framework via Popularity Dynamics,"Wang, Junting and Rathi, Praneet and Sundaram, Hari",inproceedings,10.1145/3640457.3688145,
10.1145/3640457.3688147,10.1145/3640457.3688147,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Budget Constraint, End-to-End Optimization, Incentive Recommendation, Uplift Modeling",10,560–569,Proceedings of the 18th ACM Conference on Recommender Systems,"In modern online platforms, incentives (e.g., discounts, bonus) are essential factors that enhance user engagement and increase platform revenue. Over recent years, uplift modeling has been introduced as a strategic approach to assign incentives to individual customers. Especially in many real-world applications, online platforms can only incentivize customers with specific budget constraints. This problem can be reformulated as the multi-choice knapsack problem (MCKP). The objective of this optimization is to select the optimal incentive for each customer to maximize the return on investment (ROI). Recent works in this field frequently tackle the budget allocation problem using a two-stage approach. However, this solution is confronted with the following challenges: (1) The causal inference methods often ignore the domain knowledge in online marketing, where the expected response curve of a customer should be monotonic and smooth as the incentive increases. (2) There is an optimality gap between the two stages, resulting in inferior sub-optimal allocation performance due to the loss of the incentive recommendation information for the uplift prediction under the limited budget constraint. To address these challenges, we propose a novel End-to-End Cost-Effective Incentive Recommendation (E3IR) model under the budget constraint. Specifically, our methods consist of two modules, i.e., the uplift prediction module and the differentiable allocation module. In the uplift prediction module, we construct prediction heads to capture the incremental improvement between adjacent treatments with the marketing domain constraints (i.e., monotonic and smooth). We incorporate integer linear programming (ILP) as a differentiable layer input in the differentiable allocation module. Furthermore, we conduct extensive experiments on public and real product datasets, demonstrating that our E3IR improves allocation performance compared to existing two-stage approaches.",10.1145/3640457.3688147,https://doi.org/10.1145/3640457.3688147,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,End-to-End Cost-Effective Incentive Recommendation under Budget Constraint with Uplift Modeling,"Sun, Zexu and Yang, Hao and Liu, Dugang and Weng, Yunpeng and Tang, Xing and He, Xiuqiang",inproceedings,10.1145/3640457.3688147,
10.1145/3640457.3688158,10.1145/3640457.3688158,RecSys.bib,1,['RecSys.bib'],7,RecSys '24,"Bari, Italy",,1,1,Proceedings of the 18th ACM Conference on Recommender Systems,"An increasingly important aspect of designing recommender systems involves considering how recommendations will influence consumer choices. This paper addresses this issue by introducing a method for collecting user beliefs about un-experienced goods – a critical predictor of choice behavior. We implemented this method on the MovieLens platform, resulting in a rich dataset that combines user ratings, beliefs, and observed recommendations. We document challenges to such data collection, including selection bias in response and limited coverage of the product space. This unique resource empowers researchers to delve deeper into user behavior and analyze user choices absent recommendations, measure the effectiveness of recommendations, and prototype algorithms that leverage user belief data, ultimately leading to more impactful recommender systems. The dataset can be found at https://grouplens.org/datasets/movielens/ml_belief_2024/.",10.1145/3640457.3688158,https://doi.org/10.1145/3640457.3688158,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online Recommender Systems,"Aridor, Guy and Goncalves, Duarte and Kong, Ruoyan and Kluver, Daniel and Konstan, Joseph",inproceedings,10.1145/3640457.3688158,
10.1145/3640457.3688169,10.1145/3640457.3688169,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Fairness-aware Recommendation, Recommender Systems",6,918–923,Proceedings of the 18th ACM Conference on Recommender Systems,"At present, most recommender systems involve two stakeholders, providers and customers. Apart from maximizing the recommendation accuracy, the fairness issue for both sides should also be considered. Most of previous studies try to improve two-sided fairness with post-processing algorithms or fairness-aware loss constraints, which are highly dependent on the heuristic adjustments without respect to the optimization goal of accuracy. In contrast, we propose a novel training framework, adaptive weighting towards two-sided fairness-aware recommendation&nbsp;(named Ada2Fair), which lies in the extension of the accuracy-focused objective to a controllable preference learning loss over the interaction data. Specifically, we adjust the optimization scale of an interaction sample with an adaptive weight generator, and estimate the two-sided fairness-aware weights within model training. During the training process, the recommender is trained with two-sided fairness-aware weights to boost the utility of niche providers and inactive customers in a unified way. Extensive experiments on three public datasets verify the effectiveness of&nbsp;Ada2Fair, which can achieve Pareto efficiency in two-sided fairness-aware recommendation.",10.1145/3640457.3688169,https://doi.org/10.1145/3640457.3688169,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Promoting Two-sided Fairness with Adaptive Weights for Providers and Customers in Recommendation,"Xu, Lanling and Lin, Zihan and Wang, Jinpeng and Chen, Sheng and Zhao, Wayne Xin and Wen, Ji-Rong",inproceedings,10.1145/3640457.3688169,
10.1145/3640457.3688177,10.1145/3640457.3688177,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","expected calibration error, personalized ranking, prediction bias",6,963–968,Proceedings of the 18th ACM Conference on Recommender Systems,"Well-calibrated predictions of user preferences are essential for many applications. Since recommender systems typically select the top-N items for users, calibration for those top-N items, rather than for all items, is important. We show that previous calibration methods result in miscalibrated predictions for the top-N items, despite their excellent calibration performance when evaluated on all items. In this work, we address the miscalibration in the top-N recommended items. We first define evaluation metrics for this objective and then propose a generic method to optimize calibration models focusing on the top-N items. It groups the top-N items by their ranks and optimizes distinct calibration models for each group with rank-dependent training weights. We verify the effectiveness of the proposed method for both explicit and implicit feedback datasets, using diverse classes of recommender models.",10.1145/3640457.3688177,https://doi.org/10.1145/3640457.3688177,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Calibrating the Predictions for Top-N Recommendations,"Sato, Masahiro",inproceedings,10.1145/3640457.3688177,
10.1145/3640457.3688187,10.1145/3640457.3688187,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Demographic&nbsp;Bias, Feedback Loop, Music Recommendation",6,1022–1027,Proceedings of the 18th ACM Conference on Recommender Systems,"Recent work suggests that music recommender systems are prone to disproportionally frequent recommendations of music from countries more prominently represented in the training data, notably the US. However, it remains unclear to what extent feedback loops in music recommendation influence the dynamics of such imbalance. In this work, we investigate the dynamics of representation of local (i.e., country-specific) and US-produced music in user profiles and recommendations. To this end, we conduct a feedback loop simulation study using the LFM-2b dataset. The results suggest that most of the investigated recommendation models decrease the proportion of music from local artists in their recommendations. Furthermore, we find that models preserving average proportions of US and local music do not necessarily provide country-calibrated recommendations. We also look into popularity calibration and, surprisingly, find that the most popularity-calibrated model in our study (ItemKNN) provides the least country-calibrated recommendations. In addition, users from less represented countries (e.g., Finland) are, in the long term, most affected by the under-representation of their local music in recommendations.",10.1145/3640457.3688187,https://doi.org/10.1145/3640457.3688187,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,"Oh, Behave! Country Representation Dynamics Created by Feedback Loops in Music Recommender Systems","Lesota, Oleg and Geiger, Jonas and Walder, Max and Kowald, Dominik and Schedl, Markus",inproceedings,10.1145/3640457.3688187,
10.1145/3640457.3688195,10.1145/3640457.3688195,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Data Characteristics, Datasets, Recommender Systems, SASRec, Sequential Recommendations",6,1067–1072,Proceedings of the 18th ACM Conference on Recommender Systems,"Sequential recommender systems are an important and demanded area of research. Such systems aim to use the order of interactions in a user’s history to predict future interactions. The premise is that the order of interactions and sequential patterns play an essential role. Therefore, it is crucial to use datasets that exhibit a sequential structure to evaluate sequential recommenders properly. We apply several methods based on the random shuffling of the user’s sequence of interactions to assess the strength of sequential structure across 15 datasets, frequently used for sequential recommender systems evaluation in recent research papers presented at top-tier conferences. As shuffling explicitly breaks sequential dependencies inherent in datasets, we estimate the strength of sequential patterns by comparing metrics for shuffled and original versions of the dataset. Our findings show that several popular datasets have a rather weak sequential structure.",10.1145/3640457.3688195,https://doi.org/10.1145/3640457.3688195,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Does It Look Sequential? An Analysis of Datasets for Evaluation of Sequential Recommendations,"Klenitskiy, Anton and Volodkevich, Anna and Pembek, Anton and Vasilev, Alexey",inproceedings,10.1145/3640457.3688195,
10.1145/3640457.3691718,10.1145/3640457.3691718,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Algorithm Selection, AutoRecSys, Automated Recommender Systems, Collaborative Filtering, Ranking Prediction",5,1163–1167,Proceedings of the 18th ACM Conference on Recommender Systems,"The recommender systems algorithm selection problem for ranking prediction on implicit feedback datasets is under-explored. Traditional approaches in recommender systems algorithm selection focus predominantly on rating prediction on explicit feedback datasets, leaving a research gap for ranking prediction on implicit feedback datasets. Algorithm selection is a critical challenge for nearly every practitioner in recommender systems. In this work, we take the first steps toward addressing this research gap. We evaluate the NDCG@10 of 24 recommender systems algorithms, each with two hyperparameter configurations, on 72 recommender systems datasets. We train four optimized machine-learning meta-models and one automated machine-learning meta-model with three different settings on the resulting meta-dataset. Our results show that the predictions of all tested meta-models exhibit a median Spearman correlation ranging from 0.857 to 0.918 with the ground truth. We show that the median Spearman correlation between meta-model predictions and the ground truth increases by an average of 0.124 when the meta-model is optimized to predict the ranking of algorithms instead of their performance. Furthermore, in terms of predicting the best algorithm for an unknown dataset, we demonstrate that the best optimized traditional meta-model, e.g., XGBoost, achieves a recall of 48.6%, outperforming the best tested automated machine learning meta-model, e.g., AutoGluon, which achieves a recall of 47.2%.",10.1145/3640457.3691718,https://doi.org/10.1145/3640457.3691718,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets,"Wegmeth, Lukas and Vente, Tobias and Beel, Joeran",inproceedings,10.1145/3640457.3691718,
10.1145/3640457.3691719,10.1145/3640457.3691719,RecSys.bib,1,['RecSys.bib'],8,RecSys '24,"Bari, Italy","Music Recommendation, Personalized Popularity, Recommender Systems, Sequential Recommendation",6,1168–1173,Proceedings of the 18th ACM Conference on Recommender Systems,"In the realm of music recommendation, sequential recommender systems have shown promise in capturing the dynamic nature of music consumption. Nevertheless, traditional Transformer-based models, such as SASRec and BERT4Rec, while effective, encounter challenges due to the unique characteristics of music listening habits. In fact, existing models struggle to create a coherent listening experience due to rapidly evolving preferences. Moreover, music consumption is characterized by a prevalence of repeated listening, i.e. users frequently return to their favourite tracks, an important signal that could be framed as individual or personalized popularity. This paper addresses these challenges by introducing a novel approach that incorporates personalized popularity information into sequential recommendation. By combining user-item popularity scores with model-generated scores, our method effectively balances the exploration of new music with the satisfaction of user preferences. Experimental results demonstrate that a Personalized Most Popular recommender, a method solely based on user-specific popularity, outperforms existing state-of-the-art models. Furthermore, augmenting Transformer-based models with personalized popularity awareness yields superior performance, showing improvements ranging from 25.2% to 69.8%. The code for this paper is available at https://github.com/sisinflab/personalized-popularity-awareness.",10.1145/3640457.3691719,https://doi.org/10.1145/3640457.3691719,"New York, NY, USA",Association for Computing Machinery,9798400705052,2024,Enhancing Sequential Music Recommendation with Personalized Popularity Awareness,"Abbattista, Davide and Anelli, Vito Walter and Di Noia, Tommaso and Macdonald, Craig and Petrov, Aleksandr Vladimirovich",inproceedings,10.1145/3640457.3691719,
10.1145/3687151.3687153,10.1145/3687151.3687153,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '24,"Bari, Italy","News Recommendation, Recommender Systems",5,12–16,Proceedings of the Recommender Systems Challenge 2024,"In today’s era of information overload, personalized news recommendation systems are crucial for connecting users with relevant content. The dynamic nature of user interests and the fleeting popularity of news articles pose significant challenges to accurate prediction. For this reason, the RecSys 2024 Challenge aims to inspire innovative solutions in this field. This study presents DIVAN (Deep-Interest Virality-Aware Network), our solution for the RecSys 2024 Challenge, combining a Deep Interest Network (DIN) for personalized user interest representation with a Virality-aware Click Predictor that utilizes temporal features to estimate click probability based on news popularity. A user-specific weight balances the influence of DIN and virality-based predictions, enhancing personalization and accuracy. Experiments on the Ekstra Bladet dataset from the Challenge demonstrate how promising DIVAN is in accuracy and beyond-accuracy performance.",10.1145/3687151.3687153,https://doi.org/10.1145/3687151.3687153,"New York, NY, USA",Association for Computing Machinery,9798400711275,2024,DIVAN: Deep-Interest Virality-Aware Network to Exploit Temporal Dynamics in News Recommendation,"Ferrara, Antonio and Valentini, Marco and Masciullo, Paolo and De Candia, Antonio and Abbattista, Davide and Fusco, Riccardo and Pomo, Claudio and Anelli, Vito Walter and Biancofiore, Giovanni Maria and Boratto, Ludovico and Narducci, Fedelucio",inproceedings,10.1145/3687151.3687153,
10.1145/3687151.3687156,10.1145/3687151.3687156,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '24,"Bari, Italy","LightGBM, News Recommendation, Ranker Algorithm, RecSys Challenge, Recommender Systems",5,27–31,Proceedings of the Recommender Systems Challenge 2024,"This study addresses the news recommendation task presented by Ekstra Bladet in the ACM RecSys Challenge 2024. The task aims to predict which articles users are likely to click on from a list of candidate articles, by leveraging users’ browsing history, personal information, article details, and session information. Our approach is centered around a LightGBM Ranker model. Various features were used, including user, article, and session information, as well as their interactions. Additionally, embeddings were created from users’ browsing history and news article texts, and their cosine similarities were used as additional features. Appropriate validating methods using time series were explored, and effective data sampling and ensemble methods were also proposed to fit the data within limited memory. Finally, the final model was created by performing a weighted ensemble using multiple periods and random seeds. This method achieved high performance with AUC of 0.8169. As a result, an 8th place finish was achieved among around 200 participating teams. The code is available at https://github.com/tetsuro731/RecSys-Challenge-2024-tetsuro731.",10.1145/3687151.3687156,https://doi.org/10.1145/3687151.3687156,"New York, NY, USA",Association for Computing Machinery,9798400711275,2024,Leveraging LightGBM Ranker for Efficient Large-Scale News Recommendation Systems,"Sugiura, Tetsuro and Yamagishi, Yosuke and Kishimoto, Yodai",inproceedings,10.1145/3687151.3687156,
10.1145/3687151.3687158,10.1145/3687151.3687158,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '24,"Bari, Italy","Generative Sequence Modeling, News Recommendation, Real-Time Feedback, RecSys Challenge",5,32–36,Proceedings of the Recommender Systems Challenge 2024,"Personalized news recommendation is a crucial technology for helping users discover news articles tailored to their interests. Key challenges in this field include modeling user preferences based on implicit behaviors, accounting for the influence of the news agenda on user interests, and managing the rapid decay of news items. The ACM RecSys Challenge 2024, organized by Ekstra Bladet, provide a large-scale news dataset for benchmarking news recommendation research. In this paper, we present our solution to the challenge. We propose real-time feedback learning mechanisms to capture users’ immediate interests and explore generative sequence modeling techniques to learn impression-level user behaviors. Furthermore, we develop an ensemble method to combine tree models and deep models to improve recommendation accuracy. Based on this solution, our team (""hrec"") achieved an impressive AUC score of 0.8667 on the final test set, securing the fifth place in the competition.",10.1145/3687151.3687158,https://doi.org/10.1145/3687151.3687158,"New York, NY, USA",Association for Computing Machinery,9798400711275,2024,Enhancing News Recommendation with Real-Time Feedback and Generative Sequence Modeling,"Zhang, Qi and Zhu, Jieming and Sun, Jiansheng and Cai, Guohao and Yu, Ruining and He, Bangzheng and Li, Liangbi",inproceedings,10.1145/3687151.3687158,
10.1145/3690624.3709220,10.1145/3690624.3709220,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","cold-start recommendation, cross-domain recommendation, diffusion models",10,719–728,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1,"Cross-domain recommendation (CDR) has been proven as a promising way to alleviate the cold-start issue, in which the most critical problem is how to draw an informative user representation in the target domain via the transfer of user preference existing in the source domain. Prior efforts mostly follow the embedding-and-mapping paradigm, which first integrate the preference into user representation in the source domain, and then perform a mapping function on this representation to the target domain. However, they focus on mapping features across domains, neglecting to explicitly model the preference integration process, which may lead to learning coarse user representation. Diffusion models (DMs), which contribute to more accurate user/item representations due to their explicit information injection capability, have achieved promising performance in recommendation systems. Nevertheless, these DMs-based methods cannot directly account for valuable user preference in other domains, leading to challenges in adapting to the transfer of preference for cold-start users. Consequently, the feasibility of DMs for CDR remains underexplored. To this end, we explore to utilize the explicit information injection capability of DMs for user preference integration and propose a Preference-Guided Diffusion Model for CDR to cold-start users, termed as DMCDR. Specifically, we leverage a preference encoder to establish the preference guidance signal with the user's interaction history in the source domain. Then, we explicitly inject the preference guidance signal into the user representation step by step to guide the reverse process, and ultimately generate the personalized user representation in the target domain, thus achieving the transfer of user preference across domains. Furthermore, we comprehensively explore the impact of six DMs-based variants on CDR. Extensive experiments on three real-world CDR scenarios demonstrate the superiority of our DMCDR over SOTA methods and six DMs-based variants.",10.1145/3690624.3709220,https://doi.org/10.1145/3690624.3709220,"New York, NY, USA",Association for Computing Machinery,9798400712456,2025,Exploring Preference-Guided Diffusion Model for Cross-Domain Recommendation,"Li, Xiaodong and Tang, Hengzhu and Sheng, Jiawei and Zhang, Xinghua and Gao, Li and Cheng, Suqi and Yin, Dawei and Liu, Tingwen",inproceedings,10.1145/3690624.3709220,
10.1145/3690624.3709250,10.1145/3690624.3709250,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","generative model, multimodal recommendation, quality disparity",12,1337–1348,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1,"With the explosive growth of online multimodal content, multimodal recommender systems(MRSs) have brought significant benefits to multimedia platforms. As MRSs evolve, many studies incorporate advanced technologies like graph neural networks(GNNs) and self-supervised learning(SSL), achieving remarkable results. However, these efforts still suffer from the quality disparity problem. It refers to the mixture of high and low quality across items' multiple modalities, owing to disparities in construction costs or design levels. These low-quality modalities often lack crucial details or introduce noise to the depiction of item, leading to insufficient or polluted item representation. Therefore, we propose a novel framework R2MR: Review and Rewrite Modality for Recommendation to tackle this issue. Specifically, R2MR is composed of two key components: Modality Reviewer and Modality Rewriter. The Modality Reviewer introduces a Consensus Review Mechanism. It performs perspective decomposition based on user representations and learns the consensus quality scores for modalities from diverse perspectives of multiple users. The Modality Rewriter proposes a Latent Mapping Model, which improves the quality of inferior modalities by learning various mapping patterns from high-quality modalities. Comprehensive experiments across three benchmark datasets reveal that R2MR substantially outperforms state-of-the-art methods, achieving an average improvement of 9.20%. The implementations are available at https://github.com/gutang-97/R2MR.",10.1145/3690624.3709250,https://doi.org/10.1145/3690624.3709250,"New York, NY, USA",Association for Computing Machinery,9798400712456,2025,R2MR: Review and Rewrite Modality for Recommendation,"Tang, Gu and Wang, Jinghe and Gan, Xiaoying and Lu, Bin and Zhao, Ze and Fu, Luoyi and Wang, Xinbing and Zhou, Chenghu",inproceedings,10.1145/3690624.3709250,
10.1145/3690624.3709267,10.1145/3690624.3709267,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","attributes, sequential recommendation, transformer, user modeling",12,800–811,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1,"The data on user behaviors is sparse given the vast array of user-item combinations. Attributes related to users (e.g., age), items (e.g., brand), and behaviors (e.g., co-purchase) serve as crucial input sources for item-item transitions of user's behavior prediction. While recent Transformer-based sequential recommender systems learn the attention matrix for each attribute to update item representations, the attention of a specific attribute is optimized by gradients from all input sources, leading to potential information mixture. Besides, Transformers mainly focus on intra-sequence attention for item attributes, neglecting cross-sequence relations and user attributes. Addressing these challenges, we propose the Attribute Transformer (AttrFormer) to learn attributes as explicit relations. This model transforms each type of attribute into an explicit relation defined in the feature space, and it ensures no information mixing among different input sources. Explicit relations introduce cross-sequence and intra-sequence relations. AttrFormer has novel relation-augmented heads to handle them at both the item and behavioral levels, seamlessly integrating the augmented heads into the multi-head attention mechanism. Furthermore, we employ position-to-position aggregation to refine behavior representation for users with similar patterns at the sequence level. To capture the subjective nature of user preferences, AttrFormer is trained using posterior targets where upcoming user behaviors follow a multinomial distribution with a Dirichlet prior. Our evaluations on four popular datasets, including Amazon (Toys &amp; Games and Beauty) and MovieLens (1M and 25M versions), reveal that AttrFormer outperforms leading Transformer baselines, achieving around 20% improvement in NDCG@20 scores. Extensive ablation studies also demonstrate the efficiency of AttrFormer in managing long behavior sequences and inter-sequence relations.",10.1145/3690624.3709267,https://doi.org/10.1145/3690624.3709267,"New York, NY, USA",Association for Computing Machinery,9798400712456,2025,Learning Attribute as Explicit Relation for Sequential Recommendation,"Liu, Gang and Yang, Fan and Jiao, Yang and Bagheri Garakani, Alireza and Tong, Tian and Gao, Yan and Jiang, Meng",inproceedings,10.1145/3690624.3709267,
10.1145/3690624.3709293,10.1145/3690624.3709293,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","large-scale contexts, real-time marketing, uplift modeling",12,1325–1336,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1,"Improving user engagement and platform revenue is crucial for online marketing platforms. Uplift modeling is proposed to solve this problem, which applies different treatments (e.g., discounts, bonus) to satisfy corresponding users. Despite progress in this field, limitations persist. Firstly, most of them focus on scenarios where only user features exist. However, in real-world scenarios, there are rich contexts available in the online platform (e.g., short videos, news), and the uplift model needs to infer an incentive for each user on the specific item, which is called real-time marketing. Thus, only considering the user features will lead to biased prediction of the responses, which may cause the cumulative error for uplift prediction. Moreover, due to the large-scale contexts, directly concatenating the context features with the user features will cause a severe distribution shift in the treatment and control groups. Secondly, capturing the interaction relationship between the user features and context features can better predict the user response. To solve the above limitations, we propose a novel model-agnostic Robust Uplift Modeling with Large-Scale Contexts (UMLC) framework for Real-time Marketing. Our UMLC includes two customized modules. 1) A response-guided context grouping module for extracting context features information and condensing value space through clusters. 2) A feature interaction module for obtaining better uplift prediction. Specifically, this module contains two parts: a user-context interaction component for better modeling the response; a treatment-feature interaction component for discovering the treatment assignment sensitive feature of each instance to better predict the uplift. Moreover, we conduct extensive experiments on a synthetic dataset and a real-world product dataset to verify the effectiveness and compatibility of our UMLC.",10.1145/3690624.3709293,https://doi.org/10.1145/3690624.3709293,"New York, NY, USA",Association for Computing Machinery,9798400712456,2025,Robust Uplift Modeling with Large-Scale Contexts for Real-time Marketing,"Sun, Zexu and Han, Qiyu and Zhu, Minqin and Gong, Hao and Liu, Dugang and Ma, Chen",inproceedings,10.1145/3690624.3709293,
10.1145/3690624.3709299,10.1145/3690624.3709299,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","embedding disentanglement, recommender systems, temporal popularity distribution shifts",11,1833–1843,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1,"Many modern recommender systems represent user and item attributes as embedding vectors, relying on them for accurate recommendations. However, entangled embeddings often capture not only intrinsic property factors (e.g., user interest in item property) but also popularity factors (e.g., user conformity to item popularity) indistinguishably. These embeddings, influenced by popularity distribution, may face challenges when the popularity distribution at test time differs from historical distribution. Existing remedies in the literature involve disentangled embedding learning, which aims to separately capture intrinsic and popularity factors, demonstrating plausible generalization during popularity distribution shifts. However, we highlight that these methods often overlook a crucial aspect of popularity shifts-their temporal nature-in both training and inference phases. To address this, we propose Temporal Popularity distribution shift generalizABle recommender system (TPAB), a novel disentanglement framework incorporating temporal popularity. TPAB introduce a new (1) temporal-aware embedding design for users and items. Within this design, (2) popularity coarsening and (3) popularity bootstrapping are proposed to enhance generalization further. We also provide theoretical analysis showing that the bootstrapping loss eliminates the effect of popularity on the learned model. During inference, we infer test-time popularity and corresponding embeddings, using them alongside property embeddings for prediction. Extensive experiments on real-world datasets validate TPAB, showcasing its outstanding generalization ability during temporal popularity distribution shifts.",10.1145/3690624.3709299,https://doi.org/10.1145/3690624.3709299,"New York, NY, USA",Association for Computing Machinery,9798400712456,2025,Generalizable Recommender System During Temporal Popularity Distribution Shifts,"Yoo, Hyunsik and Qiu, Ruizhong and Xu, Charlie and Wang, Fei and Tong, Hanghang",inproceedings,10.1145/3690624.3709299,
10.1145/3690624.3709308,10.1145/3690624.3709308,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","incomplete multimodal learning, multimedia popularity, multimodal generation, retrieval augmentation",11,142–152,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1,"Micro-video popularity prediction (MVPP) plays a crucial role in numerous real-world applications, including product marketing and recommendation systems. While existing methodologies predominantly assume complete modalities during multimodal learning, this assumption often fails to hold in practical scenarios due to various constraints, such as privacy concerns or data integrity issues. To address this limitation, we propose SCRAG, a novel Self-Correlation Retrieval-Augmented Generative framework designed to enhance missing-modality robustness in MVPP. SCRAG operates in a retrieval-guided generation manner that explores relevant knowledge to enhance the reconstruction of missing content, which consists of two primary components: (1) a self-correlation retriever and (2) a multimodal mixture-of-experts generator. It first acquires instances pertinent to the missing content through multimodal prompt alignment. Subsequently, the generator extracts contextual modal information from the retrieved context-rich instances. By learning the joint distribution of modalities, SCRAG effectively recovers missing content and addresses the modal heterogeneity challenge inherent in cross-modal generation approaches. Extensive experiments conducted on three real-world datasets demonstrate that SCRAG consistently outperforms state-of-the-art baselines, underscoring its effectiveness in handling incomplete modalities and improving the accuracy of micro-video popularity prediction.",10.1145/3690624.3709308,https://doi.org/10.1145/3690624.3709308,"New York, NY, USA",Association for Computing Machinery,9798400712456,2025,Seeing the Unseen in Micro-Video Popularity Prediction: Self-Correlation Retrieval for Missing Modality Generation,"Cheng, Zhangtao and Lang, Jian and Zhong, Ting and Zhou, Fan",inproceedings,10.1145/3690624.3709308,
10.1145/3690624.3709319,10.1145/3690624.3709319,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","cognitive diagnosis, educational data mining, intelligent education",11,402–412,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1,"Cognitive diagnosis is a fundamental task in intelligent education, aiming to measure students' proficiency on knowledge concepts based on practice data. Traditional methods utilize a broadly-defined latent trait θ to represent knowledge proficiency with some cognitive factors like skill or ability. However, existing methods simplify this to a narrowly-defined latent trait θ, which focuses only on knowledge or treats these cognitive factors as implicit features inferred from data. They fail to explicitly model these cognitive factors, resulting in limited performance and interpretability. To this end, we revisit essence of cognition in Educational Psychology Theory and propose a novel Cognition-aware Cognitive Diagnosis (CCD) model, where we first introduce the Cognition factor as a bridge into the long-standing three-basic-factors (Student, Exercise, Knowledge concept) paradigm. CCD has two main parts: cognition representations and a two-stage diagnostic process. In the first part, we explicitly model cognitive process (CP) dimensions from Bloom's Taxonomy of Educational Objectives, leading to two innovative concepts proposed: the student's Subjective Cognitive Ability (SCA) and the exercise's Objective Cognitive Attribute (OCA), derived by regulating the CP through S-K and E-K interactions, respectively. Then, the SCA and OCA are formed into a new cognition-aware latent trait θ. In the second part, we employ a basic interaction function and a slip and guess influence function, inputting our new θ, a continuous Q-matrix (generated by a siamese PLMs), and other features to obtain the ideal result, followed by feeding it into the slip and guess influence function to obtain the actual result. Extensive experiments on real-world datasets demonstrates the superior effectiveness and good interpretability.",10.1145/3690624.3709319,https://doi.org/10.1145/3690624.3709319,"New York, NY, USA",Association for Computing Machinery,9798400712456,2025,Revisiting Cognition in Neural Cognitive Diagnosis,"Gu, Hengnian and Luo, Guoqian and Dong, Xiaoxiao and Li, Shulin and Zhou, Dongdai",inproceedings,10.1145/3690624.3709319,
10.1145/3690624.3709335,10.1145/3690624.3709335,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","device-cloud collaboration, large language model, sequential recommendation",12,962–973,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1,"Large Language Models (LLMs) for Recommendation (LLM4Rec) is a promising research direction that has demonstrated exceptional performance in this field. However, its inability to capture real-time user preferences greatly limits the practical application of LLM4Rec because (i) LLMs are costly to train and infer frequently, and (ii) LLMs struggle to access real-time data (its large number of parameters poses an obstacle to deployment on devices). Fortunately, small recommendation models (SRMs) can effectively supplement these shortcomings of LLM4Rec diagrams by consuming minimal resources for frequent training and inference, and by conveniently accessing real-time data on devices.In light of this, we designed the Device-Cloud LLM-SRM Collaborative Recommendation Framework (LSC4Rec) under a device-cloud collaboration setting. LSC4Rec aims to integrate the advantages of both LLMs and SRMs, as well as the benefits of cloud and edge computing, achieving a complementary synergy. We enhance the practicability of LSC4Rec by designing three strategies: collaborative training, collaborative inference, and intelligent request. During training, LLM generates candidate lists to enhance the ranking ability of SRM in collaborative scenarios and enables SRM to update adaptively to capture real-time user interests. During inference, LLM and SRM are deployed on the cloud and on the device, respectively. LLM generates candidate lists and initial ranking results based on user behavior, and SRM get reranking results based on the candidate list, with final results integrating both LLM's and SRM's scores. The device determines whether a new candidate list is needed by comparing the consistency of the LLM's and SRM's sorted lists. Our comprehensive and extensive experimental analysis validates the effectiveness of each strategy in LSC4Rec.",10.1145/3690624.3709335,https://doi.org/10.1145/3690624.3709335,"New York, NY, USA",Association for Computing Machinery,9798400712456,2025,Collaboration of Large Language Models and Small Recommendation Models for Device-Cloud Recommendation,"Lv, Zheqi and Zhan, Tianyu and Wang, Wenjie and Lin, Xinyu and Zhang, Shengyu and Zhang, Wenqiao and Li, Jiwei and Kuang, Kun and Wu, Fei",inproceedings,10.1145/3690624.3709335,
10.1145/3690624.3709336,10.1145/3690624.3709336,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","cold-start problem, meta-learning, online recommendation, recommender system",11,927–937,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1,"With the rise of e-commerce and short videos, online recommender systems that can capture users' interests and update new items in real-time play an increasingly important role. In both online and offline recommendation systems, the cold-start problem caused by interaction sparsity has been impacting the effectiveness of recommendations for cold-start items. Many cold-start scheme based on fine-tuning or knowledge transferring shows excellent performance on offline recommendation. Yet, these schemes are infeasible for online recommendation on streaming data pipelines due to different training method, computational overhead and time constraints. Inspired by the above questions, we propose a model-agnostic recommendation algorithm called Popularity-Aware Meta-learning (PAM), to address the item cold-start problem under streaming data settings. PAM divides the incoming data into different meta-learning tasks by predefined item popularity thresholds. The model can distinguish and reweight behavior-related and content-related features in each task based on their different roles in different popularity levels, thus adapting to recommendations for cold-start samples. These task-fixing design significantly reduces additional computation and storage costs compared to offline methods. Furthermore, PAM also introduced data augmentation and an additional self-supervised loss specifically designed for low-popularity tasks, leveraging insights from high-popularity samples. This approach effectively mitigates the issue of inadequate supervision due to the scarcity of cold-start samples. Experimental results across multiple public datasets demonstrate the superiority of our approach over other baseline methods in addressing cold-start challenges in online streaming data scenarios.",10.1145/3690624.3709336,https://doi.org/10.1145/3690624.3709336,"New York, NY, USA",Association for Computing Machinery,9798400712456,2025,Online Item Cold-Start Recommendation with Popularity-Aware Meta-Learning,"Luo, Yunze and Jiang, Yuezihan and Jiang, Yinjie and Chen, Gaode and Wang, Jingchi and Bian, Kaigui and Li, Peiyi and Zhang, Qi",inproceedings,10.1145/3690624.3709336,
10.1145/3696410.3714524,10.1145/3696410.3714524,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","direct preference optimization, fairness, homogeneity issue, large language model-based recommendation, self-play",10,5075–5084,Proceedings of the ACM on Web Conference 2025,"Large language models (LLMs) have attracted significant attention in recommendation systems. Current work primarily applies supervised fine-tuning (SFT) to adapt the model for recommendation tasks. However, SFT on positive examples only limits the model's ability to align with user preference. To address this, researchers recently introduced Direct Preference Optimization (DPO), which explicitly aligns LLMs with user preferences using offline preference ranking data. However, we found that DPO inherently biases the model towards a few items, exacerbating the filter bubble issue and ultimately degrading user experience.In this paper, we propose SPRec, a novel self-play framework designed to mitigate over-recommendation and improve fairness without requiring additional data or manual intervention. In each self-play iteration, the model undergoes an SFT step followed by a DPO step, treating offline interaction data as positive samples and the predicted outputs from the previous iteration as negative samples. This effectively re-weights the DPO loss function using the model's logits, adaptively suppressing biased items. Extensive experiments on multiple real-world datasets demonstrate SPRec's effectiveness in enhancing recommendation accuracy and fairness.",10.1145/3696410.3714524,https://doi.org/10.1145/3696410.3714524,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,SPRec: Self-Play to Debias LLM-based Recommendation,"Gao, Chongming and Chen, Ruijun and Yuan, Shuai and Huang, Kexin and Yu, Yuanqing and He, Xiangnan",inproceedings,10.1145/3696410.3714524,
10.1145/3696410.3714530,10.1145/3696410.3714530,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","credit rating, graph neural networks, pre-training, prompt",10,5234–5243,Proceedings of the ACM on Web Conference 2025,"In the global financial market, assessing bank credit ratings is essential for evaluating financial health, managing risk, and safeguarding systemic stability. While risk can transmit rapidly within the interbank lending network, timely incorporation of the latest financial disclosures to update bank ratings is vital in the swiftly evolving financial markets. However, existing approaches primarily conduct credit rating tasks using end-to-end models trained on historical financial data, thereby overlooking the staggered timing of financial disclosure from banks. Limited excavation of the credit rating records and the temporal distribution shifts existed in different financial periods still pose challenges to improving the accuracy of the credit rating tasks. To address these challenges, in this work we propose a Dual Pairwise pre-training and prompt Tuning framework with Aligned Prototypes (DPTAP) for interbank credit rating, which enables dynamic credit updates. Specifically, the dual pairwise pre-training strategy allows the framework to capture direction and distance discrepancies between rating categories. To alleviate the adverse impact of temporal distribution shifts in quarters, the latest financial features are prompted to dynamically map the patterns of the corresponding banks in the last quarter. Furthermore, we integrate rating guides from two consecutive quarters into a set of aligned prototypes to enhance supervision during the prompt tuning process. We conducted extensive experiments on a real-world bank dataset globally in the latest 8 years. The results demonstrate the superiority of our proposed framework over various competitive models, highlighting its notable capabilities in early warning and risk contagion forecasting.",10.1145/3696410.3714530,https://doi.org/10.1145/3696410.3714530,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Dual Pairwise Pre-training and Prompt-tuning with Aligned Prototypes for Interbank Credit Rating,"Tang, Jiehao and Wang, Wenjun and Cheng, Dawei and Zhao, Hui and Jiang, Changjun",inproceedings,10.1145/3696410.3714530,
10.1145/3696410.3714583,10.1145/3696410.3714583,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","explainable recommendation, large language model, personalization, recommender systems, sentiment analysis, transformer",17,4793–4809,Proceedings of the ACM on Web Conference 2025,"Recent research on explainable recommendation generally frames the task as a standard text generation problem, and evaluates models simply based on the textual similarity between the predicted and ground-truth explanations. However, this approach fails to consider one crucial aspect of the systems: whether their outputs accurately reflect the users' (post-purchase) sentiments, i.e., whether and why they would like and/or dislike the recommended items. To shed light on this issue, we introduce new datasets and evaluation methods that focus on the users' sentiments. Specifically, we construct the datasets by explicitly extracting users' positive and negative opinions from their post-purchase reviews using an LLM, and propose to evaluate systems based on whether the generated explanations 1) align well with the users' sentiments, and 2) accurately identify both positive and negative opinions of users on the target items. We benchmark several recent models on our datasets and demonstrate that achieving strong performance on existing metrics does not ensure that the generated explanations align well with the users' sentiments. Lastly, we find that existing models can provide more sentiment-aware explanations when the users' (predicted) ratings for the target items are directly fed into the models as input. The datasets and benchmark implementation are available at: https://github.com/jchanxtarov/sent_xrec.",10.1145/3696410.3714583,https://doi.org/10.1145/3696410.3714583,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation,"Shimizu, Ryotaro and Wada, Takashi and Wang, Yu and Kruse, Johannes and O'Brien, Sean and HtaungKham, Sai and Song, Linxin and Yoshikawa, Yuya and Saito, Yuki and Tsung, Fugee and Goto, Masayuki and McAuley, Julian",inproceedings,10.1145/3696410.3714583,
10.1145/3696410.3714600,10.1145/3696410.3714600,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","embedding-based retrieval, negative sampling, recommendation systems",10,462–471,Proceedings of the ACM on Web Conference 2025,"Industrial recommendation systems typically involve a two-stage process: retrieval and ranking, which aims to match users with millions of items. In the retrieval stage, classic embedding-based retrieval (EBR) methods depend on effective negative sampling techniques to enhance both performance and efficiency. However, existing techniques often suffer from false negatives, high cost for ensuring sampling quality and semantic information deficiency. To address these limitations, we propose Effective and Semantic-Aware Negative Sampling (ESANS), which integrates two key components: Effective Dense Interpolation Strategy (EDIS) and Multimodal Semantic-Aware Clustering (MSAC). EDIS generates virtual samples within the low-dimensional embedding space to improve the diversity and density of the sampling distribution while minimizing computational costs. MSAC refines the negative sampling distribution by hierarchically clustering item representations based on multimodal information (visual, textual, behavioral), ensuring semantic consistency and reducing false negatives. Extensive offline and online experiments demonstrate the superior efficiency and performance of ESANS.",10.1145/3696410.3714600,https://doi.org/10.1145/3696410.3714600,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,ESANS: Effective and Semantic-Aware Negative Sampling for Large-Scale Retrieval Systems,"Xing, Haibo and Matsuyama, Kanefumi and Deng, Hao and Hu, Jinxin and Zhang, Yu and Zeng, Xiaoyi",inproceedings,10.1145/3696410.3714600,
10.1145/3696410.3714635,10.1145/3696410.3714635,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","cold-start user, federated learning, knowledge fusion, recommendation system",10,2700–2709,Proceedings of the ACM on Web Conference 2025,"Federated Recommendation System (FRS) usually offers recommendation services for users while keeping their data locally to ensure privacy. Currently, most FRS literature assumes that fixed users participate in federated training with personal IoT devices (e.g., mobile phones and PC). However, users may join incrementally, and retraining the entire FRS for each new participating user is unfeasible due to the high training costs and the limited global knowledge contribution from a small number of new users. To guarantee the quality service for these new users, we take a dive into the federated recommendation for cold-start users, a novel scenario where the new participating users can directly obtain a promising recommendation without comprehensive training with all participating users by leveraging both transferred knowledge from the converged warm clients and the knowledge learned from the local data.Nevertheless, the efficient transfer of knowledge from warm clients remains controversial. On the one hand, cold clients may introduce new sparse items, resulting in a shift in the item embedding distribution compared to that converged on warm clients. On the other hand, cold-start users need to match similar user information from warm clients for a collaborative recommendation, but directly sharing user information is a violation of privacy and unacceptable. To tackle these challenges, we propose an efficient and privacy-enhanced federated recommendation for cold-start users (FR-CSU) that each client can adaptively transfer both user and item knowledge separately from warm clients and implement recommendations with local and transferred knowledge fusion. Specifically, each cold client will train a mapping function locally to transfer the aligned item embedding. Meanwhile, warm clients will maintain a user prototype network collaboratively that provides privacy-friendly yet effective user information for cold-start users. Then, a linear function system will integrate the transferred and local knowledge to improve recommendations. Extensive experiments show that FR-CSU achieves superior performance compared to state-of-the-art methods.",10.1145/3696410.3714635,https://doi.org/10.1145/3696410.3714635,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Personalized Federated Recommendation for Cold-Start Users via Adaptive Knowledge Fusion,"Li, Yichen and Shan, Yijing and Liu, Yi and Wang, Haozhao and Wang, Wei and Wang, Yi and Li, Ruixuan",inproceedings,10.1145/3696410.3714635,
10.1145/3696410.3714645,10.1145/3696410.3714645,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","box embedding, cognitive diagnosis, learner modeling",12,3660–3671,Proceedings of the ACM on Web Conference 2025,"In digital education, Cognitive Diagnosis (CD) is essential for modeling learners' cognitive states, such as problem-solving ability and knowledge proficiency, by analyzing their response data, like answer correctness. However, traditional CD methods struggle with effectiveness and efficiency. They fail to capture the diversity and uncertainty of learners' cognitive states. Additionally, response prediction can be time-consuming. To address these issues, we propose BoxCD, a contrastive probabilistic box embedding model for cognitive diagnosis. BoxCD utilizes high-dimensional axis-aligned hyper-rectangles (boxes) to represent learners and exercises, with the volume of intersecting boxes used to predict learners' responses. This approach effectively captures semantic diversity and uncertainty while enhancing diagnostic effectiveness. To stabilize box embeddings, we integrate contrastive learning objectives with response prediction goals, optimizing the distance between positive and negative samples of learner and exercise boxes to improve uniformity. Additionally, we develop a rank-based response prediction method that leverages the geometric properties of box embeddings to assess learners' response correctness efficiently. Comprehensive experiments on two real-world datasets demonstrate that BoxCD outperforms traditional CD models in effectiveness and efficiency. This showcases its potential to enhance personalized learning in digital education platforms.",10.1145/3696410.3714645,https://doi.org/10.1145/3696410.3714645,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,BoxCD: Leveraging Contrastive Probabilistic Box Embedding for Effective and Efficient Learner Modeling,"Gao, Weibo and Liu, Qi and Yue, Linan and Yao, Fangzhou and Huang, Zhenya and Zhang, Zheng and Lv, Rui",inproceedings,10.1145/3696410.3714645,
10.1145/3696410.3714668,10.1145/3696410.3714668,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","large language models, movie recommendations, narrative-driven recommendations, prompting strategies, recommender systems",19,4543–4561,Proceedings of the ACM on Web Conference 2025,"Narrative-driven recommenders aim to provide personalized suggestions for user requests expressed in free-form text such as ''I want to watch a thriller with a mind-bending story, like Shutter Island.'' Although large language models (LLMs) have been shown to excel in processing general natural language queries, their effectiveness for handling such recommendation requests remains relatively unexplored. To close this gap, we compare the performance of 38 open- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in a movie recommendation setting. For this, we utilize a gold-standard, crowdworker-annotated dataset of posts from reddit's movie suggestion community and employ various prompting strategies, including zero-shot, identity, and few-shot prompting. Our findings demonstrate the ability of LLMs to generate contextually relevant movie recommendations, significantly outperforming other state-of-the-art approaches, such as doc2vec. While we find that closed-source and large-parameterized models generally perform best, medium-sized open-source models remain competitive, being only slightly outperformed by their more computationally expensive counterparts. Furthermore, we observe no significant differences across prompting strategies for most models, underscoring the effectiveness of simple approaches such as zero-shot prompting for narrative-driven recommendations. Overall, this work offers valuable insights for recommender system researchers as well as practitioners aiming to integrate LLMs into real-world recommendation tools.",10.1145/3696410.3714668,https://doi.org/10.1145/3696410.3714668,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Large Language Models as Narrative-Driven Recommenders,"Eberhard, Lukas and Ruprechter, Thorsten and Helic, Denis",inproceedings,10.1145/3696410.3714668,
10.1145/3696410.3714691,10.1145/3696410.3714691,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","e-commerce, large language models, product reviews, recommender systems",11,2948–2958,Proceedings of the ACM on Web Conference 2025,"Review personalization aims at presenting the most relevant reviews of a product according to the preferences of the individual user. Existing studies of review personalization use the reviews authored by the user as a proxy for their preferences, and henceforth as a means for learning and evaluating personalization quality. In this work, we suggest using review votes rather than authorship for personalization. We propose MAGLLM, an approach that leverages heterogeneous graphs for modeling the relationships among reviews, products, and users, with large language model (LLM) to enrich user representation on the graph. Our evaluation over a unique public dataset that includes user voting information indicates that the vote signal yields substantially higher personalization performance across a variety of recommendation methods and e-commerce domains. It also indicates that our graph-LLM approach outperforms comparative baselines and algorithmic alternatives. We conclude with concrete recommendations for e-commerce platforms seeking to enhance their review personalization experience.",10.1145/3696410.3714691,https://doi.org/10.1145/3696410.3714691,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Graph Meets LLM for Review Personalization based on User Votes,"Hirsch, Sharon and Zitnitski, Lilach and Novgorodov, Slava and Guy, Ido and Shapira, Bracha",inproceedings,10.1145/3696410.3714691,
10.1145/3696410.3714698,10.1145/3696410.3714698,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","coordinated inauthentic behavior, information operations",19,541–559,Proceedings of the ACM on Web Conference 2025,"Coordinated information operations remain a persistent challenge on social media, despite platform efforts to curb them. While previous research has primarily focused on identifying these operations within individual platforms, this study shows that coordination frequently transcends platform boundaries. Leveraging newly collected data of online conversations related to the 2024 U.S. Election across 𝕏 (formerly, Twitter), Facebook, and Telegram, we construct similarity networks to detect coordinated communities exhibiting suspicious sharing behaviors within and across platforms. Proposing an advanced coordination detection model, we reveal evidence of potential foreign interference, with Russian-affiliated media being systematically promoted across Telegram and 𝕏. Our analysis also uncovers substantial intra- and cross-platform coordinated inauthentic activity, driving the spread of highly partisan, low-credibility, and conspiratorial content. These findings highlight the urgent need for regulatory measures that extend beyond individual platforms to effectively address the growing challenge of cross-platform coordinated influence campaigns.",10.1145/3696410.3714698,https://doi.org/10.1145/3696410.3714698,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Exposing Cross-Platform Coordinated Inauthentic Activity in the Run-Up to the 2024 U.S. Election,"Cinus, Federico and Minici, Marco and Luceri, Luca and Ferrara, Emilio",inproceedings,10.1145/3696410.3714698,
10.1145/3696410.3714712,10.1145/3696410.3714712,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","dynamic link prediction, graph learning, network science",10,4101–4110,Proceedings of the ACM on Web Conference 2025,"Dynamic link prediction aims to predict the future links on dynamic graphs, which can be applied to wide scenarios such as recommender systems and social networks on the World Wide Web. Existing methods mainly (1) focus on the in-graph learning, which cannot generalize to graphs unobserved during training; or (2) achieve the cross-graph predictions in a many-many mechanism by training on multiple graphs across various domains, which results in a large computational cost. In this paper, we propose a cross-graph dynamic link predictor named CrossDyG, which achieves the cross-graph transferability in a one-many mechanism which trains on one single source graph and test on different target graphs. Specifically, we provide causal and empirical analysis on the structural bias caused by the graph-specific structural characteristics in cross-graph predictions. Then, we conduct deconfounded training to learn the universal network evolution pattern from one single source graph during training. Finally, we apply the causal intervention to leverage the graph-specific structural characteristics of each target graph during inference. Extensive experiments conducted on three benchmark data of dynamic graphs demonstrate that CrossDyG outperforms the state-of-the-art baselines by up to 11.01% and 17.02% in terms of AP and AUC, respectively. In addition, the improvements are especially significant when training on small source graphs.",10.1145/3696410.3714712,https://doi.org/10.1145/3696410.3714712,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,On the Cross-Graph Transferability of Dynamic Link Prediction,"Pan, Zhiqiang and Gao, Chen and Cai, Fei and Chen, Wanyu and Zhang, Xin and Chen, Honghui and Li, Yong",inproceedings,10.1145/3696410.3714712,
10.1145/3696410.3714759,10.1145/3696410.3714759,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","evaluation, large language model, recommendation",13,3850–3862,Proceedings of the ACM on Web Conference 2025,"With the rapid development of Large Language Models (LLMs), recent studies employed LLMs as recommenders to provide personalized information services for distinct users. Despite efforts to improve the accuracy of LLM-based recommendation models, relatively little attention is paid to beyond-utility dimensions. Moreover, there are unique evaluation aspects of LLM-based recommendation models, which have been largely ignored. To bridge this gap, we explore four new evaluation dimensions and propose a multidimensional evaluation framework. The new evaluation dimensions include: 1) history length sensitivity, 2) candidate position bias, 3) generation-involved performance, and 4) hallucinations. All four dimensions have the potential to impact performance, but are largely unnecessary for consideration in traditional systems. Using this multidimensional evaluation framework, along with traditional aspects, we evaluate the performance of seven LLM-based recommenders, with three prompting strategies, comparing them with six traditional models on both ranking and re-ranking tasks on four datasets. We find that LLMs excel at handling tasks with prior knowledge and shorter input histories in the ranking setting, and perform better in the re-ranking setting, beating traditional models across multiple dimensions. However, LLMs exhibit substantial candidate position bias issues, and some models hallucinate nonexistent items much more often than others. We intend our evaluation framework and observations to benefit future research on the use of LLMs as recommenders. The code and data are available at https://github.com/JiangDeccc/EvaLLMasRecommender.",10.1145/3696410.3714759,https://doi.org/10.1145/3696410.3714759,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Beyond Utility: Evaluating LLM as Recommender,"Jiang, Chumeng and Wang, Jiayin and Ma, Weizhi and Clarke, Charles L. A. and Wang, Shuai and Wu, Chuhan and Zhang, Min",inproceedings,10.1145/3696410.3714759,
10.1145/3696410.3714764,10.1145/3696410.3714764,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","benchmark, large vision language model, multimodal recommendation",18,275–292,Proceedings of the ACM on Web Conference 2025,"As multimedia content continues to grow on the web, the integration of visual and textual data has become a crucial challenge for web applications, particularly in recommendation systems. Large Vision Language Models (LVLMs) have demonstrated considerable potential in addressing this challenge across various tasks that require such multimodal integration. However, their application in multimodal sequential recommendation (MSR) has not been extensively studied. To bridge this gap, we introduce MSRBench, the first comprehensive benchmark designed to systematically evaluate different LVLM integration strategies in web-based recommendation scenarios. We benchmark three state-of-the-art LVLMs, i.e., GPT-4 Vision, GPT-4o, and Claude-3-Opus, on the next item prediction task using the constructed Amazon Review Plus dataset, which includes additional item descriptions generated by LVLMs. Our evaluation examines five integration strategies: using LVLMs as recommender, item enhancer, reranker, and various combinations of these roles. The benchmark results reveal that 1) using LVLMs as rerankers is the most effective strategy, significantly outperforming others that rely on LVLMs to directly generate recommendations or only enhance items; 2) GPT-4o consistently achieves the best performance across most scenarios, particularly when employed as a reranker; 3) the computational inefficiency of LVLMs presents a major barrier to their widespread adoption in real-time multimodal recommendation systems. Our code and datasets are available at https://github.com/PALIN2018/MSRBench.",10.1145/3696410.3714764,https://doi.org/10.1145/3696410.3714764,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,When Large Vision Language Models Meet Multimodal Sequential Recommendation: An Empirical Study,"Zhou, Peilin and Liu, Chao and Ren, Jing and Zhou, Xinfeng and Xie, Yueqi and Cao, Meng and Rao, Zhongtao and Huang, You-Liang and Chong, Dading and Liu, Junling and Kim, Jae Boum and Wang, Shoujin and Wong, Raymond Chi-Wing and Kim, Sunghun",inproceedings,10.1145/3696410.3714764,
10.1145/3696410.3714789,10.1145/3696410.3714789,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","caching., cdn performance, leo satellite networks",11,740–750,Proceedings of the ACM on Web Conference 2025,"In this paper, we perform a systematic study to explore a pivotal problem facing the web community: is current distributed web cache ready for future satellite Internet? First, through a worldwide performance measurement based on the RIPE Atlas platform and Starlink, the largest low-earth orbit (LEO) satellite network (LSN) today, we identify that the uneven deployment of current distributed cache servers, inter-ISP meandering routes and the last-mile congestion on LEO links jointly prevent existing terrestrial web cache from providing low-latency web access for users in emerging LSNs. Second, we propose Spache, a novel web caching system which addresses the limitations of existing ground-only cache by exploiting a bold idea: integrating web cache into LEO satellites to achieve ubiquitous and low-latency web services. Specifically, Spache leverages a key feature of LSNs called communication schedule to efficiently prefetch web contents on satellites, and adopts a schedule-driven partitioning strategy to avoid cache pollution involved by LEO mobility. Finally, we implement a prototype of Spache, and evaluate it based on real-world HTTP traces and data-driven LSN simulation. Extensive evaluations demonstrate that as compared to existing distributed caching solutions, Spache can improve cache hit ratio by 19.8% on average, reduce latency by up to 17.7%, and maintains consistently low web browsing latency for global LSN users.",10.1145/3696410.3714789,https://doi.org/10.1145/3696410.3714789,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Spache: Accelerating Ubiquitous Web Browsing via Schedule-Driven Space Caching,"Zhang, Qi and Wu, Qian and Lai, Zeqi and Li, Jihao and Li, Hewu and Liu, Yuyu and Li, Yuanjie and Liu, Jun",inproceedings,10.1145/3696410.3714789,
10.1145/3696410.3714848,10.1145/3696410.3714848,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","distributionally robust optimization, graph recommendation, out-of-distribution",14,2018–2031,Proceedings of the ACM on Web Conference 2025,"The distributionally robust optimization (DRO)-based graph neural network methods improve recommendation systems' out-of-distribution (OOD) generalization by optimizing the model's worst-case performance. However, these studies fail to consider the impact of noisy samples in the training data, which results in diminished generalization capabilities and lower accuracy. Through experimental and theoretical analysis, this paper reveals that current DRO-based graph recommendation methods assign greater weight to noise distribution, leading to model parameter learning being dominated by it. When the model overly focuses on fitting noise samples in the training data, it may learn irrelevant or meaningless features that cannot be generalized to OOD data. To address this challenge, we design a Distributionally Robust Graph model for OOD recommendation (DRGO). Specifically, our method first employs a simple and effective diffusion paradigm to alleviate the noisy effect in the latent space. Additionally, an entropy regularization term is introduced in the DRO objective function to avoid extreme sample weights in the worst-case distribution. Finally, we provide a theoretical proof of the generalization error bound of DRGO as well as a theoretical analysis of how our approach mitigates noisy sample effects, which helps to better understand the proposed framework from a theoretical perspective. We conduct extensive experiments on four datasets to evaluate the effectiveness of our framework against three typical distribution shifts, and the results demonstrate its superiority in both independently and identically distributed distributions (IID) and OOD.",10.1145/3696410.3714848,https://doi.org/10.1145/3696410.3714848,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Distributionally Robust Graph Out-of-Distribution Recommendation via Diffusion Model,"Zhao, Chu and Yang, Enneng and Liang, Yuliang and Zhao, Jianzhe and Guo, Guibing and Wang, Xingwei",inproceedings,10.1145/3696410.3714848,
10.1145/3696410.3714849,10.1145/3696410.3714849,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","distributionally robust optimization, graph recommendation, out-of-distribution",13,334–346,Proceedings of the ACM on Web Conference 2025,"Graph Neural Networks (GNNs)-based recommendation algorithms typically assume that training and testing data are drawn from independent and identically distributed (IID) spaces. However, this assumption often fails in the presence of out-of-distribution (OOD) data, resulting in significant performance degradation. In this study, we construct a Structural Causal Model (SCM) to analyze interaction data, revealing that environmental confounders (e.g., the COVID-19 pandemic) lead to unstable correlations in GNN-based models, thus impairing their generalization to OOD data. To address this issue, we propose a novel approach, graph representation learning via causal diffusion (CausalDiffRec) for OOD recommendation. This method enhances the model's generalization on OOD data by eliminating environmental confounding factors and learning invariant graph representations. Specifically, we use backdoor adjustment and variational inference to infer the real environmental distribution, thereby eliminating the impact of environmental confounders. This inferred distribution is then used as prior knowledge to guide the representation learning in the reverse phase of the diffusion process to learn the invariant representation. In addition,we provide a theoretical derivation that proves optimizing the objective function of CausalDiffRec can encourage the model to learn environment-invariant graph representations, thereby achieving excellent generalization performance in recommendations under distribution shifts. Our extensive experiments validate the effectiveness of CausalDiffRec in improving the generalization of OOD data, and the average improvement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and 11.65% on Douban datasets.",10.1145/3696410.3714849,https://doi.org/10.1145/3696410.3714849,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation,"Zhao, Chu and Yang, Enneng and Liang, Yuliang and Lan, Pengxiang and Liu, Yuting and Zhao, Jianzhe and Guo, Guibing and Wang, Xingwei",inproceedings,10.1145/3696410.3714849,
10.1145/3696410.3714860,10.1145/3696410.3714860,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","cross-domain recommendation, domain adaptation, multi-modal cross-domain recommendation, optimal transport",12,2882–2893,Proceedings of the ACM on Web Conference 2025,"Cross-Domain Recommendation (CDR) has been widely investi- gated for solving long-standing data sparsity problem via knowl- edge sharing across domains. In this paper, we focus on the Multi- Modal Cross-Domain Recommendation (MMCDR) problem where different items have multi-modal information while few users are overlapped across domains. MMCDR is particularly challenging in two aspects: fully exploiting diverse multi-modal information within each domain and leveraging useful knowledge transfer across domains. However, previous methods fail to cluster items with similar characteristics while filtering out inherit noises within different modalities, hurdling the model performance. What is worse, conventional CDR models primarily rely on overlapped users for domain adaptation, making them ill-equipped to handle scenarios where the majority of users are non-overlapped. To fill this gap, we propose Joint Similarity Item Exploration and Overlapped User Guidance (SIEOUG) for solving the MMCDR problem. SIEOUG first proposes similarity item exploration module, which not only obtains pair-wise and group-wise item-item graph knowledge, but also reduces irrelevant noise for multi-modal modeling. Then SIEOUG proposes user-item collaborative filtering module to aggregate user/item embeddings with the attention mechanism for collaborative filtering. Finally SIEOUG proposes overlapped user guidance module with optimal user matching for knowledge sharing across domains. Our empirical study on Amazon dataset with several different tasks demonstrates that SIEOUG significantly outperforms the state-of-the-art models under the MMCDR setting.",10.1145/3696410.3714860,https://doi.org/10.1145/3696410.3714860,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Joint Similarity Item Exploration and Overlapped User Guidance for Multi-Modal Cross-Domain Recommendation,"Liu, Weiming and Chen, Chaochao and Xu, Jiahe and Liao, Xinting and Wang, Fan and Zheng, Xiaolin and Fu, Zhihui and Pei, Ruiguang and Wang, Jun",inproceedings,10.1145/3696410.3714860,
10.1145/3696410.3714934,10.1145/3696410.3714934,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","community notes, crowd-sourced fact-checking, misinformation",11,3751–3761,Proceedings of the ACM on Web Conference 2025,"X's Community Notes, a crowd-sourced fact-checking system, allows users to annotate potentially misleading posts. Notes rated as helpful by a diverse set of users are prominently displayed below the original post. While demonstrably effective at reducing misinformation's impact when notes are displayed, there is an opportunity for notes to appear on many more posts: for 91% of posts where at least one note is proposed, no notes ultimately achieve sufficient support from diverse users to be shown on the platform. This motivates the development of Supernotes: AI-generated notes that synthesize information from several existing community notes and are written to foster consensus among a diverse set of users. Our framework uses an LLM to generate many diverse Supernote candidates from existing proposed notes. These candidates are then evaluated by a novel scoring model, trained on millions of historical Community Notes ratings, selecting candidates that are most likely to be rated helpful by a diverse set of users. To test our framework, we ran a human subjects experiment in which we asked participants to compare the Supernotes generated by our framework to the best existing community notes for 100 sample posts. We found that participants rated the Supernotes as significantly more helpful, and when asked to choose between the two, preferred the Supernotes 75.2% of the time. Participants also rated the Supernotes more favorably than the best existing notes on quality, clarity, coverage, context, and argumentativeness. Finally, in a follow-up experiment, we asked participants to compare the Supernotes against LLM-generated summaries and found that the participants rated the Supernotes significantly more helpful, demonstrating that both the LLM-based candidate generation and the consensus-driven scoring play crucial roles in creating notes that effectively build consensus among diverse users.",10.1145/3696410.3714934,https://doi.org/10.1145/3696410.3714934,"New York, NY, USA",Association for Computing Machinery,9798400712746,2025,Supernotes: Driving Consensus in Crowd-Sourced Fact-Checking,"De, Soham and Bakker, Michiel A. and Baxter, Jay and Saveski, Martin",inproceedings,10.1145/3696410.3714934,
10.1145/3701551.3703505,10.1145/3701551.3703505,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","boosting, collaborative filtering, model biases, recommender systems",10,222–231,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"Collaborative Filtering (CF) based recommenders often exhibit model biases, delivering strong recommendation utility to certain users or items at the expense of others. Prior research approaches these biases as isolated and standalone issues, ignoring their interconnected nature and developing separate methods, thereby compromising the specialized debiasing efforts. Thus, we introduce a boosting-based framework designed to alleviate a broad spectrum of biases. This framework employs a series of sub-models, each tailored for different user and item subgroups. Theoretically, our model ensures an exponentially decreasing upper bound on the training loss across all user and item types with increasing boosting iterations. Extensive experiments demonstrate its superior debiasing capabilities against state-of-the-art methods across four model bias types. Appendix, data and code are available at https://github.com/JP-25/CFBoost",10.1145/3701551.3703505,https://doi.org/10.1145/3701551.3703505,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,Combating Heterogeneous Model Biases in Recommendations via Boosting,"Pan, Jinhao and Caverlee, James and Zhu, Ziwei",inproceedings,10.1145/3701551.3703505,
10.1145/3701551.3703522,10.1145/3701551.3703522,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","collaborative filtering, contrastive learning, negative sampling, recommender systems, score-based generative models",10,419–428,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"Graph-based collaborative filtering (CF) has emerged as a promising approach in recommender systems. Despite its achievements, graph-based CF models face challenges due to data sparsity and negative sampling. In this paper, we propose a novel Stochastic sampling for i) COntrastive views and ii) hard NEgative samples (SCONE) to overcome these issues. SCONE generates dynamic augmented views and diverse hard negative samples via a unified stochastic sampling approach based on score-based generative models. Our extensive experiments on 6 benchmark datasets show that SCONE consistently outperforms state-of-the-art baselines. SCONE shows efficacy in addressing user sparsity and item popularity issues, while enhancing performance for both cold-start users and long-tail items. Furthermore, our approach improves the diversity of the recommendation and the uniformity of the representations. The code is available at https://github.com/jeongwhanchoi/SCONE.",10.1145/3701551.3703522,https://doi.org/10.1145/3701551.3703522,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,SCONE: A Novel Stochastic Sampling to Generate Contrastive Views and Hard Negative Samples for Recommendation,"Lee, Chaejeong and Choi, Jeongwhan and Wi, Hyowon and Cho, Sung-Bae and Park, Noseong",inproceedings,10.1145/3701551.3703522,
10.1145/3701551.3703535,10.1145/3701551.3703535,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","cross domain recommendation, negative sampling, recommender system, sequential recommendation",9,669–677,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"Negative sampling plays a crucial role for cross-domain recommendation as it provides contrastive signals to learn user preference. Existing methods usually select items with high predicted scores or popularity as hard negative samples to improve model training. However, such methods suffer from choosing false negative samples since items with high predicted scores or popularity could also indicate potential positive user preference. Although several studies devoted to discovering true negative samples, few of them leverage user cross-domain behaviors to alleviate the false negative issue. How to effectively mine and utilize hard negative samples to improve cross-domain recommendation remains an open question.In this work, we propose exploration and exploitation of hard negative samples (EXHANS) for cross-domain sequential recommendation. For better exploration, we utilize the user preference from the source domain to guide negative sampling in the target domain. The key idea is that compared with hard negative samples, false negative samples have higher probability to be consistent with the user preference in both domains. Besides, we propose adaptive popularity-based score correction to account for users' different tastes of popular items. The idea is that for users who favor popular items, such items are more likely to be false negatives rather than hard negatives. For better exploitation, we design a replay buffer to cache the obtained negative samples and further propose a curriculum learning framework to balance exploration and exploitation of hard negative samples. Extensive experiments on three real-world datasets show that our method significantly outperforms state-of-the-art negative sampling methods for cross-domain sequential recommendation, which verify the effectiveness of EXHANS.",10.1145/3701551.3703535,https://doi.org/10.1145/3701551.3703535,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,Exploration and Exploitation of Hard Negative Samples for Cross-Domain Sequential Recommendation,"Wang, Yidan and Ge, Xuri and Chen, Xin and Xie, Ruobing and Yan, Su and Zhang, Xu and Chen, Zhumin and Ma, Jun and Xin, Xin",inproceedings,10.1145/3701551.3703535,
10.1145/3701551.3703544,10.1145/3701551.3703544,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","information retrieval, query generation, scientific document search",10,895–904,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"In specialized fields like the scientific domain, constructing large-scale human-annotated datasets poses a significant challenge due to the need for domain expertise. Recent methods have employed large language models to generate synthetic queries, which serve as proxies for actual user queries. However, they lack control over the content generated, often resulting in incomplete coverage of academic concepts in documents. We introduce Concept Coverage-based Query set Generation (CCQGen) framework, designed to generate a set of queries with comprehensive coverage of the document's concepts. A key distinction of CCQGen is that it adaptively adjusts the generation process based on the previously generated queries. We identify concepts not sufficiently covered by previous queries, and leverage them as conditions for subsequent query generation. This approach guides each new query to complement the previous ones, aiding in a thorough understanding of the document. Extensive experiments demonstrate that CCQGen significantly enhances query quality and retrieval performance.",10.1145/3701551.3703544,https://doi.org/10.1145/3701551.3703544,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,Improving Scientific Document Retrieval with Concept Coverage-based Query Set Generation,"Kang, SeongKu and Jin, Bowen and Kweon, Wonbin and Zhang, Yu and Lee, Dongha and Han, Jiawei and Yu, Hwanjo",inproceedings,10.1145/3701551.3703544,
10.1145/3701551.3703554,10.1145/3701551.3703554,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","linear item-item models, sequential recommendation, temporal information",9,354–362,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"In sequential recommendation (SR), neural models have been actively explored due to their remarkable performance, but they suffer from inefficiency inherent to their complexity. Linear SR models exhibit high efficiency and achieve competitive or superior accuracy compared to neural models. However, they solely deal with the sequential order of items (i.e., sequential information) and overlook the actual timestamp (i.e., temporal information). It is limited to effectively capturing various user preference drifts over time. To address this issue, we propose a novel linear SR model, named TemporAl LinEar item-item model (TALE), incorporating temporal information while preserving training/inference efficiency. It consists of three key components. (i) Single-target augmentation concentrates on a single target item, enabling us to learn the temporal correlation for the target item. (ii) Time interval-aware weighting utilizes the actual timestamp to discern the item correlation depending on time intervals. (iii) Trend-aware normalization reflects the dynamic shift of item popularity over time. Our empirical studies show that TALE outperforms ten competing SR models by up to 18.71% gains across five benchmark datasets. It also exhibits remarkable effectiveness for evaluating long-tail items by up to 30.45% gains. The source code is available at https://github.com/psm1206/TALE.",10.1145/3701551.3703554,https://doi.org/10.1145/3701551.3703554,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,Temporal Linear Item-Item Model for Sequential Recommendation,"Park, Seongmin and Yoon, Mincheol and Choi, Minjin and Lee, Jongwuk",inproceedings,10.1145/3701551.3703554,
10.1145/3701551.3703564,10.1145/3701551.3703564,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","diversified recommendation, sequential recommendation",9,811–819,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"When we sequentially recommend top-k items to users, how can we recommend them diversely while maintaining accuracy? Aggregate-level diversity is an important topic in recommender system since it is essential to maximize the potential profit of platforms by exposing a variety of items to users. However, previous studies do not consider the order of users receiving recommendations and assume that all users receive recommendations at once. In reality, users do not simultaneously receive recommendations so the preferences of the latter users are not given during recommending to the former users. In this work, we introduce the problem of sequentially diversified recommendation and propose SAPID, an accurate method to address the problem. SAPID removes the popularity bias from the model through a negative sampling mechanism based on temporal popularities. Then, SAPID collects candidate items to recommend based on the distribution of preference scores. Finally, SAPID decides which items to recommend immediately or later according to their estimated exposure opportunities. Extensive experiments show that SAPID shows the state-of-the-art performance in real-world datasets by achieving up to 61.0% increased diversity with 38.9% higher accuracy compared to the second-best competitor.",10.1145/3701551.3703564,https://doi.org/10.1145/3701551.3703564,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,Sequentially Diversified and Accurate Recommendations in Chronological Order for a Series of Users,"Kim, Jongjin and Kang, U",inproceedings,10.1145/3701551.3703564,
10.1145/3701551.3703567,10.1145/3701551.3703567,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","click-through rate prediction, contrastive learning, correlation networks, factor graph",9,876–884,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"Predicting click-through rates is crucial in various fields, including online advertising and recommendation systems. The key to improving the performance of CTR prediction lies in learning a robust user representation, particularly by analyzing their historical behaviors. Previous studies usually model behavior sequences through attention-based sequence models or graph-based methods, which usually struggle to explore diverse latent interests or accurately model user behaviors. Moreover, this challenge is exacerbated when users' historical behaviors are sparse, a common issue in real-world business-to-business (B2B) e-commerce scenarios. In this paper, we propose a novel Graph-Enhanced Interest Network (GEIN) to capture users' latent intents and facilitate the sequential learning of sparse behavior sequences. Specifically, we first construct a hierarchical item-intent heterogeneous graph to enrich the representation of sparse behaviors using diverse information from graphs. Next, we build a user-level behavior interest factor graph to accurately capture user interests. Additionally, a contrastive learning mechanism is incorporated to mitigate the negative robustness impacts caused by sparsity. Extensive experiments on real-world datasets demonstrate that our proposed GEIN outperforms a wide range of state-of-the-art methods. Furthermore, online A/B testing also confirms the superiority of GEIN over competing baselines in a real-world production environment.",10.1145/3701551.3703567,https://doi.org/10.1145/3701551.3703567,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,Improving CTR Prediction with Graph-Enhanced Interest Networks for Sparse Behavior Sequences,"Liu, Xuanzhou and Xiao, Zhibo and Yang, Luwei and Xue, Hansheng and Ma, Jianxing and Yang, Yujiu",inproceedings,10.1145/3701551.3703567,
10.1145/3701551.3703573,10.1145/3701551.3703573,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","conversational recommendation, large language model",10,866–875,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"Large Language Models (LLMs) are revolutionizing conversational recommender systems (CRS) by effectively indexing item content, understanding complex conversational contexts, and generating relevant item titles. However, the autoregressive nature of LLMs, which outputs item titles as a long sequence of subtokens, hinders the ability to efficiently obtain and control recommendations across the entire item set. This challenge in calculating probabilities over all items limits LLMs' potential, such as (1) limiting control over recommendation popularities and (2) preventing the synergy of marrying LLMs and traditional recommender systems (RecSys).To address this challenge, we propose the Reindex-Then-Adapt (RTA) framework. It consists of two steps: (1) Reindex: a lightweight network learns to condense multi-token item titles into single tokens within the LLM and distills LLM-generated recommendations as ranked lists. This bypasses the autoregressive nature of LLMs while trying to preserve their CRS abilities; (2) Adapt: LLMs after reindexing enable efficient adjustment of probability distributions over single-token titles, further enhanced through RecSys integration. RTA bridges the strengths of LLMs and RecSys, enabling understanding of complex queries as LLMs do, while efficiently controlling recommended item distributions as in traditional RecSys. We show the effectiveness of our RTA over base LLMs across three CRS datasets with negligible additional parameters.",10.1145/3701551.3703573,https://doi.org/10.1145/3701551.3703573,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation,"He, Zhankui and Xie, Zhouhang and Steck, Harald and Liang, Dawen and Jha, Rahul and Kallus, Nathan and McAuley, Julian",inproceedings,10.1145/3701551.3703573,
10.1145/3701551.3703579,10.1145/3701551.3703579,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","popularity bias, recommender system",10,659–668,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"Recommendation Systems (RS) are often plagued by popularity bias. When training a recommendation model on a typically long-tailed dataset, the model tends to not only inherit this bias but often exacerbate it, resulting in over-representation of popular items in the recommendation lists. This study conducts comprehensive empirical and theoretical analyses to expose the root causes of this phenomenon, yielding two core insights: 1) Item popularity is memorized in the principal spectrum of the score matrix predicted by the recommendation model; 2) The dimension reduction phenomenon amplifies the relative prominence of the principal spectrum, thereby intensifying the popularity bias. Building on these insights, we propose a novel debiasing strategy that leverages a spectral norm regularizer to penalize the magnitude of the principal singular value. We have developed an efficient algorithm to expedite the calculation of the spectral norm by exploiting the spectral property of the score matrix. Extensive experiments across seven real-world datasets and three testing paradigms have been conducted to validate the superiority of the proposed method.",10.1145/3701551.3703579,https://doi.org/10.1145/3701551.3703579,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,How Do Recommendation Models Amplify Popularity Bias? An Analysis from the Spectral Perspective,"Lin, Siyi and Gao, Chongming and Chen, Jiawei and Zhou, Sheng and Hu, Binbin and Feng, Yan and Chen, Chun and Wang, Can",inproceedings,10.1145/3701551.3703579,
10.1145/3701551.3703589,10.1145/3701551.3703589,WSDM.bib,1,['WSDM.bib'],8,WSDM '25,"Hannover, Germany","diffusion prediction, graph neural network, neural architecture search, rumor detection",9,568–576,Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,"Early rumor detection is crucial for mitigating the widespread dissemination of misinformation. Existing methods predominantly rely on complete rumor diffusion graphs, which are challenging to obtain in real-world scenarios, complicating early detection efforts. To address this challenge, we propose D2, a two-stage framework for early rumor Detection, integrating cascade Diffusion prediction. This framework aims to enhance early rumor detection by incorporating diffusion prediction capabilities. Specifically, a dynamic heterogeneous graph neural network (GNN) is developed to jointly model users' social and propagation graphs, enabling accurate prediction of potential diffusion paths using limited observed data within short time windows. The inferred diffusion paths are then integrated with early-stage data, and GNNs are employed for graph classification. However, the varying data distributions across different social media platforms necessitate extensive tuning to optimize GNN architectures. To facilitate the detection of rumor diffusion graphs at the initial stages, a search space is designed across four dimensions- aggregation, merge, readout, and sequence functions-encompassing various GNN architectures. Subsequently, D2 employs an efficient differentiable search algorithm to identify high-performance GNNs within this search space. Experimental results on real social media datasets demonstrate that this approach significantly improves both the accuracy and robustness of early rumor detection.",10.1145/3701551.3703589,https://doi.org/10.1145/3701551.3703589,"New York, NY, USA",Association for Computing Machinery,9798400713293,2025,D2: Customizing Two-Stage Graph Neural Networks for Early Rumor Detection through Cascade Diffusion Prediction,"Xu, Haowei and Gao, Chao and Li, Xianghua and Wang, Zhen",inproceedings,10.1145/3701551.3703589,
10.1145/3701716.3715198,10.1145/3701716.3715198,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","digital marketing, explainable ai, large language models, marketing strategy",4,2823–2826,Companion Proceedings of the ACM on Web Conference 2025,"In this demonstration, we present SOEX, an advanced AI system tailored for enhancing online marketing through the strategic use of large language models and predictive analytics. SOEX excels in analyzing vast amounts of online content data, enabling marketers to effectively plan and refine their strategies by extracting and utilizing key insights from competitor content and market trends. The system specializes in identifying content pillars-such as target audiences, consumer needs, and product features-and leveraging these pillars to generate detailed customer personas and narratives. By focusing on the initial stages of marketing, such as strategic planning and content pillar analysis, SOEX helps marketers understand and segment their audience more precisely. The system's ability to generate data-driven stories and personas from analyzed content enhances the planning phase of marketing campaigns, ensuring that strategies are both impactful and aligned with audience expectations. Our evaluations show that SOEX significantly aids marketers in navigating and interpreting complex data, leading to more informed decision-making and optimized marketing planning.",10.1145/3701716.3715198,https://doi.org/10.1145/3701716.3715198,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,SOEX: Explainable AI for Competitor Communications Analytics,"Farseev, Aleks and Nikolenko, Sergey and Yang, Qi and Lepikhin, Kirill and You, Da-Min and Chu-Farseeva, Yu-Yi and Gossoudarev, Ilia and Ongpin, Marlo",inproceedings,10.1145/3701716.3715198,
10.1145/3701716.3715234,10.1145/3701716.3715234,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","id representation, large language model, recommender systems",10,641–650,Companion Proceedings of the ACM on Web Conference 2025,"Recently, large language models (LLMs) have shown great potential in recommendation systems (RS), however, there are still challenges in applying LLMs to large-scale RS. One major challenge is to effectively transform unique identities (IDs) in RS into a suitable training space for LLMs. Current approaches either lack collaborative signals of user behaviors, or they represent IDs with a single token, which fail to align with the autoregressive paradigm of LLMs. Consequently, the potential of IDs is not fully utilized in LLMs for recommendation, particularly in large-scale systems with numerous users, items, and sparse interactions. On the other hand, when enhancing large-scale RS, the high-dimensional representations from the last hidden layer of LLMs pose difficulties for meeting the low-latency requirements. In this paper, we propose a Hierarchical sequence ID representation method for applying LLMs to Recommender systems, called HI-RecM. Specifically, we design a tree-based ID encoding method that generates hierarchical sequence indices, then we embed the indices token-by-token into LLMs to align LLMs' autoregressive training paradigm. We design a joint dimension reduction (JDR) module to efficiently extract information, enabling lossless dimension reduction of high-dimensional LLM representations. Extensive experiments show that our method can outperform state-of-the-art methods. Moreover, HI-Rec has been deployed on Kuaishou's online advertising platform, achieving 2.1% increase of revenue. We also release the implementation code in https://github.com/Rita-73/HI-Rec.",10.1145/3701716.3715234,https://doi.org/10.1145/3701716.3715234,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,Hierarchical Sequence ID Representation of Large Language Models for Large-scale Recommendation Systems,"Zhao, Rui and Zhong, Rui and Zheng, Haoran and Yang, Wei and Lu, Chi and Jin, Beihong and Jiang, Peng and Gai, Kun",inproceedings,10.1145/3701716.3715234,
10.1145/3701716.3715486,10.1145/3701716.3715486,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","conversational recommendation, large language models",5,878–882,Companion Proceedings of the ACM on Web Conference 2025,"Conversational recommendation systems (CRS) leverage contextual information from conversations to generate recommendations but often struggle due to a lack of collaborative filtering (CF) signals, which capture user-item interaction patterns essential for accurate recommendations. We introduce Reddit-ML32M, a dataset that links Reddit conversations with interactions on MovieLens 32M, to enrich item representations by leveraging collaborative knowledge and addressing interaction sparsity in conversational datasets. We propose an LLM-based framework that uses Reddit-ML32M to align LLM-generated recommendations with CF embeddings, refining rankings for better performance. We evaluate our framework against three sets of baselines: CF-based recommenders using only interactions from CRS tasks, traditional CRS models, and LLM-based methods relying on conversational context without item representations. Our approach achieves consistent improvements, including a 12.32% increase in Hit Rate and a 9.9% improvement in NDCG, outperforming the best-performing baseline that relies on conversational context but lacks collaborative item representations.",10.1145/3701716.3715486,https://doi.org/10.1145/3701716.3715486,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,Bridging Conversational and Collaborative Signals for Conversational Recommendation,"Bin Rabiah, Ahmad and Sadeq, Nafis and McAuley, Julian",inproceedings,10.1145/3701716.3715486,
10.1145/3701716.3715856,10.1145/3701716.3715856,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","diffusion model, generative model, large language model, recommender system, semantic id",4,13–16,Companion Proceedings of the ACM on Web Conference 2025,"Recommendation models typically follow a discriminative paradigm, predicting whether items should be retrieved. While effective, the expressive capabilities of these recommender systems are limited. Users can only passively browse the recommended items rather than actively express their needs and engage in an interactive experience. With recent advances in generative models such as large language models, a paradigm shift is happening in the study of recommender systems. Researchers propose building generative recommendation models either by aligning pre-trained generative models with user behaviors or designing recommendation models within a generative framework. These models enable the systems to receive and deliver more human-like content, such as natural language, images, and beyond. In this tutorial, we first provide an overview of the latest progress in generative recommendation models, covering approaches based on large language models, semantic IDs, diffusion models, and more. We then make an in-depth discussion on the challenges, open questions, and potential future directions in developing generative recommendation models.",10.1145/3701716.3715856,https://doi.org/10.1145/3701716.3715856,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,Generative Recommendation Models: Progress and Directions,"Hou, Yupeng and Zhang, An and Sheng, Leheng and Yang, Zhengyi and Wang, Xiang and Chua, Tat-Seng and McAuley, Julian",inproceedings,10.1145/3701716.3715856,
10.1145/3701716.3715872,10.1145/3701716.3715872,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","auction, bidding, click-through rate prediction, generative models, matching, recommendation systems",4,37–40,Companion Proceedings of the ACM on Web Conference 2025,"Computational advertising is one of the most successful application scenarios of machine learning and artificial intelligence. This tutorial is designed to review the latest progress of several critical areas in computational advertising: matching, prediction, auction and bidding. Particularly, with the recent advances in generative AI such as large language models, there is a growing interest in further enhancing these areas with these techniques. In this tutorial, we first introduce the recent advances in matching, including its architecture alternatives, model developments, and how it co-evolves with the ad products which distinguishes itself from that in recommendation products. We then review the recent advances in prediction, with a focus on topics such as feature interactions, user interest models, and multi-task/domain learning. We will show how these building bricks constitute large prediction models and LLM-enhanced/LLM-based prediction models. Then, we discuss auction and bidding, a unique area in computational advertising. Both traditional and learning-based auctions will be introduced, followed by their applications in real-world ad products. Given the auction designs, we show how bidding evolves from control-based, to reinforcement learning-based, and most recently to generative AI-based. Our aim is to help the audience grasp the recent developments in computational advertising, as well as to spark inspiration for future research.",10.1145/3701716.3715872,https://doi.org/10.1145/3701716.3715872,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,Computational Advertising: Recent Advances,"Pan, Junwei and Zhang, Zhilin and Zhu, Han and Xu, Jian and Jiang, Jie and Zheng, Bo",inproceedings,10.1145/3701716.3715872,
10.1145/3701716.3717509,10.1145/3701716.3717509,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","esg ratings, financial applications, fintech, news articles",7,1774–1780,Companion Proceedings of the ACM on Web Conference 2025,"In recent years, corporate environmental, social, and governance (ESG) engagement has received significant public attention. As mandatory ESG reporting is increasingly adopted and investors place greater emphasis on sustainability in their decisions, the demand for transparent and reliable ESG ratings is growing. However, existing automatic approaches to ESG rating prediction remain limited. Many rely on traditional machine learning methods like random forests or social network analysis, rather than leveraging incoming news article streams and large multivariate time series data, which, for the first time, enables capturing the dynamic relationships between topics, sentiments, and events. In this paper, we propose a novel approach to predicting ESG ratings from news articles by uniquely combining multivariate time series construction with advanced deep learning techniques. We create an extensive dataset of 3.7 million news articles spanning three years and covering 3,000 U.S. companies, providing a robust foundation for training and evaluating our approach. Our approach achieves high accuracy and outperforms existing approaches, underscoring its potential as a scalable, data-driven solution for ESG rating prediction.",10.1145/3701716.3717509,https://doi.org/10.1145/3701716.3717509,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,Predicting Company ESG Ratings from News Articles Using Multivariate Timeseries Analysis,"Aue, Tanja and Jatowt, Adam and F\""{a}rber, Michael",inproceedings,10.1145/3701716.3717509,
10.1145/3701716.3717850,10.1145/3701716.3717850,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","cross-domain recommendation, large language models, recommender systems",8,2736–2743,Companion Proceedings of the ACM on Web Conference 2025,"Cross-Domain Recommendation (CDR) seeks to enhance item retrieval in low-resource domains by transferring knowledge from high-resource domains. While recent advancements in Large Language Models (LLMs) have demonstrated their potential in Recommender Systems (RS), their ability to effectively transfer domain knowledge for improved recommendations remains underexplored. To bridge this gap, we propose LLM4CDR, a novel CDR pipeline that constructs context-aware prompts by leveraging users' purchase history sequences from a source domain along with shared features between source and target domains. Through extensive experiments, we show that LLM4CDR achieves strong performance, particularly when using LLMs with large parameter sizes and when the source and target domains exhibit smaller domain gaps. For instance, incorporating CD &amp; Vinyl purchase history for recommendations in Movies &amp; TV yields a 64.28% MAP@1 improvement. We further investigate how key factors-source domain data, domain gap, prompt design, and LLM size-impact LLM4CDR's effectiveness in CDR tasks. Our results highlight that LLM4CDR excels when leveraging a single, closely related source domain and benefits significantly from larger LLMs. These insights pave the way for future research on LLM-driven cross-domain recommendations.",10.1145/3701716.3717850,https://doi.org/10.1145/3701716.3717850,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,Uncovering Cross-Domain Recommendation Ability of Large Language Models,"Liu, Xinyi and Wang, Ruijie and Sun, Dachun and Hakkani Tur, Dilek and Abdelzaher, Tarek",inproceedings,10.1145/3701716.3717850,
10.1145/3701716.3719226,10.1145/3701716.3719226,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","closed-loop adaptation, llm agent, llm-based simulation, self-evolving framework",5,2973–2977,Companion Proceedings of the ACM on Web Conference 2025,"Large Language Models (LLMs) have demonstrated remarkable capabilities in simulating user behavior, offering significant potential for user modeling, behavior analysis, interest matching, and the extraction of unstructured features. However, the process of user simulation necessitates the identification of both unstructured and structured features, as well as the formulation of multi-stages workflow, which remains a challenging and labor-intensive task. To address this, we propose EvolutionAgent , a novel framework grounded in a discretized material repository, which employs self-reflective and evolutionary mechanisms to automate the search for unstructured features and the generation of simulation workflow. This framework establishes an efficient and robust simulation mechanism, achieving state-of-the-art performance across three distinct datasets. Notably, EvolutionAgent exhibits exceptional robustness, even in scenarios with limited historical data for users and products, underscoring its adaptability and reliability.",10.1145/3701716.3719226,https://doi.org/10.1145/3701716.3719226,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,EvolutionAgent: A Large Model-Based Framework for User Behavior Modeling and Self-Evolving Intelligent Agents,"Luo, Junhui and Song, Li and Sun, Ranrun",inproceedings,10.1145/3701716.3719226,
10.1145/3701716.3719227,10.1145/3701716.3719227,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","agent, if-then rules, knowledge mining, large language model, reasoning, relationship graph, user-and-item modeling",5,2993–2997,Companion Proceedings of the ACM on Web Conference 2025,"Emulating real-world human behaviors within Artificial Intelligent (AI) agent systems continues to be a formidable challenge, as existing methodologies frequently have difficulty integrating the intricacies of real-world scenarios and personal preferences.To address this issue, we propose USHB, a mulit-agent framework that emphasizes advanced user and item modeling along with communication style simulation. USHB consists of 3 modules: a Knowledge-Mining Module (KMM), a User-and-Item Modeling Module (UIMM), and a Reasoning Module (RM). USHB utilizes Large Language Models (LLMs) to predict responses, reviews, and ratings tailored to individuals, guaranteeing results that are both coherent and contextually appropriate. USHB is capable of delivering precise, detailed simulations that closely mimic human behavior. We evaluated USHB using datasets from Yelp, Amazon, and Goodreads, where it consistently outperformed baseline methods. Moreover, USHB demonstrated strong generalization and maintained stable performance across a variety of model configurations. These advancements make USHB a valuable contribution to dynamic, context-aware behavior simulation, achieving a top-three ranking in the 2025 AgentSociety Challenge. Our codes are available at https://github.com/jnuaipr/AgentsChallenge.",10.1145/3701716.3719227,https://doi.org/10.1145/3701716.3719227,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,USHB: A Unified Framework for Simulating Human Behaviors in Agent Society through User-and-Item Modeling: Unified Framework for Simulating Human Behaviors,"Zhao, Renhuo and Yang, Hailong and Gu, Mingxian and Wang, Jianqi and Long, Wu and Deng, Zhaohong",inproceedings,10.1145/3701716.3719227,
10.1145/3701716.3719228,10.1145/3701716.3719228,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","automatic prompt optimization, in-context learning, llm, user behavior modeling, workflow agents",5,2988–2992,Companion Proceedings of the ACM on Web Conference 2025,"User behavior modeling is increasingly critical for personalized services and decision-making systems, yet integrating diverse user and product features into a coherent review generation process remains challenging. Thus we propose a novel collaborative optimization approach for workflow agents in user behavior modeling that integrates user and product feature extraction with review and rating generation. Firstly, to solve the difficulty in determining the optimal structure of agent workflows, we employ Monte Carlo Tree Search (MCTS) to optimize the workflow architecture, establishing a high-performance baseline. Meanwhile, to tackle the challenges in generating and optimizing single-agent prompts and demonstrations, we implement a heuristic optimization strategy for joint automated tuning of system prompts and demo cases. Furthermore, through comprehensive analysis of data distributions, we construct a dynamic routing mechanism for the agent workflow, achieving enhanced performance across diverse scenario-specific datasets. We validate the effectiveness of our methods on three real-world datasets, demonstrating significant performance improvements across all proposed techniques. This approach secured second place overall (and first in star-rating prediction) in the user modeling track of the AgentSociety Challenge @ WWW 2025.",10.1145/3701716.3719228,https://doi.org/10.1145/3701716.3719228,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,Collaborative Optimization Approach for Workflow Agents in User Behavior Modeling,"Zhang, Xinyu and Dou, Ran and Hu, Enrui and Zhao, Minjun and Ding, Yangkai and Dou, Zhicheng",inproceedings,10.1145/3701716.3719228,
10.1145/3701716.3719230,10.1145/3701716.3719230,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","agent, knowledge fusion, recommendation",5,2983–2987,Companion Proceedings of the ACM on Web Conference 2025,"With powerful semantic understanding, planning, and decision-making capabilities, LLM-based agents have been applied to solve recommendation tasks. However, challenges remain in effectively evolving user preferences within agent modules and in leveraging external knowledge to improve recommendation accuracy. In this paper, we propose an innovative agent-based framework for personalized recommendation systems that integrates adaptive knowledge fusion to address these challenges. Our framework consists of two primary components: an intelligent agent and the fusion of external knowledge. The intelligent agent includes a memory module that simulates human-like retention of user-item interactions and a reasoning module that applies Chain-of-Thought (CoT) techniques to mimic human thought processes. Furthermore, we introduce two main strategies for knowledge fusion: (1) a preranking approach using external knowledge to reorder candidates and reduce bias, and (2) an ensemble method that combines multiple ranking signals for more accurate recommendations. Evaluations on three public datasets and the AgentSociety Challenge demonstrate the framework's effectiveness in enhancing recommendation quality and adaptability. The code is open-sourced.",10.1145/3701716.3719230,https://doi.org/10.1145/3701716.3719230,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,Intelligent Agents with Adaptive Knowledge Fusion for Personalized Recommendation,"Yu, Yuanqing and Wang, Zhefan and Jiang, Chumeng and Li, Xinyi and Wang, Jiayin and Zhang, Min",inproceedings,10.1145/3701716.3719230,
10.1145/3701716.3719232,10.1145/3701716.3719232,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '25,"Sydney NSW, Australia","knowledge-driven, llm agent, simulated society, user modeling",5,2998–3002,Companion Proceedings of the ACM on Web Conference 2025,"User modeling serves as the cornerstone of modern recommendation systems, focusing on the precise identification of user preferences and behavioral signatures to enable personalized service delivery. Existing recommendation methods face issues like sparse data and lack of transparency. The advent of large language models (LLMs) has brought new possibilities for inferring user preferences, which provides natural-language-based recommendation rationales and affective expressions. Motivated by AgentSociety Challenge @ WWW 2025 focused on simulating user-item interactions, we propose a knowledge-driven LLM agent framework for simulating user-item review interactions, which includes three modules: preference refinement, dual-signal injection, and category distinguisher. Specifically, preference refinement aims to model user and item profiles, enabling LLMs to perceive users and items comprehensively. Dual-signal Injection aims to incorporate external knowledge, such as collaborative filtering and distribution knowledge. Category distinguisher is designed to analyze the differences between true data and simulated data. Both online and offline experimental results demonstrate the effectiveness of this framework and prove the great potential of LLMs in user modeling.",10.1145/3701716.3719232,https://doi.org/10.1145/3701716.3719232,"New York, NY, USA",Association for Computing Machinery,9798400713316,2025,Unveiling the Potential of LLMs in Simulated Society: A Knowledge-Driven LLM Agent Framework for User Modeling,"Zhu, Shengmao and Xu, Bingbing and Yuan, Yige and Xie, Bin and Li, Yunfan and Shen, Huawei",inproceedings,10.1145/3701716.3719232,
10.1145/3705328.3748017,10.1145/3705328.3748017,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"POI recommendations, popularity bias, popularity calibration, algorithmic fairness, user groups, context-aware recommender systems",6,593–598,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Point-of-interest (POI) recommender systems help users discover relevant locations, but their effectiveness is often compromised by popularity bias, which disadvantages less popular, yet potentially meaningful places. This paper addresses this challenge by evaluating the effectiveness of context-aware models and calibrated popularity techniques as strategies for mitigating popularity bias. Using four real-world POI datasets (Brightkite, Foursquare, Gowalla, and Yelp), we analyze the individual and combined effects of these approaches on recommendation accuracy and popularity bias. Our results reveal that context-aware models cannot be considered a uniform solution, as the models studied exhibit divergent impacts on accuracy and bias. In contrast, calibration techniques can effectively align recommendation popularity with user preferences, provided there is a careful balance between accuracy and bias mitigation. Notably, the combination of calibration and context-awareness yields recommendations that balance accuracy and close alignment with the users’ popularity profiles, i.e., popularity calibration.",10.1145/3705328.3748017,https://doi.org/10.1145/3705328.3748017,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Exploring the Effect of Context-Awareness and Popularity Calibration on Popularity Bias in POI Recommendations,"Forster, Andrea and Kopeinik, Simone and Helic, Denis and Thalmann, Stefan and Kowald, Dominik",inproceedings,10.1145/3705328.3748017,
10.1145/3705328.3748024,10.1145/3705328.3748024,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Vertical Federated Learning, Label inference attack, Recommender systems, Negative sampling, Semi-supervised learning",6,660–665,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Organizations are increasingly applying Vertical Federated Learning (VFL) to enhance recommender systems without sharing raw data among themselves. However, partial outputs in VFL remain to introduce significant privacy risks. In this study, we propose a novel label inference attack specifically tailored for VFL-based recommender systems, leveraging two common characteristics: (1) item popularity often follows a power-law distribution, and (2) random negative sampling is commonly used for implicit feedback, a substitute for non-existing true labels. By combining partial local information from VFL with this prior knowledge, a malicious party can construct a semi-supervised learning pipeline. The experimental results of three real-world datasets demonstrate that our approach achieves a higher label inference performance than the existing attacks. These findings demonstrate the need for more robust privacy preserving mechanisms in federated recommender systems.",10.1145/3705328.3748024,https://doi.org/10.1145/3705328.3748024,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Popularity‑Bias Vulnerability: Semi‑Supervised Label Inference Attack on Federated Recommender Systems,"Shinoda, Kenji and Sasai, Takeyuki and Fukushima, Shintaro",inproceedings,10.1145/3705328.3748024,
10.1145/3705328.3748035,10.1145/3705328.3748035,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Cold-Start Recommendation, Popularity Bias, Item Fairness",6,649–654,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Collaborative filtering (CF) recommender systems struggle with making predictions on unseen, or ‘cold’, items. Systems designed to address this challenge are often trained with supervision from warm CF models in order to leverage collaborative and content information from the available interaction data. However, since they learn to replicate the behavior of CF methods, cold-start models may therefore also learn to imitate their predictive biases. In this paper, we show that cold-start systems can inherit popularity bias, a common cause of recommender system unfairness arising when CF models overfit to more popular items, thereby maximizing user-oriented accuracy but neglecting rarer items. We demonstrate that cold-start recommenders not only mirror the popularity biases of warm models, but are in fact affected more severely: because they cannot infer popularity from interaction data, they instead attempt to estimate it based solely on content features. This leads to significant over-prediction of certain cold items with similar content to popular warm items, even if their ground truth popularity is very low. Through experiments on three multimedia datasets, we analyze the impact of this behavior on three generative cold-start methods. We then describe a simple post-processing bias mitigation method that, by using embedding magnitude as a proxy for predicted popularity, can produce more balanced recommendations with limited harm to user-oriented cold-start accuracy.",10.1145/3705328.3748035,https://doi.org/10.1145/3705328.3748035,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,On Inherited Popularity Bias in Cold-Start Item Recommendation,"Meehan, Gregor and Pauwels, Johan",inproceedings,10.1145/3705328.3748035,
10.1145/3705328.3748062,10.1145/3705328.3748062,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"multi-factor collaborative analysis, CTR prediction, user reviews",9,12–20,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"For items, the higher the click-through rate, the higher the rating. Thus, existing recommendation methods implicitly model click behaviors by learning user preferences and achieving accurate predictions on rating prediction tasks. However, they ignore the help of the rating behaviors for the click-through rate prediction task (CTR). Although the rating behavior occurs after the click behavior, we can still get helpful information about clicks from ratings. In this paper, we propose a multi-factor collaborative prediction method (MFC), which mines the complex relationship between click and rating behaviors, achieving accurate prediction on CTR tasks. Specifically, we factorize the complex relationship into three simple relationships, i.e., linear, sharing, and cross-correlation relationships. Thus, MFC first extracts click factors, rating factors, and their sharing factor from user click and rating behaviors with user reviews, as review-based methods have achieved great results on rating predictions. Then, a rating factor regularization method is used to learn rating factors accurately, helping to model the true relationships between click and rating behavior. Finally, MFC combines those three factors to make predictions, while click and rating factors are used to model the linear and cross-correlation relationships, and the sharing factors correspond to the sharing relation. Experiments on five real-world datasets demonstrate that MFC outperforms the best baseline by (9.19%), (9.80%), (0.69%), and (7.95%), in terms of Accuracy, Precision, Recall, and F1-score, respectively. MFC also reduces the MAE of the rating prediction task by (1.92%). The source code is available at https://github.com/dianziliu/MFC.",10.1145/3705328.3748062,https://doi.org/10.1145/3705328.3748062,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,A Multi-Factor Collaborative Prediction for Review-based Recommendation,"Liu, Junrui and Li, Tong and Yu, Mingliang and Yang, Shiqiu and Tang, Zifang and Yang, Zhen",inproceedings,10.1145/3705328.3748062,
10.1145/3705328.3748066,10.1145/3705328.3748066,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"RS quality perception, Beyond-accuracy, User study",12,165–176,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Multi-objective recommender systems (MORS) aim to optimize multiple criteria while generating recommendations, such as relevance, novelty, diversity, or exploration. These algorithms are based on the assumption that an operationalization of these criteria (i.e., translating abstract goals into measurable metrics), will reflect how users perceive them. Nevertheless, such beliefs are rarely rigorously evaluated, which can lead to a mismatch between algorithmic goals and user satisfaction. Moreover, if users are allowed to control the RS via their propensities towards such objectives, the misconceptions may further impact users’ trust and engagement. To characterize this problem, we conduct a large user study focusing on recommender systems in two domains: books and movies. Part of the study is focused on how users perceive different recommendation objectives, which we compared with well-established metrics aiming at the same objectives. We found that despite such metrics correlating to some extent with users’ perceptions, the mapping is far from perfect. Moreover, we also report on conceptual-level differences in users’ understanding of RS objectives and how this affects the results. Study data are available from .",10.1145/3705328.3748066,https://doi.org/10.1145/3705328.3748066,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,How Do Users Perceive Recommender Systems’ Objectives?,"Dokoupil, Patrik and Boratto, Ludovico and Peska, Ladislav",inproceedings,10.1145/3705328.3748066,
10.1145/3705328.3748067,10.1145/3705328.3748067,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Dual-target Cross-domain Recommendation, Large Language Models, Data Augmentation",10,451–460,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Cross-domain recommendation (CDR) has been proposed to alleviate the data sparsity issue in recommendation systems and has garnered substantial research interest. In recent years, dual-target CDR has been an increasingly prevalent research topic that emphasizes simultaneous enhancement in both the source and target domains. Many existing approaches rely on overlapping users as bridges between domains, yet in real-world scenarios, the number of such users is often severely limited, restricting their practical applicability. To overcome this limitation, alternative methods for cross-domain connections are needed, and item tags serve as a promising solution. However, real-world tags suffer from severe deficiencies in terms of both quantity and diversity, and existing studies have not fully exploited their potential. In this paper, we introduce Tag-Augmented Dual-Target Cross Domain Recommendation (TA-DTCDR), which is the first to apply LLM-distilled tag information to CDR. TA-DTCDR utilizes item tags distilled by large language models (LLMs) as an additional channel to facilitate information transfer, thereby mitigating performance decline caused by the lack of overlapping users. Furthermore, to fully leverage the natural language information carried by the distilled tags, we design a series of training tasks to align tag semantics across domains while preserving their semantic independence. The proposed method is validated on multiple tasks using public datasets, showing significant improvements over existing state-of-the-art approaches.",10.1145/3705328.3748067,https://doi.org/10.1145/3705328.3748067,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Tag-augmented Dual-target Cross-domain Recommendation,"Pan, Mingfan and Mao, Qingyang and An, Xu and Ma, Jianhui and Zhou, Gang and Cheng, Mingyue and Chen, Enhong",inproceedings,10.1145/3705328.3748067,
10.1145/3705328.3748072,10.1145/3705328.3748072,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"diffusion model, slate generation, music playlist generation, bundle generation",10,401–410,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Slate generation is a common task in streaming and e-commerce platforms, where multiple items are presented together as a list or “slate”. Traditional systems focus mostly on item-level ranking and often fail to capture the coherence of the slate as a whole. A key challenge lies in the combinatorial nature of selecting multiple items jointly. To manage this, conventional approaches often assume users interact with only one item at a time, assumption that breaks down when items are meant to be consumed together.In this paper, we introduce DMSG, a generative framework based on diffusion models for prompt-conditioned slate generation. DMSG learns high-dimensional structural patterns and generates coherent, diverse slates directly from natural language prompts. Unlike retrieval-based or autoregressive models, DMSG models the joint distribution over slates, enabling greater flexibility and diversity.We evaluate DMSG in two key domains: music playlist generation and e-commerce bundle creation. In both cases, DMSG produces high-quality slates from textual prompts without explicit personalization signals. Offline and online results show that DMSG outperforms strong baselines in both relevance and diversity, offering a scalable, low-latency solution for prompt-driven recommendation. A live A/B test on a production playlist system further demonstrates increased user engagement and content diversity.",10.1145/3705328.3748072,https://doi.org/10.1145/3705328.3748072,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Prompt-to-Slate: Diffusion Models for Prompt-Conditioned Slate Generation,"Tomasi, Federico and Fabbri, Francesco and Carter, Justin and Kalomiris, Elias and Lalmas, Mounia and Dai, Zhenwen",inproceedings,10.1145/3705328.3748072,
10.1145/3705328.3748076,10.1145/3705328.3748076,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Sequential Recommendation, Context-Adaptive Ranking, Multitask Learning, Engagement-aware Loss, Hard Negative Sampling, Next-K Title Prediction",10,62–71,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Modern video streaming services heavily rely on recommender systems. Although there are many methods for content personalization and recommendation, sequential recommendation models stand out due to their ability to summarize user behavior over time. We propose a novel sequential recommendation framework to address the following key issues: suboptimal negative sampling strategies, fixed user-history context lengths, and single-task optimization objectives, insufficient engagement-aware learning, and short-sighted prediction horizons, ultimately improving both immediate and multi-step next-title prediction for video streaming services. In this work, we propose a novel approach to capture patterns of interaction at different time scales. We also align long-term user happiness with instantaneous intent signals using multi-task learning with engagement-aware personalized loss. Finally, we extend traditional next-item prediction into a next-K forecasting task using a training strategy with soft positive label. Extensive experiments on large-scale streaming data validate the effectiveness of our approach. Our best model outperforms the baseline in NDCG@1 by up to 3.52% under realistic ranking scenarios showing the effectiveness of our engagement-aware and MoE-enhanced designs. Results also show that soft-label Multi-K training is a practical and scalable extension, and that a balanced personalized negative sampling strategy generalizes well. Our framework outperforms baselines across all ranking metrics, providing a robust solution for production-scale streaming recommendations.",10.1145/3705328.3748076,https://doi.org/10.1145/3705328.3748076,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Beyond Immediate Click: Engagement-Aware and MoE-Enhanced Transformers for Sequential Movie Recommendation,"Jiang, Haotian and Paul, Sibendu and Zhang, Haiyang and Chen, Caren",inproceedings,10.1145/3705328.3748076,
10.1145/3705328.3748086,10.1145/3705328.3748086,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"offline evaluation, target item sampling, global metrics, exposure bias, negative sampling",10,360–369,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Offline evaluation plays a central role in benchmarking recommender systems when online testing is impractical or risky. However, it is susceptible to two key sources of bias: exposure bias, where users only interact with items they are shown, and sampling bias, introduced when evaluation is performed on a subset of logged items rather than the full catalog. While prior work has proposed methods to mitigate sampling bias, these are typically assessed on fixed logged datasets rather than for their ability to support reliable model comparisons under varying exposure conditions or relative to true user preferences. In this paper, we investigate how different combinations of logging and sampling choices affect the reliability of offline evaluation. Using a fully observed dataset as ground truth, we systematically simulate diverse exposure biases and assess the reliability of common sampling strategies along four dimensions: sampling resolution (recommender model separability), fidelity (agreement with full evaluation), robustness (stability under exposure bias), and predictive power (alignment with ground truth). Our findings highlight when and how sampling distorts evaluation outcomes and offer practical guidance for selecting strategies that yield faithful and robust offline comparisons.",10.1145/3705328.3748086,https://doi.org/10.1145/3705328.3748086,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,On the Reliability of Sampling Strategies in Offline Recommender Evaluation,"Pereira, Bruno L. and Said, Alan and Santos, Rodrygo L. T.",inproceedings,10.1145/3705328.3748086,
10.1145/3705328.3748154,10.1145/3705328.3748154,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Large Language Models, Multimodal Recommendation",9,774–782,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Large language models (LLMs) have been exploited as standalone recommender systems (RSs) and, more recently, as support tools for already existing RSs. A notable example of the latter is LLMRec&nbsp;[28], which prompts a LLM with the user-item data, the items’ metadata, and the candidate items generated by other multimodal RSs to obtain an augmented version of the original dataset where a final RS is trained on. While a few recent studies have proposed reproducing and rigorously evaluating LLM-based recommender systems (RSs) as standalone approaches (first research line), little to no attention has been devoted to exploring the use of LLMs as supportive components within existing RSs, particularly in the context of multimodal recommendation (second research line). To this end, in this work, we propose the first reproducibility study of a LLMs-based RS belonging to the second research line, LLMRec, in the multimodal recommendation domain. First, we try to replicate the results of LLMRec with the authors’ provided data and our own reconstructed data, outlining critical issues in the measured recommendation performance. Then, we benchmark LLMRec: (i) with unimodal and multimodal LLMs, showing how the latter may be more beneficial in a multimodal scenario; (ii) other competitive multimodal RSs, LLMs-based solutions, and an additional dataset, demonstrating inconsistencies with the trends emerging in the original paper. Finally, in an attempt to disentangle the observed performance trends, we evaluate (for the first time in the literature) the topological differences of the original user-item graph to the LLMRec’s augmented one.",10.1145/3705328.3748154,https://doi.org/10.1145/3705328.3748154,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,How Powerful are LLMs to Support Multimodal Recommendation? A Reproducibility Study of LLMRec,"Fioretti, Maria Lucia and Laterza, Nicola and Preziosa, Alessia and Malitesta, Daniele and Pomo, Claudio and Narducci, Fedelucio and Di Noia, Tommaso",inproceedings,10.1145/3705328.3748154,
10.1145/3705328.3748158,10.1145/3705328.3748158,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Recommender Systems, Large Language Models, Privacy Risks, Model Inversion Attack",10,812–821,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"The large language model (LLM) powered recommendation paradigm has been proposed to address the limitations of traditional recommender systems (RecSys), which often struggle to handle cold-start users or items with new IDs. Despite its effectiveness, this study uncovers that LLM-empowered RecSys are vulnerable to reconstruction attacks that can expose both system and user privacy. To thoroughly examine this threat, we present the first systematic study on inversion attacks targeting LLM-empowered RecSys, wherein adversaries attempt to reconstruct original prompts that contain personal preferences, interaction histories, and demographic attributes by exploiting the output logits of recommendation models. We reproduce the vec2text framework and optimize it using our proposed method - Similarity-Guided Refinement, enabling more accurate reconstruction of textual prompts from model-generated logits. Extensive experiments across two domains (movies and books) and two representative LLM-based recommendation models demonstrate that our method achieves high-fidelity reconstructions. Specifically, we can recover nearly 65% of the user-interacted items and correctly infer age and gender in 87% of the cases. The experiments also reveal that privacy leakage is largely insensitive to the victim model’s performance but highly dependent on domain consistency and prompt complexity. These findings expose critical and privacy vulnerabilities in LLM-empowered RecSys. The code for reproduction is provided below: https://github.com/xuemingxxx/Attack_RecSys/",10.1145/3705328.3748158,https://doi.org/10.1145/3705328.3748158,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Privacy Risks of LLM-Empowered Recommender Systems: An Inversion Attack Perspective,"Wang, Yubo and Tang, Min and Shen, Nuo and Cui, Shujie and Wang, Weiqing",inproceedings,10.1145/3705328.3748158,
10.1145/3705328.3748160,10.1145/3705328.3748160,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Reproducibility, Popularity Bias, Mainstream, Children",9,783–791,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Recommender systems research seldom considers children as a user group, and when it does, it is anchored on datasets where children are underrepresented, risking overlooking their interests, favoring those of the majority, i.e., mainstream users. Recently, Ungruh et al. demonstrated that children’s consumption patterns and preferences differ from those of mainstream users, resulting in inconsistent recommendation algorithm performance and behavior for this user group. These findings, however, are based on two datasets with a limited child user sample. We reproduce and replicate this study on a wider range of datasets in the movie, music, and book domains, uncovering interaction patterns and aspects of child-recommender interactions consistent across domains, as well as those specific to some user samples in the data. We also extend insights from the original study with popularity bias metrics, given the interpretation of results from the original study. With this reproduction and extension, we uncover consumption patterns and differences between age groups stemming from intrinsic differences between children and others, and those unique to specific datasets or domains.",10.1145/3705328.3748160,https://doi.org/10.1145/3705328.3748160,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Impacts of Mainstream-Driven Algorithms on Recommendations for Children Across Domains: A Reproducibility Study,"Ungruh, Robin and Bellog\'{\i}n, Alejandro and Kowald, Dominik and Pera, Maria Soledad",inproceedings,10.1145/3705328.3748160,
10.1145/3705328.3748163,10.1145/3705328.3748163,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Recommender Systems, Music Recommendation, Dataset, Analysis, Benchmark, User Modeling",8,894–901,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"We present Yambda-5B, a large-scale open dataset sourced from the Yandex.Music streaming platform. Yambda-5B contains 4.79 billion user-item interactions from 1 million users across 9.39 million tracks. The dataset includes two primary types of interactions: implicit feedback (listening events) and explicit feedback (likes, dislikes, unlikes and undislikes). In addition, we provide audio embeddings for most tracks, generated by a convolutional neural network trained on audio spectrograms.A key distinguishing feature of Yambda-5B is the inclusion of the is_organic flag, which separates organic user actions from recommendation-driven events. This distinction is critical for developing and evaluating machine learning algorithms, as Yandex.Music relies on recommender systems to personalize track selection for users.To support rigorous benchmarking, we introduce an evaluation protocol based on a Global Temporal Split, allowing recommendation algorithms to be assessed in conditions that closely mirror real-world use. We report benchmark results for standard baselines (ItemKNN, iALS) and advanced models (SANSA, SASRec) using a variety of evaluation metrics.By releasing Yambda-5B to the community, we aim to provide a readily accessible, industrial-scale resource to advance research, foster innovation, and promote reproducible results in recommender systems.",10.1145/3705328.3748163,https://doi.org/10.1145/3705328.3748163,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Yambda-5B — A Large-Scale Multi-Modal Dataset for Ranking and Retrieval,"Ploshkin, Alexander and Tytskiy, Vladislav and Pismenny, Alexey and Baikalov, Vladimir and Taychinov, Evgeny and Permiakov, Artem and Burlakov, Daniil and Krofto, Eugene",inproceedings,10.1145/3705328.3748163,
10.1145/3705328.3748167,10.1145/3705328.3748167,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Recommender Systems, Serendipity, Large Language Models",9,746–754,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Serendipity plays a pivotal role in enhancing user satisfaction within recommender systems, yet its evaluation poses significant challenges due to its inherently subjective nature and conceptual ambiguity. Current algorithmic approaches predominantly rely on proxy metrics for indirect assessment, often failing to align with real user perceptions, thus creating a gap. With large language models (LLMs) increasingly revolutionizing evaluation methodologies across various human annotation tasks, we are inspired to explore a core research proposition: Can LLMs effectively simulate human users for serendipity evaluation?To address this question, we conduct a meta-evaluation on two datasets derived from real user studies in the e-commerce and movie domains, focusing on three key aspects: the accuracy of LLMs compared to conventional proxy metrics, the influence of auxiliary data on LLM comprehension, and the efficacy of recently popular multi-LLM techniques. Our findings indicate that even the simplest zero-shot LLMs achieve parity with, or surpass, the performance of conventional metrics. Furthermore, multi-LLM techniques and the incorporation of auxiliary data further enhance alignment with human perspectives. Based on our findings, the optimal evaluation by LLMs yields a Pearson correlation coefficient of 21.5% when compared to the results of the user study. This research implies that LLMs may serve as potentially accurate and cost-effective evaluators, introducing a new paradigm for serendipity evaluation in recommender systems. Our code is publicly available at .",10.1145/3705328.3748167,https://doi.org/10.1145/3705328.3748167,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Exploring the Potential of LLMs for Serendipity Evaluation in Recommender Systems,"Kang, Li and Zhao, Yuhan and Chen, Li",inproceedings,10.1145/3705328.3748167,
10.1145/3705328.3748169,10.1145/3705328.3748169,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Bundle recommendation, Fairness, Popularity bias, Exposure bias",10,696–705,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Recommender systems are known to exhibit fairness issues, particularly on the product side, where products and their associated suppliers receive unequal exposure in recommended results. While this problem has been widely studied in traditional recommendation settings, its implications for bundle recommendation (BR) remain largely unexplored. This emerging task introduces additional complexity: recommendations are generated at the bundle level, yet user satisfaction and product (or supplier) exposure depend on both the bundle and the individual items it contains. Existing fairness frameworks and metrics designed for traditional recommender systems may not directly translate to this multi-layered setting. In this paper, we conduct a comprehensive reproducibility study of product-side fairness in BR across three real-world datasets using four state-of-the-art BR methods. We analyze exposure disparities at both the bundle and item levels using multiple fairness metrics, uncovering important patterns. Our results show that exposure patterns differ notably between bundles and items, revealing the need for fairness interventions that go beyond bundle-level assumptions. We also find that fairness assessments vary considerably depending on the metric used, reinforcing the need for multi-faceted evaluation. Furthermore, user behavior plays a critical role: when users interact more frequently with bundles than with individual items, BR systems tend to yield fairer exposure distributions across both levels. Overall, our findings offer actionable insights for building fairer bundle recommender systems and establish a vital foundation for future research in this emerging domain.",10.1145/3705328.3748169,https://doi.org/10.1145/3705328.3748169,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,A Reproducibility Study of Product-side Fairness in Bundle Recommendation,"Nguyen, Huy-Son and Liu, Yuanna and Mansoury, Masoud and Aliannejadi, Mohammad and Hanjalic, Alan and de Rijke, Maarten",inproceedings,10.1145/3705328.3748169,
10.1145/3705328.3748753,10.1145/3705328.3748753,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Recommender systems, Full-page layout, Personalization, User behavior, Evaluation",6,1479–1484,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Full-page layouts with multiple carousels are widely used in video streaming platforms, yet understudied in recommender systems research. This paper introduces a structured approach to generating such pages by recommending coherent item collections and optimizing their arrangement. We break the problem into subcomponents and propose methods that balance user relevance, diversity, and coherence. We also present an evaluation framework tailored to this setting. We argue that this approach can improve recommendation quality beyond traditional ranked lists.",10.1145/3705328.3748753,https://doi.org/10.1145/3705328.3748753,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Full-Page Recommender: A Modular Framework for Multi-Carousel Recommendations,"Kislinger, Jan",inproceedings,10.1145/3705328.3748753,
10.1145/3705328.3748754,10.1145/3705328.3748754,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Perfume Recommender System, Perfume Context, Perfume Emotional Perception",4,1469–1472,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Compared to other recommender systems domains, perfume recommendation proves to be highly personalized and more challenging due to the very subjective factors and complex mixture of involved senses. Individual perfume preferences are influenced by subtle elements such as emotional associations, personal memories, and unique biochemistry, making it difficult for users to clearly express their olfactory preferences. This paper provides an insight of significant challenges in perfume recommendations planned to be addressed in the context of my ongoing PhD project. By exploring these areas, I aim to make a meaningful contribution to the ongoing development of perfume recommender systems.",10.1145/3705328.3748754,https://doi.org/10.1145/3705328.3748754,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,"Challenges in Perfume Recommender Systems: Navigating Subjectivity, Context and Sensory Data","Lutan, Elena-Ruxandra",inproceedings,10.1145/3705328.3748754,
10.1145/3705328.3748760,10.1145/3705328.3748760,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Recommender Systems, Multi-Stage Recommender Systems, Multi-Stakeholder Recommendations, Evaluation, Industrial Application",4,1435–1438,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"This research proposes a modular, resource-aware framework for industrial recommender systems that enables the integration and evaluation of stakeholder values at each stage of the recommendation pipeline. Motivated by the practical constraints of data availability and computational capacity, the framework supports stage-wise optimisation and selective retraining, making it suitable for low-resource environments. Ongoing experiments on open-source and real-world datasets aim to validate the framework’s adaptability, offering a contribution to the design of value-aware and operationally viable recommender systems.",10.1145/3705328.3748760,https://doi.org/10.1145/3705328.3748760,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Adding Value to Low-Resource Industrial Recommender Systems,"Kloppers, Cornelia M",inproceedings,10.1145/3705328.3748760,
10.1145/3705328.3759311,10.1145/3705328.3759311,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Recommender Systems, Sequential Recommendation, Music Recommendation, Personalized Popularity, Product Quantisation",5,1137–1141,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"In the realm of music recommendation, sequential recommenders have shown promise in capturing the dynamic nature of music consumption. A key characteristic of this domain is repetitive listening, where users frequently replay familiar tracks. To capture these repetition patterns, recent research has introduced Personalised Popularity Scores (PPS), which quantify user-specific preferences based on historical frequency. While PPS enhances relevance in recommendation, it often reinforces already-known content, limiting the system’s ability to surface novel or serendipitous items—key elements for fostering long-term user engagement and satisfaction. To address this limitation, we build upon RecJPQ, a Transformer-based framework initially developed to improve scalability in large-item catalogues through sub-item decomposition. We repurpose RecJPQ’s sub-item architecture to model personalised popularity at a finer granularity. This allows us to capture shared repetition patterns across sub-embeddings—latent structures not accessible through item-level popularity alone. We propose a novel integration of sub-ID-level personalised popularity within the RecJPQ framework, enabling explicit control over the trade-off between accuracy and personalised novelty. Our sub-ID-level PPS method (sPPS) consistently outperforms item-level PPS by achieving significantly higher personalised novelty without compromising recommendation accuracy. Code and experiments are publicly available at .",10.1145/3705328.3759311,https://doi.org/10.1145/3705328.3759311,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Balancing Accuracy and Novelty with Sub-Item Popularity,"Mallamaci, Chiara and Petrov, Aleksandr V. and Mancino, Alberto Carlo Maria and Anelli, Vito Walter and Di Noia, Tommaso and Macdonald, Craig",inproceedings,10.1145/3705328.3759311,
10.1145/3705328.3759316,10.1145/3705328.3759316,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Subjective Features, Item Representations, Soft Attributes, Personalization, Recommender Systems",5,1279–1283,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Subjective features of content items, such as emotional resonance and aesthetic quality, have become increasingly important in recommender systems (RecSys), as the field moves beyond objective content and behavioral signals. Traditionally, such features were treated as fixed item-level properties, aggregated across users. However, emerging evidence suggests that subjective features are inherently user-dependent, shaped by individual interpretations and personal perspectives. This paper presents the first direct comparison between fixed (aggregated) and user-specific (subjective) item representations for modeling subjective features in RecSys. Using three datasets spanning movies, videos, and images, with subjective features, such as eudaimonia, hedonia, emotion, and aesthetics, we evaluate the impact of the representation strategy (i.e. fixed vs. user-specific) on recommendation performance across multiple algorithms. Our findings show that user-specific representations consistently outperform aggregate ones, often with statistically significant improvements. These results underscore the importance of modeling subjectivity at the user level, offering concrete guidance for more personalized and effective recommendation systems.",10.1145/3705328.3759316,https://doi.org/10.1145/3705328.3759316,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Rethinking Subjective Features in Recommender Systems: Personal Views Over Aggregated Values,"Golubovikj, Arsen Matej and Tkal\v{c}i\v{c}, Marko",inproceedings,10.1145/3705328.3759316,
10.1145/3705328.3759319,10.1145/3705328.3759319,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"Calibration, In-processing, Fine-tuning",6,1187–1192,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Calibration is the degree to which a recommender system is able to match the distribution of a certain item attribute among the items consumed by a user with their respective recommendations. Recent work suggests that many recommenders tend to provide miscalibrated recommendations. Furthermore, most approaches aimed at improving calibration adopt the post-processing paradigm, making them computationally costly at the inference time. This work proposes CaliTune, a fine-tuning approach applied to collaborative filtering based recommenders to allow them generate better calibrated recommendations without relying on costly post-processing. We compare CaliTune to an established post-processing approach on two backbone models and datasets from movie and music domains, focusing on popularity calibration. Our results suggest that CaliTune can offer a competitive accuracy–calibration trade-off in several settings, particularly when the backbone model exhibits high miscalibration and accuracy remains important, making it a promising inference-efficient alternative in such cases.",10.1145/3705328.3759319,https://doi.org/10.1145/3705328.3759319,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Fine-tuning for Inference-efficient Calibrated Recommendations,"Lesota, Oleg and Bajko, Adrian and Walder, Max and Wenzel, Matthias and Tommasel, Antonela and Schedl, Markus",inproceedings,10.1145/3705328.3759319,
10.1145/3705328.3759323,10.1145/3705328.3759323,RecSys.bib,1,['RecSys.bib'],8,RecSys '25,,"hyperbolic geometry, manifold regularization, NCF, SASRec",5,1212–1216,Proceedings of the Nineteenth ACM Conference on Recommender Systems,"Recent work shows that hyperbolic geometry may be a better option for recommendation systems in some cases due to the natural hierarchy present in user demands. However, the choice of geometry often determines the model architecture by fixing the type of embedding. This paper discusses the manifold regularization problem statement, which allows for preserving the original architecture and standard embeddings while imposing a non-strict geometry constraint. We demonstrate using hyperbolic geometry for neural collaborative filtering in two distinct recommendation tasks based on multilayer perceptron (MLP) networks: top-k recommendation and explicit rating prediction. For a more comprehensive architecture, we also test SASRec. All tasks are evaluated on the Amazon Reviews and MovieLens1M datasets. Experiments show that manifold regularization achieves performance comparable to hyperbolic embeddings on datasets with hierarchical structure without requiring changes to the model architecture and thus leaves initial model inference unaffected.",10.1145/3705328.3759323,https://doi.org/10.1145/3705328.3759323,"New York, NY, USA",Association for Computing Machinery,9798400713644,2025,Learning geometry-aware recommender systems with manifold regularization,"Zainulabidova, Zaira and Borisova, Julia and Hvatov, Alexander",inproceedings,10.1145/3705328.3759323,
10.1145/3711896.3736903,10.1145/3711896.3736903,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","data watermarking, recommender systems",12,3819–3830,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"In the era of large foundation models, data has become a crucial component in building high-performance AI systems. As the demand for high-quality and large-scale data continues to rise, data copyright protection is attracting increasing attention. In this work, we explore the problem of data watermarking for sequential recommender systems, where a watermark is embedded into the target dataset and can be detected in models trained on that dataset. We focus on two settings: dataset watermarking, which protects the ownership of the entire dataset, and user watermarking, which safeguards the data of individual users. We present a method named Dataset Watermarking for Recommender Systems (DWRS) to address them. We define the watermark as a sequence of consecutive items inserted into normal users' interaction sequences. We define a Receptive Field (RF) to guide the inserting process to facilitate the memorization of the watermark. Extensive experiments on five representative sequential recommendation models and three benchmark datasets demonstrate the effectiveness of DWRS in protecting data copyright while preserving model utility.",10.1145/3711896.3736903,https://doi.org/10.1145/3711896.3736903,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,Data Watermarking for Sequential Recommender Systems,"Zhang, Sixiao and Long, Cheng and Yuan, Wei and Chen, Hongxu and Yin, Hongzhi",inproceedings,10.1145/3711896.3736903,
10.1145/3711896.3736967,10.1145/3711896.3736967,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","collaborative filtering, flow matching, generative models, recommender systems",11,1765–1775,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"Generative models have shown great promise in collaborative filtering by capturing the underlying distribution of user interests and preferences. However, existing approaches struggle with inaccurate posterior approximations and misalignment with the discrete nature of recommendation data, limiting their expressiveness and real-world performance. To address these limitations, we propose FlowCF, a novel flow-based recommendation system leveraging flow matching for collaborative filtering. We tailor flow matching to the unique challenges in recommendation through two key innovations: (1) a behavior-guided prior that aligns with user behavior patterns to handle the sparse and heterogeneous user-item interactions, and (2) a discrete flow framework to preserve the binary nature of implicit feedback while maintaining the benefits of flow matching, such as stable training and efficient inference. Extensive experiments demonstrate that FlowCF achieves state-of-the-art recommendation accuracy across various datasets with the fastest inference speed, making it a compelling approach for real-world recommender systems. The code is available at https://github.com/chengkai-liu/FlowCF.",10.1145/3711896.3736967,https://doi.org/10.1145/3711896.3736967,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,Flow Matching for Collaborative Filtering,"Liu, Chengkai and Zhang, Yangtian and Wang, Jianling and Ying, Rex and Caverlee, James",inproceedings,10.1145/3711896.3736967,
10.1145/3711896.3736985,10.1145/3711896.3736985,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","coreset selection, llm-based recommendation, model training",12,2126–2137,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"Although large language models (LLMs) have shown great potential in recommender systems, the prohibitive computational costs for fine-tuning LLMs on entire datasets hinder their successful deployment in real-world scenarios. To develop affordable and effective LLM-based recommender systems, we focus on the task of coreset selection which identifies a small subset of fine-tuning data to optimize the test loss, thereby facilitating efficient LLMs' fine-tuning. Although there exist some intuitive solutions of subset selection, including distribution-based and importance-based approaches, they often lead to suboptimal performance due to the misalignment with downstream fine-tuning objectives or weak generalization ability caused by individual-level sample selection. To overcome these challenges, we propose GORACS, which is a novel Group-level Optimal tRAnsport-guided Coreset Selection framework for LLM-based recommender systems. GORACS is designed based on two key principles for coreset selection: 1) selecting the subsets that minimize the test loss to align with fine-tuning objectives, and 2) enhancing model generalization through group-level data selection. Corresponding to these two principles, GORACS has two key components: 1) a Proxy Optimization Objective (POO) leveraging optimal transport and gradient information to bound the intractable test loss, thus reducing computational costs by avoiding repeated LLM retraining, and 2) a two-stage Initialization-Then-Refinement Algorithm (ITRA) for efficient group-level selection. Our extensive experiments across diverse recommendation datasets and tasks validate that GORACS significantly reduces fine-tuning costs of LLMs while achieving superior performance over the state-of-the-art baselines and full data training.",10.1145/3711896.3736985,https://doi.org/10.1145/3711896.3736985,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,GORACS: Group-level Optimal Transport-guided Coreset Selection for LLM-based Recommender Systems,"Mei, Tiehua and Chen, Hengrui and Yu, Peng and Liang, Jiaqing and Yang, Deqing",inproceedings,10.1145/3711896.3736985,
10.1145/3711896.3736987,10.1145/3711896.3736987,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","clustering, communication efficiency, federated learning, gradient robustness, recommender systems",11,1999–2009,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"As a promising privacy-aware collaborative model training paradigm, Federated Learning (FL) is becoming popular in the design of distributed recommender systems. However, Federated Recommender Systems (FedRecs) greatly suffer from two major problems: i) extremely high communication overhead due to massive item embeddings involved in recommendation systems, and ii) intolerably low training efficiency caused by the entanglement of both heterogeneous network environments and client devices. Although existing methods attempt to employ various compression techniques to reduce communication overhead, due to the parameter errors introduced by model compression, they inevitably suffer from model performance degradation. To simultaneously address the above problems, this paper presents a communication-efficient FedRec framework named FedRAS, which adopts an action-sharing strategy to cluster the gradients of item embedding into a specific number of model updating actions for communication rather than directly compressing the item embeddings. In this way, the cloud server can use the limited actions from clients to update all the items. Since gradient values are significantly smaller than item embeddings, constraining the directions of gradients (i.e., the action space) introduces smaller errors compared to compressing the entire item embedding matrix into a reduced space. To accommodate heterogeneous devices and network environments, FedRAS incorporates an adaptive clustering mechanism that dynamically adjusts the number of actions. Comprehensive experiments on well-known datasets demonstrate that FedRAS can reduce the size of communication payloads by up to 96.88%, while not sacrificing recommendation performance within various heterogeneous scenarios. We have open-sourced FedRAS at https://github.com/mastlab-T3S/FedRAS.",10.1145/3711896.3736987,https://doi.org/10.1145/3711896.3736987,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,Gradients as An Action: Towards Communication-Efficient Federated Recommender Systems via Adaptive Action Sharing,"Lu, Zhufeng and Jia, Chentao and Hu, Ming and Xie, Xiaofei and Chen, Mingsong",inproceedings,10.1145/3711896.3736987,
10.1145/3711896.3737068,10.1145/3711896.3737068,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","magnitude, popularity, recommender systems, weight decay",12,1975–1986,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"Collaborative filtering (CF) enables large-scale recommendation systems by encoding information from user-item interactions into dense ID-embedding tables. However, as embedding tables grow, closed-form solutions become impractical, necessitating the use of mini-batch gradient descent. Despite extensive work on loss function design, we argue that one core component of these pipelines is heavily overlooked: weight decay. Attaining high-performing models typically requires careful tuning of weight decay, regardless of loss, yet its necessity is not well understood. In this work, we question why weight decay is crucial in CF pipelines and how it impacts training. Through theoretical and empirical analysis, we uncover that weight decay's primary function is to encode popularity information into the magnitudes of the embedding vectors. Moreover, we find that tuning weight decay acts as a coarse, non-linear, knob to influence preference towards popular or unpopular items. Based on these findings, we propose PRISM (Popularity-awaRe Initialization Strategy for embedding Magnitudes), a straightforward yet effective solution to simplify the training of CF models. PRISM pre-encodes the popularity information typically learned through weight decay, eliminating its necessity. Our experiments show that PRISM improves performance by up to 4.77% and reduces training times by 38.48%, compared to state-of-the-art training strategies. Additionally, PRISM offers a cost-effective and meaningful strategy to mitigate popularity bias.",10.1145/3711896.3737068,https://doi.org/10.1145/3711896.3737068,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,On the Role of Weight Decay in Collaborative Filtering: A Popularity Perspective,"Loveland, Donald and Ju, Mingxuan and Zhao, Tong and Shah, Neil and Koutra, Danai",inproceedings,10.1145/3711896.3737068,
10.1145/3711896.3737116,10.1145/3711896.3737116,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","graph neural network, longitudinal data, missing data",9,3912–3920,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"In this paper, we propose a novel framework, the Sampling-guided Heterogeneous Graph Neural Network (HT-GNN), to effectively tackle the challenge of missing data imputation in longitudinal studies. Unlike traditional methods, which often require extensive preprocessing to handle irregular or inconsistent missing data, our approach accommodates arbitrary missing data patterns while maintaining computational efficiency. HT-GNN models both observations and covariates as distinct node types, connecting observation nodes at successive time points through subject-specific longitudinal subnetworks, while covariate-observation interactions are represented by attributed edges within bipartite graphs. By leveraging subject-wise mini-batch sampling and a multi-layer temporal smoothing mechanism, HT-GNN efficiently scales to large datasets, while effectively learning node representations and imputing missing data. Extensive experiments on both synthetic and real-world datasets, including the Alzheimer's Disease Neuroimaging Initiative (DNI) dataset, demonstrate that HT-GNN significantly outperforms existing imputation methods, even with high missing data rates (e.g., 80%). The empirical results highlight HT-GNN's robust imputation capabilities and superior performance, particularly in the context of complex, large-scale longitudinal data.",10.1145/3711896.3737116,https://doi.org/10.1145/3711896.3737116,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,Sampling-guided Heterogeneous Graph Neural Network with Temporal Smoothing for Scalable Longitudinal Data Imputation,"Zhang, Zhaoyang and Chen, Ziqi and Liu, Qiao and Xie, Jinhan and Zhu, Hongtu",inproceedings,10.1145/3711896.3737116,
10.1145/3711896.3737146,10.1145/3711896.3737146,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","causal inference, popularity bias, recommendation",11,2790–2800,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"Popularity bias occurs when popular items are recommended far more frequently than they should be, negatively impacting both user experience and recommendation accuracy. Existing debiasing methods mitigate popularity bias often uniformly across all users and only partially consider the time evolution of users or items. However, users have different levels of preference for item popularity, and this preference is evolving over time. To address these issues, we propose a novel method called CausalEPP (Causal Intervention on Evolving Personal Popularity) for taming recommendation bias, which accounts for the evolving personal popularity of users. Specifically, we first introduce a metric called Evolving Personal Popularity to quantify each user's preference for popular items. Then, we design a causal graph that integrates evolving personal popularity into the conformity effect, and apply deconfounded training to mitigate the popularity bias of the causal graph. During inference, we consider the evolution consistency between users and items to achieve a better recommendation. Empirical studies demonstrate that CausalEPP outperforms baseline methods in reducing popularity bias while improving recommendation accuracy.",10.1145/3711896.3737146,https://doi.org/10.1145/3711896.3737146,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,Taming Recommendation Bias with Causal Intervention on Evolving Personal Popularity,"Tan, Shiyin and Li, Dongyuan and Jiang, Renhe and Wang, Zhen and Yu, Xingtong and Okumura, Manabu",inproceedings,10.1145/3711896.3737146,
10.1145/3711896.3737156,10.1145/3711896.3737156,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","diffusion model, graph neural networks, neural ordinary differential equation, sequential recommendation",12,637–648,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"Sequential recommendation (SR) is widely deployed in e-commerce platforms, streaming services, etc., revealing significant potential to enhance user experience. The core of SR lies in exploring the sequential relationships in historical user-item interactions. However, existing methods often overlook two critical factors: irregular user interests between interactions and highly uneven item distributions over time. The former factor implies that actual user preferences are not always continuous, and long-term historical interactions may not be relevant to current purchasing behavior. Therefore, relying only on these historical interactions for recommendations may result in a lack of user interest at the target time. The latter factor, characterized by peaks and valleys in interaction frequency, may result from seasonal trends, special events, or promotions. These externally driven distributions may not align with individual user interests, leading to inaccurate recommendations. To address these deficiencies, we propose TGODE to both enhance and capture the long-term historical interactions. Specifically, we first construct the user time graph and item evolution graph, which utilize user personalized preferences and global item distribution information, respectively. To tackle the temporal sparsity caused by irregular user interactions, we design a time-guided diffusion generator to automatically obtain an augmented time-aware user graph. Additionally, we devise a user interest truncation factor to efficiently identify sparse time intervals and achieve balanced preference inference. After that, the augmented user graph and item graph are fed into a generalized graph neural ordinary differential equation (ODE) to align with the evolution of user preferences and item distributions. This allows two patterns of information evolution to be matched over time. Experimental results demonstrate that TGODE outperforms baseline methods across five datasets, with improvements ranging from 10% to 46%. The code is available at https://github.com/Qin-lab-code/TGODE.",10.1145/3711896.3737156,https://doi.org/10.1145/3711896.3737156,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,Time Matters: Enhancing Sequential Recommendations with Time-Guided Graph Neural ODEs,"Fu, Haoyan and Qin, Zhida and Yang, Shixiao and Zhang, Haoyao and Lu, Bin and Li, Shuang and Huang, Tianyu and Lui, John C.S.",inproceedings,10.1145/3711896.3737156,
10.1145/3711896.3737176,10.1145/3711896.3737176,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","graph prompt, region representation, urban foundation model",12,1071–1082,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"Urban region representation is crucial for various urban downstream tasks. However, despite the proliferation of methods and their success, acquiring general urban region knowledge and adapting to different tasks remains challenging. Existing work pays limited attention to the fine-grained functional layout semantics in urban regions, limiting their ability to capture transferable knowledge across regions. Further, inadequate handling of the unique features and relationships required for different downstream tasks may also hinder effective task adaptation. In this paper, we propose a Graph-based Urban Region Pre-training and Prompting framework (GURPP) for region representation learning. Specifically, we first construct an urban region graph and develop a subgraph-centric urban region pre-training model to capture the heterogeneous and transferable patterns of entity interactions. This model pre-trains knowledge-rich region embeddings using contrastive learning and multi-view learning methods. To further refine these representations, we design two graph-based prompting methods: a manually-defined prompt to incorporate explicit task knowledge and a task-learnable prompt to discover hidden knowledge, which enhances the adaptability of these embeddings to different tasks. Extensive experiments on various urban region prediction tasks and different cities demonstrate the superior performance of our framework.",10.1145/3711896.3737176,https://doi.org/10.1145/3711896.3737176,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,Urban Region Pre-training and Prompting: A Graph-based Approach,"Jin, Jiahui and Song, Yifan and Kan, Dong and Zhu, Haojia and Sun, Xiangguo and Li, Zhicheng and Sun, Xigang and Zhang, Jinghui",inproceedings,10.1145/3711896.3737176,
10.1145/3711896.3737398,10.1145/3711896.3737398,KDD.bib,1,['KDD.bib'],8,KDD '25,"Toronto ON, Canada","benchmarking, data generation, probabilistic modeling, recommendation",12,5710–5721,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2,"Simulating a recommendation system in a controlled environment, to identify specific behaviors and user preferences, requires highly flexible synthetic data generation models capable of mimicking the patterns and trends of real datasets. In this context, we propose HYDRA, a novel preferences data generation model driven by three main factors: user-item interaction level, item popularity, and user engagement level. The key innovations of the proposed process include the ability to generate user communities characterized by similar item adoptions, reflecting real-world social influences and trends. Additionally, HYDRA considers item popularity and user engagement as mixtures of different probability distributions, allowing for a more realistic simulation of diverse scenarios. This approach enhances the model's capacity to simulate a wide range of real-world cases, capturing the complexity and variability found in actual user behavior. We demonstrate the effectiveness of HYDRA through extensive experiments on well-known benchmark datasets. The results highlight its capability to replicate real-world data patterns, offering valuable insights for developing and testing recommendation systems in a controlled and realistic manner. The code used to perform the experiments is publicly available: https://github.com/flexibledatageneration/HYDRA.",10.1145/3711896.3737398,https://doi.org/10.1145/3711896.3737398,"New York, NY, USA",Association for Computing Machinery,9798400714542,2025,Flexible Generation of Preference Data for Recommendation Analysis,"Mungari, Simone and Coppolillo, Erica and Ritacco, Ettore and Manco, Giuseppe",inproceedings,10.1145/3711896.3737398,
10.1145/3746252.3760835,10.1145/3746252.3760835,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","graph neural network., information diffusion prediction, multi-layered social network, sequential hypergraph",5,4775–4779,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Information diffusion prediction, the forecasting of propagation paths, provides critical insights into information spread mechanisms, directly enabling applications like misinformation spread forecasting and detection for malicious account. Prior research primarily focused on combining user social graphs and information cascades for prediction, often overlooking the distinct role characteristics users exhibit during interactions. Classifying users into different roles enables the construction of a multi-layered social graph, facilitating the extraction of deeper user features. This paper introduces a model that leverages multi-dimensional interactions between user features. Specifically, to account for users' dynamic preferences, we construct sequential hypergraphs from information cascades using timestamps and utilize a hypergraph neural network to extract users' dynamic features. Furthermore, to capture users' static features, we build multi-layer social networks from the social graph based on users' roles. We employ graph convolutional networks to separately extract static features from each layer and subsequently fuse them using an attention mechanism. Superior performance of our framework is evidenced by experimental validation on real-world datasets against cutting-edge benchmarks.",10.1145/3746252.3760835,https://doi.org/10.1145/3746252.3760835,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Information Diffusion Prediction Based on User Multi-Dimensional Feature Interaction,"He, Jiaxing and Fang, Yang and Shao, Tianyang and Zhao, Xiang",inproceedings,10.1145/3746252.3760835,
10.1145/3746252.3760923,10.1145/3746252.3760923,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","counterfactual inference, recommender systems, sentiment bias",5,5079–5083,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Sentiment bias is newly discovered in Recommender Systems (RSs). Critical users and niche items are disadvantaged by such unfair recommendations. To mitigate this bias, we propose a novel approach by counterfactual inference, which is implemented in two stages. Experiment results validate that our model achieves comparable performance in rating prediction, providing better recommendations and effectively mitigating sentiment bias. To the best of our knowledge, this is the first work to employ counterfactual inference on sentiment bias mitigation in RSs.",10.1145/3746252.3760923,https://doi.org/10.1145/3746252.3760923,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Eliminating Sentiment Bias in Recommender Systems by Counterfactual Inference,"Pan, Le and Cao, Yuanjiang and Huang, Chengkai and Zhang, Wenjie and Yao, Lina",inproceedings,10.1145/3746252.3760923,
10.1145/3746252.3760965,10.1145/3746252.3760965,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","dynamic profile refinement, large language model, personalization, theory of planned behavior, user modeling",5,5063–5067,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"In this paper, we propose TRIPLE (TPB-dRIven Profiling with LLM rEfinement), a dynamic profiling framework that incorporates the Theory of Planned Behavior (TPB) into user profile modeling. Our method (1) extracts TPB components from historical text data to construct an initial user profile, (2) iteratively refines this profile by analyzing discrepancies between predicted and actual behaviors, and (3) continuously updates the user's state by incorporating newly arriving text. We evaluate TRIPLE on the LaMP datasets, focusing on rating prediction and personalized tweet paraphrasing tasks, using multiple open-source large language models. Experimental results demonstrate that TRIPLE consistently outperforms existing profiling methods across all evaluation settings. Qualitative analysis confirms that TRIPLE captures the psychological and social mechanisms underlying users' product evaluation and description. These findings provide empirical evidence that theory- driven user profiling can significantly improve personalization performance in recommender systems and related applications. Our implementation and examples of generated profiles are available at https://yestaehyung.github.io/cikm25-triple/.",10.1145/3746252.3760965,https://doi.org/10.1145/3746252.3760965,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Externalizing Social-Cognitive Structures for User Modeling: Toward Theory-Driven Profiling with LLMs,"Noh, Taehyung and Jin, Seungwan and Yeo, Haein and Han, Kyungsik",inproceedings,10.1145/3746252.3760965,
10.1145/3746252.3760970,10.1145/3746252.3760970,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","hashtags, llms, popularity prediction, social media",5,5396–5400,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Hashtag trends ignite campaigns, shift public opinion, and steer millions of dollars in advertising spend, yet forecasting which tag goes viral is elusive. Classical regressors digest surface features but ignore context, while large language models (LLMs) excel at contextual reasoning but misestimate numbers. We present BuzzProphet, a reasoning-augmented hashtag popularity prediction framework that (1) instructs an LLM to articulate a hashtag's topical virality, audience reach, and timing advantage; (2) utilizes these popularity-oriented rationales to enrich the input features; and (3) regresses on these inputs. To facilitate evaluation, we release HashView, a 7,532-hashtag benchmark curated from social media. Across diverse regressor-LLM combinations, BuzzProphet reduces RMSE by up to 2.8% and boosts correlation by 30% over baselines, while producing human-readable rationales. Results demonstrate that using LLMs as context reasoners rather than numeric predictors injects domain insight into tabular models, yielding an interpretable and deployable solution for social media trend forecasting.",10.1145/3746252.3760970,https://doi.org/10.1145/3746252.3760970,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Forecasting the Buzz: Enriching Hashtag Popularity Prediction with LLM Reasoning,"Xu, Yifei and Wu, Jiaying and Wan, Herun and Li, Yang and Hou, Zhen and Kan, Min-Yen",inproceedings,10.1145/3746252.3760970,
10.1145/3746252.3760999,10.1145/3746252.3760999,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","hyperbolic spaces, knowledge graph, recommendation",11,2956–2966,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Knowledge Graphs (KGs) enhance recommender systems but face challenges from inherent noise, sparsity, and Euclidean geometry's inadequacy for complex relational structures, critically impairing representation learning, especially for long-tail entities. Existing methods also often lack adaptive multi-source signal fusion tailored to item popularity. This paper introduces SPARK, a novel multi-stage framework systematically tackling these issues. SPARK first employs Tucker low-rank decomposition to denoise KGs and generate robust entity representations. Subsequently, an SVD-initialized hybrid geometric GNN concurrently learns representations in Euclidean and Hyperbolic spaces; the latter is strategically leveraged for its aptitude in modeling hierarchical structures, effectively capturing semantic features of sparse, long-tail items. A core contribution is an item popularity-aware adaptive fusion strategy that dynamically weights signals from collaborative filtering, refined KG embeddings, and diverse geometric spaces for precise modeling of both mainstream and long-tail items. Finally, contrastive learning aligns these multi-source representations. Extensive experiments demonstrate SPARK's significant superiority over state-of-the-art methods, particularly in improving long-tail item recommendation, offering a robust, principled approach to knowledge-enhanced recommendation. Implementation code is anonymously online. https://github.com/Applied-Machine-Learning-Lab/SPARK.",10.1145/3746252.3760999,https://doi.org/10.1145/3746252.3760999,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,SPARK: Adaptive Low-Rank Knowledge Graph Modeling in Hybrid Geometric Spaces for Recommendation,"Wang, Binhao and Xiao, Yutian and Wang, Maolin and Li, Zhiqi and Wei, Tianshuo and Guo, Ruocheng and Zhao, Xiangyu",inproceedings,10.1145/3746252.3760999,
10.1145/3746252.3761034,10.1145/3746252.3761034,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","adversarial attacks, visually-aware recommender system",10,1829–1838,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Visually-aware recommender system (VARS) has become increasingly prevalent in various online services by integrating visual features of items to enhance recommendation quality. However, VARS introduces new security vulnerabilities and malicious attackers can perform visual shilling attacks to manipulate recommendation lists via uploading generated images with visually imperceptible perturbations. While prior research has explored such threats to help service providers enhance their systems, existing visual shilling attack methods still suffer from uncontrolled pixel-space perturbation, energy dispersion dilemma and semantic misalignment in reference selection. In this work, we present Semantic-Constrained Diffusion Adversarial Generation (SC-DAG) for visual shilling attacks. SC-DAG overcomes key limitations of previous methods by focusing perturbations on semantically meaningful image regions through contour-aware segmentation, guiding adversarial generation in latent space using a conditional diffusion process, and performing a hybrid reference image selection strategy that balances popularity and semantic similarity. Extensive experiments on performing visual shilling attacks against multiple VARS models show that SC-DAG achieves state-of-the-art attack performance in elevating target items' ranking, while maintaining strong perceptual indistinguishability and minimal impact on overall recommendation performance of the system. Our work offers insights into leveraging structured semantic priors for more sophisticated adversarial manipulations against VARS and also highlights the necessity for developing more robust VARS models resilient to visual shilling attacks. We provide our implementation at https://github.com/KDEGroup/SC-DAG.",10.1145/3746252.3761034,https://doi.org/10.1145/3746252.3761034,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,SC-DAG: Semantic-Constrained Diffusion Attacks for Stealthy Exposure Manipulation in Visually-Aware Recommender Systems,"Lin, Ze and Qian, Yuqiu and Li, Xiaodong and Lyu, Ziyu and Li, Hui",inproceedings,10.1145/3746252.3761034,
10.1145/3746252.3761054,10.1145/3746252.3761054,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","conformal prediction, recommendation system, retrieval-augmented generation (rag)",10,4181–4190,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Recently, Large Language Models with Retrieval-Augmented Generation (RAG) have recently emerged as a powerful paradigm for sequential recommendation. However, existing methods typically retrieve items for each user without any principled mechanism for guaranteeing the reliability of generated recommendations, limiting their trustworthiness. To address this, we introduce SarRec : Statistically-guaranteed Augmented Retrieval for Recommendations, a framework that uses a simple retrieval step to provide relevant context and delivers calibrated, uncertainty-aware predictions with formal statistical guarantees. Specifically, SarRec first constructs the user's context set, utilizing a lightweight differentiable retrieval mechanism for identifying relevant context, and then calibrates the LLM's outputs by adapting the conformal prediction mechanism. We further provide a theoretical analysis that establishes an upper bound on the expected risk of recommendation performance metrics. Extensive experiments on multiple datasets from different domains validate the effectiveness of our framework.",10.1145/3746252.3761054,https://doi.org/10.1145/3746252.3761054,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,SarRec: Statistically-guaranteed Augmented Retrieval for Recommendation,"Zhang, Tong and Bisht, Nitin and Li, Zihao and Xu, Guandong and Wang, Xianzhi",inproceedings,10.1145/3746252.3761054,
10.1145/3746252.3761080,10.1145/3746252.3761080,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","cold-start recommendations, data augmentation, large language models, meta-learning",11,3844–3854,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"The cold-start problem remains a long-standing challenge in recommender systems. Recent advances in large language models (LLMs) have opened new avenues for addressing cold-start scenarios through data augmentation. However, existing cold-start augmentation methods often suffer from negative augmentation, manifesting as incomplete augmentation, where generated interactions fail to comprehensively reflect user preferences, and inaccurate augmentation, where they conflict with user intent. These issues largely stem from two limitations: (1) the inability to effectively incorporate collaborative signals, which are critical for preference alignment, and (2) the lack of awareness of the downstream model's learning dynamics during data augmentation. To the best of our knowledge, the latter has not been studied in the literature.Consequently, we propose a novel framework named PAnDA. To address the incomplete augmentation issue, we propose a model-agnostic preference-aligned augmentation module to iteratively extract and fuse textual information and collaborative information by user-user preference matching and user-item preference coherence, which together form a contextual cue to guide the augmentor to generate high-quality augmented data. To overcome the inaccurate augmentation issue, we propose a model-specific downstream-model-aware adaptation module to adaptively align the augmented data with the model's states during the training process, guided by gradient similarity. Extensive experiments on three public benchmark datasets demonstrate that PAnDA outperforms different groups of state-of-the-art cold-start recommendation methods in all scenarios. The source code is publicly available at https://github.com/YantongDU/PAnDA.",10.1145/3746252.3761080,https://doi.org/10.1145/3746252.3761080,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,PAnDA: Combating Negative Augmentation via Large Language Models for User Cold-Start Recommendations,"Du, Yantong and Chen, Rui and Zhao, Xiangyu and Han, Qilong and Qin, A. K.",inproceedings,10.1145/3746252.3761080,
10.1145/3746252.3761111,10.1145/3746252.3761111,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","content moderation, content-agnostic, polarization, recommender systems",11,1613–1623,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Personalized recommendation systems often drive users towards more extreme content, exacerbating opinion polarization. While content-aware moderation has been proposed to mitigate these effects, such approaches risk curtailing the freedom of speech and information. To address this concern, we propose and explore the feasibility of content-agnostic moderation as an alternative approach for reducing polarization. Content-agnostic moderation does not rely on the actual content being moderated, arguably making it less prone to forms of censorship. We establish theoretically that content-agnostic moderation cannot be guaranteed to work in a fully generic setting. However, we show that it can often be effectively achieved in practice with plausible assumptions. We introduce two novel content-agnostic moderation methods that modify recommendations from the content recommender to disperse user-item co-clusters without relying on content features. To evaluate the potential of content-agnostic moderation in controlled experiments, we built a simulation environment to analyze the closed-loop behavior of a system with a given set of users, a recommendation system, and a moderation approach. Through comprehensive experiments in this environment, we show that our proposed moderation methods significantly enhance stance neutrality and maintain high recommendation quality across various data scenarios. Our results indicate that achieving stance neutrality without direct content information is not only feasible but can also help develop more balanced and informative recommendation systems without substantially degrading user engagement.",10.1145/3746252.3761111,https://doi.org/10.1145/3746252.3761111,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Content-Agnostic Moderation for Stance-Neutral Recommendations,"Li, Nan and Kang, Bo and De Bie, Tijl",inproceedings,10.1145/3746252.3761111,
10.1145/3746252.3761126,10.1145/3746252.3761126,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","discriminative counterfactual debiasing, llm-enhanced counterfactual inference, recommender system, two-sided fairness",10,867–876,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Fairness-aware recommendation has emerged as a pivotal research area in recent years. Current fairness studies primarily examine two independent dimensions: user-side fairness and item-side fairness. However, most approaches address each side's fairness in isolation while neglecting their complex interdependencies. In this paper, we propose an LLM-Enhanced DiscriminAtive Counterfactual Debiasing Model for Two-sided Fairness in Recommendation (LeadFairRec). Specifically, we first design a two-sided causal graph that jointly models provider-customer fairness interactions through their causal relationships. Then we propose a discriminative counterfactual debiasing method, which effectively removes spurious correlations while maintaining true user-item interactions. Finally, we propose an LLM-enhanced counterfactual inference method to derive noise-resistant user/item representations from interaction data, enhancing the robustness of causal debiasing. The experimental results demonstrate the high effectiveness of our proposed model. We provide our code at https://github.com/houyimin660/LeadFairRec.",10.1145/3746252.3761126,https://doi.org/10.1145/3746252.3761126,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,LeadFairRec: LLM-enhanced Discriminative Counterfactual Debiasing for Two-sided Fairness in Recommendation,"Hou, Yimin and Kou, Yue and Shen, Derong and Zhou, Xiangmin and Li, Dong and Nie, Tiezheng and Yu, Ge",inproceedings,10.1145/3746252.3761126,
10.1145/3746252.3761155,10.1145/3746252.3761155,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","causal inference, graph convolutional network, popularity bias, recommender systems",11,2471–2481,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Graph-based recommender systems leverage neighborhood aggregation to generate node representations, which is highly sensitive to popularity bias, resulting in an echo effect during information propagation. Existing graph-based debiasing solutions refine the aggregation process with attempts such as edge reconstruction or weight adjustment. However, these methods remain inadequate in fully alleviating popularity bias. Specifically, this is because 1) they provide no insights into graph aggregation rationality, thus lacking an optimality guarantee; 2) they fail to well balance the training and debiasing process, which undermines the effectiveness. In this paper, we propose a novel approach to mitigate popularity bias through rational modeling of the graph aggregation process. We reveal that graph aggregation is a special form of backdoor adjustment in causal inference, where the aggregation weight corresponds to the historical interaction likelihood distribution. Based on this insight, we devise an encoder-decoder architecture, namely Causality-aware Graph Aggregation Weight Estimator for Debiasing (CAGED), to approximate the unbiased aggregation weight by optimizing the evidence lower bound of the interaction likelihood. In order to enhance the debiasing effectiveness during early training stages, we further design a momentum update strategy that incrementally refines the aggregation weight matrix. Extensive experiments on three datasets demonstrate that CAGED outperforms existing graph-based debiasing methods. Our implementation is available at https://github.com/QueYork/CAGED.",10.1145/3746252.3761155,https://doi.org/10.1145/3746252.3761155,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Causality-aware Graph Aggregation Weight Estimator for Popularity Debiasing in Top-K Recommendation,"Que, Yue and Zhang, Yingyi and Zhao, Xiangyu and Ma, Chen",inproceedings,10.1145/3746252.3761155,
10.1145/3746252.3761168,10.1145/3746252.3761168,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","recommendation evaluation metrics, recommender systems, social information utilization, social recommendation",10,2105–2114,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Social recommendation, which leverages users' social information to predict users' preferences, is a popular branch of recommender systems. Many existing studies have attempted to advance the performance of collaborative filtering methods by leveraging the user-user matrix to enhance user embedding learning with user's social connections. While the existing social recommender systems have demonstrated good performance in various recommendation tasks, the extent of social information usefulness in recommender systems remains unclear. This paper addresses the research gap by designing experiments to answer three research questions: (i) How useful is social information in varying user-item data sparsity? (ii) How much social information do the existing social recommendation models use? (iii) How valuable is social information for cold-start situations? Working towards answering the research questions, we introduce evaluation metrics to estimate the utilization of social information in the existing social recommendation models. We conducted experiments on three publicly available social recommendation datasets, and our results showed that there are diminishing returns when applying social information in recommender systems.",10.1145/3746252.3761168,https://doi.org/10.1145/3746252.3761168,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Usefulness and Diminishing Returns: Evaluating Social Information in Recommender Systems,"Meng, Qing and Min, Huiyu and Hee, Ming Shan and Lee, Roy Ka-Wei and Dai, Bing Tian and Xu, Shuai",inproceedings,10.1145/3746252.3761168,
10.1145/3746252.3761174,10.1145/3746252.3761174,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","graph learning, hypercomplex algebra, multimodal, prompt-aware, recommendation",12,403–414,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Modern recommender systems face critical challenges in handling information overload while addressing the inherent limitations of multimodal representation learning. Existing methods suffer from three fundamental limitations: (1) restricted ability to represent rich multimodal features through a single representation, (2) existing linear modality fusion strategies ignore the deep nonlinear correlations between modalities, and (3) static optimization methods failing to dynamically mitigate the over-smoothing problem in graph convolutional network (GCN). To overcome these limitations, we propose HPMRec, a novel Hypercomplex Prompt-aware Multimodal Recommendation framework, which utilizes hypercomplex embeddings in the form of multi-components to enhance the representation diversity of multimodal features. HPMRec adopts the hypercomplex multiplication to naturally establish nonlinear cross-modality interactions to bridge semantic gaps, which is beneficial to explore the cross-modality features. HPMRec also introduces the prompt-aware compensation mechanism to aid the misalignment between components and modality-specific features loss, and this mechanism fundamentally alleviates the over-smoothing problem. It further designs self-supervised learning tasks that enhance representation diversity and align different modalities. Extensive experiments on four public datasets show that HPMRec achieves state-of-the-art recommendation performance.",10.1145/3746252.3761174,https://doi.org/10.1145/3746252.3761174,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Hypercomplex Prompt-aware Multimodal Recommendation,"Chen, Zheyu and Xu, Jinfeng and Wang, Hewei and Yang, Shuo and Wan, Zitong and Hu, Haibo",inproceedings,10.1145/3746252.3761174,
10.1145/3746252.3761201,10.1145/3746252.3761201,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","eeg signals, few-shot learning, music recommendation, recommender systems",10,823–832,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Brain-computer interface based on electroencephalogram (EEG) has demonstrated significant potential for capturing users' implicit preferences, offering an innovative technique for music recommendation. However, we face two key challenges: (1) ineffective distinction of complex neural patterns in EEG signals, and (2) the cold-start problem, due to limited user EEG samples. To address these issues, we present EEG-FSL, a novel framework that integrates model-agnostic meta-learning (MAML) with dual-path neural feature extraction for music recommendation. EEG-FSL applies an attention-enhanced EEG encoder to extract meaningful patterns from brain signals through complementary pathways: one pathway retains temporal and phase information, while the other focuses on extracting common frequency-domain features. Furthermore, we utilize contrastive learning to explore the intrinsic structure of the data, significantly improving the model's feature differentiation ability. Additionally, we propose a meta-learning method which allows EEG-FSL to quickly adapt to new users using only a small number of EEG samples, effectively solving cold-start problem. Extensive experiments are conducted on a real-world dataset demonstrate the effectiveness of the proposed method. Specially, in few-shot scenarios, compared to the best baseline, our approach improves mean squared error in score prediction by 8.4% and classification accuracy by 16.8%. Consequently, our work provides a practical solution for next-generation brain-computer interface applications, capable of delivering highly personalized content recommendations while minimizing user data collection requirements. Our code is available at https://anonymous.4open.science/r/EEG-FSL-code-72F3/.",10.1145/3746252.3761201,https://doi.org/10.1145/3746252.3761201,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,EEG-FSL: An EEG-Based Few-Shot Learning Framework for Music Recommendation,"He, Ming and Luo, Wenbo and Zheng, Yongjie and Zhang, Junkai and Gao, Xiaolei",inproceedings,10.1145/3746252.3761201,
10.1145/3746252.3761213,10.1145/3746252.3761213,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","multi-faceted user representation, personalized federated learning, prototype learning, recommender system",10,2399–2408,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Personalized recommender systems are critical for enhancing user engagement across a range of digital platforms. However, conventional approaches rely heavily on centralized data collection, raising significant privacy concerns. Federated recommender systems (PFRS) address these concerns by decentralizing model training, ensuring user data privacy. Despite the progress, existing methods still struggle with capturing the multi-faceted nature of user and transferring global knowledge effectively. In this work, we propose FedMUR, a novel federated recommendation framework that models user representation as a Gaussian mixture distribution, capturing users' multi-faceted characteristics. Each Gaussian component corresponds to a distinct interest facet, with adaptive mixture weights representing the user's preference intensity toward each facet. To facilitate knowledge transfer, FedMUR constructs global consistent prototypes that encode shared behavioral trends across users via popularity-weighted optimal transport. These prototypes enhance local models by injecting global shared patterns into personalized representation learning. Extensive experiments across several real-world datasets demonstrate that FedMUR significantly outperforms existing state-of-the-art federated recommendation systems.",10.1145/3746252.3761213,https://doi.org/10.1145/3746252.3761213,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Personalized Federated Recommendation with Multi-Faceted User Representation and Global Consistent Prototype,"Qian, Jiaming and Liao, Xinting and Qu, Xiangmou and Fu, Zhihui and Lou, Xingyu and Zhang, Changwang and Zhou, Pengyang and Zhou, Zijun and Wang, Jun and Chen, Chaochao",inproceedings,10.1145/3746252.3761213,
10.1145/3746252.3761223,10.1145/3746252.3761223,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","knowledge graph, sentiment analysis, web semantic mining",11,4106–4116,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Fine-grained sentiment analysis, which aims to identify sentiments associated with specific aspects within sentences, faces challenges in effectively incorporating commonsense knowledge. Recent advancements leveraging large language models (LLMs) as data generators show promise but are limited by the LLMs' lack of nuanced, domain-specific understanding and pose a significant risk of data leakage during inference, potentially leading to inflated performance metrics. To address these limitations, we propose LLM-Kit, a novel framework for commonsense-enhanced fine-grained sentiment analysis that integrates knowledge via LLM-guided graph construction, effectively mitigating data leakage risks. LLM-Kit operates in two key stages: (1) Commonsense Graph Construction (CGC): We design second-order rules and leverage LLMs for evaluation to ensure the accuracy of the generated graph and mitigate the risk of data leakage from LLMs. (2) Knowledge-integration Graph Representation Learning (KGRL): We extract knowledge that is aware of various aspects through Graph Representation Learning (GRL). To capture the underlying semantic nuances within the input sentence, we develop a Sentence Semantic Learning (SSL) module based on RoBERTa that explicitly encodes internal semantics. This module provides complementary information to the GCN, improving the model's ability to discern subtle sentiment variations related to different aspects. Comprehensive experiments on three public datasets affirm that LLM-Kit achieves comparable performance with state-of-the-art models.",10.1145/3746252.3761223,https://doi.org/10.1145/3746252.3761223,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Harnessing Commonsense: LLM-Driven Knowledge Integration for Fine-Grained Sentiment Analysis,"Zhang, Kai and Han, Yupeng",inproceedings,10.1145/3746252.3761223,
10.1145/3746252.3761263,10.1145/3746252.3761263,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","evaluation., fairness, negative sampling, recommender systems",10,3720–3729,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Recommender systems trained on implicit feedback data rely on negative sampling to distinguish positive items from negative items for each user. Since the majority of positive interactions come from a small group of active users, negative samplers are often impacted by data imbalance, leading them to choose more informative negatives for prominent users while providing less useful ones for users who are not so active. This leads to inactive users being further marginalised in the training process, thus receiving inferior recommendations. In this paper, we conduct a comprehensive empirical study demonstrating that state-of-the-art negative sampling strategies provide more accurate recommendations for active users than for inactive users. We also find that increasing the number of negative samples for each positive item improves the average performance, but the benefit is distributed unequally across user groups, with active users experiencing performance gain while inactive users suffering performance degradation. To address this, we propose a group-specific negative sampling strategy that assigns smaller negative ratios to inactive user groups and larger ratios to active groups. Experiments on eight negative samplers show that our approach improves user-side fairness and performance when compared to a uniform global ratio.",10.1145/3746252.3761263,https://doi.org/10.1145/3746252.3761263,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Evaluating and Addressing Fairness Across User Groups in Negative Sampling for Recommender Systems,"Xuan, Yueqing and Sokol, Kacper and Sanderson, Mark and Chan, Jeffrey",inproceedings,10.1145/3746252.3761263,
10.1145/3746252.3761313,10.1145/3746252.3761313,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","cold-start, large language model, recommender system",11,4455–4465,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Recently, pretrained large language models (LLMs) have been widely adopted in recommendation systems to leverage their textual understanding and reasoning abilities to model user behaviors and suggest future items. A key challenge in this setting is that items on most platforms are not included in the LLM's training data. Therefore, existing methods often fine-tune LLMs by introducing auxiliary item tokens to capture item semantics. However, in real-world applications such as e-commerce and short video platforms, the item space evolves rapidly, which gives rise to a cold-start setting, where many newly introduced items receive little or even no user engagement. This poses challenges in both learning accurate item token embeddings and generalizing efficiently to accommodate the continual influx of new items. In this work, we propose a novel meta-item token learning strategy to address both these challenges simultaneously. Specifically, we introduce MI4Rec, an LLM-based approach for recommendation that uses just a few learnable meta-item tokens and an LLM encoder to dynamically aggregate meta-items based on item content. We show that this paradigm allows highly efficient and accurate learning in such challenging settings. Extensive experiments on Yelp and Amazon reviews datasets demonstrate the effectiveness of MI4Rec in both warm-start and cold-start recommendations. Notably, MI4Rec achieves an average performance improvement of 20.4% in Recall and NDCG compared to the best-performing baselines. The implementation of MI4Rec is available at https://github.com/zhengzaiyi/MI4Rec",10.1145/3746252.3761313,https://doi.org/10.1145/3746252.3761313,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,MI4Rec: Pretrained Language Model based Cold-Start Recommendation with Meta-Item Embeddings,"Zheng, Zaiyi and Zhu, Yaochen and Liu, Haochen and Ju, Mingxuan and Zhao, Tong and Shah, Neil and Li, Jundong",inproceedings,10.1145/3746252.3761313,
10.1145/3746252.3761369,10.1145/3746252.3761369,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","alignment, large language models, recommendation",11,707–717,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Recent works have shown increasing interest in using natural language-based user profiles for recommender systems, as they offer greater transparency and interpretability compared to traditional embedding-based methods. Most existing approaches rely on zero-shot inference with large language models (LLMs) to generate these profiles, but the resulting quality remains insufficient, leading to suboptimal recommendation performance. In this paper, we present LangPTune, the first end-to-end training framework designed to directly optimize LLM-generated user profiles for recommendation tasks. By explicitly training the LLM for the recommendation objective, our approach significantly outperforms zero-shot baselines. Evaluations across training setups and benchmarks show that LangPTune not only exceeds the performance of zero-shot methods but also matches the performance of state-of-the-art embedding-based baselines. Additionally, we assess whether our training framework maintains the interpretability of user profiles, using both GPT-4 simulations and crowdworker studies.",10.1145/3746252.3761369,https://doi.org/10.1145/3746252.3761369,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,LangPTune: Optimizing Language-based User Profiles for Recommendation,"Gao, Zhaolin and Zhou, Joyce and Dai, Yijia and Joachims, Thorsten",inproceedings,10.1145/3746252.3761369,
10.1145/3746252.3761427,10.1145/3746252.3761427,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","denoising, large language model, recommender system, sequential recommendation, user interest",11,3427–3437,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Sequential recommendation aims to capture user preferences by modeling sequential patterns in user-item interactions. However, these models are often influenced by noise such as accidental interactions, leading to suboptimal performance. Therefore, to reduce the effect of noise, some works propose explicitly identifying and removing noisy items. However, we find that simply relying on collaborative information may result in an over-denoising problem, especially for cold items. To overcome these limitations, we propose a novel framework: Interest Alignment for Denoising Sequential Recommendation (IADSR) which integrates both collaborative and semantic information. Specifically, IADSR is comprised of two stages: in the first stage, we obtain the collaborative and semantic embeddings of each item from a traditional sequential recommendation model and an LLM, respectively. In the second stage, we align the collaborative and semantic embeddings and then identify noise in the interaction sequence based on long-term and short-term interests captured in the collaborative and semantic modalities. Our extensive experiments on four public datasets validate the effectiveness of the proposed framework and its compatibility with different sequential recommendation systems. The code and data are released for reproducibility: https://github.com/Applied-Machine-Learning-Lab/IADSR.",10.1145/3746252.3761427,https://doi.org/10.1145/3746252.3761427,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Empowering Denoising Sequential Recommendation with Large Language Model Embeddings,"Wu, Tongzhou and Wang, Yuhao and Wang, Maolin and Zhang, Chi and Zhao, Xiangyu",inproceedings,10.1145/3746252.3761427,
10.1145/3746252.3761429,10.1145/3746252.3761429,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","large language models, recommender systems, scaling, text-based collaborative filtering, universal representation and tranfer learning",11,1643–1653,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Text-based collaborative filtering (TCF) has emerged as the prominent technique for text and news recommendation, employing language models (LMs) as text encoders to represent items. However, the current landscape of TCF models mainly relies on the utilization of relatively small or medium-sized LMs. The potential impact of using larger, more powerful language models (such as these with over 100 billion parameters) as item encoders on recommendation performance remains uncertain. Can we anticipate unprecedented results and discover new insights?To address this question, we undertake a comprehensive series of experiments aimed at exploring the performance limits of the TCF paradigm. Specifically, we progressively augment the scale of item encoders, ranging from one hundred million to one hundred billion parameters, in order to reveal the scaling limits of the TCF paradigm. Moreover, we investigate whether these exceptionally large LMs have the potential to establish a universal item representation for the recommendation task, thereby revolutionizing the traditional ID paradigm, which is considered a significant obstacle to developing transferable ''one model fits all'' recommender models. Our study not only demonstrates positive results but also uncovers unexpected negative outcomes, illuminating the current state of the TCF paradigm within the community. These findings will evoke deep reflection and inspire further research on text-based recommender systems.",10.1145/3746252.3761429,https://doi.org/10.1145/3746252.3761429,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Exploring the Upper Limits of Text-Based Collaborative Filtering Using Large Language Models: Discoveries and Insights,"Li, Ruyu and Deng, Wenhao and Cheng, Yu and Yuan, Zheng and Zhang, Jiaqi and Yuan, Fajie",inproceedings,10.1145/3746252.3761429,
10.1145/3746252.3761452,10.1145/3746252.3761452,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","continual learning, personalization, recommender systems",4,6857–6860,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Modern recommender systems operate in uniquely dynamic settings: user interests, item pools, and popularity trends shift continuously, and models must adapt in real time without forgetting past preferences. While existing tutorials on continual or lifelong learning cover broad machine learning domains (e.g., vision and graphs), they do not address recommendation-specific demands-such as balancing stability and plasticity per user, handling cold-start items, and optimizing recommendation metrics under streaming feedback. This tutorial aims to make a timely contribution by filling that gap. We begin by reviewing the background and problem settings, followed by a comprehensive overview of existing approaches. We then highlight recent efforts to apply continual learning to practical deployment environments, such as resource-constrained systems and sequential interaction settings. Finally, we discuss open challenges and future research directions. We expect this tutorial to benefit researchers and practitioners in recommender systems, data mining, AI, and information retrieval across academia and industry.",10.1145/3746252.3761452,https://doi.org/10.1145/3746252.3761452,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Continual Recommender Systems,"Yoo, Hyunsik and Kang, Seongku and Tong, Hanghang",inproceedings,10.1145/3746252.3761452,
10.1145/3746252.3761496,10.1145/3746252.3761496,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","AutoML, hyperparameter optimization, multi-objective, retrieval",8,5955–5962,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"E-commerce retrieval and ranking optimization have expanded to incorporate broader metrics that capture user engagement and business objectives. Modern search frameworks now incorporate advanced quality features, such as sales counts and document-query relevance, to better align search results with these goals. Traditional methods typically focus on click-through rate (CTR) as a measure of engagement or relevance, but this can miss true purchase intent, creating a gap between user interest and actual conversions. Joint training with the click-through conversion rate (CTCVR) has become essential for understanding buying behavior, although its sparsity poses challenges for reliable optimization. This study presents MOHPER, a Multi-Objective HyperParameter optimization framework for E-commerce Retrieval systems. Using Bayesian optimization and sampling, it jointly optimizes CTR, CTCVR, and other relevant objectives, with a focus on user engagement and conversion. To enhance configuration selection in multi-objective optimization, we propose advanced hyperparameter selection methods, including a meta-configuration voting strategy and a cumulative training approach that leverages prior optima to improve training efficiency and performance. Currently deployed in a live setting, our proposed framework substantiates its practical efficacy in achieving a balanced optimization that aligns with both user satisfaction and revenue goals.",10.1145/3746252.3761496,https://doi.org/10.1145/3746252.3761496,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,MOHPER: Multi-objective Hyperparameter Optimization Framework for E-commerce Retrieval System,"Park, Jungbae, Park and Jang, Heonseok",inproceedings,10.1145/3746252.3761496,
10.1145/3746252.3761529,10.1145/3746252.3761529,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","multi-modal large language models, recommendation systems, semantic ids",8,6217–6224,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Semantic IDs are discrete identifiers generated by quantizing the Multi-modal Large Language Models embeddings, enabling efficient multi-modal content integration in recommendation systems. However, their lack of collaborative signals results in a misalignment with downstream discriminative and generative recommendation objectives. Recent studies have introduced various alignment mechanisms to address this problem, but their two-stage framework design still leads to two main limitations: (1) inevitable information loss during alignment, and (2) inflexibility in applying adaptive alignment strategies, consequently constraining the mutual information maximization during the alignment process. To address these limitations, we propose a novel and flexible one-stage Dual-Aligned Semantic IDs (DAS) method that simultaneously optimizes quantization and alignment, preserving semantic integrity and alignment quality while avoiding the information loss typically associated with two-stage methods. Meanwhile, DAS achieves more efficient alignment between the semantic IDs and collaborative signals, with the following two innovative and effective approaches: (1) Multi-view Constrative Alignment: To maximize mutual information between semantic IDs and collaborative signals, we first incorporate an ID-based CF debias module, and then design three effective contrastive alignment methods: dual user-to-item (u2i), dual item-to-item/user-to-user (i2i/u2u), and dual co-occurrence item-to-item/user-to-user (i2i/u2u). (2) Dual Learning: By aligning the dual quantizations of users and ads, the constructed semantic IDs for users and ads achieve stronger alignment. Finally, offline experiments and online A/B tests confirm DAS's efficacy, now serving 400M+ users in Kuaishou's ad platform.",10.1145/3746252.3761529,https://doi.org/10.1145/3746252.3761529,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System,"Ye, Wencai and Sun, Mingjie and Shi, Shaoyun and Wang, Peng and Wu, Wenjin and Jiang, Peng",inproceedings,10.1145/3746252.3761529,
10.1145/3746252.3761558,10.1145/3746252.3761558,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","multi-objective optimization, reinforcement learning",8,5575–5582,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"To provide promising recommendation results, there exist three major stages in the industrial RecSys chain to support our service: (1) The first Retrieval model aims at searching hundreds of item candidates. (2) Next, the Ranking model estimates the multiple aspect probabilities Pxtrs for each retrieved item. (3) At last, the Ensemble Sort stage merges those Pxtrs into one comparable score, and then selects the best dozen items with the highest scores to recommend them. To our knowledge, the wide-accepted industry ensemble sort approach still relies on manual formula-based adjustment, i.e., assigning manual weights for Pxtrs to control its influence on fusion score. Under this framework, the RecSys severely relies on expert knowledge to determine satisfactory weight for each Pxtr, which blocks RecSys's further advancements. In this paper, we provide Pantheon, a practical neural-network based ensemble sort. Compared with formulation-based ensemble sort, our Pantheon has the following advantages: (1) Personalized Joint Training: our Pantheon is jointly trained with the real-time ranking model, which could capture ever-changing user personalized interests accurately. (2) Representation inheritance: instead of the highly compressed Pxtrs, our Pantheon utilizes the fine-grained hidden-states as model input, which could benefit from the Ranking model to enhance our model complexity. Meanwhile, to reach a balanced multi-objective ensemble sort, we further devise an iterative Pareto policy optimization (IPPO) strategy to consider the multiple objectives at the same time. To our knowledge, this paper is the first work to replace the entire formulation-based ensemble sort in industry RecSys, which was fully deployed at Kuaishou live-streaming services, serving 400 Million users daily.",10.1145/3746252.3761558,https://doi.org/10.1145/3746252.3761558,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,Pantheon: Personalized Multi-objective Ensemble Sort via Iterative Pareto Policy Optimization,"Cao, Jiangxia and Xu, Pengbo and Cheng, Yin and Guo, Kaiwei and Tang, Jian and Wang, Shijun and Leng, Dewei and Yang, Shuang and Liu, Zhaojie and Niu, Yanan and Zhou, Guorui and Gai, Kun",inproceedings,10.1145/3746252.3761558,
10.1145/3746252.3761607,10.1145/3746252.3761607,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","human-llm agent interaction, social media agent, user engagement behavior",5,6392–6396,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"We release a large-scale dataset that captures interactions between human users and CommentRobert, an LLM-based social media agent on Weibo. The dataset contains Weibo posts in which users actively mention the LLM agent account @CommentRobert, indicating that the users are interested in interacting with the platform-empowered LLM agent. The dataset contains 557,645 interactions from 304,400 unique users over 17 months. We detail our data collection methodology, user attributes, and content characteristics, underscoring the dataset's value in examining real-world human-LLM agent interactions. Our analysis offers insights into the demographic and behavioral traits of users interested in the selected LLM agent, interaction dynamics between humans and the agent, and linguistic patterns in comments. These interactions provide a unique lens through which to explore how humans perceive, trust, and communicate with LLMs. This dataset enables further research into modeling human intent understanding, improving LLM agent design, and studying the evolution of human-LLM agent relationships. Potential applications also include long-term user engagement prediction and AI-generated comment detection on social platforms. This constructed dataset is available at https://zenodo.org/records/16921462.",10.1145/3746252.3761607,https://doi.org/10.1145/3746252.3761607,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,A Large-Scale Dataset of Interactions Between Weibo Users and Platform-Empowered LLM Agent,"Gu, Shaokui and Yin, Yongjie and Gong, Qingyuan and Tong, Fenghua and Zhou, Yipeng and Duan, Qiang and Chen, Yang",inproceedings,10.1145/3746252.3761607,
10.1145/3746252.3761655,10.1145/3746252.3761655,CIKM.bib,1,['CIKM.bib'],8,CIKM '25,"Seoul, Republic of Korea","micro-video dataset, video recommendation, video understanding",6,6486–6491,Proceedings of the 34th ACM International Conference on Information and Knowledge Management,"Micro-form videos have emerged as a popular form of content, leading to extensive research in micro-video recommendation with significant implications for the entertainment, advertising, and e-commerce industries. However, the lack of publicly available large-scale micro-video datasets presents a challenge for developing effective recommender systems. To address this challenge, we introduce a comprehensive and diverse micro-video recommendation dataset, referred to as ''MicroLens.'' This dataset comprises nine million user-item interaction behaviors, one million users, and 91 thousand full-length micro-videos. It includes rich modality information such as titles, cover images, and audio associated with the videos. MicroLens serves as a benchmark for the content-driven micro-video recommendation, allowing researchers to leverage diverse video modality information, particularly the raw video features, to enhance the effectiveness of recommender systems. This goes beyond the traditional reliance on item IDs or off-the-shelf pre-extracted video/visual features, providing new avenues for improving recommendation accuracy and personalization. We have conducted extensive experiments on MicroLens, benchmarking multiple recommender models and video encoders, which have provided valuable insights into the performance of micro-video recommendation. We anticipate that this dataset will not only benefit the recommender system community but also foster advancements in the field of video understanding. Our datasets, code, and additional documents are available at https://github.com/westlake-repl/MicroLens.",10.1145/3746252.3761655,https://doi.org/10.1145/3746252.3761655,"New York, NY, USA",Association for Computing Machinery,9798400720406,2025,A Content-Driven Micro-Video Recommendation Dataset at Scale,"Ni, Yongxin and Cheng, Yu and Liu, Xiangyan and Fu, Junchen and Li, Youhua and He, Xiangnan and Zhang, Yongfeng and Yuan, Fajie",inproceedings,10.1145/3746252.3761655,
10.1145/3758126.3758127,10.1145/3758126.3758127,RecSys.bib,1,['RecSys.bib'],8,RecSysChallenge '25,,"Universal Behavioral Profile, RecSys Challenge, Transformer, Multi-task Learning, Feature Engineering, Embedding Fusion, Sequential Modeling",5,7–11,Proceedings of the Recommender Systems Challenge 2025,"Modern enterprises require robust predictive analytics, yet tasks like churn prediction and propensity modeling are often treated as isolated problems. The ACM RecSys Challenge 2025 addressed this by proposing a unified task to create generalizable user profiles from a large-scale behavioral dataset provided by Synerise. This paper presents the 4th-place solution in the academic track from team ""ririka"". Our approach centers on creating a powerful, hybrid Universal Behavioral Profile by fusing an extensive, feature-engineered vector with multiple specialized embeddings from a Universal Behavioral Transformer (UBT). We introduce a comprehensive feature engineering strategy incorporating statistical, temporal, and semantic features, and develop a multi-task UBT framework to generate distinct embeddings for objectives like churn and propensity. Through a meticulous fusion and normalization methodology, we combine these components into a single, high-dimensional user representation. Our final model proved highly effective, demonstrating robust and generalizable performance across both open and hidden evaluation tasks. Our analysis confirms that synthesizing handcrafted features with deep, sequential representations is critical for building a powerful and versatile user profile.",10.1145/3758126.3758127,https://doi.org/10.1145/3758126.3758127,"New York, NY, USA",Association for Computing Machinery,9798400720994,2025,Beyond Aggregation: A Feature-Fused Universal Behavioral Transformer for Generalizable User Representation,"Liu, Yichen and Wang, Minhao and Zhang, Ruizhi and Wu, Wen and Zhang, Wei",inproceedings,10.1145/3758126.3758127,
10.1145/502512.502525,10.1145/502512.502525,KDD.bib,1,['KDD.bib'],8,KDD '01,"San Francisco, California","Markov random fields, collaborative filtering, dependency networks, direct marketing, social networks, viral marketing",10,57–66,Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"One of the major applications of data mining is in helping companies determine which potential customers to market to. If the expected profit from a customer is greater than the cost of marketing to her, the marketing action for that customer is executed. So far, work in this area has considered only the intrinsic value of the customer (i.e, the expected profit from sales to her). We propose to model also the customer's network value: the expected profit from sales to other customers she may influence to buy, the customers those may influence, and so on recursively. Instead of viewing a market as a set of independent entities, we view it as a social network and model it as a Markov random field. We show the advantages of this approach using a social network mined from a collaborative filtering database. Marketing that exploits the network value of customers---also known as viral marketing---can be extremely effective, but is still a black art. Our work can be viewed as a step towards providing a more solid foundation for it, taking advantage of the availability of large relevant databases.",10.1145/502512.502525,https://doi.org/10.1145/502512.502525,"New York, NY, USA",Association for Computing Machinery,158113391X,2001,Mining the network value of customers,"Domingos, Pedro and Richardson, Matt",inproceedings,10.1145/502512.502525,
10.1145/502512.502576,10.1145/502512.502576,KDD.bib,1,['KDD.bib'],7,KDD '01,"San Francisco, California",,6,426–431,Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"CoIL challenge 2000 was a supervised learning contest that attracted 43 entries. The authors of 29 entries later wrote explanations of their work. This paper discusses these reports and reaches three main conclusions. First, naive Bayesian classifiers remain competitive in practice: they were used by both the winning entry and the next best entry. Second, identifying feature interactions correctly is important for maximizing predictive accuracy: this was the difference between the winning classifier and all others. Third and most important, too many researchers and practitioners in data mining do not appreciate properly the issue of statistical significance and the danger of overfitting. Given a dataset such as the one for the CoIL contest, it is pointless to apply a very complicated learning algorithm, or to perform a very time-consuming model search. In either ease, one is likely to overfit the training data and to fool oneself in estimating predictive accuracy and in discovering useful correlations.",10.1145/502512.502576,https://doi.org/10.1145/502512.502576,"New York, NY, USA",Association for Computing Machinery,158113391X,2001,Magical thinking in data mining: lessons from CoIL challenge 2000,"Elkan, Charles",inproceedings,10.1145/502512.502576,
10.1145/511446.511530,10.1145/511446.511530,TheWebConf.bib,1,['TheWebConf.bib'],8,WWW '02,"Honolulu, Hawaii, USA","streaming media, mobile network, SMIL, CDN",11,651–661,Proceedings of the 11th International Conference on World Wide Web,"In this paper, we present a mobile streaming media CDN (Content Delivery Network) architecture in which content segmentation, request routing, pre-fetch scheduling, and session handoff are controlled by SMIL (Synchronized Multimedia Integrated Language) modification. In this architecture, mobile clients simply follow modified SMIL files downloaded from a streaming portal server; these modifications enable multimedia content to be delivered to the mobile clients from the best surrogates in the CDN. The key components of this architecture are 1) content segmentation with SMIL modification, 2) on-demand rewriting of URLs in SMIL, 3) pre-fetch scheduling based on timing information derived from SMIL, 4) SMIL updates by SOAP (Simple Object Access Protocol) messaging for session handoffs due to clients mobility. We also introduce QoS control with a network agent called an ""RTP monitoring agent"" to enable appropriate control of media quality based on both network congestion and radio link conditions. The current status of our prototyping on a mobile QoS testbed ""MOBIQ"" is reported in this paper. We are currently designing the SOAP-based APIs (Application Programmable Interfaces) needed for the mobile streaming media CDN and building the CDN over the current testbed.",10.1145/511446.511530,https://doi.org/10.1145/511446.511530,"New York, NY, USA",Association for Computing Machinery,1581134495,2002,Mobile streaming media CDN enabled by dynamic SMIL,"Yoshimura, Takeshi and Yonemoto, Yoshifumi and Ohya, Tomoyuki and Etoh, Minoru and Wee, Susie",inproceedings,10.1145/511446.511530,
10.1145/956863.956893,10.1145/956863.956893,CIKM.bib,1,['CIKM.bib'],8,CIKM '03,"New Orleans, LA, USA","scheduling, query processing, indexing, data dissemination, broadcast, access methods",8,153–160,Proceedings of the Twelfth International Conference on Information and Knowledge Management,"This paper studies fast access to data that are broadcast on multiple channels. Broadcast is a useful data dissemination technique because of its scalability, but is lacking when it comes to response time. Increasing the number of available broadcast channels is a logical way of increasing throughput. Little work, however, has considered the access structures necessary for making effective use of the additional channels. We propose various indexing schemes for a multi-channel broadcast program. We demonstrate the effectiveness of our techniques in decreasing response time and tuning time via extensive experiments over a wide range of parameters.",10.1145/956863.956893,https://doi.org/10.1145/956863.956893,"New York, NY, USA",Association for Computing Machinery,1581137230,2003,Efficient data access to multi-channel broadcast programs,"Yee, Wai Gen and Navathe, Shamkant B.",inproceedings,10.1145/956863.956893,
10.1145/956863.956922,10.1145/956863.956922,CIKM.bib,1,['CIKM.bib'],8,CIKM '03,"New Orleans, LA, USA","rating model, probabilistic model, preference model, collaborative filtering, application",8,309–316,Proceedings of the Twelfth International Conference on Information and Knowledge Management,"In this paper, we describe a new model for collaborative filtering. The motivation of this work comes from the fact that two users with very similar preferences on items may have very different rating schemes. For example, one user may tend to assign a higher rating to all items than another user. Unlike previous models of collaborative filtering, which determine the similarity between two users only based on their rating performance, our model treats the user's preferences on items separately from the user's rating scheme. More specifically, for each user, we build two separate models: a preference model capturing which items are favored by the user and a rating model capturing how the user would rate an item given the preference information. The similarity of two users is computed based on the underlying preference model, instead of the surface ratings. We compare the new model with several representative previous approaches on two data sets. Experiment results show that the new model outperforms all the previous approaches that are tested consistently on both data sets.",10.1145/956863.956922,https://doi.org/10.1145/956863.956922,"New York, NY, USA",Association for Computing Machinery,1581137230,2003,Collaborative filtering with decoupled models for preferences and ratings,"Jin, Rong and Si, Luo and Zhai, ChengXiang and Callan, Jamie",inproceedings,10.1145/956863.956922,
